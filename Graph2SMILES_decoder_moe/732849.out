Logging arguments
**** model = *g2s_series_rel*
**** data_name = *USPTO_480k*
**** task = *reaction_prediction*
**** representation_end = *smiles*
**** seed = *42*
**** max_src_len = *512*
**** max_tgt_len = *512*
**** num_workers = *16*
**** verbose = *False*
**** log_file = *USPTO_480k_g2s_series_rel_smiles_smiles.train.1.log*
**** vocab_file = *./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt*
**** preprocess_output_path = **
**** save_dir = *./checkpoints/USPTO_480k_g2s_series_rel_smiles_smiles.1*
**** train_bin = *./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/train_0.npz*
**** valid_bin = *./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/val_0.npz*
**** load_from = **
**** embed_size = *256*
**** share_embeddings = *False*
**** mpn_type = *dgat*
**** encoder_num_layers = *4*
**** encoder_hidden_size = *256*
**** encoder_attn_heads = *8*
**** encoder_filter_size = *2048*
**** encoder_norm = **
**** encoder_skip_connection = **
**** encoder_positional_encoding = *none*
**** encoder_emb_scale = *sqrt*
**** compute_graph_distance = *True*
**** attn_enc_num_layers = *6*
**** attn_enc_hidden_size = *256*
**** attn_enc_heads = *8*
**** attn_enc_filter_size = *2048*
**** rel_pos = *emb_only*
**** rel_pos_buckets = *11*
**** decoder_num_layers = *6*
**** decoder_hidden_size = *256*
**** decoder_attn_heads = *8*
**** decoder_filter_size = *1024*
**** dropout = *0.3*
**** attn_dropout = *0.3*
**** max_relative_positions = *4*
**** moe_num_experts = *8*
**** moe_topk = *2*
**** moe_gating_temperature = *1.0*
**** moe_aux_loss_factor = *0.01*
**** enable_amp = *False*
**** epoch = *2000*
**** max_steps = *500000*
**** warmup_steps = *8000*
**** lr = *4.0*
**** beta1 = *0.9*
**** beta2 = *0.998*
**** eps = *1e-09*
**** weight_decay = *0.0*
**** clip_norm = *20.0*
**** batch_type = *tokens*
**** train_batch_size = *4096*
**** valid_batch_size = *4096*
**** accumulation_count = *4*
**** log_iter = *100*
**** eval_iter = *2000*
**** save_iter = *5000*
**** do_profile = *False*
**** record_shapes = *False*
**** do_predict = *False*
**** do_score = *False*
**** checkpoint_step_start = *None*
**** checkpoint_step_end = *None*
**** predict_batch_size = *4096*
**** test_bin = **
**** result_file = **
**** beam_size = *5*
**** n_best = *10*
**** temperature = *1.0*
**** predict_min_len = *1*
**** predict_max_len = *512*
**** gpu = *0*
**** type = *moe*
Loading vocab from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt
Graph2SeqSeriesRel(
  (encoder): GraphFeatEncoder(
    (mpn): DGATEncoder(
      (leaky_relu): LeakyReLU(negative_slope=0.01)
      (W_o): Sequential(
        (0): Linear(in_features=361, out_features=256, bias=True)
        (1): GELU(approximate='none')
      )
      (rnn): DGATGRU(
        (W_z): Linear(in_features=370, out_features=256, bias=True)
        (W_r): Linear(in_features=114, out_features=256, bias=False)
        (U_r): Linear(in_features=256, out_features=256, bias=True)
        (W_h): Linear(in_features=370, out_features=256, bias=True)
        (leaky_relu): LeakyReLU(negative_slope=0.01)
        (attn_W_q): Linear(in_features=114, out_features=256, bias=True)
        (attn_W_k): Linear(in_features=256, out_features=256, bias=True)
        (attn_W_v): Linear(in_features=256, out_features=256, bias=True)
        (softmax): Softmax(dim=1)
        (dropout): Dropout(p=0.3, inplace=False)
        (attn_dropout): Dropout(p=0.3, inplace=False)
      )
      (attn_W_q): Linear(in_features=105, out_features=256, bias=True)
      (attn_W_k): Linear(in_features=256, out_features=256, bias=True)
      (attn_W_v): Linear(in_features=256, out_features=256, bias=True)
      (softmax): Softmax(dim=1)
      (dropout): Dropout(p=0.3, inplace=False)
      (attn_dropout): Dropout(p=0.3, inplace=False)
    )
  )
  (attention_encoder): AttnEncoderXL(
    (dropout): Dropout(p=0.3, inplace=False)
    (attention_layers): ModuleList(
      (0-5): 6 x SALayerXL(
        (self_attn): MultiHeadedRelAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
          (relative_pe): Embedding(12, 256, padding_idx=11)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.3, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.3, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder_embeddings): Embeddings(
    (make_embedding): Sequential(
      (emb_luts): Elementwise(
        (0): Embedding(299, 256, padding_idx=0)
      )
      (pe): PositionalEncoding(
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(299, 256, padding_idx=0)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
          (relative_positions_embeddings): Embedding(9, 32)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): MoEFeedForward(
          (experts): ModuleList(
            (0-7): 8 x Sequential(
              (0): Linear(in_features=256, out_features=1024, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=1024, out_features=256, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (gate): Linear(in_features=256, out_features=8, bias=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.3, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (output_layer): Linear(in_features=256, out_features=299, bias=True)
  (criterion): CrossEntropyLoss()
)
Number of parameters = 37167611
Loading vocab from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt
Loading preprocessed features from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/train_0.npz
Loaded and initialized G2SDataset, size: 409035
Loading vocab from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt
Loading preprocessed features from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/val_0.npz
Loaded and initialized G2SDataset, size: 30000
Start training
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 100, loss: 4.07528145134449, acc: 18.723167138174176, p_norm: 272.1553249127391, g_norm: 5.000641536336266, lr:  0.000035, elapsed time:  95
Step 200, loss: 2.5820277982950213, acc: 27.96274070069194, p_norm: 272.1484614628917, g_norm: 5.303927644766858, lr:  0.000070, elapsed time:  185
Step 300, loss: 2.4310489958524704, acc: 29.24690192192793, p_norm: 272.1456220877198, g_norm: 2.3558637746195115, lr:  0.000105, elapsed time:  273
Step 400, loss: 2.376195913553238, acc: 29.54562061280012, p_norm: 272.1506481670109, g_norm: 1.6621663022347033, lr:  0.000140, elapsed time:  364
Step 500, loss: 2.149052755236626, acc: 34.43682582676411, p_norm: 272.18525844406594, g_norm: 4.492733677857489, lr:  0.000175, elapsed time:  451
Step 600, loss: 1.7692709329724312, acc: 47.05092693120241, p_norm: 272.25801405598196, g_norm: 6.381421653714036, lr:  0.000210, elapsed time:  536
Step 700, loss: 1.3932170858979225, acc: 56.05584702640772, p_norm: 272.3644114329424, g_norm: 4.051228113484892, lr:  0.000245, elapsed time:  625
Step 800, loss: 1.1886319246888162, acc: 62.34733663499355, p_norm: 272.49133069871186, g_norm: 2.557001006828427, lr:  0.000280, elapsed time:  713
Step 900, loss: 1.0763235945999623, acc: 65.8580371439457, p_norm: 272.6627117197961, g_norm: 2.757667999003508, lr:  0.000315, elapsed time:  803
Step 1000, loss: 0.9902714520692826, acc: 68.76275700330734, p_norm: 272.9032374857914, g_norm: 3.1244790377397442, lr:  0.000350, elapsed time:  892
Step 1100, loss: 0.9029120196402073, acc: 71.69207246601582, p_norm: 273.20752259669905, g_norm: 4.680270343402076, lr:  0.000385, elapsed time:  979
Step 1200, loss: 0.8351898710429668, acc: 73.8813238888979, p_norm: 273.5946569353556, g_norm: 3.384599314131257, lr:  0.000420, elapsed time:  1069
Step 1300, loss: 0.7715525192022323, acc: 75.90598613023758, p_norm: 274.03525178081037, g_norm: 2.9625986271919094, lr:  0.000455, elapsed time:  1158
Step 1400, loss: 0.7073232460021973, acc: 78.01597641408443, p_norm: 274.5339983395082, g_norm: 3.1330451526020346, lr:  0.000489, elapsed time:  1247
Step 1500, loss: 0.6640421542525291, acc: 79.52476915717125, p_norm: 275.10728564156756, g_norm: 2.387086309137427, lr:  0.000524, elapsed time:  1337
Step 1600, loss: 0.6138652169704437, acc: 81.16691508889198, p_norm: 275.7515828083064, g_norm: 3.8261311639640216, lr:  0.000559, elapsed time:  1428
Step 1700, loss: 0.5697991102933884, acc: 82.66489620506763, p_norm: 276.4771837768487, g_norm: 2.5514708169963214, lr:  0.000594, elapsed time:  1517
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 1800, loss: 0.5312657955266702, acc: 84.00041354501218, p_norm: 277.2545238786545, g_norm: 2.3243382528274643, lr:  0.000630, elapsed time:  1607
Step 1900, loss: 0.4978183875977993, acc: 85.17162963747978, p_norm: 278.13961889696253, g_norm: 2.4400965572003726, lr:  0.000665, elapsed time:  1697
Step 2000, loss: 0.4676882900297642, acc: 86.18670131266117, p_norm: 279.1189811726768, g_norm: 1.5735161606392856, lr:  0.000699, elapsed time:  1785
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 2000, eval loss: 0.3389726614952087, eval acc: 90.61663055419922
Step 2100, loss: 0.44482699789106844, acc: 87.04517076909542, p_norm: 280.2671377816807, g_norm: 1.7322071352851587, lr:  0.000734, elapsed time:  1890
Step 2200, loss: 0.4184277080744505, acc: 88.01909038424492, p_norm: 281.3869280482364, g_norm: 2.828395327548856, lr:  0.000769, elapsed time:  1976
Step 2300, loss: 0.3915608724951744, acc: 88.88230907917023, p_norm: 282.61193985169325, g_norm: 2.4259400131648365, lr:  0.000804, elapsed time:  2063
Step 2400, loss: 0.3763770969957113, acc: 89.37126453220844, p_norm: 283.96720013138054, g_norm: 1.7285611623136867, lr:  0.000839, elapsed time:  2152
Step 2500, loss: 0.3594491058588028, acc: 89.93369469046593, p_norm: 285.5238894973115, g_norm: 2.2228952765660344, lr:  0.000874, elapsed time:  2242
Step 2600, loss: 0.345782600492239, acc: 90.43595367670059, p_norm: 287.16837557548274, g_norm: 1.4555434883652039, lr:  0.000909, elapsed time:  2332
Step 2700, loss: 0.32536021947860716, acc: 91.0794326364994, p_norm: 288.85720555463223, g_norm: 1.8318609995908708, lr:  0.000944, elapsed time:  2417
Step 2800, loss: 0.31538273639976977, acc: 91.4012536406517, p_norm: 290.74735662112, g_norm: 1.969295847680617, lr:  0.000979, elapsed time:  2507
Step 2900, loss: 0.3029080741479993, acc: 91.85409584641457, p_norm: 292.8502763622477, g_norm: 2.0031445508640906, lr:  0.001014, elapsed time:  2595
Step 3000, loss: 0.3008357572555542, acc: 91.9240294098854, p_norm: 295.24275594189913, g_norm: 1.7678117728055989, lr:  0.001049, elapsed time:  2687
Step 3100, loss: 0.2880491391941905, acc: 92.38283488154411, p_norm: 297.81805578560784, g_norm: 1.4524618614859472, lr:  0.001084, elapsed time:  2775
Step 3200, loss: 0.29214541558176277, acc: 92.30050514638424, p_norm: 301.5385644652298, g_norm: 1.2603037493742206, lr:  0.001119, elapsed time:  2865
Step 3300, loss: 0.27640676084905863, acc: 92.71738065779209, p_norm: 304.29035345811, g_norm: 1.5899916270071532, lr:  0.001154, elapsed time:  2957
Step 3400, loss: 0.2663994931802154, acc: 93.05025526881218, p_norm: 307.16621810945134, g_norm: 1.3484612399734919, lr:  0.001189, elapsed time:  3047
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 3500, loss: 0.2566595076035625, acc: 93.32214237442679, p_norm: 310.1757310250764, g_norm: 1.3664139118046308, lr:  0.001224, elapsed time:  3140
Step 3600, loss: 0.2489243433624506, acc: 93.5865580290556, p_norm: 313.4774184501347, g_norm: 1.7697925226443167, lr:  0.001259, elapsed time:  3230
Step 3700, loss: 0.24686856929212808, acc: 93.62390968203545, p_norm: 316.89737961866547, g_norm: 1.443910556687555, lr:  0.001294, elapsed time:  3314
Step 3800, loss: 0.25420294925570486, acc: 93.46314939856529, p_norm: 322.2290124414841, g_norm: 1.9757599615674892, lr:  0.001329, elapsed time:  3405
Step 3900, loss: 0.24197671104222537, acc: 93.85569666326046, p_norm: 326.5143787324298, g_norm: 1.8022021472126788, lr:  0.001364, elapsed time:  3493
Step 4000, loss: 0.23256125271320344, acc: 94.0732041746378, p_norm: 330.54537412089627, g_norm: 1.464393584715787, lr:  0.001399, elapsed time:  3582
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 4000, eval loss: 0.15546823158860212, eval acc: 96.55448150634766
Step 4100, loss: 0.24117926269769668, acc: 93.94290614128113, p_norm: 336.50422184205235, g_norm: 1.2118607566018011, lr:  0.001434, elapsed time:  3687
Step 4200, loss: 0.22453107522800564, acc: 94.3435413390398, p_norm: 340.69273664541487, g_norm: 1.3719823184849442, lr:  0.001468, elapsed time:  3775
Step 4300, loss: 0.22415095109492542, acc: 94.32776440680027, p_norm: 345.4524190933582, g_norm: 1.1737179632613537, lr:  0.001503, elapsed time:  3867
Step 4400, loss: 0.2170178957656026, acc: 94.5261208564043, p_norm: 350.22653473705043, g_norm: 1.3029763012439284, lr:  0.001538, elapsed time:  3954
Step 4500, loss: 0.21008852358907462, acc: 94.70714667439461, p_norm: 355.03030297823625, g_norm: 1.6471155927393584, lr:  0.001573, elapsed time:  4042
Step 4600, loss: 0.21062272615730762, acc: 94.77006907761097, p_norm: 360.55286379509283, g_norm: 1.024172742404516, lr:  0.001608, elapsed time:  4131
Step 4700, loss: 0.21554535675793887, acc: 94.62765155732632, p_norm: 366.917315177418, g_norm: 1.1193042028027644, lr:  0.001643, elapsed time:  4222
Step 4800, loss: 0.2076809874922037, acc: 94.86188788712025, p_norm: 372.95531058053945, g_norm: 1.154081883240178, lr:  0.001678, elapsed time:  4310
Step 4900, loss: 0.20702049568295477, acc: 94.85188822448254, p_norm: 379.0326137167318, g_norm: 1.2378226918516422, lr:  0.001713, elapsed time:  4400
Step 5000, loss: 0.20304265420883894, acc: 94.9507504105568, p_norm: 385.4826172227487, g_norm: 1.2168325791552568, lr:  0.001748, elapsed time:  4491
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) c 1 c n c 2 c c c ( Br ) c c 2 c 1 N C C ( C ) O C _EOS
Predicted text: C C O C ( = O ) c 1 c n c 2 c c c ( Br ) c c 2 c 1 N C C ( C ) O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) c 1 c c ( O C c 2 c c c c c 2 ) c ( C C 2 ( C ) C O 2 ) c ( O C c 2 c c c c c 2 ) c 1 _EOS
Predicted text: C = C ( C ) C c 1 c ( O C c 2 c c c c c 2 ) c c ( C ( = O ) O C ( C ) ( C ) C ) c c 1 O C c 1 c c c c c 1 _EOS _PAD _PAD _PAD _PAD
acc_token: 0.27586206896551724, acc_seq: False

Target text: C O C ( = O ) C C c 1 c c c ( C # C c 2 c c c c ( C = O ) c 2 ) c c 1 _EOS
Predicted text: C O C ( = O ) C C c 1 c c c ( C # C c 2 c c c c ( C = O ) c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) c 1 c c c ( F ) c ( [N+] ( = O ) [O-] ) c 1 _EOS
Predicted text: O = C ( O ) c 1 c c c ( F ) c c 1 [N+] ( = O ) [O-] _EOS _PAD _PAD
acc_token: 0.4230769230769231, acc_seq: False

Target text: C O c 1 c c ( C ( = O ) c 2 c c ( F ) c c ( O C ( F ) ( F ) C ( F ) F ) c 2 ) c c c 1 F _EOS
Predicted text: C O c 1 c c ( C # N ) c c c 1 F _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.2, acc_seq: False

Evaluation (without teacher) at step 5000, eval acc (token): 0.7074054286122784, eval acc (sequence): 0.4730755954435623
Saving at step 5000
Step 5100, loss: 0.20369388630613686, acc: 94.97937938570976, p_norm: 392.3157624516947, g_norm: 1.1274680171061366, lr:  0.001783, elapsed time:  4701
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 5200, loss: 0.18880244100434018, acc: 95.4221164470275, p_norm: 398.36540897422583, g_norm: 1.2111521618455952, lr:  0.001818, elapsed time:  4789
Step 5300, loss: 0.19260253189131618, acc: 95.2828571498394, p_norm: 405.4142963975994, g_norm: 0.9061500450933908, lr:  0.001853, elapsed time:  4878
Step 5400, loss: 0.19402905778959392, acc: 95.21091313660145, p_norm: 412.41565684721354, g_norm: 1.0256196276536247, lr:  0.001888, elapsed time:  4969
Step 5500, loss: 0.18843427618965505, acc: 95.39709410071373, p_norm: 419.6699735695766, g_norm: 1.181317023768151, lr:  0.001923, elapsed time:  5060
Step 5600, loss: 0.1909517339989543, acc: 95.3339447081089, p_norm: 427.27795441864237, g_norm: 1.3824505473464943, lr:  0.001958, elapsed time:  5147
Step 5700, loss: 0.18787693658843638, acc: 95.43430463969707, p_norm: 434.7685584540616, g_norm: 0.9154610635000513, lr:  0.001993, elapsed time:  5238
Step 5800, loss: 0.18482813896611333, acc: 95.51729652285576, p_norm: 442.084381116081, g_norm: 1.0116362477406635, lr:  0.002028, elapsed time:  5325
Step 5900, loss: 0.1833776880800724, acc: 95.55755531787872, p_norm: 449.5514965306112, g_norm: 1.0507625044398738, lr:  0.002063, elapsed time:  5416
Step 6000, loss: 0.18090389348566532, acc: 95.62779621779919, p_norm: 457.6637143474677, g_norm: 1.1878137845005001, lr:  0.002098, elapsed time:  5508
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 6000, eval loss: 0.11558101877570157, eval acc: 97.67633056640625
Step 6100, loss: 0.1805018126219511, acc: 95.63183163106441, p_norm: 466.06158673571986, g_norm: 1.1272963076491151, lr:  0.002133, elapsed time:  5612
Step 6200, loss: 0.18017807187512516, acc: 95.68343144655228, p_norm: 474.69932123181945, g_norm: 0.9256526215811829, lr:  0.002168, elapsed time:  5699
Step 6300, loss: 0.1748636830970645, acc: 95.80854415893555, p_norm: 482.83257720216375, g_norm: 1.2056833479352598, lr:  0.002203, elapsed time:  5789
Step 6400, loss: 0.18003902656957507, acc: 95.65764731168747, p_norm: 492.10780834602053, g_norm: 1.1480087444453269, lr:  0.002237, elapsed time:  5879
Step 6500, loss: 0.17381168507039546, acc: 95.82579308748245, p_norm: 500.48315038122803, g_norm: 1.0244725200786222, lr:  0.002272, elapsed time:  5968
Step 6600, loss: 0.1762317551858723, acc: 95.78182353079319, p_norm: 509.3939888948746, g_norm: 1.2146391616478394, lr:  0.002307, elapsed time:  6062
Step 6700, loss: 0.17100841257721186, acc: 95.90497913956642, p_norm: 517.603300608677, g_norm: 1.1420338072250016, lr:  0.002342, elapsed time:  6148
Step 6800, loss: 0.1695608859322965, acc: 95.95513299107552, p_norm: 525.8617856183694, g_norm: 1.0057954790472232, lr:  0.002377, elapsed time:  6235
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 6900, loss: 0.16947689541516173, acc: 95.96371110852243, p_norm: 535.5764071886077, g_norm: 1.0041024051743643, lr:  0.002413, elapsed time:  6332
Step 7000, loss: 0.16855650389567017, acc: 96.00695380568504, p_norm: 544.7274681407092, g_norm: 0.8770738157744473, lr:  0.002447, elapsed time:  6421
Step 7100, loss: 0.16693122221156956, acc: 96.02713672816753, p_norm: 554.2646519629168, g_norm: 1.0790043100836781, lr:  0.002482, elapsed time:  6512
Step 7200, loss: 0.1690076113305986, acc: 96.032062292099, p_norm: 563.7338288841546, g_norm: 1.0052838423856536, lr:  0.002517, elapsed time:  6601
Step 7300, loss: 0.16665006862953305, acc: 96.0676561743021, p_norm: 572.8456316131718, g_norm: 0.8849152832629196, lr:  0.002552, elapsed time:  6690
Step 7400, loss: 0.15990428071469068, acc: 96.25902120769024, p_norm: 581.7149834406104, g_norm: 1.0532622756056351, lr:  0.002587, elapsed time:  6776
Step 7500, loss: 0.5629144274070859, acc: 85.79376736283302, p_norm: 616.829900821939, g_norm: 1.1167829929214728, lr:  0.002622, elapsed time:  6865
Step 7600, loss: 0.2454226515814662, acc: 94.434964671731, p_norm: 623.778395347487, g_norm: 0.7813250555687377, lr:  0.002657, elapsed time:  6952
Step 7700, loss: 0.1949606077000499, acc: 95.72280386090279, p_norm: 628.8959463714775, g_norm: 0.8001612190614139, lr:  0.002692, elapsed time:  7040
Step 7800, loss: 0.176848366856575, acc: 96.10446654260159, p_norm: 634.5950833887423, g_norm: 0.8262614559734608, lr:  0.002727, elapsed time:  7128
Step 7900, loss: 0.17150753952562808, acc: 96.16344088315964, p_norm: 640.8173201686681, g_norm: 0.9099493037351672, lr:  0.002762, elapsed time:  7221
Step 8000, loss: 0.16497868882492184, acc: 96.31325644254684, p_norm: 647.1901930167733, g_norm: 0.8359550322551319, lr:  0.002794, elapsed time:  7310
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 8000, eval loss: 0.10720521502196792, eval acc: 98.056640625
Step 8100, loss: 0.1604803105071187, acc: 96.35419897735119, p_norm: 654.1354426222, g_norm: 0.8610582199271241, lr:  0.002777, elapsed time:  7416
Step 8200, loss: 0.16261420987546443, acc: 96.30521363019943, p_norm: 661.5020561697469, g_norm: 0.9229016962256207, lr:  0.002760, elapsed time:  7504
Step 8300, loss: 0.16061284372583032, acc: 96.33401668071747, p_norm: 668.9399691941969, g_norm: 1.0022995517133664, lr:  0.002743, elapsed time:  7595
Step 8400, loss: 0.15242662480100988, acc: 96.51609866321087, p_norm: 675.9458768614627, g_norm: 0.7504861257693762, lr:  0.002727, elapsed time:  7683
Step 8500, loss: 0.15240208629518748, acc: 96.5180714726448, p_norm: 683.0694084556202, g_norm: 0.9588153670420194, lr:  0.002711, elapsed time:  7773
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 8600, loss: 0.15090976625829194, acc: 96.55135353999351, p_norm: 690.2328117363844, g_norm: 0.8437315139473259, lr:  0.002695, elapsed time:  7863
Step 8700, loss: 0.1444439735636115, acc: 96.71350768208504, p_norm: 697.3222113608462, g_norm: 0.9981785055316332, lr:  0.002679, elapsed time:  7952
Step 8800, loss: 0.14421629797667265, acc: 96.72792245447636, p_norm: 704.2691080394717, g_norm: 1.3529069201305794, lr:  0.002664, elapsed time:  8041
Step 8900, loss: 0.14425899615511298, acc: 96.70510202646255, p_norm: 711.8382194935633, g_norm: 0.7737830608891709, lr:  0.002649, elapsed time:  8136
Step 9000, loss: 0.14609913079068065, acc: 96.66342590749264, p_norm: 719.5745408037076, g_norm: 1.2521488295432492, lr:  0.002634, elapsed time:  8225
Step 9100, loss: 0.15289337987080218, acc: 96.59911438822746, p_norm: 728.3793623643813, g_norm: 0.8735193648638346, lr:  0.002620, elapsed time:  8315
Step 9200, loss: 0.3601524581387639, acc: 91.64955361187458, p_norm: 752.6860846292441, g_norm: 0.8174538692217305, lr:  0.002606, elapsed time:  8402
Step 9300, loss: 0.17859173454344274, acc: 96.302779763937, p_norm: 757.3683397810654, g_norm: 0.9304494808680386, lr:  0.002592, elapsed time:  8488
Step 9400, loss: 0.16042937653139233, acc: 96.6865040063858, p_norm: 762.3153666060057, g_norm: 0.6825802517622106, lr:  0.002578, elapsed time:  8577
Step 9500, loss: 0.15283062065020203, acc: 96.81576906144619, p_norm: 767.1030744276294, g_norm: 0.8212089516385563, lr:  0.002564, elapsed time:  8669
Step 9600, loss: 0.14503694277256726, acc: 96.94882662594318, p_norm: 771.7088021524931, g_norm: 0.8961095360839093, lr:  0.002551, elapsed time:  8756
Step 9700, loss: 0.14376965960487723, acc: 96.94126984477043, p_norm: 777.038793691456, g_norm: 0.8897114670443808, lr:  0.002538, elapsed time:  8847
Step 9800, loss: 0.1398826384730637, acc: 97.0024846792221, p_norm: 782.2602922832303, g_norm: 0.9364826512257478, lr:  0.002525, elapsed time:  8933
Step 9900, loss: 0.13815349608659744, acc: 97.06136292219162, p_norm: 787.5116120344084, g_norm: 0.7768165047381481, lr:  0.002512, elapsed time:  9021
Step 10000, loss: 0.13387553256936371, acc: 97.13411079347134, p_norm: 792.9692962971682, g_norm: 0.6691458551904461, lr:  0.002499, elapsed time:  9113
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 10000, eval loss: 0.0930043128505349, eval acc: 98.39313507080078
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( C ) O C ( = O ) N ( C C # C c 1 c c c ( Cl ) c c 1 ) C c 1 c c c ( F ) c ( F ) c 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N ( C C # C c 1 c c c ( F ) c ( F ) c 1 ) C c 1 c c c ( F ) c ( F ) c 1 _EOS
acc_token: 0.625, acc_seq: False

Target text: C C 1 C C C N 1 C C C O c 1 c c c ( B 2 O C ( C ) ( C ) C ( C ) ( C ) O 2 ) c c 1 _EOS
Predicted text: C C 1 C C C N 1 C C C O c 1 c c c ( B 2 O C ( C ) ( C ) C ( C ) ( C ) O 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 c 2 c ( c 3 c c c c ( F ) c 3 1 ) C ( = N O ) C C C 2 _EOS
Predicted text: C n 1 c 2 c ( c 3 c c c c ( F ) c 3 1 ) C ( = N O ) C C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C c 1 c c ( C ( = C c 2 c c ( O C ) c ( O C ) c ( O C ) c 2 ) S ( C ) = O ) n 2 n c c c 2 n 1 _EOS
Predicted text: C C C C c 1 c c ( C ( = C c 2 c c ( O C ) c ( O C ) c ( O C ) c 2 ) S ( C ) = O ) n 2 n c c c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 n c ( N C 2 c 3 c c ( C # N ) c c c 3 O C ( C ) ( C ) C 2 O ) c c c 1 = O _EOS
Predicted text: C n 1 n c ( N C 2 c 3 c c ( C # N ) c c c 3 O C ( C ) ( C ) C 2 O ) c c c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 10000, eval acc (token): 0.8235998814735788, eval acc (sequence): 0.6755126658624849
Saving at step 10000
Step 10100, loss: 0.13510796582326293, acc: 97.07067085802555, p_norm: 798.6499025014638, g_norm: 1.1252635204723724, lr:  0.002487, elapsed time:  9302
Step 10200, loss: 0.13206043846905233, acc: 97.14807119965553, p_norm: 804.2411449382706, g_norm: 0.7865279220450584, lr:  0.002475, elapsed time:  9392
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 10300, loss: 0.12850377888005068, acc: 97.22601516962644, p_norm: 809.8660761038083, g_norm: 0.6912391928018776, lr:  0.002462, elapsed time:  9481
Step 10400, loss: 0.1294465845450759, acc: 97.16796849668026, p_norm: 815.8921368892851, g_norm: 1.090197793306974, lr:  0.002451, elapsed time:  9571
Step 10500, loss: 0.3133940246980637, acc: 97.05987271666527, p_norm: 822.9909318383978, g_norm: 1.0238084700793972, lr:  0.002439, elapsed time:  9663
Step 10600, loss: 0.131092717256397, acc: 97.11588622629642, p_norm: 829.1059902739386, g_norm: 0.9467144942092478, lr:  0.002427, elapsed time:  9754
Step 10700, loss: 0.1381970750540495, acc: 97.09536042809486, p_norm: 835.8604239189176, g_norm: 0.8319116262076314, lr:  0.002416, elapsed time:  9845
Step 10800, loss: 0.13144264860078692, acc: 97.16165088117123, p_norm: 841.9058594462329, g_norm: 0.9787526239190503, lr:  0.002405, elapsed time:  9934
Step 10900, loss: 0.1278749435953796, acc: 97.21458202600479, p_norm: 847.6653577587981, g_norm: 0.9464719088264925, lr:  0.002394, elapsed time:  10024
Step 11000, loss: 0.12532232022844256, acc: 97.27004471421242, p_norm: 853.0246365663296, g_norm: 0.9617891459696186, lr:  0.002383, elapsed time:  10114
Step 11100, loss: 0.1228518507257104, acc: 97.33338466286659, p_norm: 858.5019951587027, g_norm: 0.8826955885408613, lr:  0.002372, elapsed time:  10204
Step 11200, loss: 0.12229452785104514, acc: 97.3604204505682, p_norm: 863.7845262082328, g_norm: 0.8003133992664625, lr:  0.002362, elapsed time:  10291
Step 11300, loss: 0.13146226419135928, acc: 97.18232417106628, p_norm: 869.6837582508052, g_norm: 1.3400908404625171, lr:  0.002351, elapsed time:  10381
Step 11400, loss: 0.13419691690243782, acc: 97.03284998238087, p_norm: 876.1736581604349, g_norm: 0.7364346725188073, lr:  0.002341, elapsed time:  10469
Step 11500, loss: 0.125160456225276, acc: 97.23490798473358, p_norm: 881.6552545744606, g_norm: 0.834089658333345, lr:  0.002331, elapsed time:  10561
Step 11600, loss: 0.12122301549650728, acc: 97.3456102013588, p_norm: 886.9639360381506, g_norm: 0.7446333903271437, lr:  0.002320, elapsed time:  10649
Step 11700, loss: 0.14509213195182383, acc: 97.35602681338787, p_norm: 892.5563526884749, g_norm: 1.1838688635379013, lr:  0.002311, elapsed time:  10734
Step 11800, loss: 0.12614701865240932, acc: 97.2570004016161, p_norm: 898.5454559107206, g_norm: 1.055979090780255, lr:  0.002301, elapsed time:  10824
Step 11900, loss: 0.12096976022236049, acc: 97.36012248694897, p_norm: 903.8567573694961, g_norm: 0.9842704441533782, lr:  0.002291, elapsed time:  10912
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 12000, loss: 0.11745710434304278, acc: 97.4319050241049, p_norm: 908.9877624779324, g_norm: 0.7426042295709089, lr:  0.002281, elapsed time:  11005
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 12000, eval loss: 0.08464871488511563, eval acc: 98.52792358398438
Step 12100, loss: 0.11451393604278565, acc: 97.54831525683403, p_norm: 914.096397278489, g_norm: 0.9377958240950063, lr:  0.002272, elapsed time:  11111
Step 12200, loss: 0.11646322257816792, acc: 97.47890308499336, p_norm: 919.4858089169454, g_norm: 0.9492875172780033, lr:  0.002263, elapsed time:  11204
Step 12300, loss: 0.11359711080789565, acc: 97.5384454280138, p_norm: 924.522798716094, g_norm: 0.8840695979912041, lr:  0.002253, elapsed time:  11294
Step 12400, loss: 0.121562330853194, acc: 97.40389420092106, p_norm: 930.8931265333782, g_norm: 1.1260412797954331, lr:  0.002244, elapsed time:  11382
Step 12500, loss: 0.12060721198096871, acc: 97.40109145641327, p_norm: 936.4754680369601, g_norm: 0.7584582038089072, lr:  0.002235, elapsed time:  11474
Step 12600, loss: 0.11398627061396838, acc: 97.50648012757301, p_norm: 941.2877280024525, g_norm: 0.9180986103691415, lr:  0.002226, elapsed time:  11563
Step 12700, loss: 0.11575940208509565, acc: 97.48164087533951, p_norm: 946.4227498923271, g_norm: 1.153918346256635, lr:  0.002218, elapsed time:  11653
Step 12800, loss: 0.11758680117316545, acc: 97.4690613746643, p_norm: 951.303710736721, g_norm: 0.9582600621045438, lr:  0.002209, elapsed time:  11742
Step 12900, loss: 0.11219407220371068, acc: 97.59636127948761, p_norm: 955.745968434488, g_norm: 0.7250145780914471, lr:  0.002200, elapsed time:  11831
Step 13000, loss: 0.10938849106431008, acc: 97.66403414309025, p_norm: 960.1521968553633, g_norm: 0.6494056581090795, lr:  0.002192, elapsed time:  11917
Step 13100, loss: 0.10883801843039692, acc: 97.64468942582607, p_norm: 964.5850911453501, g_norm: 0.7100280148995819, lr:  0.002184, elapsed time:  12005
Step 13200, loss: 0.11094227897934615, acc: 97.61218379437923, p_norm: 969.1835626718638, g_norm: 0.6966216665230377, lr:  0.002175, elapsed time:  12092
Step 13300, loss: 0.11027714217081666, acc: 97.60965703427792, p_norm: 973.6569571217987, g_norm: 1.020131002862417, lr:  0.002167, elapsed time:  12178
Step 13400, loss: 0.11118673144839704, acc: 97.65051557123661, p_norm: 978.1555178990071, g_norm: 1.0062913678729701, lr:  0.002159, elapsed time:  12267
Step 13500, loss: 0.11687292018905282, acc: 97.5766362696886, p_norm: 983.2408464207101, g_norm: 0.8668273275995579, lr:  0.002151, elapsed time:  12356
Step 13600, loss: 0.11980985929258167, acc: 97.43922090530396, p_norm: 988.8216185001389, g_norm: 0.8233611731615355, lr:  0.002143, elapsed time:  12449
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 13700, loss: 0.11367781297592608, acc: 97.59211450001737, p_norm: 993.6820383821375, g_norm: 0.7698561298521038, lr:  0.002135, elapsed time:  12539
Step 13800, loss: 0.12060045568272472, acc: 97.47712184488773, p_norm: 999.3015063694118, g_norm: 2.4416289521723606, lr:  0.002127, elapsed time:  12632
Step 13900, loss: 0.11350907479412854, acc: 97.61739979684353, p_norm: 1004.4233817027784, g_norm: 0.9790492219216873, lr:  0.002120, elapsed time:  12723
Step 14000, loss: 0.11745730306953192, acc: 97.56591221690178, p_norm: 1009.4840281380601, g_norm: 1.359087574041286, lr:  0.002112, elapsed time:  12813
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 14000, eval loss: 0.08402915406972174, eval acc: 98.64385986328125
Step 14100, loss: 2.0413669804204257, acc: 97.5018722563982, p_norm: 1015.2953665393062, g_norm: 1.2669575167057927, lr:  0.002105, elapsed time:  12920
Step 14200, loss: 0.11887076508253813, acc: 97.52985084056854, p_norm: 1019.7014387977373, g_norm: 0.7415671781499992, lr:  0.002097, elapsed time:  13012
Step 14300, loss: 0.11195343123748898, acc: 97.68128676712513, p_norm: 1023.3927906007208, g_norm: 0.8046316620997315, lr:  0.002090, elapsed time:  13099
Step 14400, loss: 0.10938734591007232, acc: 97.76548779010773, p_norm: 1027.2049580420203, g_norm: 0.9158859194178692, lr:  0.002083, elapsed time:  13188
Step 14500, loss: 0.10865725504234433, acc: 97.73043091595173, p_norm: 1030.6865417728966, g_norm: 0.6724376027445373, lr:  0.002075, elapsed time:  13274
Step 14600, loss: 0.10504281852394343, acc: 97.79574230313301, p_norm: 1034.2118198523608, g_norm: 0.851740431338306, lr:  0.002068, elapsed time:  13364
Step 14700, loss: 0.10855667309835554, acc: 97.75042290985584, p_norm: 1038.3109875731743, g_norm: 0.783728399983746, lr:  0.002061, elapsed time:  13452
Step 14800, loss: 0.10662565969862044, acc: 97.79718212783337, p_norm: 1042.2334713586204, g_norm: 1.1031493415138196, lr:  0.002054, elapsed time:  13544
Step 14900, loss: 0.10268294842913747, acc: 97.8679881542921, p_norm: 1045.8678024893497, g_norm: 1.0125122132833808, lr:  0.002047, elapsed time:  13632
Step 15000, loss: 0.10611469452269376, acc: 97.7752366811037, p_norm: 1050.048465017195, g_norm: 0.7636377867527993, lr:  0.002041, elapsed time:  13721
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C O C ( = O ) C ( = C N 1 C C C C C 1 ) C ( = O ) C ( F ) F _EOS
Predicted text: C C O C ( = O ) C ( = C N 1 C C C C C 1 ) C ( = O ) C ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C N ( c 2 n c n s 2 ) S ( = O ) ( = O ) c 2 c c c ( F ) c ( C # N ) c 2 ) c ( O C ) c 1 _EOS
Predicted text: C O c 1 c c c ( C N ( c 2 n c n s 2 ) S ( = O ) ( = O ) c 2 c c c ( F ) c ( C # N ) c 2 ) c ( O C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C ( O C C 2 O C ( n 3 c c ( C ) c ( = O ) [nH] c 3 = O ) C C 2 O ) ( c 2 c c c c c 2 ) c 2 c c c ( O C ) c c 2 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C ( O C C 2 O C ( n 3 c c ( C ) c ( = O ) [nH] c 3 = O ) C C 2 O ) ( c 2 c c c c c 2 ) c 2 c c c ( O C ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c c ( O C C C ( C # N ) N C ( = O ) C ( C c 2 c c c c ( C ) c 2 ) N C ( = O ) C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c c ( O C C C ( C # N ) N C ( = O ) C ( C c 2 c c c c ( C ) c 2 ) N C ( = O ) C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) C C ( C C C O C c 1 c c c c c 1 ) C ( = O ) N 1 C ( = O ) O C C 1 C c 1 c c c c c 1 _EOS
Predicted text: C C N ( C C ) C C N ( C C ) C C ( = O ) C ( C C C O C c 1 c c c c c 1 ) C ( = O ) N 1 C ( = O ) O C C 1 C c 1 c c c c c 1 ) C C _EOS
acc_token: 0.17543859649122806, acc_seq: False

Evaluation (without teacher) at step 15000, eval acc (token): 0.8612420988889413, eval acc (sequence): 0.7356902356902357
Saving at step 15000
Step 15100, loss: 0.11011209395714104, acc: 97.7529179006815, p_norm: 1054.595590319851, g_norm: 0.8505269923979638, lr:  0.002034, elapsed time:  13900
Step 15200, loss: 0.10527763632126153, acc: 97.8011314868927, p_norm: 1058.3917012208863, g_norm: 0.8104265405205728, lr:  0.002027, elapsed time:  13991
Step 15300, loss: 0.10189215247519315, acc: 97.89267875254154, p_norm: 1061.8150472310008, g_norm: 0.8308386314765159, lr:  0.002021, elapsed time:  14077
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 15400, loss: 0.09918657129639713, acc: 97.92971720742942, p_norm: 1065.0996313152145, g_norm: 1.8227919078266077, lr:  0.002014, elapsed time:  14166
Step 15500, loss: 0.09924039172939957, acc: 97.92336517572403, p_norm: 1068.8004799921143, g_norm: 0.7089256770830913, lr:  0.002007, elapsed time:  14258
Step 15600, loss: 0.09623972938396036, acc: 98.00060068070889, p_norm: 1072.2967542639171, g_norm: 0.7367107741797485, lr:  0.002001, elapsed time:  14347
Step 15700, loss: 0.10052630053833127, acc: 97.89766988158226, p_norm: 1076.2771278283938, g_norm: 0.9097758471647089, lr:  0.001995, elapsed time:  14437
Step 15800, loss: 0.11118057413958013, acc: 97.65109650790691, p_norm: 1081.457195106237, g_norm: 0.8518691632636713, lr:  0.001988, elapsed time:  14524
Step 15900, loss: 0.1067497868463397, acc: 97.7648927718401, p_norm: 1085.4851972750346, g_norm: 0.7929553050786969, lr:  0.001982, elapsed time:  14613
Step 16000, loss: 0.49580927278846504, acc: 96.97851033508778, p_norm: 1092.1939379320845, g_norm: 1.9123612440076256, lr:  0.001976, elapsed time:  14701
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 16000, eval loss: 0.12622303254902364, eval acc: 98.3935317993164
Step 16100, loss: 0.1455714464560151, acc: 97.4155572205782, p_norm: 1097.2410644603135, g_norm: 0.6761467440597597, lr:  0.001970, elapsed time:  14807
Step 16200, loss: 8.95918381575495, acc: 97.67209059000015, p_norm: 1100.4290522448434, g_norm: 0.8425563536323675, lr:  0.001964, elapsed time:  14895
Step 16300, loss: 0.1089542110916227, acc: 97.82299888134003, p_norm: 1103.1161875537068, g_norm: 0.9527185156800568, lr:  0.001958, elapsed time:  14985
Step 16400, loss: 0.10026945822872221, acc: 98.00272497534752, p_norm: 1105.5294837396864, g_norm: 0.8426156640964425, lr:  0.001952, elapsed time:  15076
Step 16500, loss: 0.09934641726315022, acc: 98.01491118967533, p_norm: 1107.9645095965893, g_norm: 0.8839654712246159, lr:  0.001946, elapsed time:  15165
Step 16600, loss: 0.09938420756720007, acc: 97.99662560224533, p_norm: 1110.777474102164, g_norm: 0.8302736412864175, lr:  0.001940, elapsed time:  15253
Step 16700, loss: 0.10183983320370317, acc: 97.94542193412781, p_norm: 1113.5905390004993, g_norm: 0.6825860985249783, lr:  0.001934, elapsed time:  15340
Step 16800, loss: 0.11086311981081963, acc: 98.05864650011063, p_norm: 1116.6881917365863, g_norm: 0.9461378729093884, lr:  0.001928, elapsed time:  15431
Step 16900, loss: 0.09722868133336306, acc: 98.05011916160583, p_norm: 1119.4999070036654, g_norm: 0.8918317162366518, lr:  0.001923, elapsed time:  15524
Step 17000, loss: 0.09842589010484516, acc: 98.0743845552206, p_norm: 1122.2500746763071, g_norm: 1.1088143683323655, lr:  0.001917, elapsed time:  15613
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 17100, loss: 0.09523080445047635, acc: 98.07353897474299, p_norm: 1124.9635052564563, g_norm: 0.890828341914592, lr:  0.001911, elapsed time:  15701
Step 17200, loss: 0.095251669799909, acc: 98.05980476737022, p_norm: 1127.674916883228, g_norm: 0.9031540021528346, lr:  0.001906, elapsed time:  15792
Step 17300, loss: 0.09375355276279151, acc: 98.12667992711067, p_norm: 1130.4563797459064, g_norm: 0.883150379792626, lr:  0.001900, elapsed time:  15881
Step 17400, loss: 0.09452367142774165, acc: 98.08505663275719, p_norm: 1133.2837279212836, g_norm: 0.9985280785528934, lr:  0.001895, elapsed time:  15970
Step 17500, loss: 0.10061633814126253, acc: 97.98714719712734, p_norm: 1136.8426573556615, g_norm: 0.8968506572838327, lr:  0.001889, elapsed time:  16062
Step 17600, loss: 0.09870336788706481, acc: 98.00665944814682, p_norm: 1139.8456149164554, g_norm: 0.7884127952556094, lr:  0.001884, elapsed time:  16151
Step 17700, loss: 0.10565357037819922, acc: 97.94682455062866, p_norm: 1143.5665268310543, g_norm: 1.1193725442930653, lr:  0.001879, elapsed time:  16243
Step 17800, loss: 0.0998483185376972, acc: 97.9756715297699, p_norm: 1146.71549881985, g_norm: 0.8449204402542103, lr:  0.001873, elapsed time:  16331
Step 17900, loss: 0.5534868347365409, acc: 97.95728227496147, p_norm: 1150.4273164709507, g_norm: 1.2223083690104968, lr:  0.001868, elapsed time:  16422
Step 18000, loss: 0.10040262863971293, acc: 97.98907826840878, p_norm: 1154.1246590757155, g_norm: 0.8471536344107241, lr:  0.001863, elapsed time:  16509
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 18000, eval loss: 0.06844595765694976, eval acc: 98.87803649902344
Step 18100, loss: 0.0962894984241575, acc: 98.05173324048519, p_norm: 1157.1979876198707, g_norm: 0.856582818912364, lr:  0.001858, elapsed time:  16616
Step 18200, loss: 0.09316864720545709, acc: 98.08923664689064, p_norm: 1159.9913290141367, g_norm: 0.7711825549028806, lr:  0.001853, elapsed time:  16702
Step 18300, loss: 0.09233922644518316, acc: 98.0921037197113, p_norm: 1162.5640104745698, g_norm: 0.7285488919943961, lr:  0.001847, elapsed time:  16787
Step 18400, loss: 0.09092452712357044, acc: 98.11052082479, p_norm: 1165.2560203780818, g_norm: 0.8291902494032757, lr:  0.001842, elapsed time:  16876
Step 18500, loss: 0.0892368919402361, acc: 98.15692910552025, p_norm: 1168.0038078920284, g_norm: 0.7223250438662999, lr:  0.001837, elapsed time:  16969
Step 18600, loss: 0.110316920299083, acc: 97.99744118750095, p_norm: 1172.3269348419647, g_norm: 0.6633391714170712, lr:  0.001833, elapsed time:  17062
Step 18700, loss: 0.09621607375331223, acc: 98.01166607439518, p_norm: 1175.3705472308493, g_norm: 0.6978152725887518, lr:  0.001828, elapsed time:  17148
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 18800, loss: 0.08920524065470814, acc: 98.18699376203527, p_norm: 1178.1298711399745, g_norm: 0.780320442891434, lr:  0.001823, elapsed time:  17239
Step 18900, loss: 0.08775876221247017, acc: 98.19389398396015, p_norm: 1180.6279797566847, g_norm: 0.8500145808586799, lr:  0.001818, elapsed time:  17326
Step 19000, loss: 0.08756428461521865, acc: 98.22422669827938, p_norm: 1183.2489017994758, g_norm: 0.9694098671348387, lr:  0.001813, elapsed time:  17415
Step 19100, loss: 0.15257195951417088, acc: 98.00946596264839, p_norm: 1187.1732620164705, g_norm: 1.2387591187664866, lr:  0.001808, elapsed time:  17504
Step 19200, loss: 0.11448034355416895, acc: 97.96977679431438, p_norm: 1190.7117130905576, g_norm: 1.0606882149715104, lr:  0.001804, elapsed time:  17594
Step 19300, loss: 0.09428920951671899, acc: 98.10540656745434, p_norm: 1193.3229528060638, g_norm: 0.9573956589837693, lr:  0.001799, elapsed time:  17683
Step 19400, loss: 0.09344271091744304, acc: 98.10347664356232, p_norm: 1195.684719266996, g_norm: 0.8885627030968125, lr:  0.001794, elapsed time:  17769
Step 19500, loss: 0.0970888421498239, acc: 98.0963791012764, p_norm: 1198.5929464496717, g_norm: 0.8376311254545165, lr:  0.001790, elapsed time:  17859
Step 19600, loss: 0.10138046448118984, acc: 98.00800731778145, p_norm: 1201.9832265140162, g_norm: 0.8765312763710351, lr:  0.001785, elapsed time:  17947
Step 19700, loss: 0.10469027999788523, acc: 97.92791293561459, p_norm: 1205.2641666361244, g_norm: 0.9888813414639582, lr:  0.001781, elapsed time:  18039
Step 19800, loss: 0.09583836264908313, acc: 98.06154699623585, p_norm: 1207.8577833574775, g_norm: 1.0359938288915318, lr:  0.001776, elapsed time:  18129
Step 19900, loss: 0.0919738639704883, acc: 98.14475226402283, p_norm: 1210.2716399452358, g_norm: 0.7986773992071876, lr:  0.001772, elapsed time:  18220
Step 20000, loss: 0.09169309264980256, acc: 98.15228520333767, p_norm: 1212.6367363978493, g_norm: 1.2662399072312762, lr:  0.001767, elapsed time:  18311
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 20000, eval loss: 0.06956259582191704, eval acc: 98.87306213378906
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) C 1 = C c 2 c c c c ( C N ( C ) C ) c 2 O C C 1 _EOS
Predicted text: C O C ( = O ) C 1 = C c 2 c c c c ( C N ( C ) C ) c 2 O C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C ( = O ) O ) n c 2 c c c 3 c ( c 2 c 1 - c 1 c c c 2 c ( c 1 ) O C O 2 ) O C O 3 _EOS
Predicted text: C O C ( = O ) c 1 n c 2 c c c 3 c ( c 2 c ( - c 2 c c c 4 c ( c 2 ) O C O 4 ) c 1 C ) O C O 3 _EOS
acc_token: 0.1276595744680851, acc_seq: False

Target text: C C ( C ) N 1 C ( = O ) N C ( c 2 c c c c c 2 ) c 2 c c 3 c ( c c 2 1 ) O C C 3 _EOS
Predicted text: C C ( C ) N ( C ( N ) = O ) c 1 c c 2 c ( c c 1 C ( O ) c 1 c c c c c 1 ) C C O 2 _EOS
acc_token: 0.36585365853658536, acc_seq: False

Target text: C C C C C C C C C C C C C ( C C C ) S ( = O ) ( = O ) Cl _EOS
Predicted text: C C C C C C C C C C C C C ( C C C ) O S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 _EOS
acc_token: 0.6206896551724138, acc_seq: False

Target text: O = c 1 c 2 c c ( S ) c c c 2 c c n 1 C C ( F ) ( F ) F _EOS
Predicted text: O = c 1 c 2 c c ( S ) c c c 2 c c n 1 C C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 20000, eval acc (token): 0.8728348949747191, eval acc (sequence): 0.763567174056916
Saving at step 20000
Step 20100, loss: 0.09217413425445557, acc: 98.16899275779724, p_norm: 1215.170680372633, g_norm: 0.6963459201338793, lr:  0.001763, elapsed time:  18494
Step 20200, loss: 0.09212513719685375, acc: 98.23922076821327, p_norm: 1217.6352077915715, g_norm: 0.7872051389540102, lr:  0.001758, elapsed time:  18585
Step 20300, loss: 0.09502602190710605, acc: 98.11644487082958, p_norm: 1220.5596671582737, g_norm: 0.7789090438748444, lr:  0.001754, elapsed time:  18673
Step 20400, loss: 0.09684837524779141, acc: 98.06777654588223, p_norm: 1223.0957939847453, g_norm: 0.8749290533974206, lr:  0.001750, elapsed time:  18762
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 20500, loss: 0.09391893784772078, acc: 98.15496061339272, p_norm: 1225.2964947318303, g_norm: 1.849482090106061, lr:  0.001746, elapsed time:  18849
Step 20600, loss: 0.244494837988168, acc: 98.20600780844688, p_norm: 1227.585375960554, g_norm: 0.8432073652817627, lr:  0.001741, elapsed time:  18939
Step 20700, loss: 0.12190602646209299, acc: 98.26198497414589, p_norm: 1230.1211090542001, g_norm: 1.392478979568865, lr:  0.001737, elapsed time:  19027
Step 20800, loss: 0.09419543871656061, acc: 98.16705751419067, p_norm: 1232.3874932021238, g_norm: 0.7442254724124608, lr:  0.001733, elapsed time:  19117
Step 20900, loss: 0.08881477576680481, acc: 98.30541245639324, p_norm: 1234.4038506417642, g_norm: 0.6850872065403815, lr:  0.001729, elapsed time:  19206
Step 21000, loss: 0.09247857199981808, acc: 98.23446649312973, p_norm: 1237.0342761959512, g_norm: 0.6563138906284278, lr:  0.001725, elapsed time:  19295
Step 21100, loss: 0.08659927169792354, acc: 98.35981093347073, p_norm: 1239.2524827962704, g_norm: 0.6577349916567661, lr:  0.001721, elapsed time:  19385
Step 21200, loss: 0.08808614675886929, acc: 98.30886407196522, p_norm: 1241.3540449698594, g_norm: 0.7637155702378687, lr:  0.001716, elapsed time:  19477
Step 21300, loss: 0.08821542832069099, acc: 98.29363159835339, p_norm: 1243.5518375771355, g_norm: 0.6579660526929189, lr:  0.001712, elapsed time:  19568
Step 21400, loss: 0.08998594329692423, acc: 98.18726436793804, p_norm: 1245.7395654275097, g_norm: 0.7429186073508323, lr:  0.001708, elapsed time:  19656
Step 21500, loss: 0.08598593066446483, acc: 98.3011282980442, p_norm: 1247.873028546546, g_norm: 0.8955639164685236, lr:  0.001704, elapsed time:  19744
Step 21600, loss: 0.08355329187586903, acc: 98.34433451294899, p_norm: 1249.8943477868236, g_norm: 0.705778711760755, lr:  0.001701, elapsed time:  19834
Step 21700, loss: 0.09178224628791214, acc: 98.19148033857346, p_norm: 1252.6226164772074, g_norm: 0.9125455079035043, lr:  0.001697, elapsed time:  19925
Step 21800, loss: 0.09326619228348136, acc: 98.1514099240303, p_norm: 1255.7598658050867, g_norm: 1.8257504900646542, lr:  0.001693, elapsed time:  20016
Step 21900, loss: 0.09345677294768392, acc: 98.15212759375572, p_norm: 1258.347214041272, g_norm: 0.7544495248902745, lr:  0.001689, elapsed time:  20104
Step 22000, loss: 0.09150910103693605, acc: 98.16653740406036, p_norm: 1260.6687690818835, g_norm: 0.6671769958010326, lr:  0.001685, elapsed time:  20190
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 22000, eval loss: 0.06380273103713992, eval acc: 98.9756851196289
Step 22100, loss: 0.09175565353594721, acc: 98.2804991453886, p_norm: 1262.8295387387175, g_norm: 0.9146535486605581, lr:  0.001681, elapsed time:  20295
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 22200, loss: 0.08830471377514727, acc: 98.26298847091996, p_norm: 1265.1655992587782, g_norm: 0.7022047306640894, lr:  0.001677, elapsed time:  20386
Step 22300, loss: 0.08145501653663814, acc: 98.42798101902008, p_norm: 1267.1803823037399, g_norm: 0.7193939449535809, lr:  0.001674, elapsed time:  20479
Step 22400, loss: 0.08215690752491354, acc: 98.36139778792858, p_norm: 1269.213936602452, g_norm: 0.9243564358356259, lr:  0.001670, elapsed time:  20571
Step 22500, loss: 0.08148500031791628, acc: 98.36941547691822, p_norm: 1271.1405077112843, g_norm: 0.7006925076597548, lr:  0.001666, elapsed time:  20658
Step 22600, loss: 0.08166425755247474, acc: 98.37089863419533, p_norm: 1273.0683024833659, g_norm: 1.0871943485048186, lr:  0.001662, elapsed time:  20744
Step 22700, loss: 0.08290371183305979, acc: 98.33263137936592, p_norm: 1275.1439449207728, g_norm: 0.8141794019639146, lr:  0.001659, elapsed time:  20833
Step 22800, loss: 0.07975155256688594, acc: 98.42615535855293, p_norm: 1277.1640122960857, g_norm: 0.820882270498896, lr:  0.001655, elapsed time:  20922
Step 22900, loss: 0.08246514058671892, acc: 98.35595279932022, p_norm: 1279.2622280439177, g_norm: 0.6876692204080838, lr:  0.001652, elapsed time:  21012
Step 23000, loss: 0.08061152715235949, acc: 98.38601411879063, p_norm: 1281.3796856758863, g_norm: 0.7223394859616443, lr:  0.001648, elapsed time:  21102
Step 23100, loss: 0.08200179169885814, acc: 98.38532054424286, p_norm: 1283.4893586004926, g_norm: 0.7541266079407606, lr:  0.001644, elapsed time:  21191
Step 23200, loss: 0.08178186786361039, acc: 98.38731908798218, p_norm: 1285.4733244780116, g_norm: 0.8438402291518584, lr:  0.001641, elapsed time:  21280
Step 23300, loss: 0.08170888129621744, acc: 98.36459130048752, p_norm: 1287.2630398518436, g_norm: 0.6266482375704197, lr:  0.001637, elapsed time:  21368
Step 23400, loss: 0.08117982005700469, acc: 98.3980682194233, p_norm: 1289.329178823487, g_norm: 0.7906412264910303, lr:  0.001634, elapsed time:  21460
Step 23500, loss: 0.08284357408061624, acc: 98.34946751594543, p_norm: 1291.3802208182028, g_norm: 0.8226206187599482, lr:  0.001630, elapsed time:  21548
Step 23600, loss: 0.08183999878820032, acc: 98.35485047101974, p_norm: 1293.437059353403, g_norm: 0.7493238258914432, lr:  0.001627, elapsed time:  21638
Step 23700, loss: 0.07939873579889536, acc: 98.40552425384521, p_norm: 1295.4459044051669, g_norm: 0.7549530940614354, lr:  0.001623, elapsed time:  21730
Step 23800, loss: 0.07897847859188914, acc: 98.42921639978886, p_norm: 1297.4082744114564, g_norm: 0.7310150602420765, lr:  0.001620, elapsed time:  21817
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 23900, loss: 0.07899995262164679, acc: 98.42067270433132, p_norm: 1299.3482978226716, g_norm: 0.7609561286968602, lr:  0.001617, elapsed time:  21907
Step 24000, loss: 0.0780557928327471, acc: 98.45253109931946, p_norm: 1301.3034444080179, g_norm: 1.0032350591519905, lr:  0.001613, elapsed time:  21996
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 24000, eval loss: 0.06023225728422403, eval acc: 99.04328155517578
Step 24100, loss: 0.07830184895545245, acc: 98.45791168510914, p_norm: 1303.2729365173088, g_norm: 0.834643892627, lr:  0.001610, elapsed time:  22104
Step 24200, loss: 0.08192751226946711, acc: 98.37047490477562, p_norm: 1305.3660811422674, g_norm: 0.8085507451882173, lr:  0.001607, elapsed time:  22191
Step 24300, loss: 0.08224068546667695, acc: 98.40982174873352, p_norm: 1307.3443536110985, g_norm: 1.083218001170303, lr:  0.001603, elapsed time:  22283
Step 24400, loss: 0.08586264741607011, acc: 98.29598893225193, p_norm: 1309.960458224186, g_norm: 1.0419248060399786, lr:  0.001600, elapsed time:  22375
Step 24500, loss: 0.08018903335556388, acc: 98.43377810716629, p_norm: 1311.9267043510763, g_norm: 0.7698019672961793, lr:  0.001597, elapsed time:  22462
Step 24600, loss: 0.07965547140687704, acc: 98.43174880743027, p_norm: 1313.7818436242924, g_norm: 0.9303606672091739, lr:  0.001593, elapsed time:  22551
Step 24700, loss: 0.08147020645439625, acc: 98.39653956890106, p_norm: 1315.7351472515054, g_norm: 0.700460369528132, lr:  0.001590, elapsed time:  22638
Step 24800, loss: 0.08064690278843045, acc: 98.41294205188751, p_norm: 1317.648933136515, g_norm: 0.686938942000408, lr:  0.001587, elapsed time:  22727
Step 24900, loss: 0.0777979761082679, acc: 98.48141440749168, p_norm: 1319.4948016419264, g_norm: 0.8781449892834279, lr:  0.001584, elapsed time:  22814
Step 25000, loss: 0.16544173038564622, acc: 98.37014326453209, p_norm: 1321.9571636609076, g_norm: 0.7715936247742039, lr:  0.001581, elapsed time:  22904
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c ( Br ) o c 1 C = C 1 C ( = O ) N c 2 c c c c c 2 1 _EOS
Predicted text: C c 1 c c ( Br ) o c 1 C = C 1 C ( = O ) N c 2 c c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c ( - c 2 c c c 3 c ( c 2 ) O C C n 2 c c ( - c 4 n c n n 4 C ( C ) C ) n c 2 - 3 ) c n 1 C O C C [Si] ( C ) ( C ) C _EOS
Predicted text: C c 1 n c ( - c 2 c c c 3 c ( c 2 ) O C C n 2 c c ( - c 4 n c n n 4 C ( C ) C ) n c 2 - 3 ) c n 1 C O C C [Si] ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 c ( = O ) n ( C C ( = O ) N c 2 c c c c c 2 ) c 2 c n c ( - c 3 c c c c c 3 ) n c 2 1 _EOS
Predicted text: C n 1 c ( = O ) n ( C C ( = O ) N c 2 c c c c c 2 ) c 2 c n c ( - c 3 c c c c c 3 ) n c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) N 1 C C N ( C ( = O ) C ( C C ( = O ) O C ( C ) ( C ) C ) N C ( = O ) c 2 c c ( O C C ( = O ) N 3 C C C C 3 C ( = O ) O ) n ( - c 3 c c c c c 3 ) n 2 ) C C 1 _EOS
Predicted text: C C O C ( = O ) N 1 C C N ( C ( = O ) C ( C C ( = O ) O C ( C ) ( C ) C ) N C ( = O ) c 2 c c ( O C C ( = O ) N 3 C C C C 3 C ( = O ) O ) n ( - c 3 c c c c c 3 ) n 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 o c ( - c 2 c c c ( Br ) c c 2 ) n c 1 C C N 1 C C C C 1 C _EOS
Predicted text: C c 1 o c ( - c 2 c c c ( Br ) c c 2 ) n c 1 C C N 1 C C C C 1 C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 25000, eval acc (token): 0.8902163361485026, eval acc (sequence): 0.7882638759110446
Saving at step 25000
Step 25100, loss: 0.083970244564116, acc: 98.35376407206059, p_norm: 1323.902131759283, g_norm: 0.790378237628345, lr:  0.001578, elapsed time:  23081
Step 25200, loss: 0.08364980361424386, acc: 98.36444444954395, p_norm: 1325.7677522367874, g_norm: 0.6773379422676014, lr:  0.001574, elapsed time:  23172
Step 25300, loss: 0.08244229232892394, acc: 98.38624821603298, p_norm: 1327.629215511085, g_norm: 0.8418539698012804, lr:  0.001571, elapsed time:  23262
Step 25400, loss: 0.08057940380647778, acc: 98.43694591522217, p_norm: 1329.5000268807044, g_norm: 0.7718952353967347, lr:  0.001568, elapsed time:  23353
Step 25500, loss: 0.08068111096508801, acc: 98.4186327457428, p_norm: 1331.2883437856176, g_norm: 0.7522662040974882, lr:  0.001565, elapsed time:  23443
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 25600, loss: 0.07853600010275841, acc: 98.47860251789662, p_norm: 1332.9765971109457, g_norm: 1.096805551801327, lr:  0.001562, elapsed time:  23533
Step 25700, loss: 0.07730875618755817, acc: 98.50727790594101, p_norm: 1334.679472013905, g_norm: 0.8012092990483837, lr:  0.001559, elapsed time:  23622
Step 25800, loss: 0.07525325110647828, acc: 98.53776758909225, p_norm: 1336.3430378791627, g_norm: 1.0359337841313891, lr:  0.001556, elapsed time:  23712
Step 25900, loss: 0.07600403433199972, acc: 98.50439459085464, p_norm: 1338.14726358272, g_norm: 0.641106590879383, lr:  0.001553, elapsed time:  23803
Step 26000, loss: 0.07534030902199447, acc: 98.54031445086002, p_norm: 1339.8236396342393, g_norm: 0.8171477041990546, lr:  0.001550, elapsed time:  23889
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 26000, eval loss: 0.05736533824354412, eval acc: 99.11861419677734
Step 26100, loss: 0.07838359053246677, acc: 98.45482762157917, p_norm: 1341.7386531382062, g_norm: 1.4997300306407735, lr:  0.001547, elapsed time:  23995
Step 26200, loss: 0.07614802032709121, acc: 98.50579984486103, p_norm: 1343.4355063877822, g_norm: 0.7598919011271544, lr:  0.001544, elapsed time:  24083
Step 26300, loss: 0.07706840077415109, acc: 98.50089481472969, p_norm: 1345.2829046693334, g_norm: 0.8402851074207556, lr:  0.001541, elapsed time:  24174
Step 26400, loss: 0.07733463917858899, acc: 98.4959885776043, p_norm: 1347.148470665888, g_norm: 0.8604112230140851, lr:  0.001538, elapsed time:  24263
Step 26500, loss: 0.07601401564665139, acc: 98.52428995072842, p_norm: 1348.914781018129, g_norm: 0.6452818889307433, lr:  0.001535, elapsed time:  24351
Step 26600, loss: 0.07854460418224335, acc: 98.48026114702225, p_norm: 1350.9175259188437, g_norm: 0.7007153258147818, lr:  0.001532, elapsed time:  24440
Step 26700, loss: 0.0760959399305284, acc: 98.5092626363039, p_norm: 1352.5682050590283, g_norm: 1.3269942619062112, lr:  0.001530, elapsed time:  24529
Step 26800, loss: 0.074928841246292, acc: 98.54908666014671, p_norm: 1354.2313539964875, g_norm: 0.9496172481489706, lr:  0.001527, elapsed time:  24618
Step 26900, loss: 0.0745363431237638, acc: 98.54936219751835, p_norm: 1355.9415309428032, g_norm: 0.6197614178614923, lr:  0.001524, elapsed time:  24705
Step 27000, loss: 0.07705646547488869, acc: 98.52362875640392, p_norm: 1357.9752622142005, g_norm: 0.8552450458455068, lr:  0.001521, elapsed time:  24797
Step 27100, loss: 0.07698902389034629, acc: 98.51846085488796, p_norm: 1359.774594621061, g_norm: 1.181704270370716, lr:  0.001518, elapsed time:  24890
Step 27200, loss: 0.07879614243283868, acc: 98.47798272967339, p_norm: 1361.4949831066558, g_norm: 0.8451115073806036, lr:  0.001515, elapsed time:  24980
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 27300, loss: 0.07643183076721859, acc: 98.51709638280845, p_norm: 1363.1892507959926, g_norm: 0.7159253710416278, lr:  0.001513, elapsed time:  25069
Step 27400, loss: 0.07251685575582087, acc: 98.62672866880894, p_norm: 1364.7900669631672, g_norm: 0.7384309269605065, lr:  0.001510, elapsed time:  25161
Step 27500, loss: 0.07387230982072651, acc: 98.57787962257862, p_norm: 1366.3974524199032, g_norm: 0.7441661325437153, lr:  0.001507, elapsed time:  25249
Step 27600, loss: 0.07237812139093876, acc: 98.61998263001442, p_norm: 1368.0564583917023, g_norm: 0.7205619156078508, lr:  0.001504, elapsed time:  25333
Step 27700, loss: 0.07268267859239132, acc: 98.6153726130724, p_norm: 1369.5901769785792, g_norm: 1.3477172926921417, lr:  0.001502, elapsed time:  25421
Step 27800, loss: 0.07516021840274334, acc: 98.56262975931168, p_norm: 1371.3399521748267, g_norm: 0.8399707684028572, lr:  0.001499, elapsed time:  25513
Step 27900, loss: 0.1062262441124767, acc: 98.50650344789028, p_norm: 1373.399930133492, g_norm: 1.0303505398291768, lr:  0.001496, elapsed time:  25605
Step 28000, loss: 0.07953004833310842, acc: 98.50482647120953, p_norm: 1375.4406906381469, g_norm: 1.1143188107017743, lr:  0.001494, elapsed time:  25697
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 28000, eval loss: 0.058573713563382604, eval acc: 99.16549682617188
Step 28100, loss: 0.0788896097522229, acc: 98.49176688492298, p_norm: 1377.1265844441214, g_norm: 0.8207967314891145, lr:  0.001491, elapsed time:  25807
Step 28200, loss: 0.07588083997368812, acc: 98.56492222845554, p_norm: 1378.689732675539, g_norm: 0.6071938391703685, lr:  0.001488, elapsed time:  25897
Step 28300, loss: 0.07634614796377719, acc: 98.54973268508911, p_norm: 1380.2132441674898, g_norm: 0.8107613664595431, lr:  0.001486, elapsed time:  25986
Step 28400, loss: 0.0732638365123421, acc: 98.60078340768814, p_norm: 1381.6998118008148, g_norm: 0.6521567887067693, lr:  0.001483, elapsed time:  26076
Step 28500, loss: 0.07443983192555606, acc: 98.57338696718216, p_norm: 1383.2377102588916, g_norm: 1.281859993718774, lr:  0.001480, elapsed time:  26164
Step 28600, loss: 0.07633211984299124, acc: 98.51147677004337, p_norm: 1384.7980974120705, g_norm: 0.9794365858909008, lr:  0.001478, elapsed time:  26254
Step 28700, loss: 0.07317088485695422, acc: 98.59805437922478, p_norm: 1386.2547717375207, g_norm: 0.7144143653593447, lr:  0.001475, elapsed time:  26339
Step 28800, loss: 0.07484950490295887, acc: 98.55172695219517, p_norm: 1387.846867814122, g_norm: 1.0082507870177293, lr:  0.001473, elapsed time:  26428
Step 28900, loss: 0.074390699560754, acc: 98.56954841315746, p_norm: 1389.2901036167145, g_norm: 0.8518771902058752, lr:  0.001470, elapsed time:  26517
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 29000, loss: 0.07291141774033938, acc: 98.60116766936726, p_norm: 1390.7692317122858, g_norm: 1.1200532016981783, lr:  0.001468, elapsed time:  26607
Step 29100, loss: 0.07183136030100286, acc: 98.62355543673038, p_norm: 1392.2319318974717, g_norm: 0.8983606635487275, lr:  0.001465, elapsed time:  26696
Step 29200, loss: 0.07188634444028139, acc: 98.63283216953278, p_norm: 1393.6872032095887, g_norm: 0.8151349054697952, lr:  0.001463, elapsed time:  26784
Step 29300, loss: 0.07128460579086095, acc: 98.6466915756464, p_norm: 1395.2283471036535, g_norm: 0.706305712380464, lr:  0.001460, elapsed time:  26879
Step 29400, loss: 0.07184727205894888, acc: 98.63756355643272, p_norm: 1396.6915545563952, g_norm: 0.7000953853703958, lr:  0.001458, elapsed time:  26968
Step 29500, loss: 0.0721919015608728, acc: 98.60395070910454, p_norm: 1398.1174805311327, g_norm: 0.659290435827516, lr:  0.001455, elapsed time:  27059
Step 29600, loss: 0.07130591885186732, acc: 98.64563624560833, p_norm: 1399.58326802794, g_norm: 0.957396321764501, lr:  0.001453, elapsed time:  27144
Step 29700, loss: 0.07127660823985935, acc: 98.63768330216408, p_norm: 1401.1214009894938, g_norm: 0.7177898771670308, lr:  0.001450, elapsed time:  27234
Step 29800, loss: 0.07248116908594966, acc: 98.60033854842186, p_norm: 1402.7028574062879, g_norm: 0.688069880408667, lr:  0.001448, elapsed time:  27324
Step 29900, loss: 0.07390743690542877, acc: 98.54694969952106, p_norm: 1404.3376340901018, g_norm: 0.8743604883113534, lr:  0.001445, elapsed time:  27413
Step 30000, loss: 0.07496797888074071, acc: 98.58457989990711, p_norm: 1406.204372349297, g_norm: 0.8773467109152937, lr:  0.001443, elapsed time:  27503
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 30000, eval loss: 0.057766572162508974, eval acc: 99.12518310546875
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C c 1 c c ( Cl ) c c c 1 C ( = O ) O _EOS
Predicted text: C c 1 c c ( Cl ) c c c 1 C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = S ( = O ) ( N c 1 c n c ( O c 2 c n c 3 c c c c c 3 c 2 ) c ( Cl ) c 1 ) c 1 c c c ( Cl ) c ( Cl ) c 1 _EOS
Predicted text: O = S ( = O ) ( N c 1 c n c ( O c 2 c n c 3 c c c c c 3 c 2 ) c ( Cl ) c 1 ) c 1 c c c ( Cl ) c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( N ( C ) S ( = O ) ( = O ) c 2 c c c s 2 ) c 2 [nH] c ( C ( = O ) N C C ( C # N ) S C c 3 c c c c c 3 ) c c 2 c 1 _EOS
Predicted text: C c 1 c c ( N ( C ) S ( = O ) ( = O ) c 2 c c c s 2 ) c 2 [nH] c ( C ( = O ) N C C ( C = N O ) S C c 3 c c c c c 3 ) c c 2 c 1 _EOS
acc_token: 0.7741935483870968, acc_seq: False

Target text: C O c 1 c c 2 c ( c 3 c 1 O C ( C ) ( C ) C 3 ) C ( c 1 c c c c ( - c 3 c c c c ( N C ( C ) = O ) c 3 ) c 1 ) = N C ( C ) ( C ) C 2 = O _EOS
Predicted text: C O c 1 c c 2 c ( c 3 c 1 O C ( C ) ( C ) C 3 ) C ( c 1 c c c c ( - c 3 c c c c ( N C ( C ) = O ) c 3 ) c 1 ) = N C ( C ) ( C ) C 2 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) c 1 c c c ( C O c 2 c c c c 3 c 2 C C ( = C C C N 2 C C C ( O ) ( c 4 c c c ( Cl ) c c 4 ) C C 2 ) c 2 c c c n c 2 O 3 ) c c 1 _EOS
Predicted text: O = C ( O ) c 1 c c c ( C O c 2 c c c c 3 c 2 C C ( = C C C N 2 C C C ( O ) ( c 4 c c c ( Cl ) c c 4 ) C C 2 ) c 2 c c c n c 2 O 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 30000, eval acc (token): 0.8905916108017103, eval acc (sequence): 0.7943322586119125
Saving at step 30000
Step 30100, loss: 0.07505108575336635, acc: 98.58717119693756, p_norm: 1407.9202981857745, g_norm: 0.9813284925646902, lr:  0.001441, elapsed time:  27696
Step 30200, loss: 0.0746352484356612, acc: 98.59905044734478, p_norm: 1409.482439693913, g_norm: 0.7528699653183549, lr:  0.001438, elapsed time:  27787
Step 30300, loss: 0.0731302486732602, acc: 98.62031303346157, p_norm: 1410.8895761974316, g_norm: 0.770904576756013, lr:  0.001436, elapsed time:  27877
Step 30400, loss: 0.07044939893763512, acc: 98.68354035913944, p_norm: 1412.1712430759405, g_norm: 0.6915453760981468, lr:  0.001433, elapsed time:  27963
Step 30500, loss: 0.07318040412850678, acc: 98.62229984998703, p_norm: 1413.5651207950027, g_norm: 1.0353414629911173, lr:  0.001431, elapsed time:  28051
Step 30600, loss: 0.07176189023070037, acc: 98.64169676601887, p_norm: 1415.0166100170056, g_norm: 0.7939123936755488, lr:  0.001429, elapsed time:  28142
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 30700, loss: 0.07286330856955968, acc: 98.61588522459083, p_norm: 1416.5016269315086, g_norm: 0.8297182075723605, lr:  0.001426, elapsed time:  28233
Step 30800, loss: 0.07044178081676364, acc: 98.71353024244308, p_norm: 1417.9731671799727, g_norm: 0.9982150420911711, lr:  0.001424, elapsed time:  28324
Step 30900, loss: 0.07330404899083078, acc: 98.64832472801208, p_norm: 1419.3739173542144, g_norm: 0.7752299407754224, lr:  0.001422, elapsed time:  28413
Step 31000, loss: 0.07157459696754813, acc: 98.68786762654781, p_norm: 1420.6662833923187, g_norm: 0.8365432803143217, lr:  0.001419, elapsed time:  28501
Step 31100, loss: 0.07088261927943677, acc: 98.6839837282896, p_norm: 1422.1075129406213, g_norm: 0.8084015511331883, lr:  0.001417, elapsed time:  28590
Step 31200, loss: 0.07136715224944055, acc: 98.65020260214806, p_norm: 1423.4395769898363, g_norm: 0.7843854068372262, lr:  0.001415, elapsed time:  28680
Step 31300, loss: 0.069202461829409, acc: 98.70749785006046, p_norm: 1424.7689983067678, g_norm: 0.7526618243207366, lr:  0.001413, elapsed time:  28769
Step 31400, loss: 0.07644251516088843, acc: 98.63121612370014, p_norm: 1426.1498214533985, g_norm: 0.7981193988538083, lr:  0.001410, elapsed time:  28856
Step 31500, loss: 0.07694274413399399, acc: 98.57641240954399, p_norm: 1427.724646117082, g_norm: 0.6752126821227449, lr:  0.001408, elapsed time:  28942
Step 31600, loss: 0.0740665023215115, acc: 98.64321960508823, p_norm: 1429.2216495218424, g_norm: 0.8841151287979971, lr:  0.001406, elapsed time:  29035
Step 31700, loss: 0.07354103777557612, acc: 98.63440871238708, p_norm: 1430.629132654256, g_norm: 1.626583605896616, lr:  0.001404, elapsed time:  29124
Step 31800, loss: 0.07322915370576083, acc: 98.62625701725483, p_norm: 1432.0041717855602, g_norm: 0.8717348490429951, lr:  0.001402, elapsed time:  29217
Step 31900, loss: 0.0726441543083638, acc: 98.6404240578413, p_norm: 1433.3521367374717, g_norm: 0.7192610363534071, lr:  0.001399, elapsed time:  29308
Step 32000, loss: 0.07077158154919744, acc: 98.69699203968048, p_norm: 1434.5996882261013, g_norm: 1.2446791641555706, lr:  0.001397, elapsed time:  29396
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 32000, eval loss: 0.0541748804040253, eval acc: 99.19805908203125
Step 32100, loss: 0.07162382951937615, acc: 98.6720373481512, p_norm: 1435.9842389020605, g_norm: 0.94741920024768, lr:  0.001395, elapsed time:  29504
Step 32200, loss: 0.07154521495569498, acc: 98.681691005826, p_norm: 1437.240936597332, g_norm: 1.2004054506827742, lr:  0.001393, elapsed time:  29592
Step 32300, loss: 0.07109966784715653, acc: 98.66998401284218, p_norm: 1438.5685742797102, g_norm: 0.6608188645788785, lr:  0.001391, elapsed time:  29682
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 32400, loss: 0.07006947356033562, acc: 98.70720439158362, p_norm: 1439.9911814295099, g_norm: 0.9419207795304265, lr:  0.001388, elapsed time:  29775
Step 32500, loss: 0.07855827172286808, acc: 98.70220731198788, p_norm: 1441.7977738652394, g_norm: 1.0848380941648728, lr:  0.001386, elapsed time:  29867
Step 32600, loss: 0.07334379862062633, acc: 98.66193740069866, p_norm: 1443.3071036455024, g_norm: 0.893926098775012, lr:  0.001384, elapsed time:  29955
Step 32700, loss: 0.0696727143926546, acc: 98.74815176427364, p_norm: 1444.5459319681463, g_norm: 0.6834211531552076, lr:  0.001382, elapsed time:  30046
Step 32800, loss: 0.07012368379626423, acc: 98.71736440062523, p_norm: 1445.8481512215687, g_norm: 0.6898372842694824, lr:  0.001380, elapsed time:  30139
Step 32900, loss: 0.07011432586237788, acc: 98.72596010565758, p_norm: 1447.1534909674804, g_norm: 0.6549965242606479, lr:  0.001378, elapsed time:  30230
Step 33000, loss: 0.07372141144238413, acc: 98.61480286717415, p_norm: 1448.5659414188137, g_norm: 1.0929262678319103, lr:  0.001376, elapsed time:  30317
Step 33100, loss: 0.07029999154619873, acc: 98.70839788019657, p_norm: 1449.8459490370938, g_norm: 0.745510660471804, lr:  0.001374, elapsed time:  30406
Step 33200, loss: 0.06926539574749768, acc: 98.71650214493275, p_norm: 1451.0272101948715, g_norm: 0.8065604315786886, lr:  0.001372, elapsed time:  30495
Step 33300, loss: 0.06812492781784385, acc: 98.75114117562771, p_norm: 1452.2224402592146, g_norm: 0.7603538893811376, lr:  0.001370, elapsed time:  30584
Step 33400, loss: 0.06948909853585064, acc: 98.7177767008543, p_norm: 1453.4714240121816, g_norm: 0.6384535097099262, lr:  0.001368, elapsed time:  30674
Step 33500, loss: 0.06846107273362577, acc: 98.7208601385355, p_norm: 1454.624927721408, g_norm: 0.6385323469581533, lr:  0.001365, elapsed time:  30762
Step 33600, loss: 0.06744637679308653, acc: 98.75751732289791, p_norm: 1455.8377003007001, g_norm: 0.7900266022791788, lr:  0.001363, elapsed time:  30851
Step 33700, loss: 0.06929348008707166, acc: 98.69122606515884, p_norm: 1457.0395970720447, g_norm: 0.7690105293844063, lr:  0.001361, elapsed time:  30937
Step 33800, loss: 0.07011980751529336, acc: 98.66834272444248, p_norm: 1458.2981619946142, g_norm: 0.6380107958475115, lr:  0.001359, elapsed time:  31027
Step 33900, loss: 0.06805521882604808, acc: 98.73542837798595, p_norm: 1459.6323354164472, g_norm: 0.7240915350691217, lr:  0.001357, elapsed time:  31121
Step 34000, loss: 0.0688332214858383, acc: 98.7054069340229, p_norm: 1460.8398369971342, g_norm: 0.7938704889582668, lr:  0.001355, elapsed time:  31209
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 34000, eval loss: 0.05589847486466169, eval acc: 99.15546417236328
Step 34100, loss: 0.06987297139596194, acc: 98.69155357778072, p_norm: 1462.0654300305632, g_norm: 0.8241261339376917, lr:  0.001353, elapsed time:  31313
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 34200, loss: 0.0670020932526286, acc: 98.75348924997434, p_norm: 1463.2844363566392, g_norm: 0.6593576885768923, lr:  0.001351, elapsed time:  31404
Step 34300, loss: 0.0666342536592856, acc: 98.78014203906059, p_norm: 1464.4962323904356, g_norm: 0.7076827930332616, lr:  0.001349, elapsed time:  31496
Step 34400, loss: 0.06629124343395233, acc: 98.79084493219852, p_norm: 1465.7239945613721, g_norm: 0.9737054121842077, lr:  0.001347, elapsed time:  31587
Step 34500, loss: 0.06719837978482246, acc: 98.75080992281437, p_norm: 1466.927216658802, g_norm: 0.7392254699607311, lr:  0.001346, elapsed time:  31674
Step 34600, loss: 0.06747667673043907, acc: 98.76325775682926, p_norm: 1468.0571727199729, g_norm: 0.8412242730926018, lr:  0.001344, elapsed time:  31760
Step 34700, loss: 0.06724066101480275, acc: 98.78470940887928, p_norm: 1469.377757582083, g_norm: 0.806072136602621, lr:  0.001342, elapsed time:  31854
Step 34800, loss: 0.06813997487537563, acc: 98.77700211107731, p_norm: 1470.6468033466165, g_norm: 0.7023723382186411, lr:  0.001340, elapsed time:  31946
Step 34900, loss: 0.0673421271983534, acc: 98.75968024134636, p_norm: 1471.8270782768327, g_norm: 0.7254680197975132, lr:  0.001338, elapsed time:  32036
Step 35000, loss: 0.06779633812606335, acc: 98.74303776025772, p_norm: 1472.9859594836253, g_norm: 0.7069733888803585, lr:  0.001336, elapsed time:  32122
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c c ( C C 2 C C ( O ) C N 2 ) c c 1 F _EOS
Predicted text: C c 1 c c c ( C C 2 C C ( O ) C N 2 ) c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C n 1 c 2 c ( c 3 c c ( Cl ) c c c 3 1 ) C C C ( C ( C ) ( C ( = O ) O C ) S ( = O ) ( = O ) c 1 c c c c c 1 ) C 2 _EOS
Predicted text: C O C C n 1 c 2 c ( c 3 c c ( Cl ) c c c 3 1 ) C C C ( C ( C ) ( C ( = O ) O C ) S ( = O ) ( = O ) c 1 c c c c c 1 ) C 2 _EOS
acc_token: 0.2, acc_seq: False

Target text: C N ( C ) C C N 1 C C C C c 2 c c ( N ) c c c 2 1 _EOS
Predicted text: C N ( C ) C C N 1 C C C C c 2 c c ( N ) c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C n 1 c c c 2 c ( C ) c ( C C ( = O ) O ) c ( C ) c ( N C ( = O ) C ( C ) ( C ) C ) c 2 1 _EOS
Predicted text: C C C C C C C C n 1 c c c 2 c ( C ) c ( C C ( = O ) O ) c ( C ) c ( N C ( = O ) C ( C ) ( C ) C ) c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( C 2 C C C O 2 ) c ( C ( F ) ( F ) F ) c c 1 N _EOS
Predicted text: C O C ( = O ) c 1 c c ( C 2 C C C O 2 ) c ( C ( F ) ( F ) F ) c c 1 N _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 35000, eval acc (token): 0.9029377955382651, eval acc (sequence): 0.8185631882538018
Saving at step 35000
Step 35100, loss: 0.06713455801829696, acc: 98.75913281738758, p_norm: 1474.163018104411, g_norm: 0.8269048199586451, lr:  0.001334, elapsed time:  32290
Step 35200, loss: 0.06822969086002559, acc: 98.74569034576416, p_norm: 1475.4625063085384, g_norm: 0.8352562662930598, lr:  0.001332, elapsed time:  32382
Step 35300, loss: 0.06999908534344286, acc: 98.715303003788, p_norm: 1476.7531506730256, g_norm: 0.7673645616528787, lr:  0.001330, elapsed time:  32470
Step 35400, loss: 0.07347278127446771, acc: 98.66734683513641, p_norm: 1478.1855723334727, g_norm: 0.7749366342196902, lr:  0.001328, elapsed time:  32562
Step 35500, loss: 0.07006348632276058, acc: 98.73379541933537, p_norm: 1479.3232885442073, g_norm: 0.7921082882209641, lr:  0.001326, elapsed time:  32647
Step 35600, loss: 0.07008270976133645, acc: 98.72283287346363, p_norm: 1480.5239319828484, g_norm: 0.6367992207473385, lr:  0.001325, elapsed time:  32737
Step 35700, loss: 0.06844659480266273, acc: 98.76032301783562, p_norm: 1481.6611861574186, g_norm: 0.7030105447330877, lr:  0.001323, elapsed time:  32826
Step 35800, loss: 0.06822118998970836, acc: 98.75717270374298, p_norm: 1482.7728476645577, g_norm: 1.0802656535741417, lr:  0.001321, elapsed time:  32917
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 35900, loss: 0.06536605781806049, acc: 98.82194930641212, p_norm: 1483.8374323613484, g_norm: 0.6736929255490366, lr:  0.001319, elapsed time:  33009
Step 36000, loss: 0.06492876298259943, acc: 98.83448933064938, p_norm: 1484.9411109703751, g_norm: 0.8504390781372732, lr:  0.001317, elapsed time:  33098
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 36000, eval loss: 0.05713340831920506, eval acc: 99.12189483642578
Step 36100, loss: 0.06532051396090538, acc: 98.80883754789829, p_norm: 1486.079333044067, g_norm: 0.8418455838569958, lr:  0.001315, elapsed time:  33203
Step 36200, loss: 0.06694118849933148, acc: 98.77544763684273, p_norm: 1487.2941703146307, g_norm: 0.8412740046070016, lr:  0.001314, elapsed time:  33294
Step 36300, loss: 0.06911141091492028, acc: 98.73671081662178, p_norm: 1488.6269704669548, g_norm: 0.655427708728017, lr:  0.001312, elapsed time:  33384
Step 36400, loss: 0.06744066016748547, acc: 98.79858273267746, p_norm: 1489.7420786603682, g_norm: 0.7992061431429164, lr:  0.001310, elapsed time:  33473
Step 36500, loss: 0.0650725666526705, acc: 98.84319140017033, p_norm: 1490.8274905229775, g_norm: 0.725211964269213, lr:  0.001308, elapsed time:  33560
Step 36600, loss: 0.06625685725361109, acc: 98.81042544543743, p_norm: 1491.8825615304183, g_norm: 0.9288337056615654, lr:  0.001306, elapsed time:  33648
Step 36700, loss: 0.9852464812248946, acc: 98.81027601659298, p_norm: 1493.1548773270051, g_norm: 0.6507360504419185, lr:  0.001305, elapsed time:  33741
Step 36800, loss: 0.0680011946009472, acc: 98.80321224033833, p_norm: 1494.303836428555, g_norm: 0.6402910655465329, lr:  0.001303, elapsed time:  33832
Step 36900, loss: 0.06914424845017493, acc: 98.77776682376862, p_norm: 1495.3886697206813, g_norm: 0.767591795908653, lr:  0.001301, elapsed time:  33921
Step 37000, loss: 0.07628585366532206, acc: 98.69906291365623, p_norm: 1496.8131811722976, g_norm: 0.7202310922258133, lr:  0.001299, elapsed time:  34011
Step 37100, loss: 0.0718598381150514, acc: 98.73973998427391, p_norm: 1497.978236710422, g_norm: 0.7645110254294041, lr:  0.001298, elapsed time:  34099
Step 37200, loss: 0.07044254641979933, acc: 98.75597354769707, p_norm: 1499.0272175263835, g_norm: 0.7052672284961977, lr:  0.001296, elapsed time:  34184
Step 37300, loss: 0.06805791995488107, acc: 98.79821713268757, p_norm: 1500.0543482384896, g_norm: 0.6694552432861176, lr:  0.001294, elapsed time:  34276
Step 37400, loss: 0.07777368715032935, acc: 98.7775247991085, p_norm: 1501.1667408533608, g_norm: 1.4201980397272504, lr:  0.001292, elapsed time:  34366
Step 37500, loss: 0.07302698449231684, acc: 98.70043550431728, p_norm: 1502.2869590077942, g_norm: 0.8249685520331816, lr:  0.001291, elapsed time:  34455
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 37600, loss: 0.07084531862455518, acc: 98.77266996535496, p_norm: 1503.3503613267903, g_norm: 0.6792780180363494, lr:  0.001289, elapsed time:  34544
Step 37700, loss: 0.06871036165393889, acc: 98.81310868263245, p_norm: 1504.4054191676094, g_norm: 0.6700497208712274, lr:  0.001287, elapsed time:  34634
Step 37800, loss: 0.06910810138098895, acc: 98.81210793554783, p_norm: 1505.7707539081325, g_norm: 0.9976420832190155, lr:  0.001285, elapsed time:  34723
Step 37900, loss: 19870.906976034184, acc: 98.76535655558109, p_norm: 1507.1009738793796, g_norm: 0.9222851837115642, lr:  0.001284, elapsed time:  34813
Step 38000, loss: 0.0710349590331316, acc: 98.80869603157043, p_norm: 1508.0716043869888, g_norm: 0.6290869733045564, lr:  0.001282, elapsed time:  34900
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 38000, eval loss: 0.055775715336203575, eval acc: 99.21719360351562
Step 38100, loss: 0.07337142299860716, acc: 98.79273182153702, p_norm: 1509.4220698092927, g_norm: 0.8372072811326641, lr:  0.001280, elapsed time:  35008
Step 38200, loss: 0.0715842720028013, acc: 98.79695162177086, p_norm: 1510.5596900952225, g_norm: 0.7329311742533877, lr:  0.001279, elapsed time:  35100
Step 38300, loss: 0.23553214870393277, acc: 98.83307895064354, p_norm: 1511.4384517144274, g_norm: 0.9951489438672562, lr:  0.001277, elapsed time:  35191
Step 38400, loss: 0.069773128926754, acc: 98.83118695020676, p_norm: 1512.4464876425911, g_norm: 0.6378457484720201, lr:  0.001275, elapsed time:  35282
Step 38500, loss: 0.07321920270100236, acc: 98.73599545657635, p_norm: 1513.6093229002975, g_norm: 0.8637397000622905, lr:  0.001274, elapsed time:  35370
Step 38600, loss: 0.07114429778419434, acc: 98.77213829755783, p_norm: 1514.5981347165923, g_norm: 0.7315310613327631, lr:  0.001272, elapsed time:  35456
Step 38700, loss: 0.07048174131661654, acc: 98.78292208909988, p_norm: 1515.6806275101956, g_norm: 0.7045039018065639, lr:  0.001270, elapsed time:  35547
Step 38800, loss: 0.06804402696900069, acc: 98.79273143410683, p_norm: 1516.6656835027466, g_norm: 0.7783857157396918, lr:  0.001269, elapsed time:  35639
Step 38900, loss: 0.06711833380162716, acc: 98.83158428966999, p_norm: 1517.5742461821005, g_norm: 0.6133855954977744, lr:  0.001267, elapsed time:  35728
Step 39000, loss: 0.06621760443784297, acc: 98.85391816496849, p_norm: 1518.465592436712, g_norm: 0.6472456064644799, lr:  0.001266, elapsed time:  35817
Step 39100, loss: 0.06528633269481361, acc: 98.8503851890564, p_norm: 1519.4028184676322, g_norm: 0.7584955878836033, lr:  0.001264, elapsed time:  35908
Step 39200, loss: 0.06585348787717521, acc: 98.83712434768677, p_norm: 1520.367444035192, g_norm: 0.7607539596564435, lr:  0.001262, elapsed time:  35996
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 39300, loss: 0.06691336889217421, acc: 98.79441471312833, p_norm: 1521.4540623180928, g_norm: 0.6776288796991324, lr:  0.001261, elapsed time:  36086
Step 39400, loss: 0.06242178786545992, acc: 98.89776253700256, p_norm: 1522.3746599870078, g_norm: 0.8943997752650108, lr:  0.001259, elapsed time:  36175
Step 39500, loss: 0.06197684409096837, acc: 98.91902101039886, p_norm: 1523.309415996889, g_norm: 0.6393187197926214, lr:  0.001258, elapsed time:  36266
Step 39600, loss: 0.0640245203115046, acc: 98.83032244443893, p_norm: 1524.2620995783934, g_norm: 0.9517424428498579, lr:  0.001256, elapsed time:  36357
Step 39700, loss: 0.06342555045615882, acc: 98.85372079908848, p_norm: 1525.3133838518881, g_norm: 0.6255601113752176, lr:  0.001254, elapsed time:  36448
Step 39800, loss: 0.06250401654280723, acc: 98.87999613583088, p_norm: 1526.3356577768445, g_norm: 0.7175550352375863, lr:  0.001253, elapsed time:  36538
Step 39900, loss: 0.06364928015973419, acc: 98.86293648183346, p_norm: 1527.3187483794843, g_norm: 0.8668281475559334, lr:  0.001251, elapsed time:  36626
Step 40000, loss: 0.06326458622235805, acc: 98.86485041677952, p_norm: 1528.2807072633568, g_norm: 0.7640928657689783, lr:  0.001250, elapsed time:  36714
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 40000, eval loss: 0.05051822151988747, eval acc: 99.30667114257812
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) C 1 C N ( C C O S ( C ) ( = O ) = O ) C C C 1 N C ( = O ) O C c 1 c c c c c 1 _EOS
Predicted text: C O C ( = O ) C 1 C N ( C C O S ( C ) ( = O ) = O ) C C C 1 N C ( = O ) O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( N c 2 c ( C # N ) c n c 3 c c ( C = C C ( = O ) O C ( C ) ( C ) C ) s c 2 3 ) c ( Cl ) c c 1 Cl _EOS
Predicted text: C O c 1 c c ( N c 2 c ( C # N ) c n c 3 c c ( C = C C ( = O ) O C ( C ) ( C ) C ) s c 2 3 ) c ( Cl ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C O c 1 c c c ( O C C = C ( c 2 c c c ( C # C C N 3 C C O C C 3 ) c c 2 ) c 2 c c c c ( C ( F ) ( F ) F ) c 2 ) c c 1 C _EOS
Predicted text: C O C ( = O ) C O c 1 c c c ( O C C = C ( c 2 c c c ( C # C C N 3 C C O C C 3 ) c c 2 ) c 2 c c c c ( C ( F ) ( F ) F ) c 2 ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: F c 1 c c c ( - c 2 n c n ( C 3 C C N C 3 ) c 2 - c 2 c c n c n 2 ) c c 1 _EOS
Predicted text: N c 1 n c c c ( - c 2 c ( - c 3 c c c ( F ) c c 3 ) n c n 2 C 2 C C N C 2 ) n 1 _EOS
acc_token: 0.23684210526315788, acc_seq: False

Target text: C C O C 1 = N C ( Cl ) = N C ( N ) N 1 O C ( F ) F _EOS
Predicted text: C C O C 1 = N C ( Cl ) = N C ( N ) N 1 O C ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 40000, eval acc (token): 0.89544388686366, eval acc (sequence): 0.8098267939201131
Saving at step 40000
Step 40100, loss: 0.061785720731131734, acc: 98.90972538292408, p_norm: 1529.2204381117454, g_norm: 0.810950415179494, lr:  0.001248, elapsed time:  36905
Step 40200, loss: 0.06351321522146464, acc: 98.88231183588505, p_norm: 1530.2049981442951, g_norm: 0.8014299718465983, lr:  0.001247, elapsed time:  36995
Step 40300, loss: 0.06339183065574616, acc: 98.86805181205273, p_norm: 1531.1999618096713, g_norm: 0.6690437010344543, lr:  0.001245, elapsed time:  37085
Step 40400, loss: 0.06566230584867298, acc: 98.80256134271622, p_norm: 1532.2683614758705, g_norm: 0.9530080074665835, lr:  0.001243, elapsed time:  37176
Step 40500, loss: 0.0635590086877346, acc: 98.8707264661789, p_norm: 1533.3106107044728, g_norm: 0.9931578509920169, lr:  0.001242, elapsed time:  37266
Step 40600, loss: 0.06349365937523543, acc: 98.85865710675716, p_norm: 1534.3014369629673, g_norm: 0.8278986053421572, lr:  0.001240, elapsed time:  37358
Step 40700, loss: 0.06474772156681866, acc: 98.84187154471874, p_norm: 1535.3038421739923, g_norm: 0.5859522519866549, lr:  0.001239, elapsed time:  37444
Step 40800, loss: 0.06429093631915749, acc: 98.83592419326305, p_norm: 1536.3114931697705, g_norm: 0.6683106881455323, lr:  0.001237, elapsed time:  37531
Step 40900, loss: 0.12286103691905736, acc: 98.8756607323885, p_norm: 1537.345917407347, g_norm: 1.099979926357015, lr:  0.001236, elapsed time:  37621
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 41000, loss: 0.062054322533327946, acc: 98.9285924002787, p_norm: 1538.3269791462703, g_norm: 0.658036795217748, lr:  0.001234, elapsed time:  37711
Step 41100, loss: 0.06345512598287315, acc: 98.8707337975502, p_norm: 1539.258663414435, g_norm: 0.7574223948317074, lr:  0.001233, elapsed time:  37798
Step 41200, loss: 0.06220814392901957, acc: 98.89724732935429, p_norm: 1540.2287557062352, g_norm: 0.6470812981498475, lr:  0.001231, elapsed time:  37888
Step 41300, loss: 0.06283995448611676, acc: 98.89815330505371, p_norm: 1541.2329317914869, g_norm: 0.7873017693370311, lr:  0.001230, elapsed time:  37980
Step 41400, loss: 0.06566513945348561, acc: 98.82240609824657, p_norm: 1542.2906581404868, g_norm: 0.7102870884129199, lr:  0.001228, elapsed time:  38070
Step 41500, loss: 0.06368524563964456, acc: 98.88805691897869, p_norm: 1543.2082526682257, g_norm: 0.7477370287440062, lr:  0.001227, elapsed time:  38160
Step 41600, loss: 0.06335250116419047, acc: 98.8874527066946, p_norm: 1544.1193964623274, g_norm: 0.7293324557343198, lr:  0.001225, elapsed time:  38251
Step 41700, loss: 0.06321076421067119, acc: 98.88241955637932, p_norm: 1545.039385330206, g_norm: 0.6020297521819089, lr:  0.001224, elapsed time:  38340
Step 41800, loss: 0.06401123682036997, acc: 98.84959262609482, p_norm: 1546.0692641989865, g_norm: 0.8228571127674013, lr:  0.001222, elapsed time:  38428
Step 41900, loss: 0.06544646324589848, acc: 98.83072370290756, p_norm: 1547.0834134146983, g_norm: 0.6734924721763764, lr:  0.001221, elapsed time:  38515
Step 42000, loss: 0.06108880941290409, acc: 98.94640626013279, p_norm: 1548.000347559929, g_norm: 0.6824658667453829, lr:  0.001220, elapsed time:  38605
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 42000, eval loss: 0.055371293798089014, eval acc: 99.21820068359375
Step 42100, loss: 0.06140012483578175, acc: 98.94239109754562, p_norm: 1548.8499448233486, g_norm: 0.8038072433589388, lr:  0.001218, elapsed time:  38710
Step 42200, loss: 0.06222814650740474, acc: 98.89670665562153, p_norm: 1549.80864638456, g_norm: 1.1979290998632015, lr:  0.001217, elapsed time:  38803
Step 42300, loss: 0.06305710138753057, acc: 98.87764538824558, p_norm: 1550.7361392433972, g_norm: 0.6119906838712045, lr:  0.001215, elapsed time:  38888
Step 42400, loss: 0.06385383376851678, acc: 98.84344498813152, p_norm: 1551.6912802848358, g_norm: 0.9416556797492539, lr:  0.001214, elapsed time:  38976
Step 42500, loss: 0.06246567994356155, acc: 98.90653885900974, p_norm: 1552.682354173752, g_norm: 0.7298140171914774, lr:  0.001212, elapsed time:  39069
Step 42600, loss: 0.06280263099353761, acc: 98.91726748645306, p_norm: 1553.5926821257299, g_norm: 0.767535381510497, lr:  0.001211, elapsed time:  39159
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 42700, loss: 0.06408196946527467, acc: 98.88310827333342, p_norm: 1554.6283674022445, g_norm: 0.8261883179214936, lr:  0.001209, elapsed time:  39248
Step 42800, loss: 0.06328812998719513, acc: 98.91224658489227, p_norm: 1555.6201562223525, g_norm: 0.7892563322263436, lr:  0.001208, elapsed time:  39338
Step 42900, loss: 0.06585258335806429, acc: 98.84248851239681, p_norm: 1556.7216312140692, g_norm: 0.5652613513070027, lr:  0.001207, elapsed time:  39426
Step 43000, loss: 0.06319714268669487, acc: 98.89390835165977, p_norm: 1557.5875619236629, g_norm: 0.7522993104286325, lr:  0.001205, elapsed time:  39517
Step 43100, loss: 0.06043154125101864, acc: 98.96710623800755, p_norm: 1558.457488738006, g_norm: 0.6541863043992378, lr:  0.001204, elapsed time:  39606
Step 43200, loss: 0.06037356847897172, acc: 98.95474022626877, p_norm: 1559.321754189056, g_norm: 0.9774856190562831, lr:  0.001202, elapsed time:  39696
Step 43300, loss: 0.06401022644713521, acc: 98.91286262869835, p_norm: 1560.3051324939693, g_norm: 0.8335758014023068, lr:  0.001201, elapsed time:  39785
Step 43400, loss: 0.06227477008476853, acc: 98.94157533347607, p_norm: 1561.282234142141, g_norm: 0.7178409948089918, lr:  0.001200, elapsed time:  39876
Step 43500, loss: 0.06248721049632877, acc: 98.92052991688251, p_norm: 1562.170231707248, g_norm: 0.8639780970020449, lr:  0.001198, elapsed time:  39967
Step 43600, loss: 0.06262225762940943, acc: 98.91556270420551, p_norm: 1563.106887350732, g_norm: 0.7042433122781041, lr:  0.001197, elapsed time:  40058
Step 43700, loss: 0.06264673434197902, acc: 98.89535899460316, p_norm: 1563.9995413399188, g_norm: 0.6991260425608959, lr:  0.001196, elapsed time:  40150
Step 43800, loss: 0.06144216453190893, acc: 98.92153495550156, p_norm: 1564.8554138485715, g_norm: 1.001349327732926, lr:  0.001194, elapsed time:  40237
Step 43900, loss: 0.06043102895841002, acc: 98.9295668900013, p_norm: 1565.754240067418, g_norm: 0.822831688027232, lr:  0.001193, elapsed time:  40327
Step 44000, loss: 0.0610784266423434, acc: 98.91385032236576, p_norm: 1566.6691291802993, g_norm: 0.8990677527236872, lr:  0.001191, elapsed time:  40416
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 44000, eval loss: 0.052392468992620726, eval acc: 99.2335205078125
Step 44100, loss: 0.06282682180404663, acc: 98.9114396572113, p_norm: 1567.5370613486832, g_norm: 0.8257881525138006, lr:  0.001190, elapsed time:  40522
Step 44200, loss: 0.06264028782956302, acc: 98.92577162384987, p_norm: 1568.4356693643513, g_norm: 0.6736404963133173, lr:  0.001189, elapsed time:  40614
Step 44300, loss: 0.07146039627492427, acc: 98.8464183807373, p_norm: 1569.4110081443525, g_norm: 0.7647055996866663, lr:  0.001187, elapsed time:  40697
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 44400, loss: 0.06303033755893447, acc: 98.93180488356882, p_norm: 1570.3091216476255, g_norm: 0.6619000239994002, lr:  0.001186, elapsed time:  40786
Step 44500, loss: 0.06423133315052837, acc: 98.9012739956379, p_norm: 1571.242677096585, g_norm: 1.167112823983216, lr:  0.001185, elapsed time:  40876
Step 44600, loss: 0.06395226505119353, acc: 98.90094904601574, p_norm: 1572.174821438118, g_norm: 0.8007203860874821, lr:  0.001183, elapsed time:  40966
Step 44700, loss: 0.07390582791529596, acc: 98.92776748538017, p_norm: 1573.031968831735, g_norm: 0.8859134522406724, lr:  0.001182, elapsed time:  41058
Step 44800, loss: 0.6907637912034988, acc: 98.87792085111141, p_norm: 1574.2140803070715, g_norm: 0.9872170286930136, lr:  0.001181, elapsed time:  41151
Step 44900, loss: 0.062474895045161245, acc: 98.92508879303932, p_norm: 1575.0423907971406, g_norm: 0.9599977535525429, lr:  0.001179, elapsed time:  41236
Step 45000, loss: 0.06163408230058849, acc: 98.94794811308384, p_norm: 1575.938959595473, g_norm: 0.6303940179338006, lr:  0.001178, elapsed time:  41327
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) c 1 c c ( S ( C ) ( = O ) = O ) c ( O c 2 c c c c ( S ( F ) ( F ) ( F ) ( F ) F ) c 2 ) c c 1 C _EOS
Predicted text: C O C ( = O ) c 1 c c ( S ( C ) ( = O ) = O ) c ( O c 2 c c c c ( S ( F ) ( F ) ( F ) ( F ) F ) c 2 ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C c 1 c [nH] c 2 c ( - c 3 c c s c 3 ) c c c c 1 2 ) N C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C C ( C ) ( C c 1 c [nH] c 2 c ( - c 3 c c s c 3 ) c c c c 1 2 ) N C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = S ) O C 1 C C C ( C N C ( = O ) c 2 c c c ( Cl ) c c 2 Cl ) ( C C 2 C C 2 ) C C 1 _EOS
Predicted text: C C ( = O ) S C 1 C C C ( C N C ( = O ) c 2 c c c ( Cl ) c c 2 Cl ) ( C C 2 C C 2 ) C C 1 _EOS
acc_token: 0.9555555555555556, acc_seq: False

Target text: C C C C C C c 1 c c c ( - c 2 c c c ( C 3 C C C ( C O ) C C 3 ) c c 2 ) n c 1 _EOS
Predicted text: C C C C C C c 1 c c c ( - c 2 c c c ( C 3 C C C ( C O ) C C 3 ) c c 2 ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 c c ( S ( = O ) c 2 c c c c c 2 ) c 2 c c c c c 2 1 _EOS
Predicted text: C n 1 c c ( S ( = O ) c 2 c c c c c 2 ) c 2 c c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 45000, eval acc (token): 0.9113213101910416, eval acc (sequence): 0.8378223495702005
Saving at step 45000
Step 45100, loss: 0.06053264898248017, acc: 98.96419654786587, p_norm: 1576.7585582504062, g_norm: 0.9498616447171929, lr:  0.001177, elapsed time:  41502
Step 45200, loss: 0.06096152118872851, acc: 98.96588331460953, p_norm: 1577.541607654415, g_norm: 0.6217330640323844, lr:  0.001176, elapsed time:  41591
Step 45300, loss: 0.06153390449471772, acc: 98.93507800996304, p_norm: 1578.3628922914495, g_norm: 0.6857113858465763, lr:  0.001174, elapsed time:  41680
Step 45400, loss: 0.06084132487419993, acc: 98.95554828643799, p_norm: 1579.2160524825372, g_norm: 0.8503883538281917, lr:  0.001173, elapsed time:  41772
Step 45500, loss: 0.060602075392380356, acc: 98.96614809334278, p_norm: 1580.038101735108, g_norm: 0.895024211503065, lr:  0.001172, elapsed time:  41861
Step 45600, loss: 0.06562789169605822, acc: 98.88513831794262, p_norm: 1580.9175047750923, g_norm: 0.5969114846725946, lr:  0.001170, elapsed time:  41951
Step 45700, loss: 0.06508699724916368, acc: 98.89321577548981, p_norm: 1581.7660679754874, g_norm: 0.6234465084096056, lr:  0.001169, elapsed time:  42039
Step 45800, loss: 0.06368559934664518, acc: 98.90306879580021, p_norm: 1582.6057486894917, g_norm: 0.985858781724446, lr:  0.001168, elapsed time:  42127
Step 45900, loss: 0.06340498650446534, acc: 98.91842287778854, p_norm: 1583.4718295085602, g_norm: 0.7330419754836762, lr:  0.001167, elapsed time:  42218
Step 46000, loss: 0.06591352782212198, acc: 98.89542077481747, p_norm: 1584.5719670350675, g_norm: 1.0120677034328165, lr:  0.001165, elapsed time:  42306
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 46000, eval loss: 0.054831131938844944, eval acc: 99.250732421875
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 46100, loss: 0.06561593791071456, acc: 98.86564609423206, p_norm: 1585.5768597120125, g_norm: 0.7943941269032038, lr:  0.001164, elapsed time:  42412
Step 46200, loss: 0.06232543373014778, acc: 98.93730214238167, p_norm: 1586.4473070102813, g_norm: 0.833560369504029, lr:  0.001163, elapsed time:  42502
Step 46300, loss: 0.06425074943806976, acc: 98.95019687712193, p_norm: 1587.2988698170298, g_norm: 0.7386717973308022, lr:  0.001161, elapsed time:  42593
Step 46400, loss: 0.062051946818828585, acc: 98.95337317883968, p_norm: 1588.096691369846, g_norm: 0.7142784600779593, lr:  0.001160, elapsed time:  42684
Step 46500, loss: 0.0620974053721875, acc: 98.9620883911848, p_norm: 1588.9313720069813, g_norm: 0.607375354233494, lr:  0.001159, elapsed time:  42773
Step 46600, loss: 0.06473407898098231, acc: 98.9175021648407, p_norm: 1589.7877920048202, g_norm: 0.7612154366197844, lr:  0.001158, elapsed time:  42861
Step 46700, loss: 0.06218778257258237, acc: 98.9515602439642, p_norm: 1590.6544671709614, g_norm: 0.792404441658074, lr:  0.001157, elapsed time:  42953
Step 46800, loss: 0.061563255270011726, acc: 98.94739411771297, p_norm: 1591.5013550511767, g_norm: 0.7308492417379514, lr:  0.001155, elapsed time:  43043
Step 46900, loss: 0.06037897625006736, acc: 98.9872414469719, p_norm: 1592.2973499871293, g_norm: 1.033442556836277, lr:  0.001154, elapsed time:  43134
Step 47000, loss: 0.06137750203255564, acc: 98.94037109613419, p_norm: 1593.0726487139716, g_norm: 0.8115799010162474, lr:  0.001153, elapsed time:  43223
Step 47100, loss: 0.061684296699240804, acc: 98.91514079272747, p_norm: 1593.897700318754, g_norm: 0.7983158647021436, lr:  0.001152, elapsed time:  43310
Step 47200, loss: 0.060869804662652315, acc: 98.94117869436741, p_norm: 1594.7563399861112, g_norm: 0.7589659706765121, lr:  0.001150, elapsed time:  43399
Step 47300, loss: 0.06070128771942109, acc: 98.95097351074219, p_norm: 1595.6584669842937, g_norm: 0.6686190295046617, lr:  0.001149, elapsed time:  43487
Step 47400, loss: 0.05984807192813605, acc: 98.95895530283451, p_norm: 1596.4258263802963, g_norm: 0.6626826802590815, lr:  0.001148, elapsed time:  43575
Step 47500, loss: 0.30696539444383236, acc: 98.79399961233139, p_norm: 1597.8385926249437, g_norm: 0.6672202828916031, lr:  0.001147, elapsed time:  43668
Step 47600, loss: 0.062170741641893984, acc: 98.93762256205082, p_norm: 1598.6275893253446, g_norm: 0.6495767668118497, lr:  0.001146, elapsed time:  43758
Step 47700, loss: 0.06054439953062683, acc: 98.94410096108913, p_norm: 1599.322816868154, g_norm: 0.9138448937912246, lr:  0.001144, elapsed time:  43845
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 47800, loss: 0.05834227632130346, acc: 99.01376048625255, p_norm: 1600.0554155434443, g_norm: 0.79095629070973, lr:  0.001143, elapsed time:  43938
Step 47900, loss: 0.05878187025897205, acc: 98.99868313968182, p_norm: 1600.796683530891, g_norm: 0.8017641654533381, lr:  0.001142, elapsed time:  44029
Step 48000, loss: 0.06532450030557811, acc: 98.99035230278969, p_norm: 1601.5992373127847, g_norm: 1.3531990858368192, lr:  0.001141, elapsed time:  44116
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 48000, eval loss: 0.04957906940951942, eval acc: 99.35521697998047
Step 48100, loss: 0.06093146905303001, acc: 98.96995404362679, p_norm: 1602.403037590934, g_norm: 0.5641918022403725, lr:  0.001140, elapsed time:  44223
Step 48200, loss: 0.059477617153897884, acc: 99.01302471756935, p_norm: 1603.1731623528049, g_norm: 0.6999712608615255, lr:  0.001138, elapsed time:  44313
Step 48300, loss: 0.05952986808028072, acc: 98.99585689604282, p_norm: 1603.9183035473106, g_norm: 0.6781903930029574, lr:  0.001137, elapsed time:  44399
Step 48400, loss: 0.06029135121032596, acc: 98.95546287298203, p_norm: 1604.6925490057702, g_norm: 0.6567774659681072, lr:  0.001136, elapsed time:  44488
Step 48500, loss: 0.059229965088889, acc: 99.00063824653625, p_norm: 1605.480809607302, g_norm: 0.8521254947093817, lr:  0.001135, elapsed time:  44578
Step 48600, loss: 0.06011563543230295, acc: 98.97805206477642, p_norm: 1606.2618458087593, g_norm: 0.9369500068412314, lr:  0.001134, elapsed time:  44670
Step 48700, loss: 0.06132072578649968, acc: 98.95667557418346, p_norm: 1607.1335348557636, g_norm: 0.7187067447274765, lr:  0.001133, elapsed time:  44758
Step 48800, loss: 0.060570880263112484, acc: 98.96067859232426, p_norm: 1607.8611118801323, g_norm: 0.6238036166021712, lr:  0.001131, elapsed time:  44846
Step 48900, loss: 0.058398279868997635, acc: 99.00360278785229, p_norm: 1608.5810589980717, g_norm: 0.6252990884132241, lr:  0.001130, elapsed time:  44939
Step 49000, loss: 0.0590141955204308, acc: 98.97814257442951, p_norm: 1609.31453210005, g_norm: 1.2199042060540743, lr:  0.001129, elapsed time:  45030
Step 49100, loss: 0.059628982413560155, acc: 98.97576397657394, p_norm: 1610.0892272865444, g_norm: 1.021586760864464, lr:  0.001128, elapsed time:  45119
Step 49200, loss: 0.059019256625324486, acc: 98.98159193992615, p_norm: 1610.9299340165928, g_norm: 0.9441244650556486, lr:  0.001127, elapsed time:  45210
Step 49300, loss: 0.05843798015266657, acc: 99.00332927703857, p_norm: 1611.668958750251, g_norm: 0.8197656036119146, lr:  0.001126, elapsed time:  45297
Step 49400, loss: 0.05913527502212673, acc: 98.9693651497364, p_norm: 1612.4179248199002, g_norm: 0.6507011946409409, lr:  0.001124, elapsed time:  45386
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 49500, loss: 0.05934112707601292, acc: 99.01689256982827, p_norm: 1613.2257131329961, g_norm: 0.723288118680657, lr:  0.001123, elapsed time:  45478
Step 49600, loss: 0.06235167210921645, acc: 98.940573990345, p_norm: 1614.1361695254898, g_norm: 0.6518338648186517, lr:  0.001122, elapsed time:  45567
Step 49700, loss: 0.060875039747916165, acc: 98.9938577413559, p_norm: 1614.961725351336, g_norm: 0.7299941227029486, lr:  0.001121, elapsed time:  45656
Step 49800, loss: 0.0650990177039057, acc: 98.91192860901356, p_norm: 1615.9145159528023, g_norm: 0.8817326292414377, lr:  0.001120, elapsed time:  45746
Step 49900, loss: 0.06353532674722373, acc: 98.92895819246769, p_norm: 1616.7164802501716, g_norm: 0.7367332968220399, lr:  0.001119, elapsed time:  45836
Step 50000, loss: 0.0652932250360027, acc: 98.92967855930328, p_norm: 1617.6516080963604, g_norm: 1.026588094531907, lr:  0.001118, elapsed time:  45928
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 50000, eval loss: 0.05291093533858656, eval acc: 99.29415893554688
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) C ( C C C C C = C ( c 1 c c c c c 1 ) c 1 c c c n c 1 ) S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 _EOS
Predicted text: C O C ( = O ) C ( C C C C C = C ( c 1 c c c c c 1 ) c 1 c c c n c 1 ) S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( S C ( C C C C ( F ) ( F ) F ) c 2 c c c ( C ( = O ) O ) c c 2 ) c c ( C ) c 1 Br _EOS
Predicted text: C c 1 c c ( S C ( C C C C ( F ) ( F ) F ) c 2 c c c ( C ( = O ) O ) c c 2 ) c c ( C ) c 1 Br _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( N C = O ) c 1 c c c 2 c ( c 1 ) n c n 2 - c 1 c c c c ( Br ) c 1 _EOS
Predicted text: C C ( N C = O ) c 1 c c c 2 c ( c 1 ) n c n 2 - c 1 c c c c ( Br ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) n 1 n n c ( C c 2 c c c c c 2 ) n 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c c ( C c 2 n n [nH] n 2 ) c c 1 _EOS
acc_token: 0.5925925925925926, acc_seq: False

Target text: C C S ( = O ) ( = O ) O _EOS
Predicted text: C C S ( = O ) ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 50000, eval acc (token): 0.91337254504806, eval acc (sequence): 0.8366364141507686
Saving at step 50000
Step 50100, loss: 0.06255943648982792, acc: 98.95550712943077, p_norm: 1618.4704246059111, g_norm: 0.796016568745977, lr:  0.001117, elapsed time:  46123
Step 50200, loss: 0.06018686995841563, acc: 98.99691861867905, p_norm: 1619.1185103653859, g_norm: 0.9408647708341591, lr:  0.001115, elapsed time:  46211
Step 50300, loss: 0.06027114844415337, acc: 98.98756593465805, p_norm: 1619.8263176081844, g_norm: 0.7112212246937346, lr:  0.001114, elapsed time:  46300
Step 50400, loss: 0.060420784601010386, acc: 98.97740045189857, p_norm: 1620.5815501352033, g_norm: 0.676072307579454, lr:  0.001113, elapsed time:  46393
Step 50500, loss: 0.0597808874072507, acc: 98.98894746601582, p_norm: 1621.349160225305, g_norm: 1.0445810950231045, lr:  0.001112, elapsed time:  46481
Step 50600, loss: 0.059684079526923596, acc: 98.99783213436604, p_norm: 1622.058544159293, g_norm: 0.6645940032096642, lr:  0.001111, elapsed time:  46571
Step 50700, loss: 0.05930125319864601, acc: 99.00691348314285, p_norm: 1622.7391666798019, g_norm: 0.6267911369159184, lr:  0.001110, elapsed time:  46657
Step 50800, loss: 0.05813319687731564, acc: 99.03246480226517, p_norm: 1623.4443937481092, g_norm: 0.7851423163735884, lr:  0.001109, elapsed time:  46746
Step 50900, loss: 0.059962864532135424, acc: 98.96604870259762, p_norm: 1624.1332178409561, g_norm: 0.9275935358509839, lr:  0.001108, elapsed time:  46834
Step 51000, loss: 0.058468475486151875, acc: 99.00563687086105, p_norm: 1624.8099606708306, g_norm: 0.9066142411052317, lr:  0.001107, elapsed time:  46923
Step 51100, loss: 0.059307365156710146, acc: 98.98474681377411, p_norm: 1625.5476641844057, g_norm: 0.6794948548044141, lr:  0.001106, elapsed time:  47011
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 51200, loss: 0.059047472143254565, acc: 99.00118791435848, p_norm: 1626.4097053546004, g_norm: 0.5751948403287083, lr:  0.001105, elapsed time:  47102
Step 51300, loss: 0.05785662150010466, acc: 99.03857128322124, p_norm: 1627.076390539469, g_norm: 0.6171550793141375, lr:  0.001103, elapsed time:  47188
Step 51400, loss: 0.05675634274259209, acc: 99.06902429461479, p_norm: 1627.7760769180034, g_norm: 0.7296316081610768, lr:  0.001102, elapsed time:  47278
Step 51500, loss: 0.05777385113295168, acc: 99.03819736838341, p_norm: 1628.5413402421354, g_norm: 0.6836736829528788, lr:  0.001101, elapsed time:  47367
Step 51600, loss: 0.05765416651032865, acc: 99.03202185034752, p_norm: 1629.258231565362, g_norm: 0.9746217319041491, lr:  0.001100, elapsed time:  47456
Step 51700, loss: 0.058373340014368294, acc: 99.01419457793236, p_norm: 1629.9719309150164, g_norm: 0.6588246411251238, lr:  0.001099, elapsed time:  47545
Step 51800, loss: 0.05782861581537872, acc: 99.01548480987549, p_norm: 1630.6547379038934, g_norm: 0.7066069803549649, lr:  0.001098, elapsed time:  47634
Step 51900, loss: 0.05653223591390997, acc: 99.05503758788109, p_norm: 1631.333938238857, g_norm: 0.6039400748128623, lr:  0.001097, elapsed time:  47724
Step 52000, loss: 0.057407296118326484, acc: 99.03078806400299, p_norm: 1632.1048599573628, g_norm: 0.6827516586650111, lr:  0.001096, elapsed time:  47813
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 52000, eval loss: 0.05158100480213763, eval acc: 99.27955627441406
Step 52100, loss: 0.057653005118481815, acc: 99.0319292396307, p_norm: 1632.8932069211864, g_norm: 0.7408087841165849, lr:  0.001095, elapsed time:  47915
Step 52200, loss: 0.05664550929795951, acc: 99.04055306315422, p_norm: 1633.627583582535, g_norm: 0.5949657400145457, lr:  0.001094, elapsed time:  48006
Step 52300, loss: 0.05809786473400891, acc: 99.03770552575588, p_norm: 1634.3620457444715, g_norm: 0.7425314481026881, lr:  0.001093, elapsed time:  48096
Step 52400, loss: 0.05828586809337139, acc: 99.0041209757328, p_norm: 1635.1192233417926, g_norm: 1.0586502247456309, lr:  0.001092, elapsed time:  48188
Step 52500, loss: 0.05888768398668617, acc: 98.98565405607224, p_norm: 1635.8373589674097, g_norm: 0.6102711244166729, lr:  0.001091, elapsed time:  48278
Step 52600, loss: 0.056174518475309014, acc: 99.05034598708153, p_norm: 1636.565353018874, g_norm: 0.5350058180412378, lr:  0.001090, elapsed time:  48370
Step 52700, loss: 0.05758575272280723, acc: 99.01973457634449, p_norm: 1637.3334246252127, g_norm: 0.744511095710827, lr:  0.001089, elapsed time:  48460
Step 52800, loss: 0.05787545092403889, acc: 99.00677567720413, p_norm: 1638.0506741140039, g_norm: 0.5866700551177404, lr:  0.001088, elapsed time:  48548
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 52900, loss: 0.05736647316935792, acc: 99.00869005058536, p_norm: 1638.7961700291564, g_norm: 0.7928475658060288, lr:  0.001087, elapsed time:  48638
Step 53000, loss: 0.055053865974768995, acc: 99.08134652674198, p_norm: 1639.476246870912, g_norm: 0.6649653571453764, lr:  0.001086, elapsed time:  48725
Step 53100, loss: 0.054587510866113007, acc: 99.08377802371979, p_norm: 1640.1554032065762, g_norm: 0.7012459105451009, lr:  0.001085, elapsed time:  48814
Step 53200, loss: 0.05521518365945667, acc: 99.07503427565098, p_norm: 1640.8432661347272, g_norm: 0.632920282956678, lr:  0.001084, elapsed time:  48901
Step 53300, loss: 0.05685540217440575, acc: 99.03391118347645, p_norm: 1641.5838447605079, g_norm: 0.6582056621046545, lr:  0.001083, elapsed time:  48990
Step 53400, loss: 0.05817818567156792, acc: 98.99052232503891, p_norm: 1642.416960560432, g_norm: 0.6241427911089715, lr:  0.001082, elapsed time:  49079
Step 53500, loss: 0.055604627719148994, acc: 99.06934356689453, p_norm: 1643.0933856894808, g_norm: 0.6943694607752, lr:  0.001081, elapsed time:  49170
Step 53600, loss: 0.05693802604917437, acc: 99.02978983521461, p_norm: 1643.834429105322, g_norm: 0.7925428144175426, lr:  0.001080, elapsed time:  49261
Step 53700, loss: 0.05892698041163385, acc: 98.98851871490479, p_norm: 1644.5893301299207, g_norm: 1.0359991984649026, lr:  0.001079, elapsed time:  49349
Step 53800, loss: 0.056526063927449285, acc: 99.06497459113598, p_norm: 1645.3486311347972, g_norm: 0.6829719948078486, lr:  0.001078, elapsed time:  49442
Step 53900, loss: 0.05813006566371769, acc: 99.02044454216957, p_norm: 1646.089223249494, g_norm: 0.6198110786236449, lr:  0.001077, elapsed time:  49531
Step 54000, loss: 0.05680876684375107, acc: 99.06021471321583, p_norm: 1646.8590624465182, g_norm: 0.6719305814157156, lr:  0.001076, elapsed time:  49623
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 54000, eval loss: 0.051710076350718746, eval acc: 99.27452850341797
Step 54100, loss: 0.05739525644574314, acc: 99.03739587962627, p_norm: 1647.5516381791208, g_norm: 0.7378684170954852, lr:  0.001075, elapsed time:  49726
Step 54200, loss: 0.05748518839478493, acc: 99.0531928986311, p_norm: 1648.2431348628534, g_norm: 0.7757430277643895, lr:  0.001074, elapsed time:  49816
Step 54300, loss: 0.05734001894015819, acc: 99.06793066859245, p_norm: 1648.9034100429076, g_norm: 0.8322120763398508, lr:  0.001073, elapsed time:  49906
Step 54400, loss: 0.0594983480963856, acc: 99.00052466988564, p_norm: 1649.6277495131446, g_norm: 1.4875842349157513, lr:  0.001072, elapsed time:  49997
Step 54500, loss: 0.1695434046909213, acc: 99.01797027885914, p_norm: 1650.3483421033775, g_norm: 0.5938636518269824, lr:  0.001071, elapsed time:  50085
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 54600, loss: 0.05892597531797874, acc: 99.03589707998493, p_norm: 1651.0274847433627, g_norm: 0.695904451122498, lr:  0.001070, elapsed time:  50176
Step 54700, loss: 0.05644365502055734, acc: 99.10502158105373, p_norm: 1651.6415599704064, g_norm: 0.6784482642358082, lr:  0.001069, elapsed time:  50264
Step 54800, loss: 0.10169720691628754, acc: 99.04234980046749, p_norm: 1652.3896512529004, g_norm: 0.6451721616942141, lr:  0.001068, elapsed time:  50352
Step 54900, loss: 0.05943371187429875, acc: 99.06927633285522, p_norm: 1653.0588784063318, g_norm: 0.7110955184275802, lr:  0.001067, elapsed time:  50446
Step 55000, loss: 0.05869059226009995, acc: 99.05079329013824, p_norm: 1653.7620249503764, g_norm: 0.595932609837877, lr:  0.001066, elapsed time:  50532
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c c 2 c c c ( = O ) n ( C C C C 3 ( C ( = O ) O ) C C N ( C C S c 4 c c c c c 4 ) C C 3 ) c 2 c 1 _EOS
Predicted text: C O c 1 c c c 2 c c c ( = O ) n ( C C C C 3 ( C ( = O ) O ) C C N ( C C S c 4 c c c c c 4 ) C C 3 ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( Cl ) c 1 c c c c c 1 _EOS
Predicted text: O = C ( Cl ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n [nH] c c 1 - c 1 c c c 2 n c c c ( N 3 C C N ( C ( = O ) N ( C ) C ) C C 3 ) c 2 c 1 _EOS
Predicted text: C c 1 n [nH] c c 1 - c 1 c c c 2 n c c c ( N 3 C C N ( C ( = O ) N ( C ) C ) C C 3 ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = c 1 c c ( C ( F ) ( F ) F ) [nH] c ( = O ) n 1 - c 1 c c ( O c 2 c c c c c 2 [N+] ( = O ) [O-] ) c ( Cl ) c c 1 F _EOS
Predicted text: O = c 1 c c ( C ( F ) ( F ) F ) [nH] c ( = O ) n 1 - c 1 c c ( O c 2 c c c c c 2 [N+] ( = O ) [O-] ) c ( Cl ) c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C O c 1 c ( C # N ) c ( - c 2 c c c ( Cl ) c c 2 Cl ) c n 2 c ( Br ) c n c 1 2 _EOS
Predicted text: C C ( C ) C O c 1 c ( C # N ) c ( - c 2 c c c ( Cl ) c c 2 Cl ) c n 2 c ( Br ) c n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 55000, eval acc (token): 0.9110581120634156, eval acc (sequence): 0.8374426118007141
Saving at step 55000
Step 55100, loss: 0.058281785389408466, acc: 99.0374384522438, p_norm: 1654.4443726681106, g_norm: 0.6414287370834607, lr:  0.001065, elapsed time:  50704
Step 55200, loss: 0.058570249783806504, acc: 99.07349096238613, p_norm: 1655.096946171734, g_norm: 0.9992805646995163, lr:  0.001064, elapsed time:  50793
Step 55300, loss: 0.06255921240895987, acc: 98.98509128391743, p_norm: 1655.9111739002926, g_norm: 0.9692567327711095, lr:  0.001063, elapsed time:  50882
Step 55400, loss: 0.06115478311665356, acc: 99.02021257579327, p_norm: 1656.6860601780709, g_norm: 0.6289335436246337, lr:  0.001062, elapsed time:  50974
Step 55500, loss: 0.059485854576341805, acc: 99.03921703994274, p_norm: 1657.3800482816216, g_norm: 0.538972519770383, lr:  0.001061, elapsed time:  51066
Step 55600, loss: 0.2095061616273597, acc: 99.02659559249878, p_norm: 1658.115057764953, g_norm: 0.7776671063392097, lr:  0.001060, elapsed time:  51157
Step 55700, loss: 0.060161948315799234, acc: 99.03210540115833, p_norm: 1658.7479087255074, g_norm: 0.7595213328430648, lr:  0.001059, elapsed time:  51247
Step 55800, loss: 0.05933123842347413, acc: 99.04327915608883, p_norm: 1659.3457506649347, g_norm: 0.6332292185635231, lr:  0.001058, elapsed time:  51337
Step 55900, loss: 0.05840753275901079, acc: 99.03831839561462, p_norm: 1659.9656871255809, g_norm: 0.6212489641463567, lr:  0.001057, elapsed time:  51426
Step 56000, loss: 0.05635097112040967, acc: 99.08386288583279, p_norm: 1660.5662429703743, g_norm: 0.6509383221008959, lr:  0.001056, elapsed time:  51516
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 56000, eval loss: 0.05010523485019803, eval acc: 99.3275375366211
Step 56100, loss: 0.05697971613612026, acc: 99.04901984333992, p_norm: 1661.1951959978628, g_norm: 0.714124176245264, lr:  0.001055, elapsed time:  51619
Step 56200, loss: 0.05716712760739028, acc: 99.04003821313381, p_norm: 1661.8298601584645, g_norm: 0.5843397309168971, lr:  0.001054, elapsed time:  51708
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 56300, loss: 0.0550126113163922, acc: 99.08694156050386, p_norm: 1662.480988222788, g_norm: 0.7558088814657573, lr:  0.001053, elapsed time:  51797
Step 56400, loss: 0.05530010310932994, acc: 99.06353424489498, p_norm: 1663.2223430170475, g_norm: 0.9984020068826601, lr:  0.001052, elapsed time:  51887
Step 56500, loss: 0.05511831544805318, acc: 99.07473877072334, p_norm: 1663.8639330475473, g_norm: 0.9968763598836864, lr:  0.001051, elapsed time:  51975
Step 56600, loss: 0.05432848718948662, acc: 99.09779578447342, p_norm: 1664.5271755633682, g_norm: 0.6493496280708532, lr:  0.001051, elapsed time:  52065
Step 56700, loss: 0.05485446959268302, acc: 99.09443044662476, p_norm: 1665.1823439724856, g_norm: 0.691974770151164, lr:  0.001050, elapsed time:  52152
Step 56800, loss: 0.05569701624102891, acc: 99.07732453942299, p_norm: 1665.8726129183635, g_norm: 0.7207603894115083, lr:  0.001049, elapsed time:  52244
Step 56900, loss: 0.05622159232851118, acc: 99.06726932525635, p_norm: 1666.5310677611137, g_norm: 0.9043759164765254, lr:  0.001048, elapsed time:  52335
Step 57000, loss: 0.055946694440208375, acc: 99.07794596254826, p_norm: 1667.1856450352375, g_norm: 0.7674766656590357, lr:  0.001047, elapsed time:  52424
Step 57100, loss: 0.056493807388469576, acc: 99.08147998154163, p_norm: 1667.8660079808812, g_norm: 0.7353524201963154, lr:  0.001046, elapsed time:  52513
Step 57200, loss: 0.05790384489577263, acc: 99.01674228906631, p_norm: 1668.5210797254865, g_norm: 0.7023134918368246, lr:  0.001045, elapsed time:  52599
Step 57300, loss: 0.054975263886153695, acc: 99.09291985630989, p_norm: 1669.2050600813318, g_norm: 0.6330934606501587, lr:  0.001044, elapsed time:  52690
Step 57400, loss: 0.060226432080380615, acc: 99.00857891142368, p_norm: 1669.9553609179645, g_norm: 1.192723663751569, lr:  0.001043, elapsed time:  52781
Step 57500, loss: 0.06240374496206641, acc: 98.99312955141068, p_norm: 1670.68835499497, g_norm: 0.715073947803366, lr:  0.001042, elapsed time:  52871
Step 57600, loss: 0.05951082954648882, acc: 99.02695010602474, p_norm: 1671.3102747113421, g_norm: 0.6643601568945452, lr:  0.001041, elapsed time:  52959
Step 57700, loss: 0.05810997786000371, acc: 99.03913789987564, p_norm: 1671.8924347462905, g_norm: 0.693624843226354, lr:  0.001040, elapsed time:  53048
Step 57800, loss: 0.056802066904492673, acc: 99.0758607685566, p_norm: 1672.5451076828685, g_norm: 0.8908864524785146, lr:  0.001040, elapsed time:  53141
Step 57900, loss: 0.056562394569627944, acc: 99.04438371956348, p_norm: 1673.1668171742194, g_norm: 0.7125085088839254, lr:  0.001039, elapsed time:  53229
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 58000, loss: 0.054060039089682974, acc: 99.11465720266621, p_norm: 1673.7511178747197, g_norm: 0.6446945383636159, lr:  0.001038, elapsed time:  53322
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 58000, eval loss: 0.04910439712926746, eval acc: 99.33406829833984
Step 58100, loss: 0.054115730142220854, acc: 99.10918653011322, p_norm: 1674.3400670993506, g_norm: 0.7147353098606186, lr:  0.001037, elapsed time:  53426
Step 58200, loss: 0.05554715652950108, acc: 99.10326823592186, p_norm: 1674.9851768698463, g_norm: 0.7594298586430855, lr:  0.001036, elapsed time:  53514
Step 58300, loss: 0.05502718269824982, acc: 99.11105641722679, p_norm: 1675.6176082550737, g_norm: 0.8607912015945329, lr:  0.001035, elapsed time:  53607
Step 58400, loss: 0.054962501688860355, acc: 99.12443405389786, p_norm: 1676.2308360780112, g_norm: 0.6803324180593351, lr:  0.001034, elapsed time:  53699
Step 58500, loss: 0.056182094165124, acc: 99.08165714144707, p_norm: 1676.8328491594204, g_norm: 0.7065718487484144, lr:  0.001033, elapsed time:  53786
Step 58600, loss: 0.057580008977092804, acc: 99.03534822165966, p_norm: 1677.6001825171104, g_norm: 0.7207598095614258, lr:  0.001032, elapsed time:  53878
Step 58700, loss: 0.07286936554592102, acc: 99.04713340103626, p_norm: 1678.5072922804684, g_norm: 1.0255025100733524, lr:  0.001032, elapsed time:  53969
Step 58800, loss: 0.05809695327654481, acc: 99.02633585035801, p_norm: 1679.1805258949576, g_norm: 0.7088029219663452, lr:  0.001031, elapsed time:  54057
Step 58900, loss: 0.055890936250798405, acc: 99.07173305749893, p_norm: 1679.7461380356829, g_norm: 0.7275660830380175, lr:  0.001030, elapsed time:  54146
Step 59000, loss: 0.054578357180580496, acc: 99.11153708398342, p_norm: 1680.3010164342484, g_norm: 0.5767472195265287, lr:  0.001029, elapsed time:  54236
Step 59100, loss: 0.05306811878457665, acc: 99.12369821965694, p_norm: 1680.8610270640693, g_norm: 0.5436068666310633, lr:  0.001028, elapsed time:  54324
Step 59200, loss: 0.053727908227592706, acc: 99.11997628211975, p_norm: 1681.3995117692477, g_norm: 0.9725121404553964, lr:  0.001027, elapsed time:  54411
Step 59300, loss: 0.05368414579425007, acc: 99.1158477216959, p_norm: 1682.0068779161168, g_norm: 0.6578056992339639, lr:  0.001026, elapsed time:  54504
Step 59400, loss: 0.054510437231510875, acc: 99.09510770440102, p_norm: 1682.616523175649, g_norm: 0.6668381929842334, lr:  0.001025, elapsed time:  54595
Step 59500, loss: 0.05623646339867264, acc: 99.04205140471458, p_norm: 1683.256065778306, g_norm: 0.9305776023068366, lr:  0.001025, elapsed time:  54687
Step 59600, loss: 0.055396513761952516, acc: 99.08032581210136, p_norm: 1683.904669440025, g_norm: 0.5741750281057036, lr:  0.001024, elapsed time:  54775
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 59700, loss: 0.054900259066086546, acc: 99.09766575242982, p_norm: 1684.4557282702053, g_norm: 1.2767471888873039, lr:  0.001023, elapsed time:  54861
Step 59800, loss: 0.052601607111282644, acc: 99.14728362858295, p_norm: 1685.0221156403409, g_norm: 0.6548272815733346, lr:  0.001022, elapsed time:  54951
Step 59900, loss: 0.05434994378592819, acc: 99.08758130669594, p_norm: 1685.5941379677586, g_norm: 0.6779480430439105, lr:  0.001021, elapsed time:  55036
Step 60000, loss: 0.05312805248890072, acc: 99.13511274755001, p_norm: 1686.2099368927445, g_norm: 0.7152949904951548, lr:  0.001020, elapsed time:  55127
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 60000, eval loss: 0.04884013595059515, eval acc: 99.34793853759766
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: N # C C N C ( = O ) C 1 C C ( S ( = O ) ( = O ) c 2 c c c c c 2 Cl ) C N 1 C ( c 1 c c c c c 1 ) C ( F ) ( F ) F _EOS
Predicted text: N # C C N C ( = O ) C 1 C C ( S ( = O ) ( = O ) c 2 c c c c c 2 Cl ) C N 1 C ( c 1 c c c c c 1 ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C 1 C C C ( c 2 c c c ( - c 3 c c ( F ) c ( [N+] ( = O ) [O-] ) c c 3 F ) c c 2 ) C C 1 _EOS
Predicted text: C C C C C C 1 C C C ( c 2 c c c ( - c 3 c c ( F ) c ( [N+] ( = O ) [O-] ) c c 3 F ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C ( = O ) c 1 c ( - c 2 c c c ( F ) c c 2 ) o c 2 n c 3 c ( c c 1 2 ) C ( C ) C N ( S ( C ) ( = O ) = O ) C C N 3 S ( C ) ( = O ) = O _EOS
Predicted text: C N C ( = O ) c 1 c ( - c 2 c c c ( F ) c c 2 ) o c 2 n c 3 c ( c c 1 2 ) C ( C O ) C N ( S ( C ) ( = O ) = O ) C C N 3 S ( C ) ( = O ) = O _EOS
acc_token: 0.5857142857142857, acc_seq: False

Target text: C C ( = O ) N 1 C C 2 C C C 3 c 4 c c c ( O ) c c 4 C C C 2 3 C 1 _EOS
Predicted text: C C ( = O ) N 1 C C 2 C C C 3 c 4 c c c ( O ) c c 4 C C C 3 ( C 1 ) C 2 _EOS
acc_token: 0.9117647058823529, acc_seq: False

Target text: O = C ( N c 1 c c c c ( Cl ) c 1 ) c 1 n c c n c 1 N c 1 c c c n c 1 _EOS
Predicted text: O = C ( N c 1 c c c c ( Cl ) c 1 ) c 1 n c c n c 1 N c 1 c c c n c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 60000, eval acc (token): 0.9176754653846945, eval acc (sequence): 0.8468619246861925
Saving at step 60000
Step 60100, loss: 0.05289623557589948, acc: 99.12695038318634, p_norm: 1686.8016830654522, g_norm: 1.1205173029684004, lr:  0.001019, elapsed time:  55310
Step 60200, loss: 0.053378275567665695, acc: 99.12694509327412, p_norm: 1687.436372713556, g_norm: 0.652163562436522, lr:  0.001019, elapsed time:  55400
Step 60300, loss: 0.05543404910247773, acc: 99.07095141708851, p_norm: 1688.055444701604, g_norm: 0.565749892152833, lr:  0.001018, elapsed time:  55485
Step 60400, loss: 0.054644626923836766, acc: 99.08990494906902, p_norm: 1688.6504535586298, g_norm: 0.6409677456911882, lr:  0.001017, elapsed time:  55573
Step 60500, loss: 0.053123003677465024, acc: 99.13469950854778, p_norm: 1689.2647843303575, g_norm: 0.7674971457899774, lr:  0.001016, elapsed time:  55664
Step 60600, loss: 0.052878181007690726, acc: 99.1395962536335, p_norm: 1689.8636831169065, g_norm: 0.7616154485904285, lr:  0.001015, elapsed time:  55755
Step 60700, loss: 0.0545728417718783, acc: 99.10312020778656, p_norm: 1690.4714906244383, g_norm: 0.6718184866885337, lr:  0.001014, elapsed time:  55844
Step 60800, loss: 0.05546827633399516, acc: 99.07316981256008, p_norm: 1691.1187348630692, g_norm: 0.8581647039911162, lr:  0.001014, elapsed time:  55934
Step 60900, loss: 0.05531370640266687, acc: 99.0739171653986, p_norm: 1691.74377410844, g_norm: 0.5792122756252722, lr:  0.001013, elapsed time:  56022
Step 61000, loss: 0.053604797120206056, acc: 99.12564581632614, p_norm: 1692.3329790624798, g_norm: 0.7058899018768886, lr:  0.001012, elapsed time:  56113
Step 61100, loss: 0.05542660775128752, acc: 99.09077963232994, p_norm: 1693.0757102967304, g_norm: 0.7187441515259149, lr:  0.001011, elapsed time:  56205
Step 61200, loss: 0.056329628294333814, acc: 99.0700258910656, p_norm: 1693.7301304079494, g_norm: 0.6562850202783606, lr:  0.001010, elapsed time:  56295
Step 61300, loss: 0.055022341362200675, acc: 99.09281907975674, p_norm: 1694.347201005459, g_norm: 0.7861977759721464, lr:  0.001009, elapsed time:  56385
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 61400, loss: 0.054199235476830754, acc: 99.10430942220664, p_norm: 1694.9572023772998, g_norm: 0.6218125914514301, lr:  0.001009, elapsed time:  56480
Step 61500, loss: 0.052499808981083335, acc: 99.15727087855339, p_norm: 1695.5064654435655, g_norm: 0.6855004822821958, lr:  0.001008, elapsed time:  56573
Step 61600, loss: 0.052724913000129166, acc: 99.13923686742783, p_norm: 1696.0543174434413, g_norm: 0.6815147293729442, lr:  0.001007, elapsed time:  56662
Step 61700, loss: 0.05400321535766125, acc: 99.10327634215355, p_norm: 1696.6343108910876, g_norm: 0.6781691710692713, lr:  0.001006, elapsed time:  56751
Step 61800, loss: 0.05381430120673031, acc: 99.12538047134876, p_norm: 1697.2213284167412, g_norm: 0.7222222244228138, lr:  0.001005, elapsed time:  56840
Step 61900, loss: 0.052872165343724194, acc: 99.13330678641796, p_norm: 1697.8219116388163, g_norm: 0.6767000739237314, lr:  0.001005, elapsed time:  56929
Step 62000, loss: 0.05318107241764665, acc: 99.12239615619183, p_norm: 1698.4212717951398, g_norm: 0.7003719483288333, lr:  0.001004, elapsed time:  57018
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 62000, eval loss: 0.04887036226689815, eval acc: 99.33985900878906
Step 62100, loss: 0.0534572344366461, acc: 99.14359803497791, p_norm: 1699.03893592056, g_norm: 0.6973787973567523, lr:  0.001003, elapsed time:  57124
Step 62200, loss: 0.05350378890987486, acc: 99.1184904128313, p_norm: 1699.619767848944, g_norm: 0.6705654612645545, lr:  0.001002, elapsed time:  57213
Step 62300, loss: 0.053553990498185156, acc: 99.10556903481483, p_norm: 1700.2115952544132, g_norm: 0.6359055657488866, lr:  0.001001, elapsed time:  57300
Step 62400, loss: 0.052465356946922836, acc: 99.15096965432167, p_norm: 1700.7560642830147, g_norm: 0.8374249424682301, lr:  0.001001, elapsed time:  57390
Step 62500, loss: 0.05337249292060733, acc: 99.12497714161873, p_norm: 1701.3409794190177, g_norm: 0.6474943081103229, lr:  0.001000, elapsed time:  57480
Step 62600, loss: 0.05264159297104925, acc: 99.14500325918198, p_norm: 1701.8981617639727, g_norm: 0.6194429703762201, lr:  0.000999, elapsed time:  57570
Step 62700, loss: 0.05340581343509257, acc: 99.12972305715084, p_norm: 1702.5127433357834, g_norm: 0.5149539408288697, lr:  0.000998, elapsed time:  57662
Step 62800, loss: 0.05300368913915008, acc: 99.1446595788002, p_norm: 1703.0860360967586, g_norm: 0.8107483577502237, lr:  0.000997, elapsed time:  57753
Step 62900, loss: 0.05423956304322928, acc: 99.10812620818615, p_norm: 1703.6910216268352, g_norm: 0.7645609676166172, lr:  0.000997, elapsed time:  57845
Step 63000, loss: 0.05554914854001254, acc: 99.07750311493874, p_norm: 1704.3108680217945, g_norm: 0.8858474952925008, lr:  0.000996, elapsed time:  57932
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 63100, loss: 0.05410398772591841, acc: 99.10919082076023, p_norm: 1704.9013716065535, g_norm: 0.7196322651276225, lr:  0.000995, elapsed time:  58022
Step 63200, loss: 0.05331289330497384, acc: 99.1652797460556, p_norm: 1705.486032447694, g_norm: 0.977067366850361, lr:  0.000994, elapsed time:  58112
Step 63300, loss: 0.05594491835683584, acc: 99.11287531256676, p_norm: 1706.0844696395056, g_norm: 0.6751491438155381, lr:  0.000993, elapsed time:  58201
Step 63400, loss: 0.05606287960428744, acc: 99.08695910871029, p_norm: 1706.6468214206166, g_norm: 0.6138507402598188, lr:  0.000993, elapsed time:  58286
Step 63500, loss: 0.05366321714129299, acc: 99.14240723848343, p_norm: 1707.2173060754092, g_norm: 0.5030495327950306, lr:  0.000992, elapsed time:  58376
Step 63600, loss: 0.052993795983493325, acc: 99.15431459248066, p_norm: 1707.7707648099974, g_norm: 0.8801849739139617, lr:  0.000991, elapsed time:  58467
Step 63700, loss: 0.05805763125885278, acc: 99.09816581010818, p_norm: 1708.4646054723144, g_norm: 0.6753348614299578, lr:  0.000990, elapsed time:  58555
Step 63800, loss: 0.055615868121385574, acc: 99.15027342736721, p_norm: 1708.9858989874397, g_norm: 0.648721771392376, lr:  0.000989, elapsed time:  58645
Step 63900, loss: 0.05484652529004961, acc: 99.13261717557907, p_norm: 1709.5109233742924, g_norm: 0.7011682485375469, lr:  0.000989, elapsed time:  58735
Step 64000, loss: 0.054173235343769194, acc: 99.13003952801228, p_norm: 1710.0675074513297, g_norm: 0.6071855480921543, lr:  0.000988, elapsed time:  58825
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 64000, eval loss: 0.048026259262114755, eval acc: 99.37936401367188
Step 64100, loss: 0.05394593350589275, acc: 99.11419574916363, p_norm: 1710.6331829001174, g_norm: 0.7677444952496768, lr:  0.000987, elapsed time:  58929
Step 64200, loss: 0.052803333299234506, acc: 99.1297802478075, p_norm: 1711.2150890384007, g_norm: 0.5754482893988929, lr:  0.000986, elapsed time:  59019
Step 64300, loss: 0.052178896251134574, acc: 99.15918628871441, p_norm: 1711.7856294926428, g_norm: 0.6328792078450063, lr:  0.000986, elapsed time:  59108
Step 64400, loss: 0.05250885674729943, acc: 99.14914025366306, p_norm: 1712.338817928731, g_norm: 0.5777393601938201, lr:  0.000985, elapsed time:  59197
Step 64500, loss: 0.05283730415161699, acc: 99.14586047828197, p_norm: 1712.8976604229354, g_norm: 0.6743530276462645, lr:  0.000984, elapsed time:  59287
Step 64600, loss: 0.05330950094852596, acc: 99.12386193871498, p_norm: 1713.48490336508, g_norm: 0.6965414775735681, lr:  0.000983, elapsed time:  59375
Step 64700, loss: 0.05363000178243965, acc: 99.11719258129597, p_norm: 1714.0809346669078, g_norm: 0.7497090199384808, lr:  0.000983, elapsed time:  59468
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 64800, loss: 0.054851940031124105, acc: 99.07880852890962, p_norm: 1714.7317990055976, g_norm: 0.7640683613790128, lr:  0.000982, elapsed time:  59561
Step 64900, loss: 0.052111867871135475, acc: 99.15363968908787, p_norm: 1715.2594925064318, g_norm: 1.021727523075926, lr:  0.000981, elapsed time:  59652
Step 65000, loss: 0.05125165630597621, acc: 99.1912931650877, p_norm: 1715.8173815412586, g_norm: 0.6316012840089658, lr:  0.000980, elapsed time:  59744
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c c ( C S c 2 n c ( C ) c ( C O ) n 2 C ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C S c 2 n c ( C ) c ( C O ) n 2 C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c c c ( C ( = O ) N c 2 n c 3 c ( s 2 ) C c 2 c c c c c 2 - 3 ) c c 1 _EOS
Predicted text: N # C c 1 c c c ( C ( = O ) N c 2 n c 3 c ( s 2 ) C c 2 c c c c c 2 - 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C 1 = N C 2 ( C O 1 ) c 1 c c ( O ) c c c 1 O c 1 n c c ( C 3 C C O C C 3 ) c c 1 2 _EOS
Predicted text: N C 1 = N C 2 ( C O 1 ) c 1 c c ( O ) c c c 1 O c 1 n c c ( C 3 C C O C C 3 ) c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C c 1 n c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) s c 1 C O c 1 c c c ( C ( = O ) O C ) c ( Cl ) c 1 _EOS
Predicted text: C C C C c 1 n c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) s c 1 C O c 1 c c c ( C ( = O ) O C ) c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 C C C ( N 2 C c 3 c ( O C c 4 c n c 5 c c c c c 5 c 4 ) c c c c 3 C 2 = O ) C ( = O ) N 1 _EOS
Predicted text: O = C 1 C C C ( N 2 C c 3 c ( O C c 4 c n c 5 c c c c c 5 c 4 ) c c c c 3 C 2 = O ) C ( = O ) N 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 65000, eval acc (token): 0.9195678176891932, eval acc (sequence): 0.8496910214467467
Saving at step 65000
Step 65100, loss: 0.05194580318406224, acc: 99.15866611897945, p_norm: 1716.3344642963336, g_norm: 0.5732242834988993, lr:  0.000980, elapsed time:  59916
Step 65200, loss: 0.051972524765878915, acc: 99.15596316754818, p_norm: 1716.914838701928, g_norm: 0.6723365257604251, lr:  0.000979, elapsed time:  60002
Step 65300, loss: 0.05158248745370656, acc: 99.1786083728075, p_norm: 1717.5146066100688, g_norm: 0.6657794720591586, lr:  0.000978, elapsed time:  60091
Step 65400, loss: 0.05369245474226773, acc: 99.13692846894264, p_norm: 1718.0698209334557, g_norm: 0.6410668286605189, lr:  0.000977, elapsed time:  60184
Step 65500, loss: 0.05275879492051899, acc: 99.14608082175255, p_norm: 1718.6636973952952, g_norm: 0.719493110316925, lr:  0.000977, elapsed time:  60275
Step 65600, loss: 0.052019188525155184, acc: 99.16530138254166, p_norm: 1719.2033823502695, g_norm: 0.6896935836025445, lr:  0.000976, elapsed time:  60363
Step 65700, loss: 0.05406695797108114, acc: 99.11181159317493, p_norm: 1719.7770748278674, g_norm: 0.5735768544303677, lr:  0.000975, elapsed time:  60450
Step 65800, loss: 0.05244103415403515, acc: 99.15038314461708, p_norm: 1720.3241455471787, g_norm: 0.7241534991297798, lr:  0.000974, elapsed time:  60541
Step 65900, loss: 0.05418551746755838, acc: 99.12223590910435, p_norm: 1720.8748421375803, g_norm: 0.5697990819310913, lr:  0.000974, elapsed time:  60627
Step 66000, loss: 0.11317745544947684, acc: 99.10748076438904, p_norm: 1721.6395434982935, g_norm: 0.80373027229548, lr:  0.000973, elapsed time:  60721
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 66000, eval loss: 0.05017906298860911, eval acc: 99.40116882324219
Step 66100, loss: 0.057333505125716326, acc: 99.09195487201214, p_norm: 1722.2633761873742, g_norm: 0.6534180684780151, lr:  0.000972, elapsed time:  60824
Step 66200, loss: 0.05413546237628907, acc: 99.16482612490654, p_norm: 1722.75729201972, g_norm: 0.7056315159673011, lr:  0.000971, elapsed time:  60914
Step 66300, loss: 0.05650349098723382, acc: 99.12281388044357, p_norm: 1723.2412303944213, g_norm: 0.8213216318869812, lr:  0.000971, elapsed time:  61002
Step 66400, loss: 0.07530749647412449, acc: 99.14192788302898, p_norm: 1723.7838259546143, g_norm: 0.6305728484614402, lr:  0.000970, elapsed time:  61093
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 66500, loss: 0.0559417711566237, acc: 99.13424321498823, p_norm: 1724.2898383532183, g_norm: 0.6119660969269024, lr:  0.000969, elapsed time:  61182
Step 66600, loss: 0.05415422747377306, acc: 99.16332730650902, p_norm: 1724.809361950104, g_norm: 0.6576505610669618, lr:  0.000968, elapsed time:  61272
Step 66700, loss: 0.054850594513118266, acc: 99.16558428108692, p_norm: 1725.3554891254971, g_norm: 0.8957464380284563, lr:  0.000968, elapsed time:  61360
Step 66800, loss: 0.05473884643055499, acc: 99.17685729265213, p_norm: 1725.7877374159007, g_norm: 0.6316738531390942, lr:  0.000967, elapsed time:  61449
Step 66900, loss: 0.05464111446868628, acc: 99.16748198866844, p_norm: 1726.2769578718219, g_norm: 0.8330977741054009, lr:  0.000966, elapsed time:  61539
Step 67000, loss: 0.055120839597657324, acc: 99.13593728840351, p_norm: 1726.7202003871, g_norm: 0.8158705101068999, lr:  0.000966, elapsed time:  61626
Step 67100, loss: 0.0526384891429916, acc: 99.1834025233984, p_norm: 1727.2491248712633, g_norm: 0.7943765339864138, lr:  0.000965, elapsed time:  61717
Step 67200, loss: 0.0549230480985716, acc: 99.12700462341309, p_norm: 1727.7716256705892, g_norm: 0.8764991866319963, lr:  0.000964, elapsed time:  61808
Step 67300, loss: 0.0530164938652888, acc: 99.1810944378376, p_norm: 1728.3220822548665, g_norm: 0.5624284968460841, lr:  0.000963, elapsed time:  61902
Step 67400, loss: 0.05336520155891776, acc: 99.13225439190865, p_norm: 1728.8368972780622, g_norm: 0.65800599381309, lr:  0.000963, elapsed time:  61988
Step 67500, loss: 0.052464971840381625, acc: 99.16014485061169, p_norm: 1729.3602486183393, g_norm: 0.6882713208089531, lr:  0.000962, elapsed time:  62077
Step 67600, loss: 0.05182998978532851, acc: 99.169626891613, p_norm: 1729.9242885310482, g_norm: 0.7474539332937321, lr:  0.000961, elapsed time:  62166
Step 67700, loss: 0.05256522610783577, acc: 99.14840041100979, p_norm: 1730.4921423688722, g_norm: 0.763252100177088, lr:  0.000961, elapsed time:  62256
Step 67800, loss: 0.05113617486320436, acc: 99.19051766395569, p_norm: 1731.0161364821806, g_norm: 0.5856724446311395, lr:  0.000960, elapsed time:  62343
Step 67900, loss: 0.051081086648628114, acc: 99.18403153121471, p_norm: 1731.5335219997603, g_norm: 0.663802427418152, lr:  0.000959, elapsed time:  62436
Step 68000, loss: 0.052296088142320514, acc: 99.15589904785156, p_norm: 1732.0574921767122, g_norm: 0.7633723744070932, lr:  0.000958, elapsed time:  62523
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 68000, eval loss: 0.04606170091778039, eval acc: 99.4139404296875
Step 68100, loss: 0.05368047650903463, acc: 99.14054128527641, p_norm: 1732.745724310892, g_norm: 0.9312177891985097, lr:  0.000958, elapsed time:  62630
Step 68200, loss: 0.05301119657699019, acc: 99.17032893002033, p_norm: 1733.2757971244394, g_norm: 0.8589411016178142, lr:  0.000957, elapsed time:  62720
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 68300, loss: 0.05266227206173665, acc: 99.1704473720295, p_norm: 1733.8260488929413, g_norm: 0.7740963793165085, lr:  0.000956, elapsed time:  62809
Step 68400, loss: 0.05424615419935435, acc: 99.13059286773205, p_norm: 1734.3049732875402, g_norm: 0.8266749572897156, lr:  0.000956, elapsed time:  62896
Step 68500, loss: 0.053230548868887125, acc: 99.16788011789322, p_norm: 1734.8171344104633, g_norm: 0.556094908397448, lr:  0.000955, elapsed time:  62987
Step 68600, loss: 0.053135937210172415, acc: 99.14746609330177, p_norm: 1735.3245193599912, g_norm: 0.7271737153296243, lr:  0.000954, elapsed time:  63074
Step 68700, loss: 0.05226461679674685, acc: 99.17096875607967, p_norm: 1735.8181515878573, g_norm: 0.7178683655390125, lr:  0.000954, elapsed time:  63160
Step 68800, loss: 0.0511431211233139, acc: 99.20719642937183, p_norm: 1736.32808100923, g_norm: 1.6404227600450656, lr:  0.000953, elapsed time:  63251
Step 68900, loss: 0.05202826021239162, acc: 99.16873969137669, p_norm: 1736.8329780919744, g_norm: 0.5329558425285778, lr:  0.000952, elapsed time:  63342
Step 69000, loss: 0.05274271818809211, acc: 99.13506257534027, p_norm: 1737.3497987909896, g_norm: 0.5634713188053244, lr:  0.000951, elapsed time:  63432
Step 69100, loss: 0.05292066596914083, acc: 99.17204350233078, p_norm: 1737.8687297953497, g_norm: 0.5501873865567352, lr:  0.000951, elapsed time:  63521
Step 69200, loss: 0.05270055699162185, acc: 99.19471244513988, p_norm: 1738.3767100593127, g_norm: 0.7408087491293824, lr:  0.000950, elapsed time:  63611
Step 69300, loss: 0.05255776314530522, acc: 99.17920324206352, p_norm: 1738.8861307771363, g_norm: 0.6735143867902506, lr:  0.000949, elapsed time:  63701
Step 69400, loss: 0.05236224672291428, acc: 99.16039279103279, p_norm: 1739.363538521631, g_norm: 0.8434427221743341, lr:  0.000949, elapsed time:  63789
Step 69500, loss: 0.05229629272595048, acc: 99.18812404572964, p_norm: 1739.8700401283604, g_norm: 0.8265422381796074, lr:  0.000948, elapsed time:  63879
Step 69600, loss: 0.05188302433118224, acc: 99.1893009096384, p_norm: 1740.4032987350267, g_norm: 0.8411332367608035, lr:  0.000947, elapsed time:  63973
Step 69700, loss: 0.05277816041838378, acc: 99.15365998446941, p_norm: 1740.9207604997036, g_norm: 0.754917307049903, lr:  0.000947, elapsed time:  64064
Step 69800, loss: 0.053347651376388965, acc: 99.12932598590851, p_norm: 1741.450079725125, g_norm: 0.6774947539978512, lr:  0.000946, elapsed time:  64153
Step 69900, loss: 0.051315115573816, acc: 99.17464625835419, p_norm: 1741.9511909453354, g_norm: 0.7149360621471307, lr:  0.000945, elapsed time:  64243
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 70000, loss: 0.05114119095421994, acc: 99.18458989603603, p_norm: 1742.4677215677557, g_norm: 0.7447603270523253, lr:  0.000945, elapsed time:  64331
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 70000, eval loss: 0.048087635580450316, eval acc: 99.3665771484375
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( C ( = O ) N C 1 ( c 2 c c c c c 2 ) C C C ( = O ) C C 1 ) c 1 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 1 _EOS
Predicted text: C C ( C ) ( C ( = O ) N C 1 ( c 2 c c c c c 2 ) C C C ( = O ) C C 1 ) c 1 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: Br C C C C C C C 1 C C C C C 1 _EOS
Predicted text: Br C C C C C C C 1 C C C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C # C c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c c c ( N ) c 1 C # N _EOS
Predicted text: C c 1 c ( C # C c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c c c ( N ) c 1 C # N _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 n c c ( Cl ) c 1 - c 1 c c ( C ( = O ) O ) o c 1 Cl _EOS
Predicted text: C n 1 n c c ( Cl ) c 1 - c 1 c c ( C ( = O ) O ) o c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C S ( = O ) ( = O ) c 1 c c c 2 o c ( N 3 C C N ( C ( = O ) c 4 c c ( S ( C ) ( = O ) = O ) c c c 4 O C C ( C ) C ) C C 3 ) n c 2 c 1 _EOS
Predicted text: C C S ( = O ) ( = O ) c 1 c c c 2 o c ( N 3 C C N ( C ( = O ) c 4 c c ( S ( C ) ( = O ) = O ) c c c 4 O C C ( C ) C ) C C 3 ) n c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 70000, eval acc (token): 0.9215934010507189, eval acc (sequence): 0.852665102246061
Saving at step 70000
Step 70100, loss: 0.04979601131752134, acc: 99.21628214418888, p_norm: 1743.0092761734145, g_norm: 0.7940133337387353, lr:  0.000944, elapsed time:  64516
Step 70200, loss: 0.04930481645744294, acc: 99.22745057940483, p_norm: 1743.4955208282445, g_norm: 0.6465535949287695, lr:  0.000943, elapsed time:  64605
Step 70300, loss: 0.05128248040098697, acc: 99.18487372994423, p_norm: 1744.0235627480683, g_norm: 0.6998990732027077, lr:  0.000943, elapsed time:  64697
Step 70400, loss: 0.052101447051391005, acc: 99.16461093723774, p_norm: 1744.6011603017641, g_norm: 0.7651012759513137, lr:  0.000942, elapsed time:  64789
Step 70500, loss: 0.052366434512659904, acc: 99.1574539989233, p_norm: 1745.1409012316024, g_norm: 2.0651425303016175, lr:  0.000941, elapsed time:  64880
Step 70600, loss: 0.052117885835468766, acc: 99.16625674068928, p_norm: 1745.679399397789, g_norm: 0.5829996995219306, lr:  0.000941, elapsed time:  64967
Step 70700, loss: 0.05115449476055801, acc: 99.19629970192909, p_norm: 1746.1705361634495, g_norm: 0.7231811631919428, lr:  0.000940, elapsed time:  65055
Step 70800, loss: 0.0507730209082365, acc: 99.20039868354797, p_norm: 1746.639289679802, g_norm: 0.9563050677001244, lr:  0.000939, elapsed time:  65145
Step 70900, loss: 0.051423478750512, acc: 99.18134903907776, p_norm: 1747.1542662326074, g_norm: 0.7972686590331267, lr:  0.000939, elapsed time:  65237
Step 71000, loss: 0.05156341624446213, acc: 99.18481726944447, p_norm: 1747.68477936662, g_norm: 0.7450362048606568, lr:  0.000938, elapsed time:  65323
Step 71100, loss: 0.05012254831846803, acc: 99.21027347445488, p_norm: 1748.1843877420783, g_norm: 0.7345663722432527, lr:  0.000937, elapsed time:  65414
Step 71200, loss: 0.05073878110386431, acc: 99.19801926612854, p_norm: 1748.6742457666612, g_norm: 0.5086877089599796, lr:  0.000937, elapsed time:  65501
Step 71300, loss: 0.05158272373490035, acc: 99.19395716488361, p_norm: 1749.2875097304218, g_norm: 0.7264969213474447, lr:  0.000936, elapsed time:  65589
Step 71400, loss: 0.05196147139184177, acc: 99.19870495796204, p_norm: 1749.8058462298325, g_norm: 0.6178316158383789, lr:  0.000935, elapsed time:  65682
Step 71500, loss: 0.05303711131680757, acc: 99.1763674467802, p_norm: 1750.3908452867727, g_norm: 0.5919383630364069, lr:  0.000935, elapsed time:  65771
Step 71600, loss: 0.05318712320644409, acc: 99.17152006924152, p_norm: 1750.8925453127763, g_norm: 0.6829857056448028, lr:  0.000934, elapsed time:  65859
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 71700, loss: 0.052146499292467424, acc: 99.19250035108468, p_norm: 1751.3846968622106, g_norm: 0.6573522406597136, lr:  0.000933, elapsed time:  65951
Step 71800, loss: 0.11829180750064552, acc: 99.24055677652359, p_norm: 1751.853764146619, g_norm: 0.7879480995491013, lr:  0.000933, elapsed time:  66045
Step 71900, loss: 0.05256197575014085, acc: 99.1990673840046, p_norm: 1752.3179569415365, g_norm: 0.8596722544680576, lr:  0.000932, elapsed time:  66133
Step 72000, loss: 0.051942178262397644, acc: 99.1928218305111, p_norm: 1752.7819166084885, g_norm: 0.645218975684264, lr:  0.000931, elapsed time:  66222
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 72000, eval loss: 0.04847576154395938, eval acc: 99.39002227783203
Step 72100, loss: 0.05133371545933187, acc: 99.20261676609516, p_norm: 1753.2770571425363, g_norm: 0.7212715579875035, lr:  0.000931, elapsed time:  66327
Step 72200, loss: 0.052196900057606396, acc: 99.16578602790833, p_norm: 1753.7572947246679, g_norm: 0.7500849011323585, lr:  0.000930, elapsed time:  66415
Step 72300, loss: 0.05101566969417035, acc: 99.19590318202972, p_norm: 1754.2519990037276, g_norm: 0.5629811129627985, lr:  0.000929, elapsed time:  66503
Step 72400, loss: 0.052759609357453885, acc: 99.16738960146904, p_norm: 1754.7884419714965, g_norm: 0.7537497525105711, lr:  0.000929, elapsed time:  66591
Step 72500, loss: 0.05282797975465656, acc: 99.1852440983057, p_norm: 1755.3325592130232, g_norm: 0.7699773519340647, lr:  0.000928, elapsed time:  66681
Step 72600, loss: 0.050076732020825146, acc: 99.24611246585846, p_norm: 1755.8038848746266, g_norm: 0.6195004155807013, lr:  0.000928, elapsed time:  66773
Step 72700, loss: 0.052036481387913225, acc: 99.18560408055782, p_norm: 1756.2679886339436, g_norm: 0.6206487059794645, lr:  0.000927, elapsed time:  66862
Step 72800, loss: 0.052013351283967495, acc: 99.17174834012985, p_norm: 1756.758465603544, g_norm: 0.6595511304650017, lr:  0.000926, elapsed time:  66949
Step 72900, loss: 0.05120265055913478, acc: 99.21611167490482, p_norm: 1757.3002117572214, g_norm: 0.6014772799551144, lr:  0.000926, elapsed time:  67039
Step 73000, loss: 0.05236710834316909, acc: 99.17338520288467, p_norm: 1757.778906653081, g_norm: 0.7733413877366327, lr:  0.000925, elapsed time:  67127
Step 73100, loss: 0.05149240551982075, acc: 99.18627128005028, p_norm: 1758.2810388086698, g_norm: 0.8925875564124228, lr:  0.000924, elapsed time:  67217
Step 73200, loss: 0.052001874269917606, acc: 99.17658764123917, p_norm: 1758.809250441621, g_norm: 0.6405490570908289, lr:  0.000924, elapsed time:  67308
Step 73300, loss: 0.051549171302467583, acc: 99.19417782127857, p_norm: 1759.2886662385863, g_norm: 0.5757633398002638, lr:  0.000923, elapsed time:  67398
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 73400, loss: 0.049871455947348556, acc: 99.23044645756706, p_norm: 1759.769026627869, g_norm: 0.6312113687624684, lr:  0.000922, elapsed time:  67488
Step 73500, loss: 0.051108697825111446, acc: 99.21136970818043, p_norm: 1760.2468763057525, g_norm: 0.5711486531438928, lr:  0.000922, elapsed time:  67578
Step 73600, loss: 0.05060390126425773, acc: 99.22501689195633, p_norm: 1760.759177567507, g_norm: 0.8309154232866515, lr:  0.000921, elapsed time:  67671
Step 73700, loss: 0.0502562750922516, acc: 99.22529451549053, p_norm: 1761.2569235231183, g_norm: 0.490575363518334, lr:  0.000921, elapsed time:  67762
Step 73800, loss: 0.05146098566707224, acc: 99.18090617656708, p_norm: 1761.810499035187, g_norm: 0.5981778375257016, lr:  0.000920, elapsed time:  67854
Step 73900, loss: 0.050430383863858876, acc: 99.20611408352852, p_norm: 1762.3277919230936, g_norm: 0.714972096869763, lr:  0.000919, elapsed time:  67943
Step 74000, loss: 0.050118612460792064, acc: 99.19810308516026, p_norm: 1762.7837686680994, g_norm: 0.6006373691547369, lr:  0.000919, elapsed time:  68031
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 74000, eval loss: 0.045693028625100864, eval acc: 99.42501068115234
Step 74100, loss: 0.05022181023377925, acc: 99.2042730152607, p_norm: 1763.2504748761094, g_norm: 0.5287913358114225, lr:  0.000918, elapsed time:  68135
Step 74200, loss: 0.04930600738152861, acc: 99.23778294026852, p_norm: 1763.7453105473878, g_norm: 0.6764923022381608, lr:  0.000918, elapsed time:  68226
Step 74300, loss: 0.05009000918827951, acc: 99.20967227220535, p_norm: 1764.261741353451, g_norm: 0.6042154944735288, lr:  0.000917, elapsed time:  68315
Step 74400, loss: 0.04918137030210346, acc: 99.23778952658176, p_norm: 1764.7152970480065, g_norm: 0.5344291019744347, lr:  0.000916, elapsed time:  68403
Step 74500, loss: 0.05018975180573761, acc: 99.20454305410385, p_norm: 1765.1854595386635, g_norm: 0.7597690035933173, lr:  0.000916, elapsed time:  68493
Step 74600, loss: 0.05213231663685292, acc: 99.21181263029575, p_norm: 1765.7110253315263, g_norm: 0.6639035607093328, lr:  0.000915, elapsed time:  68583
Step 74700, loss: 0.05458824491593987, acc: 99.12936702370644, p_norm: 1766.2274530186216, g_norm: 0.8550957277015062, lr:  0.000914, elapsed time:  68673
Step 74800, loss: 0.05335886732675135, acc: 99.16414518654346, p_norm: 1766.7186809381672, g_norm: 0.7271298382756537, lr:  0.000914, elapsed time:  68762
Step 74900, loss: 0.051522365640848874, acc: 99.19096682965755, p_norm: 1767.160911741203, g_norm: 0.6729427362468223, lr:  0.000913, elapsed time:  68852
Step 75000, loss: 0.053218862218782303, acc: 99.14463226497173, p_norm: 1767.6419468979027, g_norm: 0.68595754462663, lr:  0.000913, elapsed time:  68939
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) c 1 c c c c ( C c 2 c c c ( C O c 3 c c c ( C ( C ) = O ) c ( O ) c 3 - c 3 c c c c n 3 ) c c 2 ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c c ( C c 2 c c c ( C O c 3 c c c ( C ( C ) = O ) c ( O ) c 3 - c 3 c c c c n 3 ) c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: c 1 c n ( C C 2 C C C C C C 2 ) c n 1 _EOS
Predicted text: c 1 c n ( C C 2 C C C C C C 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( O ) C C c 1 n c ( N N ) c c ( N 2 C C O C C 2 ) n 1 _EOS
Predicted text: C C ( C ) ( O ) C C c 1 n c ( N N ) c c ( N 2 C C O C C 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C 1 C N ( C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) C 1 _EOS
Predicted text: O = C 1 c 2 c c c c c 2 C ( = O ) N 1 C 1 C N ( C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) C 1 _EOS
acc_token: 0.10344827586206896, acc_seq: False

Target text: C C O C C C N C ( = O ) c 1 c c 2 [nH] n c ( - c 3 c c 4 c c ( C O ) c c c 4 [nH] 3 ) c 2 s 1 _EOS
Predicted text: C C O C C C N C ( = O ) c 1 c c 2 [nH] n c ( - c 3 c c 4 c c ( C O ) c c c 4 [nH] 3 ) c 2 s 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 75000, eval acc (token): 0.9219889473045245, eval acc (sequence): 0.8533587257617729
Saving at step 75000
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 75100, loss: 0.04959528840079941, acc: 99.2392060478627, p_norm: 1768.095580206955, g_norm: 0.7260196966640068, lr:  0.000912, elapsed time:  69110
Step 75200, loss: 0.05084379381500184, acc: 99.19240821897984, p_norm: 1768.596920580398, g_norm: 0.7116568219553987, lr:  0.000911, elapsed time:  69200
Step 75300, loss: 0.05005703450646251, acc: 99.21669229865074, p_norm: 1769.018967319232, g_norm: 0.6523455702236372, lr:  0.000911, elapsed time:  69289
Step 75400, loss: 0.05035559204407036, acc: 99.19439215958118, p_norm: 1769.4958917467393, g_norm: 0.716575744606399, lr:  0.000910, elapsed time:  69374
Step 75500, loss: 0.049171846876852214, acc: 99.2270867228508, p_norm: 1769.9120160841937, g_norm: 0.5917810509821414, lr:  0.000910, elapsed time:  69461
Step 75600, loss: 0.049742728853598234, acc: 99.20942586660385, p_norm: 1770.373884761471, g_norm: 0.6582990344544845, lr:  0.000909, elapsed time:  69550
Step 75700, loss: 0.050999859739094974, acc: 99.19993548095226, p_norm: 1770.8702978978533, g_norm: 0.6134016871519435, lr:  0.000908, elapsed time:  69640
Step 75800, loss: 0.04928538647014648, acc: 99.23336178064346, p_norm: 1771.3649294991583, g_norm: 1.0968872862617323, lr:  0.000908, elapsed time:  69730
Step 75900, loss: 0.049787793573923406, acc: 99.22439689934254, p_norm: 1771.8832445430226, g_norm: 0.9053525409999028, lr:  0.000907, elapsed time:  69820
Step 76000, loss: 0.049079438108019534, acc: 99.24927735328674, p_norm: 1772.380684301471, g_norm: 0.6353569177718531, lr:  0.000907, elapsed time:  69911
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 76000, eval loss: 0.04833901012316345, eval acc: 99.33576965332031
Step 76100, loss: 0.049137553120963275, acc: 99.23536351323128, p_norm: 1772.847777804317, g_norm: 0.686442714532594, lr:  0.000906, elapsed time:  70017
Step 76200, loss: 0.04980597564484924, acc: 99.2237274646759, p_norm: 1773.3177377405289, g_norm: 0.6819031118438883, lr:  0.000905, elapsed time:  70108
Step 76300, loss: 0.04945070320740342, acc: 99.23019063472748, p_norm: 1773.742510697856, g_norm: 0.594800334992557, lr:  0.000905, elapsed time:  70197
Step 76400, loss: 0.04948024349287152, acc: 99.23938369750977, p_norm: 1774.2282893421916, g_norm: 0.6475992606585128, lr:  0.000904, elapsed time:  70290
Step 76500, loss: 0.05087130816653371, acc: 99.19315874576569, p_norm: 1774.6791616230528, g_norm: 0.6368635854386245, lr:  0.000904, elapsed time:  70378
Step 76600, loss: 0.049673586110584436, acc: 99.22874253988266, p_norm: 1775.1415899978067, g_norm: 0.7230136622358139, lr:  0.000903, elapsed time:  70464
Step 76700, loss: 0.04920586924999952, acc: 99.23241943120956, p_norm: 1775.5962740078205, g_norm: 0.7364281911979298, lr:  0.000902, elapsed time:  70556
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 76800, loss: 0.04882623590714303, acc: 99.23903830905459, p_norm: 1776.0564365039834, g_norm: 0.6789899482783615, lr:  0.000902, elapsed time:  70646
Step 76900, loss: 0.04912416025996208, acc: 99.23437549173832, p_norm: 1776.5517292825148, g_norm: 0.6536035491122356, lr:  0.000901, elapsed time:  70736
Step 77000, loss: 0.04895970170386135, acc: 99.23404560983181, p_norm: 1777.0356309353845, g_norm: 0.8093989772604154, lr:  0.000901, elapsed time:  70823
Step 77100, loss: 0.0503183003468439, acc: 99.2200367897749, p_norm: 1777.5021223088827, g_norm: 0.7281169745620606, lr:  0.000900, elapsed time:  70908
Step 77200, loss: 0.04846062615513801, acc: 99.26424784958363, p_norm: 1777.963949953881, g_norm: 0.5999574777120344, lr:  0.000900, elapsed time:  70999
Step 77300, loss: 0.049005814706906674, acc: 99.2326839864254, p_norm: 1778.4231066007778, g_norm: 0.7795718410158199, lr:  0.000899, elapsed time:  71087
Step 77400, loss: 0.04928584228735417, acc: 99.23248919844627, p_norm: 1778.8623202320302, g_norm: 0.6192414586037521, lr:  0.000898, elapsed time:  71174
Step 77500, loss: 0.04992534527089447, acc: 99.21820770204067, p_norm: 1779.3600257189455, g_norm: 1.0627132237530217, lr:  0.000898, elapsed time:  71265
Step 77600, loss: 0.05093454845249653, acc: 99.19677998125553, p_norm: 1779.947697619513, g_norm: 0.6302649300345232, lr:  0.000897, elapsed time:  71354
Step 77700, loss: 0.050505472011864186, acc: 99.20628049969673, p_norm: 1780.4178984032721, g_norm: 0.620469767259901, lr:  0.000897, elapsed time:  71443
Step 77800, loss: 0.049557833774015306, acc: 99.22419229149818, p_norm: 1780.8618752878467, g_norm: 0.689717494359217, lr:  0.000896, elapsed time:  71534
Step 77900, loss: 0.05027593697421253, acc: 99.21170473098755, p_norm: 1781.3315666219046, g_norm: 0.8377564745850435, lr:  0.000895, elapsed time:  71623
Step 78000, loss: 0.052875915472395715, acc: 99.20859581232071, p_norm: 1781.879791419058, g_norm: 0.7339441775018848, lr:  0.000895, elapsed time:  71714
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 78000, eval loss: 0.05105673527345062, eval acc: 99.32989501953125
Step 78100, loss: 0.05269181345589459, acc: 99.19949516654015, p_norm: 1782.386334791512, g_norm: 0.8238832209936311, lr:  0.000894, elapsed time:  71825
Step 78200, loss: 0.05149667970836162, acc: 99.21353852748871, p_norm: 1782.8508930019595, g_norm: 0.5925239738289018, lr:  0.000894, elapsed time:  71918
Step 78300, loss: 0.050656640296801926, acc: 99.22718614339828, p_norm: 1783.2783740576413, g_norm: 0.7448253182672975, lr:  0.000893, elapsed time:  72008
Step 78400, loss: 0.05108182786032558, acc: 99.21204455196857, p_norm: 1783.7028255971768, g_norm: 0.6529193114203755, lr:  0.000893, elapsed time:  72095
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 78500, loss: 0.05041167097485095, acc: 99.2214585356322, p_norm: 1784.1394913954427, g_norm: 0.6692117141611328, lr:  0.000892, elapsed time:  72184
Step 78600, loss: 0.05050462446641177, acc: 99.2203857600689, p_norm: 1784.5654199652527, g_norm: 0.7107978201005574, lr:  0.000891, elapsed time:  72272
Step 78700, loss: 0.048652405496686695, acc: 99.27278216183186, p_norm: 1784.971209040582, g_norm: 6.922565109344233, lr:  0.000891, elapsed time:  72363
Step 78800, loss: 0.04941400211304426, acc: 99.25115798413754, p_norm: 1785.4240111135368, g_norm: 0.646156772732393, lr:  0.000890, elapsed time:  72452
Step 78900, loss: 0.050142013845033945, acc: 99.23794087767601, p_norm: 1785.8626157809986, g_norm: 0.7750244515495724, lr:  0.000890, elapsed time:  72542
Step 79000, loss: 0.05001087970100343, acc: 99.23831036686897, p_norm: 1786.3138996703121, g_norm: 0.7545062346598729, lr:  0.000889, elapsed time:  72630
Step 79100, loss: 0.04970856791362167, acc: 99.23649276793003, p_norm: 1786.7494950445362, g_norm: 1.0054100598234954, lr:  0.000889, elapsed time:  72722
Step 79200, loss: 0.04924661274533719, acc: 99.24739573895931, p_norm: 1787.2208691125552, g_norm: 0.7296252300675462, lr:  0.000888, elapsed time:  72814
Step 79300, loss: 0.04934637291356921, acc: 99.23124414682388, p_norm: 1787.6667667937245, g_norm: 0.7560783410684004, lr:  0.000888, elapsed time:  72904
Step 79400, loss: 0.0497047184035182, acc: 99.23793333768845, p_norm: 1788.1091646348832, g_norm: 0.6272946839591359, lr:  0.000887, elapsed time:  72990
Step 79500, loss: 0.04976085987873376, acc: 99.21766202151775, p_norm: 1788.5444408787546, g_norm: 0.5615101819146623, lr:  0.000886, elapsed time:  73081
Step 79600, loss: 0.049057680685073136, acc: 99.24662014842033, p_norm: 1788.9714173402297, g_norm: 0.7485500939169842, lr:  0.000886, elapsed time:  73170
Step 79700, loss: 0.04878692595753819, acc: 99.2480341643095, p_norm: 1789.4090104834575, g_norm: 0.5196101621271939, lr:  0.000885, elapsed time:  73260
Step 79800, loss: 0.049446944687515496, acc: 99.22703686356544, p_norm: 1789.858392506893, g_norm: 0.6645673219628027, lr:  0.000885, elapsed time:  73353
Step 79900, loss: 0.049783195834606886, acc: 99.22560273110867, p_norm: 1790.3222448283468, g_norm: 0.5249362409182493, lr:  0.000884, elapsed time:  73441
Step 80000, loss: 0.04939324545674026, acc: 99.23839917778969, p_norm: 1790.7451296806494, g_norm: 0.8658861292527313, lr:  0.000884, elapsed time:  73530
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 80000, eval loss: 0.044621297083795086, eval acc: 99.43319702148438
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C C C C O c 1 c c ( C ( = O ) N C ( C c 2 c c c c c 2 ) C ( O ) C N ) c c ( N 2 C C C C 2 = O ) c 1 _EOS
Predicted text: C C C C C O c 1 c c ( C ( = O ) N C ( C c 2 c c c c c 2 ) C ( O ) C N ) c c ( N 2 C C C C 2 = O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( N C C O c 1 c c c ( - c 2 c c c ( O C C ( = O ) O ) c c 2 ) c c 1 ) C ( O ) c 1 c c c ( O C c 2 c c c c c 2 ) c ( N S ( C ) ( = O ) = O ) c 1 _EOS
Predicted text: C C ( N C C O c 1 c c c ( - c 2 c c c ( O C C ( = O ) O ) c c 2 ) c c 1 ) C ( O ) c 1 c c c ( O C c 2 c c c c c 2 ) c ( N S ( C ) ( = O ) = O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) c 1 c c c ( C C c 2 c c c c c 2 ) c c 1 N c 1 c c c c c 1 F _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) c 1 c c c ( C C c 2 c c c c c 2 ) c c 1 N c 1 c c c c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) C n 1 c ( - c 2 c c c c 3 c ( Br ) c c c c 2 3 ) n c ( - c 2 c c c c c 2 ) c ( C # N ) c 1 = O _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) C O c 1 n c ( - c 2 c c c c 3 c ( Br ) c c c c 2 3 ) n c ( - c 2 c c c c c 2 ) c 1 C # N _EOS _PAD _PAD _PAD
acc_token: 0.4032258064516129, acc_seq: False

Target text: C C ( C ) ( C ) O C ( = O ) N C ( C c 1 c c c ( F ) c c 1 ) C ( = O ) N 1 C C C ( O ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C ( C c 1 c c c ( F ) c c 1 ) C ( = O ) N 1 C C C ( O ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 80000, eval acc (token): 0.9192742992454218, eval acc (sequence): 0.8556980314249594
Saving at step 80000
Step 80100, loss: 0.0505193508323282, acc: 99.19805328547955, p_norm: 1791.2197087395868, g_norm: 0.7494178665014898, lr:  0.000883, elapsed time:  73717
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 80200, loss: 0.04835064271025859, acc: 99.27609752188842, p_norm: 1791.6384441312302, g_norm: 0.6644574164141092, lr:  0.000883, elapsed time:  73807
Step 80300, loss: 0.04817858264315873, acc: 99.276685282588, p_norm: 1792.0389614196497, g_norm: 0.8621311043115596, lr:  0.000882, elapsed time:  73896
Step 80400, loss: 0.04778794199693948, acc: 99.28191596269608, p_norm: 1792.464891276745, g_norm: 0.6413042953314143, lr:  0.000881, elapsed time:  73986
Step 80500, loss: 0.04815351107623428, acc: 99.26251086592674, p_norm: 1792.9120563009453, g_norm: 0.6607641385154414, lr:  0.000881, elapsed time:  74077
Step 80600, loss: 0.049181090146303175, acc: 99.23882533609867, p_norm: 1793.343890491059, g_norm: 0.6560437582514108, lr:  0.000880, elapsed time:  74168
Step 80700, loss: 0.04951843703631312, acc: 99.23346543312073, p_norm: 1793.7734094850634, g_norm: 0.5464788340205856, lr:  0.000880, elapsed time:  74257
Step 80800, loss: 0.04923871168401092, acc: 99.2453857511282, p_norm: 1794.2131636171691, g_norm: 0.7492068553568638, lr:  0.000879, elapsed time:  74346
Step 80900, loss: 0.04987243137788028, acc: 99.22265630960464, p_norm: 1794.6510411479314, g_norm: 0.606753413442934, lr:  0.000879, elapsed time:  74435
Step 81000, loss: 0.04784152219071984, acc: 99.26752100884914, p_norm: 1795.0660698415686, g_norm: 0.6049632282004044, lr:  0.000878, elapsed time:  74528
Step 81100, loss: 0.049244051002897325, acc: 99.22536450624466, p_norm: 1795.496727393096, g_norm: 1.0255991681080208, lr:  0.000878, elapsed time:  74616
Step 81200, loss: 0.049656511968933045, acc: 99.22207315266132, p_norm: 1795.913444850941, g_norm: 0.741284697606495, lr:  0.000877, elapsed time:  74704
Step 81300, loss: 0.04759452196769416, acc: 99.28007304668427, p_norm: 1796.3539938319884, g_norm: 0.601874996342286, lr:  0.000877, elapsed time:  74795
Step 81400, loss: 0.048855686490423975, acc: 99.23979645967484, p_norm: 1796.790305406293, g_norm: 0.6719482601488911, lr:  0.000876, elapsed time:  74882
Step 81500, loss: 0.048597493516281245, acc: 99.2508022338152, p_norm: 1797.2018087483107, g_norm: 0.626284250712039, lr:  0.000875, elapsed time:  74972
Step 81600, loss: 0.04856625678483397, acc: 99.24786478281021, p_norm: 1797.6275324385115, g_norm: 0.729293989632325, lr:  0.000875, elapsed time:  75060
Step 81700, loss: 0.048815214866772295, acc: 99.23764690756798, p_norm: 1798.0586903057317, g_norm: 0.5916541231005041, lr:  0.000874, elapsed time:  75149
Step 81800, loss: 0.04937335375696421, acc: 99.23479001224041, p_norm: 1798.5168817210526, g_norm: 0.6718203580218961, lr:  0.000874, elapsed time:  75241
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 81900, loss: 0.04825497108047121, acc: 99.26313426595172, p_norm: 1798.949921456165, g_norm: 0.6900120105040041, lr:  0.000873, elapsed time:  75331
Step 82000, loss: 0.047598367943428456, acc: 99.27970059216022, p_norm: 1799.3558644619372, g_norm: 0.6853672356807021, lr:  0.000873, elapsed time:  75420
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 82000, eval loss: 0.04409107113257053, eval acc: 99.46854400634766
Step 82100, loss: 0.04903963730670512, acc: 99.24847240746021, p_norm: 1799.7926412532468, g_norm: 0.7243750922431775, lr:  0.000872, elapsed time:  75521
Step 82200, loss: 0.0475821765884757, acc: 99.28226001560688, p_norm: 1800.2102450162365, g_norm: 0.7454328960147834, lr:  0.000872, elapsed time:  75611
Step 82300, loss: 0.04794102087151259, acc: 99.26814872026443, p_norm: 1800.6643047307355, g_norm: 0.6143114568909399, lr:  0.000871, elapsed time:  75702
Step 82400, loss: 0.04803358618170023, acc: 99.26026764512062, p_norm: 1801.103582167543, g_norm: 0.6468942497078997, lr:  0.000871, elapsed time:  75791
Step 82500, loss: 0.04868891951162368, acc: 99.25479331612587, p_norm: 1801.4978806606848, g_norm: 0.6308593191639069, lr:  0.000870, elapsed time:  75880
Step 82600, loss: 0.04783067393116653, acc: 99.26862840354443, p_norm: 1801.908941039039, g_norm: 0.8447876130659845, lr:  0.000870, elapsed time:  75969
Step 82700, loss: 0.04811453344766051, acc: 99.27167603373528, p_norm: 1802.3265404858148, g_norm: 0.5731484333511712, lr:  0.000869, elapsed time:  76059
Step 82800, loss: 0.04912170924711973, acc: 99.23598974943161, p_norm: 1802.7855402841792, g_norm: 0.5921798363276353, lr:  0.000869, elapsed time:  76147
Step 82900, loss: 0.049027422731742265, acc: 99.23515212535858, p_norm: 1803.2270387174708, g_norm: 0.7208837953494609, lr:  0.000868, elapsed time:  76235
Step 83000, loss: 0.04885885378345847, acc: 99.24761815369129, p_norm: 1803.674969766301, g_norm: 0.7179851530080888, lr:  0.000868, elapsed time:  76324
Step 83100, loss: 0.04801214846782386, acc: 99.2731900960207, p_norm: 1804.0872937158088, g_norm: 0.7020426334235287, lr:  0.000867, elapsed time:  76418
Step 83200, loss: 0.04945361852180213, acc: 99.22334969043732, p_norm: 1804.52419583465, g_norm: 0.6337318350881432, lr:  0.000866, elapsed time:  76506
Step 83300, loss: 0.048529303218238055, acc: 99.25570344924927, p_norm: 1804.9820855341907, g_norm: 0.6952391078288345, lr:  0.000866, elapsed time:  76599
Step 83400, loss: 0.04878253511618823, acc: 99.2574298530817, p_norm: 1805.4065739178, g_norm: 0.6219060641080624, lr:  0.000865, elapsed time:  76686
Step 83500, loss: 0.0485595324030146, acc: 99.25944949686527, p_norm: 1805.8350886090705, g_norm: 0.5657927948622803, lr:  0.000865, elapsed time:  76779
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6822
Step 83600, loss: 0.04706493161841115, acc: 99.30349349679045, p_norm: 1806.27129696836, g_norm: 0.7861398928213434, lr:  0.000864, elapsed time:  76870
Step 83700, loss: 0.048780137193389236, acc: 99.23643949627876, p_norm: 1806.6760231289936, g_norm: 0.6182303880182266, lr:  0.000864, elapsed time:  76957
Step 83800, loss: 0.04660659225191921, acc: 99.31937989592552, p_norm: 1807.1130176017175, g_norm: 0.7647463472762165, lr:  0.000863, elapsed time:  77047
Step 83900, loss: 0.049076699572615325, acc: 99.23617124557495, p_norm: 1807.5330047319824, g_norm: 0.6340993659345046, lr:  0.000863, elapsed time:  77137
Step 84000, loss: 0.04796442275866866, acc: 99.26271472871304, p_norm: 1807.946566488218, g_norm: 0.80353967288533, lr:  0.000862, elapsed time:  77225
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 84000, eval loss: 0.04538697678595783, eval acc: 99.42262268066406
Step 84100, loss: 0.04780812554061413, acc: 99.27139663696289, p_norm: 1808.36612497764, g_norm: 1.0752766329665657, lr:  0.000862, elapsed time:  77328
Step 84200, loss: 0.048574184817261994, acc: 99.24963909387589, p_norm: 1808.7985179449079, g_norm: 0.5436732557347984, lr:  0.000861, elapsed time:  77414
Step 84300, loss: 0.04894437374547124, acc: 99.2530784457922, p_norm: 1809.3049393209706, g_norm: 0.6870128291528258, lr:  0.000861, elapsed time:  77509
Step 84400, loss: 0.048727782159112394, acc: 99.25964646041393, p_norm: 1809.704333980822, g_norm: 0.5206704831602189, lr:  0.000860, elapsed time:  77598
Step 84500, loss: 0.047682177843526005, acc: 99.29002772271633, p_norm: 1810.1429852754832, g_norm: 0.8545212806781465, lr:  0.000860, elapsed time:  77689
Step 84600, loss: 0.048743745354004206, acc: 99.25279830396175, p_norm: 1810.5622645680257, g_norm: 0.6925733308399276, lr:  0.000859, elapsed time:  77777
Step 84700, loss: 0.04925889268983155, acc: 99.24216428399086, p_norm: 1810.9631960135882, g_norm: 0.6749610612691651, lr:  0.000859, elapsed time:  77865
Step 84800, loss: 0.04803347031585872, acc: 99.2743017077446, p_norm: 1811.3452170750184, g_norm: 0.5754320463387762, lr:  0.000858, elapsed time:  77956
Step 84900, loss: 0.04811291021760553, acc: 99.26583917438984, p_norm: 1811.7460368790728, g_norm: 0.6132861782486597, lr:  0.000858, elapsed time:  78045
Step 85000, loss: 0.048181631420738995, acc: 99.26306024193764, p_norm: 1812.150551798466, g_norm: 0.6465226529766737, lr:  0.000857, elapsed time:  78135
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C C C c 1 n c ( C ( O ) C C ) c ( C ( N ) = O ) n 1 C c 1 c c c ( - c 2 c c c c c 2 C ( = O ) O ) c c 1 _EOS
Predicted text: C C C C c 1 n c ( C ( O ) C C ) c ( C ( N ) = O ) n 1 C c 1 c c c ( - c 2 c c c c c 2 C ( = O ) O ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( F ) C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C ( C O ) O C 1 n 1 c c c ( = O ) [nH] c 1 = O _EOS
Predicted text: C O c 1 c c c ( C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) O C ( n 2 c c c ( = O ) [nH] c 2 = O ) C 1 O _EOS
acc_token: 0.10416666666666667, acc_seq: False

Target text: C O c 1 c c c ( C N c 2 c ( Cl ) c c c 3 c 2 C C N ( C ( = O ) C ( F ) ( F ) F ) C C 3 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C N c 2 c ( Cl ) c c c 3 c 2 C C N ( C ( = O ) C ( F ) ( F ) F ) C C 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( O ) ( C C N ) c 1 c c c ( - c 2 c c c ( F ) c c 2 ) c c 1 _EOS
Predicted text: C C ( O ) ( C C N ) c 1 c c c ( - c 2 c c c ( F ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c c c 1 N C c 1 c c c ( F ) c c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c c c 1 N C c 1 c c c ( F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 85000, eval acc (token): 0.9203833447501024, eval acc (sequence): 0.852866473149492
Saving at step 85000
Step 85100, loss: 0.04925813824404031, acc: 99.22659261524677, p_norm: 1812.5487556888604, g_norm: 0.8957548907796119, lr:  0.000857, elapsed time:  78305
Step 85200, loss: 0.04820064154453576, acc: 99.2625944018364, p_norm: 1812.969573102353, g_norm: 0.6736523590902549, lr:  0.000856, elapsed time:  78399
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 85300, loss: 0.04736645471082249, acc: 99.29409882619014, p_norm: 1813.3588673826039, g_norm: 0.6518360699693833, lr:  0.000856, elapsed time:  78493
Step 85400, loss: 0.047844639304094015, acc: 99.2860165387392, p_norm: 1813.84465810757, g_norm: 1.7431610832123652, lr:  0.000855, elapsed time:  78582
Step 85500, loss: 0.04750617073848844, acc: 99.2975995093584, p_norm: 1814.2807576307484, g_norm: 0.7857765791290703, lr:  0.000855, elapsed time:  78674
Step 85600, loss: 0.04859131883829832, acc: 99.25621157884598, p_norm: 1814.7068152713346, g_norm: 0.8553132536647556, lr:  0.000854, elapsed time:  78765
Step 85700, loss: 0.048953819144517186, acc: 99.24259017407894, p_norm: 1815.1134079872231, g_norm: 0.5538849320056446, lr:  0.000854, elapsed time:  78853
Step 85800, loss: 0.048011805168353024, acc: 99.27391897141933, p_norm: 1815.505607851398, g_norm: 0.7161998908696017, lr:  0.000853, elapsed time:  78941
Step 85900, loss: 0.047757500228472055, acc: 99.26575243473053, p_norm: 1815.8900356161646, g_norm: 0.609252857435022, lr:  0.000853, elapsed time:  79030
Step 86000, loss: 0.048812134144827726, acc: 99.23913405835629, p_norm: 1816.2950791899552, g_norm: 0.6567386690190055, lr:  0.000852, elapsed time:  79118
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 86000, eval loss: 0.04627760909497738, eval acc: 99.41344451904297
Step 86100, loss: 0.04780317498836666, acc: 99.29223418235779, p_norm: 1816.6648313403994, g_norm: 0.5940063087213576, lr:  0.000852, elapsed time:  79225
Step 86200, loss: 0.04887038177810609, acc: 99.28408022224903, p_norm: 1817.0452077304574, g_norm: 0.713836361809713, lr:  0.000851, elapsed time:  79312
Step 86300, loss: 0.04804773889482021, acc: 99.30083805322647, p_norm: 1817.4383667931174, g_norm: 0.6165805455548027, lr:  0.000851, elapsed time:  79401
Step 86400, loss: 0.0488407451659441, acc: 99.27552814781666, p_norm: 1817.8513623333017, g_norm: 0.6917136855579528, lr:  0.000850, elapsed time:  79491
Step 86500, loss: 0.048309986144304276, acc: 99.28981174528599, p_norm: 1818.2227120619411, g_norm: 0.6019695751790246, lr:  0.000850, elapsed time:  79581
Step 86600, loss: 0.04867983506061137, acc: 99.27491170167923, p_norm: 1818.6012745485855, g_norm: 0.7096294835293017, lr:  0.000849, elapsed time:  79668
Step 86700, loss: 0.05048620637040585, acc: 99.21601581573486, p_norm: 1819.0200487827235, g_norm: 0.6769022208224088, lr:  0.000849, elapsed time:  79757
Step 86800, loss: 0.04972598446533084, acc: 99.25567401945591, p_norm: 1819.4723459551067, g_norm: 0.6391888839152537, lr:  0.000848, elapsed time:  79848
Step 86900, loss: 0.048220993601717055, acc: 99.27830299735069, p_norm: 1819.9314089174986, g_norm: 0.6051372342148241, lr:  0.000848, elapsed time:  79942
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 87000, loss: 0.0481765410694162, acc: 99.27840871787248, p_norm: 1820.3130430002768, g_norm: 0.6440082589383327, lr:  0.000847, elapsed time:  80031
Step 87100, loss: 0.046781251220963896, acc: 99.30908085405827, p_norm: 1820.6933591250565, g_norm: 0.6066081968279725, lr:  0.000847, elapsed time:  80119
Step 87200, loss: 0.04814143159426749, acc: 99.27270531654358, p_norm: 1821.0751586907822, g_norm: 0.7256812638730108, lr:  0.000846, elapsed time:  80209
Step 87300, loss: 0.047027335627935825, acc: 99.29566888511181, p_norm: 1821.4434982109826, g_norm: 0.574308846470596, lr:  0.000846, elapsed time:  80294
Step 87400, loss: 0.0466619018279016, acc: 99.31664277613163, p_norm: 1821.8810753963219, g_norm: 0.6616602560895231, lr:  0.000845, elapsed time:  80384
Step 87500, loss: 0.047583527769893406, acc: 99.29126161336899, p_norm: 1822.273324530065, g_norm: 0.5258745994626258, lr:  0.000845, elapsed time:  80474
Step 87600, loss: 0.04613865892868489, acc: 99.32259194552898, p_norm: 1822.6641863751815, g_norm: 0.6060312460405138, lr:  0.000844, elapsed time:  80564
Step 87700, loss: 0.047745149726979436, acc: 99.27898548543453, p_norm: 1823.0754829568832, g_norm: 0.7277477415748994, lr:  0.000844, elapsed time:  80656
Step 87800, loss: 0.0469901464227587, acc: 99.30418325960636, p_norm: 1823.5001484390461, g_norm: 0.6930487281932212, lr:  0.000843, elapsed time:  80747
Step 87900, loss: 0.04706296853721142, acc: 99.29434175789356, p_norm: 1823.9011929266742, g_norm: 0.72379142965933, lr:  0.000843, elapsed time:  80837
Step 88000, loss: 0.04694030934944749, acc: 99.2942408323288, p_norm: 1824.296126752811, g_norm: 0.7762056899911404, lr:  0.000843, elapsed time:  80928
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 88000, eval loss: 0.04543681722134351, eval acc: 99.43692779541016
Step 88100, loss: 0.04802459801547229, acc: 99.25520597398281, p_norm: 1824.6948915569012, g_norm: 0.5801106395518104, lr:  0.000842, elapsed time:  81033
Step 88200, loss: 0.04782272158656269, acc: 99.27520622313023, p_norm: 1825.089162322953, g_norm: 0.5162081039093684, lr:  0.000842, elapsed time:  81121
Step 88300, loss: 0.04764577280730009, acc: 99.28456650674343, p_norm: 1825.4614421288954, g_norm: 0.7389150337322887, lr:  0.000841, elapsed time:  81208
Step 88400, loss: 0.047329756896942854, acc: 99.2753167450428, p_norm: 1825.8483784773978, g_norm: 0.7178244213266333, lr:  0.000841, elapsed time:  81301
Step 88500, loss: 0.049739343454129996, acc: 99.21506761014462, p_norm: 1826.2660285438872, g_norm: 0.6807264477050285, lr:  0.000840, elapsed time:  81390
Step 88600, loss: 0.04910197883378714, acc: 99.23540234565735, p_norm: 1826.6911917402822, g_norm: 0.7806964953545174, lr:  0.000840, elapsed time:  81482
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 88700, loss: 0.047782297584399655, acc: 99.27694652211014, p_norm: 1827.0574934863, g_norm: 0.6611940514729455, lr:  0.000839, elapsed time:  81571
Step 88800, loss: 0.0469476042734459, acc: 99.29900492727757, p_norm: 1827.4608639371784, g_norm: 0.6276848309037841, lr:  0.000839, elapsed time:  81661
Step 88900, loss: 0.047199407732114194, acc: 99.2996461391449, p_norm: 1827.8546279278066, g_norm: 0.6180910626055135, lr:  0.000838, elapsed time:  81755
Step 89000, loss: 0.045830547511577606, acc: 99.32526713609695, p_norm: 1828.2235302900647, g_norm: 0.585078860263401, lr:  0.000838, elapsed time:  81844
Step 89100, loss: 0.04727166600059718, acc: 99.29635299742222, p_norm: 1828.6103135182861, g_norm: 0.5303189668843014, lr:  0.000837, elapsed time:  81933
Step 89200, loss: 0.04681853032670915, acc: 99.29942537844181, p_norm: 1829.0148705414733, g_norm: 0.6766679760476165, lr:  0.000837, elapsed time:  82023
Step 89300, loss: 0.047039677347056566, acc: 99.30191205441952, p_norm: 1829.4081447877563, g_norm: 0.5371429344648725, lr:  0.000836, elapsed time:  82109
Step 89400, loss: 0.047992961858399213, acc: 99.27376466989517, p_norm: 1829.818858241823, g_norm: 0.7276877872453593, lr:  0.000836, elapsed time:  82197
Step 89500, loss: 0.04629714220762253, acc: 99.31971591711044, p_norm: 1830.2081548168078, g_norm: 0.49696248141688926, lr:  0.000835, elapsed time:  82291
Step 89600, loss: 0.04657007078640163, acc: 99.31149360537529, p_norm: 1830.6042251391668, g_norm: 0.736390363930409, lr:  0.000835, elapsed time:  82380
Step 89700, loss: 0.04716283898800611, acc: 99.29757776856422, p_norm: 1830.9682890585457, g_norm: 0.6717727880252987, lr:  0.000834, elapsed time:  82470
Step 89800, loss: 0.04670109713450074, acc: 99.3010716587305, p_norm: 1831.3519833898588, g_norm: 0.5248964329728849, lr:  0.000834, elapsed time:  82559
Step 89900, loss: 0.04760515723377466, acc: 99.27898339927197, p_norm: 1831.7446385855933, g_norm: 0.6678387402860932, lr:  0.000834, elapsed time:  82648
Step 90000, loss: 0.0468647800758481, acc: 99.3017795085907, p_norm: 1832.1172744354437, g_norm: 0.533866455016565, lr:  0.000833, elapsed time:  82738
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 90000, eval loss: 0.04709400184452532, eval acc: 99.40592956542969
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) C ( N C ( = O ) O C ( C ) ( C ) C ) C 1 C ( C C Cl ) C 1 C ( = O ) O C C _EOS
Predicted text: C C O C ( = O ) C ( N C ( = O ) O C ( C ) ( C ) C ) C 1 C ( C C Cl ) C 1 C ( = O ) O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C C C C C C C C C C C O c 1 c c ( O C C C Br ) c c ( C ( = O ) O C c 2 c c c c c 2 ) c 1 _EOS
Predicted text: C C C C C C C C C C C C C C C C C O c 1 c c ( O C C C Br ) c c ( C ( = O ) O C c 2 c c c c c 2 ) c 1 _EOS _PAD
acc_token: 0.4807692307692308, acc_seq: False

Target text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N c 2 c c c ( C ( = O ) O ) c ( C ( F ) ( F ) F ) c 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 F _EOS
Predicted text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N c 2 c c c ( C ( = O ) O ) c ( C ( F ) ( F ) F ) c 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C C ( = O ) C C ( = O ) c 1 c c c 2 c ( c 1 ) c 1 c c ( - c 3 c c c ( Cl ) c c 3 Cl ) c ( = O ) n ( C ) c 1 n 2 C _EOS
Predicted text: C N ( C ) C C ( = O ) C C ( = O ) c 1 c c c 2 c ( c 1 ) c 1 c c ( - c 3 c c c ( Cl ) c c 3 Cl ) c ( = O ) n ( C ) c 1 n 2 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C C c 1 c c c c c 1 - c 1 c c ( C ( F ) ( F ) F ) c ( C ( C N ) C c 2 c c c ( O C C O c 3 c ( Cl ) c c ( C ) c c 3 Cl ) c c 2 ) c n 1 _EOS
Predicted text: C O C C C c 1 c c c c c 1 - c 1 c c ( C ( F ) ( F ) F ) c ( C ( C N ) C c 2 c c c ( O C C O c 3 c ( Cl ) c c ( C ) c c 3 Cl ) c c 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 90000, eval acc (token): 0.9253727692177138, eval acc (sequence): 0.8573145604395604
Saving at step 90000
Step 90100, loss: 0.047838639747351405, acc: 99.26600535213947, p_norm: 1832.501201485282, g_norm: 0.7539292722013932, lr:  0.000833, elapsed time:  82919
Step 90200, loss: 0.04746282326988876, acc: 99.27848480641842, p_norm: 1832.8901225188413, g_norm: 0.8232868674618038, lr:  0.000832, elapsed time:  83008
Step 90300, loss: 0.04789394121151418, acc: 99.27592670917511, p_norm: 1833.2874475897188, g_norm: 0.6909869572003199, lr:  0.000832, elapsed time:  83100
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 90400, loss: 0.04750339152573356, acc: 99.28170222206684, p_norm: 1833.6647179815398, g_norm: 0.735592071049653, lr:  0.000831, elapsed time:  83189
Step 90500, loss: 0.04665723379701376, acc: 99.29514399170876, p_norm: 1834.0457626574528, g_norm: 0.5863920093310344, lr:  0.000831, elapsed time:  83280
Step 90600, loss: 0.04649093664251268, acc: 99.31046235561371, p_norm: 1834.4511697416767, g_norm: 0.7322609495747263, lr:  0.000830, elapsed time:  83375
Step 90700, loss: 0.0469906827295199, acc: 99.29499280452728, p_norm: 1834.8525876544331, g_norm: 0.6334116697261305, lr:  0.000830, elapsed time:  83465
Step 90800, loss: 0.046198480944149196, acc: 99.3236019462347, p_norm: 1835.222606139288, g_norm: 0.7243215774983133, lr:  0.000829, elapsed time:  83552
Step 90900, loss: 0.04758297525811941, acc: 99.27322605252266, p_norm: 1835.604645214496, g_norm: 0.622072952649855, lr:  0.000829, elapsed time:  83641
Step 91000, loss: 0.045874416013248265, acc: 99.31874558329582, p_norm: 1835.980649056988, g_norm: 0.9367443461870645, lr:  0.000828, elapsed time:  83730
Step 91100, loss: 0.04736745735630393, acc: 99.28297284245491, p_norm: 1836.375929575531, g_norm: 0.6094820649780633, lr:  0.000828, elapsed time:  83818
Step 91200, loss: 0.04671598678920418, acc: 99.30523711442947, p_norm: 1836.7476563903933, g_norm: 0.5120127715904623, lr:  0.000828, elapsed time:  83907
Step 91300, loss: 0.045867731045000255, acc: 99.32565842568874, p_norm: 1837.1234758276667, g_norm: 0.6878945461459842, lr:  0.000827, elapsed time:  83999
Step 91400, loss: 0.046990675488486885, acc: 99.29457928240299, p_norm: 1837.5348282843736, g_norm: 0.7826553912542575, lr:  0.000827, elapsed time:  84087
Step 91500, loss: 0.047974893087521196, acc: 99.26766350865364, p_norm: 1837.8871883537415, g_norm: 0.6662547702350459, lr:  0.000826, elapsed time:  84173
Step 91600, loss: 0.04875876372680068, acc: 99.2832930535078, p_norm: 1838.34460894446, g_norm: 0.648083219630381, lr:  0.000826, elapsed time:  84261
Step 91700, loss: 0.048439005524851385, acc: 99.28432892262936, p_norm: 1838.7326395882237, g_norm: 0.5911743517831234, lr:  0.000825, elapsed time:  84351
Step 91800, loss: 0.05029509873129427, acc: 99.24633213877678, p_norm: 1839.1334923677655, g_norm: 0.6229694499603591, lr:  0.000825, elapsed time:  84441
Step 91900, loss: 0.04784554939717054, acc: 99.32627031207085, p_norm: 1839.4939287632985, g_norm: 0.49278298336960275, lr:  0.000824, elapsed time:  84529
Step 92000, loss: 0.047514237989671526, acc: 99.30456484854221, p_norm: 1839.845495703791, g_norm: 0.5365764165519037, lr:  0.000824, elapsed time:  84619
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 92000, eval loss: 0.04643536688759922, eval acc: 99.41049194335938
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 92100, loss: 0.04745922558860063, acc: 99.30132083206556, p_norm: 1840.2015461279102, g_norm: 1.1210702470543636, lr:  0.000824, elapsed time:  84730
Step 92200, loss: 0.04673952035605908, acc: 99.30459687113762, p_norm: 1840.5573597905648, g_norm: 0.5960586707649326, lr:  0.000823, elapsed time:  84821
Step 92300, loss: 0.04680767875630409, acc: 99.30747066438198, p_norm: 1840.912365560902, g_norm: 0.5967547008453951, lr:  0.000823, elapsed time:  84914
Step 92400, loss: 0.04844923751428723, acc: 99.2967848032713, p_norm: 1841.3556577338375, g_norm: 1.1816668459412294, lr:  0.000822, elapsed time:  85006
Step 92500, loss: 0.05118835196830332, acc: 99.2685831040144, p_norm: 1841.7890086664577, g_norm: 0.9613343097282216, lr:  0.000822, elapsed time:  85096
Step 92600, loss: 0.050817781798541545, acc: 99.23652839660645, p_norm: 1842.1586136863848, g_norm: 0.5507949880984976, lr:  0.000821, elapsed time:  85188
Step 92700, loss: 0.0498172431346029, acc: 99.26566414535046, p_norm: 1842.5344003678415, g_norm: 0.5252951867054123, lr:  0.000821, elapsed time:  85276
Step 92800, loss: 0.04673182250466198, acc: 99.32051859796047, p_norm: 1842.8452120431168, g_norm: 0.5865722874127219, lr:  0.000820, elapsed time:  85366
Step 92900, loss: 0.046133452751673756, acc: 99.33518953621387, p_norm: 1843.192463927121, g_norm: 0.6519791929284846, lr:  0.000820, elapsed time:  85457
Step 93000, loss: 0.04640097377821803, acc: 99.31039467453957, p_norm: 1843.5422146893156, g_norm: 0.6123621286523974, lr:  0.000820, elapsed time:  85546
Step 93100, loss: 0.04746147851459682, acc: 99.28282947838306, p_norm: 1843.9159082655926, g_norm: 0.698487137647501, lr:  0.000819, elapsed time:  85635
Step 93200, loss: 0.04709218087606132, acc: 99.30069522559643, p_norm: 1844.2666001960324, g_norm: 0.7877137096165969, lr:  0.000819, elapsed time:  85723
Step 93300, loss: 0.04640605913475156, acc: 99.31410546600819, p_norm: 1844.6156001672346, g_norm: 0.5051633340168549, lr:  0.000818, elapsed time:  85814
Step 93400, loss: 0.04640129330568016, acc: 99.31773333251476, p_norm: 1844.9722143649294, g_norm: 0.4982440883253078, lr:  0.000818, elapsed time:  85907
Step 93500, loss: 0.04777348618023097, acc: 99.28516787290573, p_norm: 1845.344483172154, g_norm: 0.6507706086902906, lr:  0.000817, elapsed time:  85999
Step 93600, loss: 0.0467516517220065, acc: 99.31338305771351, p_norm: 1845.6907545200013, g_norm: 0.8186554741229541, lr:  0.000817, elapsed time:  86088
Step 93700, loss: 0.04635302253533155, acc: 99.31469082832336, p_norm: 1846.048672792388, g_norm: 0.7087116861172614, lr:  0.000816, elapsed time:  86178
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 93800, loss: 0.046541457676064615, acc: 99.31190996917326, p_norm: 1846.446616702828, g_norm: 0.6942389043641395, lr:  0.000816, elapsed time:  86268
Step 93900, loss: 0.04641894408967346, acc: 99.3282519876957, p_norm: 1846.7738760034863, g_norm: 0.6337784013177037, lr:  0.000816, elapsed time:  86354
Step 94000, loss: 0.04655408721417189, acc: 99.31495913863182, p_norm: 1847.1568835818227, g_norm: 0.6396710407260353, lr:  0.000815, elapsed time:  86444
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 94000, eval loss: 0.048349526524543794, eval acc: 99.37225341796875
Step 94100, loss: 0.04667683284729719, acc: 99.30798949301243, p_norm: 1847.5095071313362, g_norm: 0.7720882176201888, lr:  0.000815, elapsed time:  86550
Step 94200, loss: 0.0457136643351987, acc: 99.32509985566139, p_norm: 1847.893665834731, g_norm: 0.6674293528931994, lr:  0.000814, elapsed time:  86640
Step 94300, loss: 0.04571035829372704, acc: 99.31874085962772, p_norm: 1848.2809043830773, g_norm: 0.5505645449526455, lr:  0.000814, elapsed time:  86730
Step 94400, loss: 0.04642459637019783, acc: 99.30929881334305, p_norm: 1848.6393789167337, g_norm: 0.7035346059566834, lr:  0.000813, elapsed time:  86820
Step 94500, loss: 0.04596747084986418, acc: 99.31190066039562, p_norm: 1848.992069279262, g_norm: 0.7536809225084742, lr:  0.000813, elapsed time:  86908
Step 94600, loss: 0.045841949228197336, acc: 99.32763686776161, p_norm: 1849.3555803090812, g_norm: 0.5841278224276908, lr:  0.000813, elapsed time:  86999
Step 94700, loss: 0.04697838749270886, acc: 99.29383105039597, p_norm: 1849.7236579713733, g_norm: 0.659580924276076, lr:  0.000812, elapsed time:  87086
Step 94800, loss: 0.04666996030602604, acc: 99.30390553176403, p_norm: 1850.0827619746774, g_norm: 0.6515813174737475, lr:  0.000812, elapsed time:  87176
Step 94900, loss: 0.04634635977447033, acc: 99.31502006947994, p_norm: 1850.4766819074846, g_norm: 0.6542344298416236, lr:  0.000811, elapsed time:  87266
Step 95000, loss: 0.045349927158094945, acc: 99.34380857646465, p_norm: 1850.8262543452595, g_norm: 0.5888448430426042, lr:  0.000811, elapsed time:  87355
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Target text: Br c 1 c c c c ( - c 2 c c c c c 2 ) n 1 _EOS
Predicted text: Br c 1 c c c c ( - c 2 c c c c c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( S ( = O ) ( = O ) O C C 2 O C ( = O ) N C 2 C c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: C c 1 c c c ( S ( = O ) ( = O ) O C C 2 O C ( = O ) N C 2 C c 2 c c c c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O C C 1 O C ( O c 2 n [nH] c ( C ( C ) C ) c 2 C c 2 c c c ( O C C C ( = O ) N C ( C ) ( C ) C ( N ) = O ) c c 2 C ) C ( O C ( C ) = O ) C ( O C ( C ) = O ) C 1 O C ( C ) = O _EOS
Predicted text: C C ( = O ) O C C 1 O C ( O c 2 n [nH] c ( C ( C ) C ) c 2 C c 2 c c c ( O C C C ( = O ) N C ( C ) ( C ) C ( N ) = O ) c c 2 C ) C ( O C ( C ) = O ) C ( O C ( C ) = O ) C 1 O C ( C ) = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C C ( C # N ) C C ( = O ) O _EOS
Predicted text: C C ( C ) C C ( C # N ) C C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = c 1 [nH] c 2 c c c ( - c 3 c c c c c 3 Cl ) c c 2 c 2 c c [nH] c 1 2 _EOS
Predicted text: O = c 1 [nH] c 2 c c c ( - c 3 c c c c c 3 Cl ) c c 2 c 2 c c [nH] c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 95000, eval acc (token): 0.9226862571728693, eval acc (sequence): 0.857116854750637
Saving at step 95000
Step 95100, loss: 0.046942037264816466, acc: 99.29373462498188, p_norm: 1851.2301508736468, g_norm: 0.5991947805973552, lr:  0.000810, elapsed time:  87532
Step 95200, loss: 0.04585409375373274, acc: 99.32048586010933, p_norm: 1851.571505839419, g_norm: 0.6368616775535751, lr:  0.000810, elapsed time:  87624
Step 95300, loss: 0.04654558372683823, acc: 99.3152377307415, p_norm: 1851.9463644428579, g_norm: 0.7156566454527099, lr:  0.000810, elapsed time:  87714
Step 95400, loss: 0.04851937233004719, acc: 99.27493238449097, p_norm: 1852.3414402041788, g_norm: 0.6904983619179971, lr:  0.000809, elapsed time:  87803
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 95500, loss: 0.04734550353611078, acc: 99.32664146198529, p_norm: 1852.680522988301, g_norm: 0.4587852997452365, lr:  0.000809, elapsed time:  87894
Step 95600, loss: 0.04631305432412773, acc: 99.34939314424992, p_norm: 1853.0153855132658, g_norm: 0.7635851309331001, lr:  0.000808, elapsed time:  87985
Step 95700, loss: 0.045921282237395646, acc: 99.34416377544403, p_norm: 1853.3405400991105, g_norm: 0.8283571894180692, lr:  0.000808, elapsed time:  88075
Step 95800, loss: 0.04561469585634768, acc: 99.34120981395245, p_norm: 1853.682040205794, g_norm: 0.8087104966346668, lr:  0.000807, elapsed time:  88161
Step 95900, loss: 0.04552435752004385, acc: 99.3392051756382, p_norm: 1854.0413094613525, g_norm: 0.7060242036902008, lr:  0.000807, elapsed time:  88251
Step 96000, loss: 0.045389372655190524, acc: 99.33462962508202, p_norm: 1854.3855794455708, g_norm: 0.5883156468115477, lr:  0.000807, elapsed time:  88343
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 96000, eval loss: 0.0465045727789402, eval acc: 99.39456176757812
Step 96100, loss: 0.04688499180600047, acc: 99.29927758872509, p_norm: 1854.767708321279, g_norm: 0.670358145001666, lr:  0.000806, elapsed time:  88448
Step 96200, loss: 0.04503438114654273, acc: 99.35414503514767, p_norm: 1855.1436169067742, g_norm: 0.8617271804564812, lr:  0.000806, elapsed time:  88539
Step 96300, loss: 0.04676817678846419, acc: 99.3142689615488, p_norm: 1855.4840898461005, g_norm: 0.6103106937871374, lr:  0.000805, elapsed time:  88628
Step 96400, loss: 0.04633017478510738, acc: 99.316192060709, p_norm: 1855.850465796422, g_norm: 0.7221122288818018, lr:  0.000805, elapsed time:  88717
Step 96500, loss: 0.046498911646194754, acc: 99.31438279151917, p_norm: 1856.2020010096942, g_norm: 0.5713541989009647, lr:  0.000805, elapsed time:  88807
Step 96600, loss: 0.04638217931613326, acc: 99.3034827709198, p_norm: 1856.5546200122942, g_norm: 0.8154697977609634, lr:  0.000804, elapsed time:  88894
Step 96700, loss: 0.04620758084580302, acc: 99.32055746018887, p_norm: 1856.9022761720246, g_norm: 0.7511022140066046, lr:  0.000804, elapsed time:  88982
Step 96800, loss: 0.04626859586685896, acc: 99.31527671217918, p_norm: 1857.2393557147852, g_norm: 1.325814151236444, lr:  0.000803, elapsed time:  89070
Step 96900, loss: 0.04763740596827119, acc: 99.2683373093605, p_norm: 1857.5974066253411, g_norm: 0.9117091897890637, lr:  0.000803, elapsed time:  89158
Step 97000, loss: 0.04673417460173369, acc: 99.30285200476646, p_norm: 1857.9598017559354, g_norm: 0.6417841625107165, lr:  0.000802, elapsed time:  89247
Step 97100, loss: 0.04719147267751396, acc: 99.28628648817539, p_norm: 1858.3197403051126, g_norm: 0.859290235120285, lr:  0.000802, elapsed time:  89337
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 97200, loss: 0.046468265978596345, acc: 99.30887133548633, p_norm: 1858.6975461726925, g_norm: 0.6740986431793347, lr:  0.000802, elapsed time:  89430
Step 97300, loss: 0.045057029225863514, acc: 99.35397477447987, p_norm: 1859.02894374333, g_norm: 0.6914707467366715, lr:  0.000801, elapsed time:  89521
Step 97400, loss: 0.04499755491968244, acc: 99.35256259143353, p_norm: 1859.3525272552165, g_norm: 0.5896768526507891, lr:  0.000801, elapsed time:  89610
Step 97500, loss: 0.04788486312143505, acc: 99.29409183561802, p_norm: 1859.7539949185523, g_norm: 0.6055582000485126, lr:  0.000800, elapsed time:  89698
Step 97600, loss: 0.05042671350296587, acc: 99.29551015794277, p_norm: 1860.133430529532, g_norm: 0.6588931087255997, lr:  0.000800, elapsed time:  89787
Step 97700, loss: 0.05067881465423852, acc: 99.28343850374222, p_norm: 1860.5094759845636, g_norm: 1.1883586515949665, lr:  0.000800, elapsed time:  89875
Step 97800, loss: 0.0496049098810181, acc: 99.30586384236813, p_norm: 1860.8270998299433, g_norm: 0.6918362962564905, lr:  0.000799, elapsed time:  89963
Step 97900, loss: 0.11063645955175161, acc: 99.33166082203388, p_norm: 1861.2328938989926, g_norm: 0.5774504041744057, lr:  0.000799, elapsed time:  90055
Step 98000, loss: 0.05180773319676518, acc: 99.31972669064999, p_norm: 1861.5414570772768, g_norm: 0.5558970400457385, lr:  0.000798, elapsed time:  90146
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 98000, eval loss: 0.049815514516085416, eval acc: 99.41039276123047
Step 98100, loss: 0.04975919964723289, acc: 99.3128288090229, p_norm: 1861.8105762208327, g_norm: 0.5132012738167548, lr:  0.000798, elapsed time:  90253
Step 98200, loss: 0.04880948570556939, acc: 99.32108037173748, p_norm: 1862.1054808882582, g_norm: 0.6620430217658464, lr:  0.000798, elapsed time:  90344
Step 98300, loss: 0.047900018906220795, acc: 99.31578378379345, p_norm: 1862.4080731144263, g_norm: 0.6004943614213629, lr:  0.000797, elapsed time:  90439
Step 98400, loss: 0.04622999326325953, acc: 99.33657270669937, p_norm: 1862.7067078944285, g_norm: 0.6482291519767761, lr:  0.000797, elapsed time:  90531
Step 98500, loss: 0.047817278783768416, acc: 99.28018869459629, p_norm: 1863.08967980841, g_norm: 0.6606925942320357, lr:  0.000796, elapsed time:  90630
Step 98600, loss: 0.04604341633152217, acc: 99.32488465309143, p_norm: 1863.4133317862381, g_norm: 0.5106135370116025, lr:  0.000796, elapsed time:  90721
Step 98700, loss: 0.0454842114308849, acc: 99.34159503877163, p_norm: 1863.7414684194212, g_norm: 0.6801445325600587, lr:  0.000796, elapsed time:  90813
Step 98800, loss: 0.04619775804225355, acc: 99.3356673270464, p_norm: 1864.0956166649853, g_norm: 0.7227197471422804, lr:  0.000795, elapsed time:  90909
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 98900, loss: 0.04794957132885237, acc: 99.3109272816045, p_norm: 1864.4819517433023, g_norm: 0.6232834248197706, lr:  0.000795, elapsed time:  91006
Step 99000, loss: 0.0463750132592395, acc: 99.33531218767166, p_norm: 1864.8213703798376, g_norm: 0.7453549465811963, lr:  0.000794, elapsed time:  91096
Step 99100, loss: 0.0479355920990929, acc: 99.3068782389164, p_norm: 1865.2222278564757, g_norm: 0.7697989877019837, lr:  0.000794, elapsed time:  91184
Step 99200, loss: 0.04889362594112754, acc: 99.32896526157856, p_norm: 1865.574716428394, g_norm: 0.6459199655251913, lr:  0.000794, elapsed time:  91278
Step 99300, loss: 0.04844891543965787, acc: 99.3259777277708, p_norm: 1865.9094894184718, g_norm: 0.6841371745297833, lr:  0.000793, elapsed time:  91367
Step 99400, loss: 0.047015053210780026, acc: 99.33190239965916, p_norm: 1866.237228007552, g_norm: 0.5813076481550227, lr:  0.000793, elapsed time:  91456
Step 99500, loss: 0.04708254667930305, acc: 99.34605130553246, p_norm: 1866.6080683170917, g_norm: 0.5130562550572964, lr:  0.000792, elapsed time:  91546
Step 99600, loss: 0.04702927873004228, acc: 99.32798944413662, p_norm: 1866.9177199394392, g_norm: 0.6113760771286999, lr:  0.000792, elapsed time:  91633
Step 99700, loss: 0.04621612091548741, acc: 99.33488015830517, p_norm: 1867.210692383814, g_norm: 0.8618663484220969, lr:  0.000792, elapsed time:  91720
Step 99800, loss: 0.04519273960962891, acc: 99.35842083394527, p_norm: 1867.5131787793757, g_norm: 0.6023252720219144, lr:  0.000791, elapsed time:  91810
Step 99900, loss: 0.04726958077866584, acc: 99.2903379201889, p_norm: 1867.8585565815554, g_norm: 0.715771260678935, lr:  0.000791, elapsed time:  91901
Step 100000, loss: 0.04662791565991938, acc: 99.32994496822357, p_norm: 1868.187906141274, g_norm: 0.5971298144410512, lr:  0.000790, elapsed time:  91991
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 100000, eval loss: 0.04564366089180113, eval acc: 99.44737243652344
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C 1 ( C ) C C S c 2 c c c ( C = O ) c c 2 1 _EOS
Predicted text: C C 1 ( C ) C C S c 2 c c c ( C = O ) c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C ( O ) C c 1 c c c ( O C c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: O = C ( O ) C ( O ) C c 1 c c c ( O C c 2 c c c c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( S ( = O ) ( = O ) N c 2 c c c ( S c 3 c c c ( S ( = O ) ( = O ) N 4 C C C C C 4 ) c c 3 ) n n 2 ) c ( Cl ) c c 1 Cl _EOS
Predicted text: C c 1 c c ( S ( = O ) ( = O ) N c 2 c c c ( S ( = O ) ( = O ) N 3 C C C C C 3 ) c c 2 ) c ( Cl ) c c 1 Cl _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.375, acc_seq: False

Target text: C C O C ( = O ) c 1 c n c c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c n c c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( [O-] ) C 1 C C N ( C C ( O ) C O c 2 c c c c 3 n c c c c 2 3 ) C C 1 _EOS
Predicted text: O = C ( O ) C 1 C C N ( C C ( O ) C O c 2 c c c c 3 n c c c c 2 3 ) C C 1 _EOS
acc_token: 0.9736842105263158, acc_seq: False

Evaluation (without teacher) at step 100000, eval acc (token): 0.9286014869635683, eval acc (sequence): 0.8685158501440923
Saving at step 100000
Step 100100, loss: 0.0471579444501549, acc: 99.32047711312771, p_norm: 1868.5254932041976, g_norm: 0.62023866207502, lr:  0.000790, elapsed time:  92182
Step 100200, loss: 0.0460305842384696, acc: 99.34567093849182, p_norm: 1868.8517593269185, g_norm: 0.6491282866439494, lr:  0.000790, elapsed time:  92271
Step 100300, loss: 0.04806492280680686, acc: 99.30759687721729, p_norm: 1869.2102285860894, g_norm: 0.5565883420937345, lr:  0.000789, elapsed time:  92360
Step 100400, loss: 0.047709081578068434, acc: 99.32007582485676, p_norm: 1869.5453017151774, g_norm: 0.5446394013457044, lr:  0.000789, elapsed time:  92447
Step 100500, loss: 0.045778082944452764, acc: 99.34819649159908, p_norm: 1869.881277726217, g_norm: 0.6510451794023385, lr:  0.000788, elapsed time:  92540
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6823
Step 100600, loss: 0.045919573471988016, acc: 99.32562771128185, p_norm: 1870.2120882121176, g_norm: 0.8038165353630714, lr:  0.000788, elapsed time:  92633
Step 100700, loss: 0.04422118035610765, acc: 99.37538860738277, p_norm: 1870.5212409069625, g_norm: 0.6707166450241376, lr:  0.000788, elapsed time:  92722
Step 100800, loss: 0.04612128815613687, acc: 99.33272723853588, p_norm: 1870.944984222985, g_norm: 0.7402208425280774, lr:  0.000787, elapsed time:  92813
Step 100900, loss: 0.04545939645729959, acc: 99.35153502225876, p_norm: 1871.303220046605, g_norm: 0.7221313045248186, lr:  0.000787, elapsed time:  92906
Step 101000, loss: 0.04494659753981978, acc: 99.35025505721569, p_norm: 1871.6399386081455, g_norm: 0.5389707135503814, lr:  0.000786, elapsed time:  92998
Step 101100, loss: 0.04439547630958259, acc: 99.36620426177979, p_norm: 1871.9609977627022, g_norm: 0.49930357554725374, lr:  0.000786, elapsed time:  93097
Step 101200, loss: 0.04631041571032256, acc: 99.31334944069386, p_norm: 1872.2974034069575, g_norm: 0.691152310629828, lr:  0.000786, elapsed time:  93185
Step 101300, loss: 0.04560050413012504, acc: 99.35147352516651, p_norm: 1872.6288257676274, g_norm: 0.5497689257270565, lr:  0.000785, elapsed time:  93272
Step 101400, loss: 0.045243414076976476, acc: 99.3377190977335, p_norm: 1872.9788879150879, g_norm: 0.5513678346058658, lr:  0.000785, elapsed time:  93350
Step 101500, loss: 0.045363602493889627, acc: 99.33879660069942, p_norm: 1873.319427833011, g_norm: 0.7057324487019694, lr:  0.000784, elapsed time:  93438
Step 101600, loss: 0.044430658761411904, acc: 99.35492223501205, p_norm: 1873.6167889932888, g_norm: 0.5818856515175234, lr:  0.000784, elapsed time:  93527
Step 101700, loss: 0.044614566010423004, acc: 99.34710064530373, p_norm: 1873.9499918520194, g_norm: 0.7603754979475208, lr:  0.000784, elapsed time:  93622
Step 101800, loss: 0.045071835662238297, acc: 99.3517895936966, p_norm: 1874.2708350063194, g_norm: 0.5816880198713696, lr:  0.000783, elapsed time:  93719
Step 101900, loss: 0.045277899843640626, acc: 99.33988915383816, p_norm: 1874.6056686292482, g_norm: 0.6907946061267618, lr:  0.000783, elapsed time:  93806
Step 102000, loss: 0.048321878421120346, acc: 99.26270678639412, p_norm: 1875.0029179137118, g_norm: 0.5902092968301348, lr:  0.000783, elapsed time:  93897
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 102000, eval loss: 0.048176101911813006, eval acc: 99.41011810302734
Step 102100, loss: 0.04592397396452725, acc: 99.34061270952225, p_norm: 1875.3374526507007, g_norm: 0.6324953545098779, lr:  0.000782, elapsed time:  94003
Step 102200, loss: 0.04551599444821477, acc: 99.34599924087524, p_norm: 1875.6666516130088, g_norm: 0.5329672383118362, lr:  0.000782, elapsed time:  94092
Step 102300, loss: 0.045826229653321206, acc: 99.3232820481062, p_norm: 1875.9934795989625, g_norm: 0.6446108696317328, lr:  0.000781, elapsed time:  94181
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6822
Step 102400, loss: 0.04424237016653157, acc: 99.37598212776942, p_norm: 1876.3150547020214, g_norm: 0.6503292307727653, lr:  0.000781, elapsed time:  94272
Step 102500, loss: 0.04452360103838146, acc: 99.36037902534008, p_norm: 1876.6438947522784, g_norm: 0.6616275573680459, lr:  0.000781, elapsed time:  94344
Step 102600, loss: 0.04535636710934341, acc: 99.33404153585434, p_norm: 1876.960829499049, g_norm: 0.7755260046495295, lr:  0.000780, elapsed time:  94432
Step 102700, loss: 0.04334213887806982, acc: 99.39846524596214, p_norm: 1877.2556494970968, g_norm: 0.663866035436048, lr:  0.000780, elapsed time:  94519
Step 102800, loss: 0.04519925591070205, acc: 99.35139854252338, p_norm: 1877.583257901255, g_norm: 0.6964650875308533, lr:  0.000779, elapsed time:  94610
Step 102900, loss: 0.0452379812579602, acc: 99.34063731133938, p_norm: 1877.9458371831606, g_norm: 0.6395033866735246, lr:  0.000779, elapsed time:  94699
Step 103000, loss: 0.04486275935545564, acc: 99.36096931993961, p_norm: 1878.27883902211, g_norm: 0.7326950705038064, lr:  0.000779, elapsed time:  94788
Step 103100, loss: 0.0445065681822598, acc: 99.37087436020374, p_norm: 1878.6230785731805, g_norm: 0.5531371880433776, lr:  0.000778, elapsed time:  94877
Step 103200, loss: 0.04522719866130501, acc: 99.35071627795696, p_norm: 1878.9782049897271, g_norm: 1.0061831308916915, lr:  0.000778, elapsed time:  94971
Step 103300, loss: 0.04688495141454041, acc: 99.30605660378933, p_norm: 1879.3444375536742, g_norm: 0.6880319797662006, lr:  0.000778, elapsed time:  95062
Step 103400, loss: 0.04477469822857529, acc: 99.36104629933834, p_norm: 1879.673788311873, g_norm: 0.6462913091894713, lr:  0.000777, elapsed time:  95152
Step 103500, loss: 0.045025257542729374, acc: 99.34702587127686, p_norm: 1880.0025811588632, g_norm: 0.5317445810949147, lr:  0.000777, elapsed time:  95247
Step 103600, loss: 0.04475990056991577, acc: 99.34406693279743, p_norm: 1880.3121125618316, g_norm: 0.5456135990988327, lr:  0.000776, elapsed time:  95338
Step 103700, loss: 0.04632216068916023, acc: 99.3233403712511, p_norm: 1880.63314957427, g_norm: 0.5796542082819859, lr:  0.000776, elapsed time:  95428
Step 103800, loss: 0.045647281971760094, acc: 99.33090204000473, p_norm: 1880.9514283799374, g_norm: 0.6061799769455148, lr:  0.000776, elapsed time:  95526
Step 103900, loss: 0.04478182087186724, acc: 99.35780742764473, p_norm: 1881.264814776061, g_norm: 0.6552989914911913, lr:  0.000775, elapsed time:  95614
Step 104000, loss: 0.058130748397670684, acc: 99.31772966682911, p_norm: 1881.615062024944, g_norm: 0.6380343635780281, lr:  0.000775, elapsed time:  95705
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 104000, eval loss: 0.04742528412491083, eval acc: 99.38807678222656
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 104100, loss: 0.04580209771662357, acc: 99.35524376174111, p_norm: 1881.9473571269505, g_norm: 0.8843951657497242, lr:  0.000775, elapsed time:  95820
Step 104200, loss: 0.04498139901086688, acc: 99.36780612170696, p_norm: 1882.2760780685542, g_norm: 0.6928357756152275, lr:  0.000774, elapsed time:  95911
Step 104300, loss: 0.04527423817198724, acc: 99.36834973096848, p_norm: 1882.5918766622851, g_norm: 0.5792197157585318, lr:  0.000774, elapsed time:  96001
Step 104400, loss: 0.04580594449304044, acc: 99.34588950872421, p_norm: 1882.9411524319876, g_norm: 0.5474328907312644, lr:  0.000774, elapsed time:  96091
Step 104500, loss: 0.045153471692465245, acc: 99.35032343864441, p_norm: 1883.2631991713745, g_norm: 0.6822666798511146, lr:  0.000773, elapsed time:  96180
Step 104600, loss: 0.04503878398798406, acc: 99.36294195055962, p_norm: 1883.567549167557, g_norm: 0.6505202824066344, lr:  0.000773, elapsed time:  96269
Step 104700, loss: 0.04425964659079909, acc: 99.3682900518179, p_norm: 1883.845684739485, g_norm: 0.6327265982964947, lr:  0.000772, elapsed time:  96361
Step 104800, loss: 0.04537095420528203, acc: 99.33146233856678, p_norm: 1884.1955758338067, g_norm: 0.8095531414837763, lr:  0.000772, elapsed time:  96456
Step 104900, loss: 0.04428855603560805, acc: 99.36994022130966, p_norm: 1884.5175792229927, g_norm: 0.627219004662959, lr:  0.000772, elapsed time:  96547
Step 105000, loss: 0.04477915042079985, acc: 99.34890694916248, p_norm: 1884.8313153980243, g_norm: 0.639820540352174, lr:  0.000771, elapsed time:  96637
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C c 1 n c ( C O c 2 c c ( N ) c ( Cl ) c c 2 C ( = O ) N C 2 C N 3 C C C 2 C C 3 ) c s 1 _EOS
Predicted text: C c 1 n c ( C O c 2 c c ( N ) c ( Cl ) c c 2 C ( = O ) N C 2 C N 3 C C C 2 C C 3 ) c s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c 2 c ( c n n 2 C C ) c ( N C 2 C C O C C 2 ) c 1 C N C ( = O ) c 1 c c c c ( S ( = O ) ( = O ) N ( C ) C c 2 c c c c ( Br ) c 2 ) c 1 _EOS
Predicted text: C C c 1 n c 2 c ( c n n 2 C C ) c ( N C 2 C C O C C 2 ) c 1 C N C ( = O ) c 1 c c c c ( S ( = O ) ( = O ) N ( C ) C c 2 c c c c ( Br ) c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O c 1 c c ( - n 2 c ( = O ) c c ( C ( F ) ( F ) F ) n ( C ) c 2 = O ) c ( F ) c c 1 Br _EOS
Predicted text: C C O c 1 c c ( - n 2 c ( = O ) c c ( C ( F ) ( F ) F ) n ( C ) c 2 = O ) c ( F ) c c 1 Br _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) n 1 n c n c 1 - c 1 c n 2 c ( n 1 ) - c 1 c c c ( C 3 C N C 3 ) c c 1 O C C 2 _EOS
Predicted text: C C ( C ) n 1 n c n c 1 - c 1 c n 2 c ( n 1 ) - c 1 c c c ( C 3 C N C 3 ) c c 1 O C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( Cl ) c c ( C ( = O ) N c 2 c c c ( Cl ) c n 2 ) c 1 N C ( = O ) c 1 s c c ( C N 2 C C N = C 2 C C # N ) c 1 Cl _EOS
Predicted text: C O c 1 c c ( Cl ) c c ( C ( = O ) N c 2 c c c ( Cl ) c n 2 ) c 1 N C ( = O ) c 1 s c c ( C N 2 C C N = C 2 C C # N ) c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 105000, eval acc (token): 0.9309182937855016, eval acc (sequence): 0.8704065329309426
Saving at step 105000
Step 105100, loss: 0.04498769054189324, acc: 99.34862241148949, p_norm: 1885.141488715581, g_norm: 0.8737464547687026, lr:  0.000771, elapsed time:  96815
Step 105200, loss: 0.04422293985262513, acc: 99.37000145018101, p_norm: 1885.438080473308, g_norm: 0.6552749902770454, lr:  0.000771, elapsed time:  96911
Step 105300, loss: 0.04443360372912139, acc: 99.3721978366375, p_norm: 1885.743524058963, g_norm: 0.4558737813846929, lr:  0.000770, elapsed time:  97001
Step 105400, loss: 0.044998157401569185, acc: 99.34177163243294, p_norm: 1886.0788610806733, g_norm: 0.6086177440665007, lr:  0.000770, elapsed time:  97093
Step 105500, loss: 0.044646683442406354, acc: 99.35693441331387, p_norm: 1886.4086852461753, g_norm: 0.6881096460082663, lr:  0.000769, elapsed time:  97181
Step 105600, loss: 0.0453632356133312, acc: 99.33636938035488, p_norm: 1886.7561794426401, g_norm: 0.5654244089194853, lr:  0.000769, elapsed time:  97275
Step 105700, loss: 0.046792707853019234, acc: 99.30039629340172, p_norm: 1887.1179677274106, g_norm: 0.6329904262982351, lr:  0.000769, elapsed time:  97365
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 105800, loss: 0.04439001628856357, acc: 99.37616265737094, p_norm: 1887.4210889647547, g_norm: 1.9149818917612218, lr:  0.000768, elapsed time:  97456
Step 105900, loss: 0.04499261525925249, acc: 99.35821649432182, p_norm: 1887.7511368965882, g_norm: 0.6394524071115035, lr:  0.000768, elapsed time:  97546
Step 106000, loss: 0.04405386752448976, acc: 99.3843816369772, p_norm: 1888.065094964878, g_norm: 0.5982987342625111, lr:  0.000768, elapsed time:  97638
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 106000, eval loss: 0.044836656209081414, eval acc: 99.44029235839844
Step 106100, loss: 0.044939053822308776, acc: 99.34901250898838, p_norm: 1888.3591322911768, g_norm: 0.5544561126511119, lr:  0.000767, elapsed time:  97743
Step 106200, loss: 0.04507079914212227, acc: 99.34270791709423, p_norm: 1888.6761314647126, g_norm: 0.6837362877103028, lr:  0.000767, elapsed time:  97832
Step 106300, loss: 0.0439124452136457, acc: 99.37655630707741, p_norm: 1888.9896772477503, g_norm: 0.5593631306577684, lr:  0.000767, elapsed time:  97923
Step 106400, loss: 0.046536330389790236, acc: 99.31007046997547, p_norm: 1889.3201549684386, g_norm: 0.6376956770648543, lr:  0.000766, elapsed time:  98014
Step 106500, loss: 0.04442313802894205, acc: 99.36165657639503, p_norm: 1889.654836050859, g_norm: 0.6541769414523945, lr:  0.000766, elapsed time:  98115
Step 106600, loss: 0.04406440709717572, acc: 99.38039615750313, p_norm: 1889.9512059665349, g_norm: 0.6711981338043654, lr:  0.000765, elapsed time:  98209
Step 106700, loss: 0.04508992187678814, acc: 99.34469124674797, p_norm: 1890.265918183796, g_norm: 0.5377302394657821, lr:  0.000765, elapsed time:  98296
Step 106800, loss: 0.044353301147930325, acc: 99.36926937103271, p_norm: 1890.577677986293, g_norm: 0.8128117711893351, lr:  0.000765, elapsed time:  98386
Step 106900, loss: 0.04405965250451118, acc: 99.3762817978859, p_norm: 1890.9097345074192, g_norm: 0.6695737183552486, lr:  0.000764, elapsed time:  98480
Step 107000, loss: 0.045585279650986195, acc: 99.33380924165249, p_norm: 1891.240551579586, g_norm: 0.8176722712760435, lr:  0.000764, elapsed time:  98573
Step 107100, loss: 0.04440473839640617, acc: 99.37230981886387, p_norm: 1891.5402059845244, g_norm: 0.544130646013204, lr:  0.000764, elapsed time:  98663
Step 107200, loss: 0.0445467189932242, acc: 99.3699264973402, p_norm: 1891.867519595864, g_norm: 0.7988976855985438, lr:  0.000763, elapsed time:  98752
Step 107300, loss: 0.044953825511038305, acc: 99.35227479040623, p_norm: 1892.1956513112038, g_norm: 0.8724456956452734, lr:  0.000763, elapsed time:  98842
Step 107400, loss: 0.044685547654516995, acc: 99.36245302855968, p_norm: 1892.5047275245547, g_norm: 0.4919675522196426, lr:  0.000763, elapsed time:  98931
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 107500, loss: 0.04391546798384663, acc: 99.38604315516375, p_norm: 1892.8132220304474, g_norm: 0.7471624996872173, lr:  0.000762, elapsed time:  99028
Step 107600, loss: 0.044605776676908133, acc: 99.36093847453594, p_norm: 1893.201828574795, g_norm: 0.7221036882942065, lr:  0.000762, elapsed time:  99116
Step 107700, loss: 0.04445431431289762, acc: 99.3721217662096, p_norm: 1893.511984085327, g_norm: 0.5535062595842366, lr:  0.000762, elapsed time:  99206
Step 107800, loss: 0.04498495010659099, acc: 99.34661227464676, p_norm: 1893.822287916181, g_norm: 0.5405662150725682, lr:  0.000761, elapsed time:  99292
Step 107900, loss: 0.04438122128136456, acc: 99.37629994750023, p_norm: 1894.1377915046592, g_norm: 0.6913835147714548, lr:  0.000761, elapsed time:  99383
Step 108000, loss: 0.044141118908301, acc: 99.37257754802704, p_norm: 1894.4166087518781, g_norm: 0.6281454294951287, lr:  0.000761, elapsed time:  99473
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 108000, eval loss: 0.044396848827600484, eval acc: 99.48219299316406
Step 108100, loss: 0.04359828738961369, acc: 99.38900573551655, p_norm: 1894.7126842266832, g_norm: 0.6351306532169457, lr:  0.000760, elapsed time:  99582
Step 108200, loss: 0.04444613186642528, acc: 99.35456371307373, p_norm: 1895.0341238555093, g_norm: 0.6304372035404967, lr:  0.000760, elapsed time:  99673
Step 108300, loss: 0.04493527302518487, acc: 99.35009531676769, p_norm: 1895.3730523509785, g_norm: 0.5078903020984821, lr:  0.000759, elapsed time:  99761
Step 108400, loss: 0.0439075973816216, acc: 99.37978039681911, p_norm: 1895.6792945411698, g_norm: 0.7060138680057562, lr:  0.000759, elapsed time:  99854
Step 108500, loss: 0.04485068944748491, acc: 99.35184262692928, p_norm: 1895.9927648243574, g_norm: 0.5536989987747516, lr:  0.000759, elapsed time:  99947
Step 108600, loss: 0.04493193098343909, acc: 99.34224642813206, p_norm: 1896.2939100856604, g_norm: 0.9300426301498875, lr:  0.000758, elapsed time:  100033
Step 108700, loss: 0.04395326029974967, acc: 99.37947370111942, p_norm: 1896.6112363254324, g_norm: 0.4445664888268262, lr:  0.000758, elapsed time:  100125
Step 108800, loss: 0.04482656071428209, acc: 99.35362154245377, p_norm: 1896.905138488234, g_norm: 0.61087366104482, lr:  0.000758, elapsed time:  100212
Step 108900, loss: 0.045126530532725154, acc: 99.34279911220074, p_norm: 1897.2177150482005, g_norm: 0.8307948128654183, lr:  0.000757, elapsed time:  100303
Step 109000, loss: 0.04379619786515832, acc: 99.38129219412804, p_norm: 1897.4987351598372, g_norm: 0.6306422912495272, lr:  0.000757, elapsed time:  100391
Step 109100, loss: 0.043350646747276185, acc: 99.39789718389511, p_norm: 1897.8191641848762, g_norm: 0.5014965484193757, lr:  0.000757, elapsed time:  100485
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 109200, loss: 0.04413005174021816, acc: 99.37013341716273, p_norm: 1898.1335882008977, g_norm: 0.731378655843761, lr:  0.000756, elapsed time:  100577
Step 109300, loss: 0.044351816335693, acc: 99.35716392099857, p_norm: 1898.425233294766, g_norm: 0.6196574814284199, lr:  0.000756, elapsed time:  100666
Step 109400, loss: 0.04345076261088252, acc: 99.38664755225182, p_norm: 1898.736569326438, g_norm: 0.5658072314642411, lr:  0.000756, elapsed time:  100761
Step 109500, loss: 0.044301394340582195, acc: 99.37257799506187, p_norm: 1899.065928095558, g_norm: 0.9120911901276527, lr:  0.000755, elapsed time:  100851
Step 109600, loss: 0.0450723271491006, acc: 99.37440755963326, p_norm: 1899.3954267107852, g_norm: 0.680711368118151, lr:  0.000755, elapsed time:  100942
Step 109700, loss: 0.04415448470972479, acc: 99.38889810442924, p_norm: 1899.708275112601, g_norm: 0.7086632667919346, lr:  0.000755, elapsed time:  101032
Step 109800, loss: 0.04514855170156807, acc: 99.35282979905605, p_norm: 1900.0181374576262, g_norm: 0.6572085830251931, lr:  0.000754, elapsed time:  101122
Step 109900, loss: 0.04433871720917523, acc: 99.39517053961754, p_norm: 1900.3585327065432, g_norm: 0.6313880873662716, lr:  0.000754, elapsed time:  101215
Step 110000, loss: 0.04499973629135638, acc: 99.37333332002163, p_norm: 1900.6739617119679, g_norm: 0.8094716409352287, lr:  0.000754, elapsed time:  101285
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Evaluation (with teacher) at step 110000, eval loss: 0.04299157200381163, eval acc: 99.49244689941406
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Target text: C C C C C C = C C C = C C C C C C C C C O _EOS
Predicted text: C C C C C C = C C C = C C C C C C C C C O _EOS
acc_token: 1.0, acc_seq: True

Target text: O C ( c 1 c c ( - c 2 c c c 3 n c c n c 3 c 2 ) c s 1 ) C ( F ) ( F ) F _EOS
Predicted text: O C ( c 1 c c ( - c 2 c c c 3 n c c n c 3 c 2 ) c s 1 ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: N C ( = O ) c 1 c c c ( O c 2 c c c ( C = O ) c c 2 ) n c 1 _EOS
Predicted text: N C ( = O ) c 1 c c c ( O c 2 c c c ( C = O ) c c 2 ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C C ( = O ) N 2 C C C 3 ( C C 2 ) C N ( C 2 C C c 4 c c ( B 5 O C ( C ) ( C ) C ( C ) ( C ) O 5 ) c c c 4 2 ) C 3 ) n c 1 _EOS
Predicted text: C O c 1 c c c ( C C ( = O ) N 2 C C C 3 ( C C 2 ) C N ( C 2 C C c 4 c c ( B 5 O C ( C ) ( C ) C ( C ) ( C ) O 5 ) c c c 4 2 ) C 3 ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C O c 1 c c c ( C ( = O ) O c 2 c c c ( C ( = O ) O ) c ( F ) c 2 ) c c 1 _EOS
Predicted text: C C C C C C C C O c 1 c c c ( C ( = O ) O c 2 c c c ( C ( = O ) O ) c ( F ) c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 110000, eval acc (token): 0.9259463436302295, eval acc (sequence): 0.8613187178209599
Saving at step 110000
Step 110100, loss: 0.04441039430443197, acc: 99.38197910785675, p_norm: 1900.9494611755802, g_norm: 0.9482204291739108, lr:  0.000753, elapsed time:  101451
Step 110200, loss: 0.045441662054508926, acc: 99.34072445333004, p_norm: 1901.2202201718196, g_norm: 0.7988801353730223, lr:  0.000753, elapsed time:  101541
Step 110300, loss: 0.04526450014673174, acc: 99.34830041229725, p_norm: 1901.5232842910987, g_norm: 0.7466975215908805, lr:  0.000753, elapsed time:  101630
Step 110400, loss: 0.044899103036150335, acc: 99.36888013780117, p_norm: 1901.8161510114946, g_norm: 0.563358744994983, lr:  0.000752, elapsed time:  101719
Step 110500, loss: 0.044509416460059584, acc: 99.37267856299877, p_norm: 1902.1046172941412, g_norm: 0.804114726925283, lr:  0.000752, elapsed time:  101804
Step 110600, loss: 0.0440605765581131, acc: 99.38435515761375, p_norm: 1902.4289779197595, g_norm: 0.6344672485152898, lr:  0.000752, elapsed time:  101872
Step 110700, loss: 0.044637973019853235, acc: 99.3840434551239, p_norm: 1902.7171256575737, g_norm: 0.6354634047116324, lr:  0.000751, elapsed time:  101943
Step 110800, loss: 0.04410674079786986, acc: 99.38848385214806, p_norm: 1903.0127897221853, g_norm: 0.6752766278936408, lr:  0.000751, elapsed time:  102014
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6822
Step 110900, loss: 0.04376059217799094, acc: 99.37911036588417, p_norm: 1903.326348468707, g_norm: 0.7444635149587732, lr:  0.000750, elapsed time:  102084
Step 111000, loss: 0.043755444646812976, acc: 99.37866884469986, p_norm: 1903.6245363500611, g_norm: 0.47343096413506414, lr:  0.000750, elapsed time:  102155
Step 111100, loss: 0.049105454916134474, acc: 99.35597217082977, p_norm: 1903.9701183395305, g_norm: 0.5015862145800383, lr:  0.000750, elapsed time:  102224
Step 111200, loss: 0.04500008393079043, acc: 99.36388677358627, p_norm: 1904.2889785386783, g_norm: 0.4633198394960976, lr:  0.000749, elapsed time:  102293
Step 111300, loss: 0.04473034316208214, acc: 99.37678629159927, p_norm: 1904.5561689312972, g_norm: 0.8622857980734884, lr:  0.000749, elapsed time:  102381
Step 111400, loss: 0.04430324364453554, acc: 99.3827440738678, p_norm: 1904.8609563005361, g_norm: 0.47531233118363203, lr:  0.000749, elapsed time:  102475
Step 111500, loss: 0.04441262240055949, acc: 99.38336230814457, p_norm: 1905.1390009266531, g_norm: 0.8447604601765142, lr:  0.000748, elapsed time:  102567
Step 111600, loss: 0.04554838270880282, acc: 99.35687492787838, p_norm: 1905.4198377132536, g_norm: 0.5506079443826066, lr:  0.000748, elapsed time:  102656
Step 111700, loss: 0.047770326593890786, acc: 99.35934421420097, p_norm: 1905.7052954980663, g_norm: 0.6152327698210776, lr:  0.000748, elapsed time:  102748
Step 111800, loss: 0.046153505225665865, acc: 99.36251209676266, p_norm: 1906.0332937954508, g_norm: 0.6368656721681702, lr:  0.000747, elapsed time:  102838
Step 111900, loss: 0.04292352829594165, acc: 99.44020555913448, p_norm: 1906.281760745172, g_norm: 0.6275589052066035, lr:  0.000747, elapsed time:  102934
Step 112000, loss: 0.044473529611714184, acc: 99.36554086208344, p_norm: 1906.5568625409257, g_norm: 0.6741777806972822, lr:  0.000747, elapsed time:  103030
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 112000, eval loss: 0.04490781754255296, eval acc: 99.45551300048828
Step 112100, loss: 0.043350495547056195, acc: 99.40028536319733, p_norm: 1906.8515732808908, g_norm: 0.6900691141791728, lr:  0.000746, elapsed time:  103143
Step 112200, loss: 0.04465316114015877, acc: 99.36232449114323, p_norm: 1907.1702772026522, g_norm: 0.5898044499063061, lr:  0.000746, elapsed time:  103234
Step 112300, loss: 0.04522177336271852, acc: 99.34098123013973, p_norm: 1907.4809275529688, g_norm: 0.6686258243364729, lr:  0.000746, elapsed time:  103327
Step 112400, loss: 0.04390984313096851, acc: 99.3755549043417, p_norm: 1907.7859398901053, g_norm: 0.5821737574363995, lr:  0.000745, elapsed time:  103417
Step 112500, loss: 0.04371898831333965, acc: 99.37635189294815, p_norm: 1908.0791645941033, g_norm: 0.5870612498550816, lr:  0.000745, elapsed time:  103510
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 112600, loss: 0.04369077110079242, acc: 99.374920693203, p_norm: 1908.3799692845275, g_norm: 0.6256241236456688, lr:  0.000745, elapsed time:  103599
Step 112700, loss: 0.043261776673607526, acc: 99.38581620156765, p_norm: 1908.6816182735577, g_norm: 0.7123003348239921, lr:  0.000744, elapsed time:  103693
Step 112800, loss: 0.04444369370117784, acc: 99.3609534651041, p_norm: 1908.9867428404903, g_norm: 0.854580123156526, lr:  0.000744, elapsed time:  103783
Step 112900, loss: 0.04389427593909204, acc: 99.37873342633247, p_norm: 1909.3301160877752, g_norm: 0.6581640803907197, lr:  0.000744, elapsed time:  103877
Step 113000, loss: 0.043599293190054594, acc: 99.39297573268414, p_norm: 1909.6332375503857, g_norm: 0.6579432561367786, lr:  0.000743, elapsed time:  103969
Step 113100, loss: 0.04381109558045864, acc: 99.37874153256416, p_norm: 1909.9347129966827, g_norm: 0.6463412685111313, lr:  0.000743, elapsed time:  104063
Step 113200, loss: 0.04346452507656068, acc: 99.3953407406807, p_norm: 1910.204172168672, g_norm: 0.6273890536594994, lr:  0.000743, elapsed time:  104153
Step 113300, loss: 0.04332191496621817, acc: 99.3754090666771, p_norm: 1910.487727708445, g_norm: 0.6842626945179677, lr:  0.000743, elapsed time:  104246
Step 113400, loss: 0.04312486620619893, acc: 99.39857544004917, p_norm: 1910.74927342179, g_norm: 1.0508714361146285, lr:  0.000742, elapsed time:  104340
Step 113500, loss: 0.043499536742456255, acc: 99.39142994582653, p_norm: 1911.056946681048, g_norm: 0.6811916627485995, lr:  0.000742, elapsed time:  104434
Step 113600, loss: 0.04405407126992941, acc: 99.36340627074242, p_norm: 1911.345780386247, g_norm: 0.6655971408419956, lr:  0.000742, elapsed time:  104522
Step 113700, loss: 0.04364103830419481, acc: 99.38712152838707, p_norm: 1911.6330783891924, g_norm: 0.6212911416990721, lr:  0.000741, elapsed time:  104612
Step 113800, loss: 0.04383101507090032, acc: 99.38818097114563, p_norm: 1911.9241956829858, g_norm: 0.5655108209397657, lr:  0.000741, elapsed time:  104706
Step 113900, loss: 0.04325695763807744, acc: 99.3924820870161, p_norm: 1912.2103065011931, g_norm: 0.5782056614826862, lr:  0.000741, elapsed time:  104798
Step 114000, loss: 0.04304600329604, acc: 99.40623264014721, p_norm: 1912.4871829856727, g_norm: 0.5287499886464821, lr:  0.000740, elapsed time:  104890
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 114000, eval loss: 0.046359489243477554, eval acc: 99.40203857421875
Step 114100, loss: 0.04560933133587241, acc: 99.37614543735981, p_norm: 1912.7888498884915, g_norm: 0.5019864954999854, lr:  0.000740, elapsed time:  104999
Step 114200, loss: 0.04469600470270962, acc: 99.36626946926117, p_norm: 1913.0465026446593, g_norm: 0.5030894128731256, lr:  0.000740, elapsed time:  105088
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 114300, loss: 0.04336816495960921, acc: 99.39312248384182, p_norm: 1913.3817781235898, g_norm: 0.8036369404168513, lr:  0.000739, elapsed time:  105188
Step 114400, loss: 0.04342936607543379, acc: 99.38499274849892, p_norm: 1913.6811838940855, g_norm: 0.6269888481072606, lr:  0.000739, elapsed time:  105279
Step 114500, loss: 0.043192716813646254, acc: 99.39865985512733, p_norm: 1913.9711072136752, g_norm: 0.6299091884578312, lr:  0.000739, elapsed time:  105371
Step 114600, loss: 0.04376836983952671, acc: 99.38280528783798, p_norm: 1914.279730236881, g_norm: 0.7103120843041003, lr:  0.000738, elapsed time:  105462
Step 114700, loss: 0.044375393572263416, acc: 99.36005413532257, p_norm: 1914.5882137633976, g_norm: 0.6661347986890137, lr:  0.000738, elapsed time:  105551
Step 114800, loss: 0.04426833118312061, acc: 99.37146669626236, p_norm: 1914.8807033751755, g_norm: 0.6371082400123363, lr:  0.000738, elapsed time:  105640
Step 114900, loss: 0.04393761015962809, acc: 99.37483447790146, p_norm: 1915.1695428238359, g_norm: 0.651963653562338, lr:  0.000737, elapsed time:  105732
Step 115000, loss: 0.043967775288037955, acc: 99.37676890194416, p_norm: 1915.4699337686218, g_norm: 0.8293350455787365, lr:  0.000737, elapsed time:  105825
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Target text: C c 1 c c ( N 2 C C C 3 ( C C 2 ) O C C O 3 ) c 2 c c c c ( - c 3 c c c ( Cl ) c c 3 Cl ) c 2 n 1 _EOS
Predicted text: C c 1 c c ( N 2 C C C 3 ( C C 2 ) O C C O 3 ) c 2 c c c c ( - c 3 c c c ( Cl ) c c 3 Cl ) c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N C C ( C C 1 ( C ( = O ) N C 2 C C C ( C ( = O ) O C C ) C C 2 ) C C C C 1 ) C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C C N C C ( C C 1 ( C ( = O ) N C 2 C C C ( C ( = O ) O C C ) C C 2 ) C C C C 1 ) C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 n c ( C ( F ) ( F ) F ) c ( C S ( = O ) ( = O ) C 2 = N O C ( C ) ( C ) C 2 ) c 1 C # N _EOS
Predicted text: C n 1 n c ( C ( F ) ( F ) F ) c ( C S ( = O ) ( = O ) C 2 = N O C ( C ) ( C ) C 2 ) c 1 C # N _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c c c c ( C C ( = O ) N c 2 n c ( - c 3 c [nH] c 4 n c c c c 3 4 ) c s 2 ) c 1 _EOS
Predicted text: N c 1 c c c c ( C C ( = O ) N c 2 n c ( - c 3 c [nH] c 4 n c c c c 3 4 ) c s 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( S ( = O ) ( = O ) N c 2 c c ( - c 3 s c ( N C ( C ) = O ) n c 3 C ) c n c 2 Cl ) c ( O C ) c 1 _EOS
Predicted text: C O c 1 c c c ( S ( = O ) ( = O ) N c 2 c c ( - c 3 s c ( N C ( C ) = O ) n c 3 C ) c n c 2 Cl ) c ( O C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 115000, eval acc (token): 0.9267184385110395, eval acc (sequence): 0.8644991212653779
Saving at step 115000
Step 115100, loss: 0.04219739983789623, acc: 99.42126187682152, p_norm: 1915.7415041550737, g_norm: 0.6527079291901289, lr:  0.000737, elapsed time:  106012
Step 115200, loss: 0.04377260847017169, acc: 99.37738271057606, p_norm: 1916.0346231735834, g_norm: 0.5658302866090843, lr:  0.000736, elapsed time:  106110
Step 115300, loss: 0.043789720330387354, acc: 99.37439063191414, p_norm: 1916.3492039056564, g_norm: 0.6556300935396616, lr:  0.000736, elapsed time:  106204
Step 115400, loss: 0.044167256033979356, acc: 99.37289354205132, p_norm: 1916.6764890475847, g_norm: 0.5292202794585523, lr:  0.000736, elapsed time:  106299
Step 115500, loss: 0.04391602772753686, acc: 99.37342582643032, p_norm: 1916.9599735103811, g_norm: 0.64310229268861, lr:  0.000735, elapsed time:  106397
Step 115600, loss: 0.04284741961862892, acc: 99.41458614170551, p_norm: 1917.2287954406931, g_norm: 0.6353722896093609, lr:  0.000735, elapsed time:  106488
Step 115700, loss: 0.04273571107536554, acc: 99.41024161875248, p_norm: 1917.5015070882525, g_norm: 0.6187801739919311, lr:  0.000735, elapsed time:  106581
Step 115800, loss: 0.0427647306676954, acc: 99.41389444470406, p_norm: 1917.7929667918486, g_norm: 1.0226997620542877, lr:  0.000734, elapsed time:  106676
Step 115900, loss: 0.04294535348657519, acc: 99.41387443244457, p_norm: 1918.0680033424903, g_norm: 0.6557029726785771, lr:  0.000734, elapsed time:  106771
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 116000, loss: 0.0435157125231935, acc: 99.38785934922707, p_norm: 1918.3437404396593, g_norm: 0.5960433831333453, lr:  0.000734, elapsed time:  106865
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 116000, eval loss: 0.04367014002054929, eval acc: 99.45907592773438
Step 116100, loss: 0.04296690956223756, acc: 99.41218827664852, p_norm: 1918.6442176243406, g_norm: 0.6878684452936582, lr:  0.000733, elapsed time:  106968
Step 116200, loss: 0.04323438925202936, acc: 99.4006317704916, p_norm: 1918.95766546912, g_norm: 0.7616214437585825, lr:  0.000733, elapsed time:  107058
Step 116300, loss: 0.043095390936359765, acc: 99.39141815900803, p_norm: 1919.2425052041885, g_norm: 0.6123516042624858, lr:  0.000733, elapsed time:  107146
Step 116400, loss: 0.04356419275980443, acc: 99.39577214419842, p_norm: 1919.5301193224027, g_norm: 0.6108842299308033, lr:  0.000733, elapsed time:  107238
Step 116500, loss: 0.04297896101139486, acc: 99.40077182650566, p_norm: 1919.8057694999686, g_norm: 0.6528263107999829, lr:  0.000732, elapsed time:  107331
Step 116600, loss: 0.04347104075364769, acc: 99.39014342427254, p_norm: 1920.0931417795548, g_norm: 0.6907721143225672, lr:  0.000732, elapsed time:  107420
Step 116700, loss: 0.042976620392873886, acc: 99.40315560996532, p_norm: 1920.3843450698873, g_norm: 0.48064677738863343, lr:  0.000732, elapsed time:  107510
Step 116800, loss: 0.04351582878269255, acc: 99.3897845596075, p_norm: 1920.6565992175326, g_norm: 0.6427100798044879, lr:  0.000731, elapsed time:  107595
Step 116900, loss: 0.043126338166184726, acc: 99.40059074759483, p_norm: 1920.9588880809831, g_norm: 0.5474502632110292, lr:  0.000731, elapsed time:  107686
Step 117000, loss: 0.04287699791137129, acc: 99.41615742444992, p_norm: 1921.2470840563456, g_norm: 0.6877612024963446, lr:  0.000731, elapsed time:  107779
Step 117100, loss: 0.043944245502352715, acc: 99.37549205124378, p_norm: 1921.529795074019, g_norm: 0.6192418372347009, lr:  0.000730, elapsed time:  107867
Step 117200, loss: 0.04389835965819657, acc: 99.37697614729404, p_norm: 1921.7980969738126, g_norm: 0.7427221777492125, lr:  0.000730, elapsed time:  107956
Step 117300, loss: 0.04372544642072171, acc: 99.38342614471912, p_norm: 1922.0955723840755, g_norm: 1.0891371523014362, lr:  0.000730, elapsed time:  108044
Step 117400, loss: 0.043945776699110865, acc: 99.38323077559471, p_norm: 1922.3667849916562, g_norm: 0.6473454112269861, lr:  0.000729, elapsed time:  108134
Step 117500, loss: 0.042521221851930024, acc: 99.43399855494499, p_norm: 1922.631009181119, g_norm: 0.7071582418540789, lr:  0.000729, elapsed time:  108225
Step 117600, loss: 0.04435768806841225, acc: 99.35985854268074, p_norm: 1922.9159387803443, g_norm: 0.5336432078882076, lr:  0.000729, elapsed time:  108314
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 117700, loss: 0.04404732797562928, acc: 99.36852514300098, p_norm: 1923.2052267726729, g_norm: 0.6585396402320536, lr:  0.000728, elapsed time:  108403
Step 117800, loss: 0.0427719135209918, acc: 99.42025412619114, p_norm: 1923.506129993995, g_norm: 0.5138047530909002, lr:  0.000728, elapsed time:  108493
Step 117900, loss: 0.04342765394132584, acc: 99.38594616949558, p_norm: 1923.767374366603, g_norm: 0.6650914498146251, lr:  0.000728, elapsed time:  108582
Step 118000, loss: 0.04356533596292138, acc: 99.38502112030983, p_norm: 1924.0726850624674, g_norm: 0.47757572603331455, lr:  0.000728, elapsed time:  108671
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 118000, eval loss: 0.04357176043093205, eval acc: 99.48545837402344
Step 118100, loss: 0.04341691196430474, acc: 99.38672061264515, p_norm: 1924.3281681052988, g_norm: 0.685054112314081, lr:  0.000727, elapsed time:  108772
Step 118200, loss: 0.043162828264757994, acc: 99.38976900279522, p_norm: 1924.60540815764, g_norm: 1.1855689249439483, lr:  0.000727, elapsed time:  108861
Step 118300, loss: 0.0426263778610155, acc: 99.41657397150993, p_norm: 1924.8862412692724, g_norm: 0.853606069367584, lr:  0.000727, elapsed time:  108951
Step 118400, loss: 0.04301835770253092, acc: 99.40613962709904, p_norm: 1925.1587456554828, g_norm: 0.5739349255444537, lr:  0.000726, elapsed time:  109040
Step 118500, loss: 0.04252063731197268, acc: 99.4157959073782, p_norm: 1925.4502939041668, g_norm: 0.8972315032760628, lr:  0.000726, elapsed time:  109127
Step 118600, loss: 0.04280905892141163, acc: 99.40376684069633, p_norm: 1925.735428810394, g_norm: 0.6220820768511359, lr:  0.000726, elapsed time:  109218
Step 118700, loss: 0.04386849428061396, acc: 99.36974401772022, p_norm: 1926.0510228413307, g_norm: 0.7047142245734705, lr:  0.000725, elapsed time:  109312
Step 118800, loss: 0.042372391708195206, acc: 99.42182698845863, p_norm: 1926.3507867933413, g_norm: 0.5854132132241651, lr:  0.000725, elapsed time:  109407
Step 118900, loss: 0.04374089367222041, acc: 99.38290263712406, p_norm: 1926.6179489960236, g_norm: 0.6297783094222403, lr:  0.000725, elapsed time:  109488
Step 119000, loss: 0.04483267293777317, acc: 99.37066976726055, p_norm: 1926.9129427875446, g_norm: 0.7880615993303433, lr:  0.000725, elapsed time:  109579
Step 119100, loss: 0.045359042449854316, acc: 99.39112856984138, p_norm: 1927.2645590236577, g_norm: 0.5527768885807556, lr:  0.000724, elapsed time:  109673
Step 119200, loss: 0.0435979964537546, acc: 99.42043434083462, p_norm: 1927.5361330237783, g_norm: 0.7298948000431217, lr:  0.000724, elapsed time:  109768
Step 119300, loss: 0.044716567476280035, acc: 99.38460646569729, p_norm: 1927.810357969988, g_norm: 0.6216509648291288, lr:  0.000724, elapsed time:  109859
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 119400, loss: 0.04595239170877939, acc: 99.37194148402902, p_norm: 1928.121969954049, g_norm: 0.5757110485129042, lr:  0.000723, elapsed time:  109948
Step 119500, loss: 0.04672028430737555, acc: 99.38891364634037, p_norm: 1928.4237817383312, g_norm: 0.8804327490826613, lr:  0.000723, elapsed time:  110040
Step 119600, loss: 0.046243629772216084, acc: 99.38505928218365, p_norm: 1928.7065305490505, g_norm: 0.7040239685485715, lr:  0.000723, elapsed time:  110131
Step 119700, loss: 0.04503679254557937, acc: 99.39385178685188, p_norm: 1928.9678950702037, g_norm: 0.8462256337303304, lr:  0.000722, elapsed time:  110221
Step 119800, loss: 0.04395439607091248, acc: 99.39706811308861, p_norm: 1929.2218800672833, g_norm: 0.9936302057910665, lr:  0.000722, elapsed time:  110313
Step 119900, loss: 0.04307011500000954, acc: 99.42306047677994, p_norm: 1929.5005911077185, g_norm: 0.7398151215424105, lr:  0.000722, elapsed time:  110403
Step 120000, loss: 0.043286861972883346, acc: 99.41665463149548, p_norm: 1929.7511252309064, g_norm: 0.5520153830114095, lr:  0.000721, elapsed time:  110494
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 120000, eval loss: 0.04691211229190228, eval acc: 99.40809631347656
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: N C 1 C c 2 c c c c ( N 3 C C C C 3 = O ) c 2 N ( C c 2 c c s c 2 ) C 1 = O _EOS
Predicted text: N C 1 C c 2 c c c c ( N 3 C C C C 3 = O ) c 2 N ( C c 2 c c s c 2 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C c 1 n c 2 c ( N ) n c 3 c c ( O c 4 c c c ( [N+] ( = O ) [O-] ) c c 4 ) c c c 3 c 2 n 1 C C ( C ) C _EOS
Predicted text: C C C c 1 n c 2 c ( N ) n c 3 c c ( O c 4 c c c ( [N+] ( = O ) [O-] ) c c 4 ) c c c 3 c 2 n 1 C C ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c c ( [N+] ( = O ) [O-] ) n 1 C C N 1 C ( = O ) C C ( C ) ( C ) C C 1 = O _EOS
Predicted text: C c 1 n c c ( [N+] ( = O ) [O-] ) n 1 C C N 1 C ( = O ) C C ( C ) ( C ) C C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N ( C C ) C ( = O ) C C C C C C N C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C C N ( C C ) C ( = O ) C C C C C C N C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C O c 1 c c c ( S C ( C C ) C N S ( = O ) ( = O ) c 2 c c c ( O C ( F ) ( F ) F ) c c 2 ) c c 1 C _EOS
Predicted text: C C O C ( = O ) C O c 1 c c c ( S C ( C C ) C N S ( = O ) ( = O ) c 2 c c c ( O C ( F ) ( F ) F ) c c 2 ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 120000, eval acc (token): 0.9292220055978243, eval acc (sequence): 0.8666432707492543
Saving at step 120000
Step 120100, loss: 0.042923374376259746, acc: 99.42392028868198, p_norm: 1930.0078480211848, g_norm: 0.595690849784282, lr:  0.000721, elapsed time:  110682
Step 120200, loss: 0.043221437688916925, acc: 99.42154417932034, p_norm: 1930.303302880819, g_norm: 0.5691315919922146, lr:  0.000721, elapsed time:  110774
Step 120300, loss: 0.04376622105017305, acc: 99.39189244806767, p_norm: 1930.5856776477606, g_norm: 0.5675437245104187, lr:  0.000721, elapsed time:  110865
Step 120400, loss: 0.0446155562531203, acc: 99.38123625516891, p_norm: 1930.840965701578, g_norm: 0.670295646042769, lr:  0.000720, elapsed time:  110952
Step 120500, loss: 0.04313404035754502, acc: 99.40917141735554, p_norm: 1931.1072568277193, g_norm: 0.6245933384043214, lr:  0.000720, elapsed time:  111044
Step 120600, loss: 0.04318871037568897, acc: 99.4033864736557, p_norm: 1931.3734307461095, g_norm: 0.569217135620941, lr:  0.000720, elapsed time:  111132
Step 120700, loss: 0.04233233996666968, acc: 99.41546729207039, p_norm: 1931.6395913553279, g_norm: 0.5244062770524304, lr:  0.000719, elapsed time:  111220
Step 120800, loss: 0.04437435255385935, acc: 99.37015718221664, p_norm: 1931.900614311901, g_norm: 0.7403837074553777, lr:  0.000719, elapsed time:  111311
Step 120900, loss: 0.042872605766169726, acc: 99.40256710350513, p_norm: 1932.167932655057, g_norm: 0.6831505788041968, lr:  0.000719, elapsed time:  111398
Step 121000, loss: 0.04289545113220811, acc: 99.39933186769485, p_norm: 1932.4494370144923, g_norm: 0.682756981757301, lr:  0.000718, elapsed time:  111490
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 121100, loss: 0.04222744075170078, acc: 99.42064484946485, p_norm: 1932.6900336238612, g_norm: 0.5294635466716426, lr:  0.000718, elapsed time:  111578
Step 121200, loss: 0.042084113769233225, acc: 99.42756828665733, p_norm: 1932.9709357178078, g_norm: 0.6137425528733436, lr:  0.000718, elapsed time:  111667
Step 121300, loss: 0.04228707405738533, acc: 99.41082540154457, p_norm: 1933.2579041247636, g_norm: 0.5933437468505647, lr:  0.000718, elapsed time:  111758
Step 121400, loss: 0.04210033243056387, acc: 99.42886598408222, p_norm: 1933.521936927336, g_norm: 0.8570051220217861, lr:  0.000717, elapsed time:  111848
Step 121500, loss: 0.04262475350406021, acc: 99.41107094287872, p_norm: 1933.8164814592674, g_norm: 0.6933268045818989, lr:  0.000717, elapsed time:  111936
Step 121600, loss: 0.042553734476678075, acc: 99.41868081688881, p_norm: 1934.1290605203712, g_norm: 0.6270267124188525, lr:  0.000717, elapsed time:  112027
Step 121700, loss: 0.043789569125510755, acc: 99.38340100646019, p_norm: 1934.418126625154, g_norm: 0.6402384050410127, lr:  0.000716, elapsed time:  112117
Step 121800, loss: 0.04325467868242413, acc: 99.40337832272053, p_norm: 1934.6796306428773, g_norm: 0.6543029966930181, lr:  0.000716, elapsed time:  112206
Step 121900, loss: 0.043501735981553796, acc: 99.39142613112926, p_norm: 1934.9578562715544, g_norm: 0.525289653438568, lr:  0.000716, elapsed time:  112295
Step 122000, loss: 0.04292658428195864, acc: 99.40516075491905, p_norm: 1935.2383117172064, g_norm: 0.6923471570304951, lr:  0.000716, elapsed time:  112383
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 122000, eval loss: 0.04537294713780283, eval acc: 99.4457015991211
Step 122100, loss: 0.04373846082482487, acc: 99.38218808174133, p_norm: 1935.523070943075, g_norm: 0.759853118584215, lr:  0.000715, elapsed time:  112487
Step 122200, loss: 0.04240405023097992, acc: 99.4251649081707, p_norm: 1935.7916004404592, g_norm: 0.6905103060165526, lr:  0.000715, elapsed time:  112579
Step 122300, loss: 0.043584353080950676, acc: 99.3847326785326, p_norm: 1936.0758787037744, g_norm: 0.5546494780214593, lr:  0.000715, elapsed time:  112668
Step 122400, loss: 0.04285797438118607, acc: 99.41546346247196, p_norm: 1936.3414285820058, g_norm: 0.6541244363281646, lr:  0.000714, elapsed time:  112756
Step 122500, loss: 0.04278089621569961, acc: 99.40906931459904, p_norm: 1936.6096101933317, g_norm: 0.5588700971037834, lr:  0.000714, elapsed time:  112848
Step 122600, loss: 0.041735859555192295, acc: 99.4332033842802, p_norm: 1936.8781498227363, g_norm: 0.6636309123128363, lr:  0.000714, elapsed time:  112939
Step 122700, loss: 0.04256875136867166, acc: 99.41138380765915, p_norm: 1937.1499018016611, g_norm: 1.0931371434367714, lr:  0.000713, elapsed time:  113030
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 122800, loss: 0.04226677925024756, acc: 99.4168255014799, p_norm: 1937.4077279497094, g_norm: 0.6640126936894791, lr:  0.000713, elapsed time:  113118
Step 122900, loss: 0.04126219510100782, acc: 99.44730040431023, p_norm: 1937.6903541313907, g_norm: 0.7964737709063237, lr:  0.000713, elapsed time:  113212
Step 123000, loss: 0.04233119965530932, acc: 99.42659805715084, p_norm: 1937.9765642847074, g_norm: 0.5226902530298456, lr:  0.000713, elapsed time:  113302
Step 123100, loss: 0.042643385431729255, acc: 99.41052681207657, p_norm: 1938.2554543470726, g_norm: 0.640454982393538, lr:  0.000712, elapsed time:  113389
Step 123200, loss: 0.04198348641395569, acc: 99.43669533729553, p_norm: 1938.502210071092, g_norm: 0.5195309245894941, lr:  0.000712, elapsed time:  113478
Step 123300, loss: 0.041881536142900584, acc: 99.43559877574444, p_norm: 1938.7744938584563, g_norm: 0.7966624267398202, lr:  0.000712, elapsed time:  113568
Step 123400, loss: 0.042176304012537004, acc: 99.4275107383728, p_norm: 1939.046520321879, g_norm: 0.7721928644725649, lr:  0.000711, elapsed time:  113654
Step 123500, loss: 0.042000537645071744, acc: 99.43047544360161, p_norm: 1939.3511270537695, g_norm: 0.6882046460338073, lr:  0.000711, elapsed time:  113745
Step 123600, loss: 0.042840707097202536, acc: 99.40410226583481, p_norm: 1939.6405409601277, g_norm: 0.5350399218039452, lr:  0.000711, elapsed time:  113838
Step 123700, loss: 0.04269585737492889, acc: 99.41206701099873, p_norm: 1939.9079589703947, g_norm: 0.609304287072036, lr:  0.000711, elapsed time:  113930
Step 123800, loss: 0.043068328546360134, acc: 99.39846889674664, p_norm: 1940.1947102473791, g_norm: 0.710372515358586, lr:  0.000710, elapsed time:  114018
Step 123900, loss: 0.18696059234440326, acc: 99.41583143174648, p_norm: 1940.4864752920982, g_norm: 0.66302330170009, lr:  0.000710, elapsed time:  114112
Step 124000, loss: 0.04473636942449957, acc: 99.40767395496368, p_norm: 1940.772672069356, g_norm: 0.7272941425976533, lr:  0.000710, elapsed time:  114210
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 124000, eval loss: 0.045130999013781536, eval acc: 99.48033142089844
Step 124100, loss: 0.04518883099779487, acc: 99.38635148108006, p_norm: 1941.0186027244213, g_norm: 0.6321273177200905, lr:  0.000709, elapsed time:  114314
Step 124200, loss: 0.043206297904253003, acc: 99.44711726903915, p_norm: 1941.251361078076, g_norm: 0.7762443967306553, lr:  0.000709, elapsed time:  114409
Step 124300, loss: 0.04443849322386086, acc: 99.39539907872677, p_norm: 1941.5352940981606, g_norm: 0.6080092399893173, lr:  0.000709, elapsed time:  114500
Step 124400, loss: 0.045020080953836444, acc: 99.38350927829742, p_norm: 1941.819870108787, g_norm: 0.5747879757771043, lr:  0.000709, elapsed time:  114594
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 124500, loss: 0.044246577750428104, acc: 99.38990887421281, p_norm: 1942.0613985631658, g_norm: 0.7223391960084226, lr:  0.000708, elapsed time:  114684
Step 124600, loss: 0.043656007251702246, acc: 99.3910244256258, p_norm: 1942.3224761868362, g_norm: 0.6453184707882686, lr:  0.000708, elapsed time:  114774
Step 124700, loss: 0.0412360799126327, acc: 99.4653555303812, p_norm: 1942.572158208587, g_norm: 0.7168324273822124, lr:  0.000708, elapsed time:  114867
Step 124800, loss: 0.04148456547409296, acc: 99.43195249140263, p_norm: 1942.8228623505145, g_norm: 0.6050845902665388, lr:  0.000707, elapsed time:  114955
Step 124900, loss: 0.04192214770708233, acc: 99.426752358675, p_norm: 1943.1026077879685, g_norm: 0.588625196009993, lr:  0.000707, elapsed time:  115046
Step 125000, loss: 0.04085607217159122, acc: 99.45478396117687, p_norm: 1943.379213205469, g_norm: 0.7820503028420387, lr:  0.000707, elapsed time:  115139
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O C ( = O ) C 1 ( O ) C c 2 c c ( Cl ) c c c 2 C 1 = O _EOS
Predicted text: C O C ( = O ) C 1 C c 2 c c ( Cl ) c c c 2 C 1 = O _EOS _PAD _PAD _PAD
acc_token: 0.3448275862068966, acc_seq: False

Target text: C C O C ( = O ) C C 1 c 2 c c c c c 2 C ( = O ) N 1 C C _EOS
Predicted text: C C O C ( = O ) C C 1 c 2 c c c c c 2 C ( = O ) N 1 C C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 N ( C C 2 C O C C O 2 ) c 2 c c c c c 2 C 1 2 C O c 1 c c 3 c ( c c 1 2 ) O C C O 3 _EOS
Predicted text: O = C 1 N ( C C 2 C O C C O 2 ) c 2 c c c c c 2 C 1 2 C O c 1 c c 3 c ( c c 1 2 ) O C C O 3 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n n c ( - c 2 c c c 3 n c n c ( N c 4 c c c 5 c ( c n n 5 C c 5 c c c c ( F ) c 5 F ) c 4 ) c 3 c 2 ) o 1 . Cl _EOS
Predicted text: C c 1 n n c ( - c 2 c c c 3 n c n c ( N c 4 c c c 5 c ( c n n 5 C c 5 c c c c ( F ) c 5 F ) c 4 ) c 3 c 2 ) o 1 . Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C N ( C C 1 ( C ( = O ) O ) C C C C 1 ) O C c 1 c c c c c 1 _EOS
Predicted text: O = C N ( C C 1 ( C ( = O ) O ) C C C C 1 ) O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 125000, eval acc (token): 0.9261972956823316, eval acc (sequence): 0.8642245307089484
Saving at step 125000
Step 125100, loss: 0.04239729254040867, acc: 99.41138707101345, p_norm: 1943.65450199724, g_norm: 0.74328787497166, lr:  0.000707, elapsed time:  115318
Step 125200, loss: 0.042649087114259604, acc: 99.41202533245087, p_norm: 1943.9413968740068, g_norm: 0.5266736936929348, lr:  0.000706, elapsed time:  115407
Step 125300, loss: 0.04174106144346297, acc: 99.43578536808491, p_norm: 1944.197262540453, g_norm: 0.6195681248092982, lr:  0.000706, elapsed time:  115500
Step 125400, loss: 0.04280904846731573, acc: 99.39497908949852, p_norm: 1944.4504999866595, g_norm: 0.7160883548605634, lr:  0.000706, elapsed time:  115589
Step 125500, loss: 0.04217901856638491, acc: 99.42550256848335, p_norm: 1944.7202122854237, g_norm: 0.6865571689225691, lr:  0.000705, elapsed time:  115683
Step 125600, loss: 0.04274642582517117, acc: 99.40374232828617, p_norm: 1944.9932213931638, g_norm: 0.5554522934910937, lr:  0.000705, elapsed time:  115777
Step 125700, loss: 0.04271732295863331, acc: 99.39962241053581, p_norm: 1945.242061916956, g_norm: 0.7345167300314317, lr:  0.000705, elapsed time:  115871
Step 125800, loss: 0.043047076892107725, acc: 99.40320359170437, p_norm: 1945.5145302739722, g_norm: 0.7699119689696687, lr:  0.000705, elapsed time:  115963
Step 125900, loss: 0.04236381695605815, acc: 99.42143569886684, p_norm: 1945.774222872422, g_norm: 0.6555794224677791, lr:  0.000704, elapsed time:  116057
Step 126000, loss: 0.04355006522033364, acc: 99.39601048827171, p_norm: 1946.0546323764984, g_norm: 0.5818260129833295, lr:  0.000704, elapsed time:  116150
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 126000, eval loss: 0.04556599559262395, eval acc: 99.42913818359375
Step 126100, loss: 0.04252131897956133, acc: 99.41455651819706, p_norm: 1946.31991335162, g_norm: 0.6556066846114629, lr:  0.000704, elapsed time:  116258
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 126200, loss: 0.04286010396569522, acc: 99.402149577639, p_norm: 1946.5686727979619, g_norm: 0.4720234756772387, lr:  0.000704, elapsed time:  116346
Step 126300, loss: 0.04196088945027441, acc: 99.43144336342812, p_norm: 1946.8248335097294, g_norm: 0.5186188169270255, lr:  0.000703, elapsed time:  116437
Step 126400, loss: 0.04207729231100529, acc: 99.42586961388588, p_norm: 1947.0874615725595, g_norm: 0.6505995547732495, lr:  0.000703, elapsed time:  116524
Step 126500, loss: 0.04188725636806339, acc: 99.43480235338211, p_norm: 1947.3500344027275, g_norm: 0.6067088751368998, lr:  0.000703, elapsed time:  116611
Step 126600, loss: 0.041590410144999625, acc: 99.4371717274189, p_norm: 1947.5868800902895, g_norm: 0.5451578128297498, lr:  0.000702, elapsed time:  116702
Step 126700, loss: 0.04160704093519598, acc: 99.44084577262402, p_norm: 1947.851632408653, g_norm: 0.6002201708418378, lr:  0.000702, elapsed time:  116800
Step 126800, loss: 0.04198563519865275, acc: 99.42945557832718, p_norm: 1948.0977830590668, g_norm: 0.6085017071561742, lr:  0.000702, elapsed time:  116887
Step 126900, loss: 0.04205084608402103, acc: 99.42460399866104, p_norm: 1948.348406126728, g_norm: 0.7317659372634823, lr:  0.000702, elapsed time:  116975
Step 127000, loss: 0.04247730816248804, acc: 99.41751895844936, p_norm: 1948.605050258868, g_norm: 0.7335489440373099, lr:  0.000701, elapsed time:  117057
Step 127100, loss: 0.04180756112094969, acc: 99.42792658507824, p_norm: 1948.8564368467144, g_norm: 0.7134372447337028, lr:  0.000701, elapsed time:  117153
Step 127200, loss: 0.04225749023724348, acc: 99.42495189607143, p_norm: 1949.1229526154993, g_norm: 0.6345698305339763, lr:  0.000701, elapsed time:  117249
Step 127300, loss: 0.04256170697044581, acc: 99.41725143790245, p_norm: 1949.4204873813342, g_norm: 0.580219961740981, lr:  0.000700, elapsed time:  117341
Step 127400, loss: 0.04233293672092259, acc: 99.40524956583977, p_norm: 1949.672582347881, g_norm: 0.4620330868038686, lr:  0.000700, elapsed time:  117432
Step 127500, loss: 0.042377722254022955, acc: 99.4197151362896, p_norm: 1949.9505108449162, g_norm: 0.8376304181207873, lr:  0.000700, elapsed time:  117522
Step 127600, loss: 0.04340570854954422, acc: 99.38608564436436, p_norm: 1950.2329042558988, g_norm: 0.758347116734644, lr:  0.000700, elapsed time:  117614
Step 127700, loss: 0.04300649519544095, acc: 99.39776507019997, p_norm: 1950.4874750285644, g_norm: 0.7771953448067459, lr:  0.000699, elapsed time:  117706
Step 127800, loss: 0.042408328941091894, acc: 99.42352311313152, p_norm: 1950.7473931988438, g_norm: 0.555379975353977, lr:  0.000699, elapsed time:  117797
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 127900, loss: 0.04174235533858203, acc: 99.44427245603897, p_norm: 1951.0119455467577, g_norm: 0.6105220287264274, lr:  0.000699, elapsed time:  117892
Step 128000, loss: 0.04126258570235222, acc: 99.46010805666447, p_norm: 1951.2579378876967, g_norm: 0.7225169774799275, lr:  0.000699, elapsed time:  117980
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 128000, eval loss: 0.044533907305449254, eval acc: 99.45201110839844
Step 128100, loss: 0.04138546279631555, acc: 99.45324769616127, p_norm: 1951.484637498462, g_norm: 0.6971750409031705, lr:  0.000698, elapsed time:  118087
Step 128200, loss: 0.041368037476204336, acc: 99.45359721779823, p_norm: 1951.7311251658643, g_norm: 0.6720111735026161, lr:  0.000698, elapsed time:  118176
Step 128300, loss: 0.04267120415810496, acc: 99.41456919908524, p_norm: 1951.9821599292272, g_norm: 0.6762822318365151, lr:  0.000698, elapsed time:  118262
Step 128400, loss: 0.042209452334791425, acc: 99.4295517206192, p_norm: 1952.2571215986957, g_norm: 0.46502835848957164, lr:  0.000697, elapsed time:  118351
Step 128500, loss: 0.04077632346656174, acc: 99.46748919785023, p_norm: 1952.4834110634747, g_norm: 0.5473560115883396, lr:  0.000697, elapsed time:  118440
Step 128600, loss: 0.04354624104686081, acc: 99.37862719595432, p_norm: 1952.7618933239476, g_norm: 0.6523593367580024, lr:  0.000697, elapsed time:  118529
Step 128700, loss: 0.04157422164455056, acc: 99.44542326033115, p_norm: 1953.0189409246655, g_norm: 0.6630809170286793, lr:  0.000697, elapsed time:  118621
Step 128800, loss: 0.04112398994155228, acc: 99.46116855740547, p_norm: 1953.2685563260156, g_norm: 0.6227865333559641, lr:  0.000696, elapsed time:  118717
Step 128900, loss: 0.04251327234320343, acc: 99.41315384209156, p_norm: 1953.5307837882622, g_norm: 0.5941311750961974, lr:  0.000696, elapsed time:  118807
Step 129000, loss: 0.043050065957941114, acc: 99.40105186402798, p_norm: 1953.8439113004497, g_norm: 0.7680509581684957, lr:  0.000696, elapsed time:  118897
Step 129100, loss: 0.0423902525100857, acc: 99.42644834518433, p_norm: 1954.0962780489294, g_norm: 0.5812503312304493, lr:  0.000696, elapsed time:  118990
Step 129200, loss: 0.04211466463748366, acc: 99.42873995006084, p_norm: 1954.329743801241, g_norm: 0.6058582689971426, lr:  0.000695, elapsed time:  119082
Step 129300, loss: 0.04214230767916888, acc: 99.42238065600395, p_norm: 1954.5795725394112, g_norm: 0.5396141896173791, lr:  0.000695, elapsed time:  119175
Step 129400, loss: 0.04235392434988171, acc: 99.4234988540411, p_norm: 1954.8445172523702, g_norm: 0.6789375341834413, lr:  0.000695, elapsed time:  119272
Step 129500, loss: 0.04234371103346348, acc: 99.41370721161366, p_norm: 1955.07183356449, g_norm: 0.7306889033217933, lr:  0.000695, elapsed time:  119363
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 129600, loss: 0.0417504326969607, acc: 99.43798932780699, p_norm: 1955.3422289016164, g_norm: 0.6358648586501653, lr:  0.000694, elapsed time:  119464
Step 129700, loss: 0.04135718013159931, acc: 99.44802531599998, p_norm: 1955.599441036847, g_norm: 0.9444235529239342, lr:  0.000694, elapsed time:  119555
Step 129800, loss: 0.0408998989732936, acc: 99.45801474153996, p_norm: 1955.8364812916457, g_norm: 0.7010590040267147, lr:  0.000694, elapsed time:  119645
Step 129900, loss: 0.04228209094610065, acc: 99.4233673363924, p_norm: 1956.0766649601662, g_norm: 0.5285022351443323, lr:  0.000693, elapsed time:  119735
Step 130000, loss: 0.04207741091959179, acc: 99.46232502162457, p_norm: 1956.2975903704842, g_norm: 0.6594577491389731, lr:  0.000693, elapsed time:  119830
Calling G2SDataset.batch()
Done, time:  0.05 s, total batches: 526
Evaluation (with teacher) at step 130000, eval loss: 0.04724439410492777, eval acc: 99.45613098144531
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c ( N ) c ( O ) c 2 c 1 C C C 2 = O _EOS
Predicted text: C c 1 c c ( N ) c ( O ) c 2 c 1 C C C 2 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N C C 1 C N ( c 2 c ( F ) c c 3 c ( = O ) c ( C ( = O ) O ) c n ( C C ) c 3 c 2 F ) C C O 1 _EOS
Predicted text: C C N C C 1 C N ( c 2 c ( F ) c c 3 c ( = O ) c ( C ( = O ) O ) c n ( C C ) c 3 c 2 F ) C C O 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C C 2 C N ( c 3 c c c ( Cl ) n c 3 ) C 2 C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C C 2 C N ( c 3 c c c ( Cl ) n c 3 ) C 2 C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C O c 1 n c c c c 1 O c 1 c c ( - n 2 c ( = O ) c c ( C ( F ) ( F ) F ) n ( C ) c 2 = O ) c ( F ) c c 1 Cl _EOS
Predicted text: C O C ( = O ) C O c 1 n c c c c 1 O c 1 c c ( - n 2 c ( = O ) c c ( C ( F ) ( F ) F ) n ( C ) c 2 = O ) c ( F ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N 1 C C N ( C ( = O ) c 2 c c c ( N C ( = O ) N 3 C C c 4 c ( - c 5 c n c ( N ) n c 5 ) n c ( N 5 C C O C C 5 ) n c 4 3 ) c ( C ) c 2 ) C C 1 _EOS
Predicted text: C C N 1 C C N ( C ( = O ) c 2 c c c ( N C ( = O ) N 3 C C c 4 c ( - c 5 c n c ( N ) n c 5 ) n c ( N 5 C C O C C 5 ) n c 4 3 ) c ( C ) c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 130000, eval acc (token): 0.9317375631106254, eval acc (sequence): 0.8720238095238095
Saving at step 130000
Step 130100, loss: 0.041841312828473746, acc: 99.43166781961918, p_norm: 1956.5376558847856, g_norm: 1.0535066152796333, lr:  0.000693, elapsed time:  120021
Step 130200, loss: 0.04157399836461991, acc: 99.44623185694218, p_norm: 1956.806219203295, g_norm: 0.5878697345503721, lr:  0.000693, elapsed time:  120112
Step 130300, loss: 0.04388377865310758, acc: 99.39332543313503, p_norm: 1957.0658659422354, g_norm: 0.5757702207958277, lr:  0.000692, elapsed time:  120201
Step 130400, loss: 0.04410649064462632, acc: 99.41167975962162, p_norm: 1957.3499343669316, g_norm: 0.7663294022478466, lr:  0.000692, elapsed time:  120288
Step 130500, loss: 0.04413345065433532, acc: 99.41820034384727, p_norm: 1957.6214967364413, g_norm: 0.6543991331603412, lr:  0.000692, elapsed time:  120381
Step 130600, loss: 0.04411219364963472, acc: 99.41298884153366, p_norm: 1957.9032859191238, g_norm: 3.7271388659660207, lr:  0.000692, elapsed time:  120471
Step 130700, loss: 0.043819918246008456, acc: 99.42122742533684, p_norm: 1958.1247448442855, g_norm: 0.5301115563362575, lr:  0.000691, elapsed time:  120566
Step 130800, loss: 0.04290461657103151, acc: 99.42586360871792, p_norm: 1958.344349717851, g_norm: 0.5272764945814362, lr:  0.000691, elapsed time:  120655
Step 130900, loss: 0.04316527380142361, acc: 99.41905543208122, p_norm: 1958.5985493409676, g_norm: 0.6073154697356757, lr:  0.000691, elapsed time:  120743
Step 131000, loss: 0.04312672583851963, acc: 99.4216868430376, p_norm: 1958.890945645469, g_norm: 0.6116401781742923, lr:  0.000691, elapsed time:  120840
Step 131100, loss: 0.0427377243200317, acc: 99.4417964220047, p_norm: 1959.1197983785034, g_norm: 0.7104588576168676, lr:  0.000690, elapsed time:  120930
Step 131200, loss: 0.044077219697646795, acc: 99.39686317741871, p_norm: 1959.3763572949456, g_norm: 0.8291862194044645, lr:  0.000690, elapsed time:  121020
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 131300, loss: 0.050821648618734595, acc: 99.44235867825313, p_norm: 1959.597233756063, g_norm: 0.6310738314301301, lr:  0.000690, elapsed time:  121115
Step 131400, loss: 0.042892623227089643, acc: 99.4386276602745, p_norm: 1959.832018883732, g_norm: 0.6202332902462555, lr:  0.000689, elapsed time:  121202
Step 131500, loss: 4.373930157665163, acc: 99.46236836910248, p_norm: 1960.0766243866503, g_norm: 0.6195460329588993, lr:  0.000689, elapsed time:  121291
Step 131600, loss: 0.043399262470193205, acc: 99.41004379093647, p_norm: 1960.307905753492, g_norm: 0.6080564092271817, lr:  0.000689, elapsed time:  121378
Step 131700, loss: 0.04213818448130041, acc: 99.445332467556, p_norm: 1960.5425641038566, g_norm: 0.5580310989475753, lr:  0.000689, elapsed time:  121467
Step 131800, loss: 0.042702429620549084, acc: 99.43541820347309, p_norm: 1960.8118573993213, g_norm: 0.5700707843290928, lr:  0.000688, elapsed time:  121561
Step 131900, loss: 0.04258215882349759, acc: 99.44501946866512, p_norm: 1961.0622596058759, g_norm: 0.6324480705036305, lr:  0.000688, elapsed time:  121651
Step 132000, loss: 0.041929969545453784, acc: 99.4494419246912, p_norm: 1961.280713227509, g_norm: 0.5720907760182737, lr:  0.000688, elapsed time:  121739
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 132000, eval loss: 0.043556004930287606, eval acc: 99.4755859375
Step 132100, loss: 0.04235668328590691, acc: 99.42438572645187, p_norm: 1961.5243927451734, g_norm: 0.7134336896733904, lr:  0.000688, elapsed time:  121855
Step 132200, loss: 0.04191297507379204, acc: 99.45344512164593, p_norm: 1961.7631266612782, g_norm: 0.5697002756891262, lr:  0.000687, elapsed time:  121944
Step 132300, loss: 0.041950777913443746, acc: 99.44376553595066, p_norm: 1962.0124609067786, g_norm: 0.6876078473649764, lr:  0.000687, elapsed time:  122036
Step 132400, loss: 0.04246683320961893, acc: 99.42393365502357, p_norm: 1962.2953251811527, g_norm: 0.522749684973425, lr:  0.000687, elapsed time:  122135
Step 132500, loss: 0.0418538148701191, acc: 99.44111977517605, p_norm: 1962.5460437668867, g_norm: 0.5638351859827826, lr:  0.000687, elapsed time:  122230
Step 132600, loss: 0.041445498638786375, acc: 99.45539590716362, p_norm: 1962.7952494777323, g_norm: 0.662736786709142, lr:  0.000686, elapsed time:  122321
Step 132700, loss: 0.04224468795116991, acc: 99.42065285146236, p_norm: 1963.0792117827837, g_norm: 0.6313639136995641, lr:  0.000686, elapsed time:  122411
Step 132800, loss: 0.0422856795694679, acc: 99.43191201984882, p_norm: 1963.3362924484504, g_norm: 0.7453342375868064, lr:  0.000686, elapsed time:  122505
Step 132900, loss: 0.04309821635484695, acc: 99.39735843241215, p_norm: 1963.5605985947798, g_norm: 0.9471976584868477, lr:  0.000686, elapsed time:  122600
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 133000, loss: 0.043454252030913056, acc: 99.43722888790349, p_norm: 1963.8664775618881, g_norm: 0.5302634378379093, lr:  0.000685, elapsed time:  122697
Step 133100, loss: 0.0415302680246532, acc: 99.44983838498592, p_norm: 1964.090778886838, g_norm: 0.5079695670211352, lr:  0.000685, elapsed time:  122790
Step 133200, loss: 0.039985569431446495, acc: 99.49817718565464, p_norm: 1964.3242328515128, g_norm: 1.316512957467428, lr:  0.000685, elapsed time:  122881
Step 133300, loss: 0.04189051669090986, acc: 99.43028718233109, p_norm: 1964.6149318443008, g_norm: 0.550576568253572, lr:  0.000685, elapsed time:  122971
Step 133400, loss: 0.04123251917306334, acc: 99.44782757759094, p_norm: 1964.851182227148, g_norm: 0.7849548868443297, lr:  0.000684, elapsed time:  123062
Step 133500, loss: 0.060189982783049344, acc: 99.42995204031467, p_norm: 1965.1739411914248, g_norm: 0.5688042991484294, lr:  0.000684, elapsed time:  123153
Step 133600, loss: 0.044462437415495513, acc: 99.43975485861301, p_norm: 1965.4017444742503, g_norm: 0.6100419909795135, lr:  0.000684, elapsed time:  123247
Step 133700, loss: 0.0439611442014575, acc: 99.43217316269875, p_norm: 1965.6322336925625, g_norm: 0.6096379968776404, lr:  0.000684, elapsed time:  123339
Step 133800, loss: 0.04322605759836733, acc: 99.43391162157059, p_norm: 1965.8332056621277, g_norm: 0.6118921470829487, lr:  0.000683, elapsed time:  123426
Step 133900, loss: 0.042754297517240046, acc: 99.43273384869099, p_norm: 1966.0587618834338, g_norm: 0.5741214515110737, lr:  0.000683, elapsed time:  123522
Step 134000, loss: 0.04288239385932684, acc: 99.41875712573528, p_norm: 1966.32272384622, g_norm: 0.8770834519018574, lr:  0.000683, elapsed time:  123612
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 134000, eval loss: 0.044998389296233635, eval acc: 99.44956970214844
Step 134100, loss: 0.041689731976948675, acc: 99.4464482665062, p_norm: 1966.5725209589611, g_norm: 0.41792305242029515, lr:  0.000682, elapsed time:  123724
Step 134200, loss: 0.04321389250922948, acc: 99.4270000308752, p_norm: 1966.8210578773708, g_norm: 0.674404120484754, lr:  0.000682, elapsed time:  123818
Step 134300, loss: 0.04388563605491072, acc: 99.41963085532188, p_norm: 1967.0626734522316, g_norm: 0.7532720341853075, lr:  0.000682, elapsed time:  123909
Step 134400, loss: 0.04278017390985042, acc: 99.41728147864342, p_norm: 1967.3138167099178, g_norm: 0.6853192554977633, lr:  0.000682, elapsed time:  123997
Step 134500, loss: 0.04226890081074089, acc: 99.42775191366673, p_norm: 1967.5630932512881, g_norm: 0.5678624042263268, lr:  0.000681, elapsed time:  124092
Step 134600, loss: 0.04258530447259545, acc: 99.41700795292854, p_norm: 1967.8077100816718, g_norm: 0.7702230022061678, lr:  0.000681, elapsed time:  124186
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 134700, loss: 0.042129966550835625, acc: 99.4283081138905, p_norm: 1968.0787684501624, g_norm: 0.57093306502223, lr:  0.000681, elapsed time:  124279
Step 134800, loss: 0.0417973649315536, acc: 99.4293062388897, p_norm: 1968.3080282351818, g_norm: 0.5462816276438186, lr:  0.000681, elapsed time:  124370
Step 134900, loss: 0.04087932987138629, acc: 99.45187652111053, p_norm: 1968.5600566589774, g_norm: 0.47714464193612266, lr:  0.000680, elapsed time:  124464
Step 135000, loss: 0.042016600179485976, acc: 99.42275848984718, p_norm: 1968.7935447570012, g_norm: 0.6154885192048642, lr:  0.000680, elapsed time:  124552
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C C ( C ) C ( N C c 1 c c c ( - c 2 c c c c c 2 C # N ) c c 1 ) C ( = O ) O C _EOS
Predicted text: C C C ( C ) C ( N C c 1 c c c ( - c 2 c c c c c 2 C # N ) c c 1 ) C ( = O ) O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O c 1 c c 2 c ( N 3 C C C ( n 4 c ( = O ) c 5 c c ( C ) c c c 5 n ( C ) c 4 = O ) C C 3 ) n c ( N 3 C C O C C 3 ) n c 2 c c 1 O C C ( = O ) O _EOS
Predicted text: C C O c 1 c c 2 c ( N 3 C C C ( n 4 c ( = O ) c 5 c c ( C ) c c c 5 n ( C ) c 4 = O ) C C 3 ) n c ( N 3 C C O C C 3 ) n c 2 c c 1 O C C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C 1 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C C 1 N 1 C C C ( N C ( = O ) O C c 2 c c c c c 2 ) C 1 = O _EOS
Predicted text: C C C C 1 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C C 1 N 1 C C C ( N C ( = O ) O C c 2 c c c c c 2 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) c 1 c c c c c 1 C ( = O ) N c 1 c c c ( C ( = O ) N 2 C C C C ( O ) c 3 c c ( Cl ) c c c 3 2 ) c n 1 _EOS
Predicted text: O = C ( O ) c 1 c c c c c 1 C ( = O ) N c 1 c c c ( C ( = O ) N 2 C C C C ( O ) c 3 c c ( Cl ) c c c 3 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( N C ( C ) = O ) c c c 1 O C _EOS
Predicted text: C O C ( = O ) c 1 c c ( N C ( C ) = O ) c c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 135000, eval acc (token): 0.9336903773740935, eval acc (sequence): 0.8766999093381687
Saving at step 135000
Step 135100, loss: 0.04119348414242267, acc: 99.44748876988888, p_norm: 1969.055953593123, g_norm: 1.27017079288919, lr:  0.000680, elapsed time:  124728
Step 135200, loss: 0.04201029851567, acc: 99.42587120831013, p_norm: 1969.2963056720964, g_norm: 0.6975459872089639, lr:  0.000680, elapsed time:  124820
Step 135300, loss: 0.040921077807433905, acc: 99.45459231734276, p_norm: 1969.5243282150216, g_norm: 0.5018816461411231, lr:  0.000679, elapsed time:  124910
Step 135400, loss: 0.04115324940998107, acc: 99.45067484676838, p_norm: 1969.7653134839582, g_norm: 0.4420845240499762, lr:  0.000679, elapsed time:  124999
Step 135500, loss: 0.04123275965917855, acc: 99.45063699781895, p_norm: 1970.0114227736963, g_norm: 0.5186432946193961, lr:  0.000679, elapsed time:  125093
Step 135600, loss: 0.04167302113957703, acc: 99.43265344202518, p_norm: 1970.2584131020249, g_norm: 0.6354318394669664, lr:  0.000679, elapsed time:  125182
Step 135700, loss: 0.04097494222223759, acc: 99.45556627213955, p_norm: 1970.509553054653, g_norm: 0.7527269896685758, lr:  0.000678, elapsed time:  125276
Step 135800, loss: 0.04194463966879994, acc: 99.42160518467426, p_norm: 1970.7432517553975, g_norm: 0.501373487735473, lr:  0.000678, elapsed time:  125364
Step 135900, loss: 0.04229056815151125, acc: 99.4197496175766, p_norm: 1970.9901981611247, g_norm: 0.6760760946030044, lr:  0.000678, elapsed time:  125456
Step 136000, loss: 0.04169324761256576, acc: 99.4329262971878, p_norm: 1971.2413004162263, g_norm: 0.6008264522950162, lr:  0.000678, elapsed time:  125546
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 136000, eval loss: 0.04478686261922121, eval acc: 99.4560317993164
Step 136100, loss: 0.0413309507118538, acc: 99.45095130801201, p_norm: 1971.5059782300282, g_norm: 0.6546097148275327, lr:  0.000677, elapsed time:  125652
Step 136200, loss: 0.041897357194684445, acc: 99.42071335017681, p_norm: 1971.7543125745021, g_norm: 0.5248400040111966, lr:  0.000677, elapsed time:  125740
Step 136300, loss: 0.041245698337443175, acc: 99.44428610801697, p_norm: 1971.9780952914834, g_norm: 0.8922764091819204, lr:  0.000677, elapsed time:  125830
Step 136400, loss: 0.04127456956543028, acc: 99.45515866577625, p_norm: 1972.2130689313094, g_norm: 0.5495435795686249, lr:  0.000677, elapsed time:  125922
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 136500, loss: 0.0408408366356842, acc: 99.45380502375798, p_norm: 1972.4444148082973, g_norm: 0.6831081965008423, lr:  0.000676, elapsed time:  126014
Step 136600, loss: 0.04072635733522475, acc: 99.45420062541962, p_norm: 1972.6622303599643, g_norm: 0.47928455872048026, lr:  0.000676, elapsed time:  126102
Step 136700, loss: 0.03989924577064812, acc: 99.48679846525192, p_norm: 1972.8854101741047, g_norm: 0.5120922139322837, lr:  0.000676, elapsed time:  126189
Step 136800, loss: 0.04123640413861722, acc: 99.44298504292965, p_norm: 1973.117787396731, g_norm: 0.6253850983252004, lr:  0.000676, elapsed time:  126277
Step 136900, loss: 0.04086674096994102, acc: 99.45683752000332, p_norm: 1973.3739415860255, g_norm: 0.766172465342579, lr:  0.000675, elapsed time:  126369
Step 137000, loss: 0.04160207473207265, acc: 99.44421701133251, p_norm: 1973.618493863057, g_norm: 0.6043264816817882, lr:  0.000675, elapsed time:  126459
Step 137100, loss: 0.04186790232080966, acc: 99.4402688741684, p_norm: 1973.866259467298, g_norm: 0.6890365194575607, lr:  0.000675, elapsed time:  126552
Step 137200, loss: 0.04084289300721139, acc: 99.47536920011044, p_norm: 1974.1219694686845, g_norm: 0.600982325803234, lr:  0.000675, elapsed time:  126645
Step 137300, loss: 0.04191624000202864, acc: 99.42724297940731, p_norm: 1974.3811208179939, g_norm: 0.848341969547661, lr:  0.000674, elapsed time:  126733
Step 137400, loss: 0.040852119182236496, acc: 99.47387129068375, p_norm: 1974.6427275283777, g_norm: 0.636771975423068, lr:  0.000674, elapsed time:  126826
Step 137500, loss: 0.041805283492431046, acc: 99.43344438076019, p_norm: 1974.8492038132565, g_norm: 0.5272765488495983, lr:  0.000674, elapsed time:  126913
Step 137600, loss: 0.04156960607040674, acc: 99.44035163521767, p_norm: 1975.0849563770894, g_norm: 0.7531056021263521, lr:  0.000674, elapsed time:  127005
Step 137700, loss: 0.042562805735506117, acc: 99.41630434989929, p_norm: 1975.3445213727223, g_norm: 0.7247987002705769, lr:  0.000674, elapsed time:  127094
Step 137800, loss: 0.04139209642540664, acc: 99.44496540725231, p_norm: 1975.5555575140884, g_norm: 0.6129309882351329, lr:  0.000673, elapsed time:  127185
Step 137900, loss: 0.04114251431077719, acc: 99.45255699753761, p_norm: 1975.795239368092, g_norm: 0.49166685350547273, lr:  0.000673, elapsed time:  127276
Step 138000, loss: 0.04138088549952954, acc: 99.45305827260017, p_norm: 1976.0273917029429, g_norm: 0.7967311668566922, lr:  0.000673, elapsed time:  127368
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 138000, eval loss: 0.04456169664859775, eval acc: 99.45909881591797
Step 138100, loss: 0.04063547599129379, acc: 99.47245912253857, p_norm: 1976.2893188633777, g_norm: 0.6653788554188952, lr:  0.000673, elapsed time:  127477
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 138200, loss: 0.04095539402577185, acc: 99.46241158409687, p_norm: 1976.5264029654838, g_norm: 0.6175159150717479, lr:  0.000672, elapsed time:  127573
Step 138300, loss: 0.0405932590784505, acc: 99.46719391644001, p_norm: 1976.7533018398178, g_norm: 0.5916905767227796, lr:  0.000672, elapsed time:  127663
Step 138400, loss: 0.0407973923580721, acc: 99.45876854658127, p_norm: 1977.0166394303274, g_norm: 0.7824950817731716, lr:  0.000672, elapsed time:  127753
Step 138500, loss: 0.040787273896858094, acc: 99.4527353644371, p_norm: 1977.2574033977637, g_norm: 0.8208302810064878, lr:  0.000672, elapsed time:  127844
Step 138600, loss: 0.040657664462924, acc: 99.46968185901642, p_norm: 1977.525600699398, g_norm: 0.5940161716816335, lr:  0.000671, elapsed time:  127938
Step 138700, loss: 0.04195417006500066, acc: 99.43169157207012, p_norm: 1977.795689366163, g_norm: 0.6256807136257261, lr:  0.000671, elapsed time:  128027
Step 138800, loss: 0.04160695790313184, acc: 99.4301418364048, p_norm: 1978.0364525268294, g_norm: 0.6038855743340652, lr:  0.000671, elapsed time:  128113
Step 138900, loss: 0.04104710935615003, acc: 99.45847856998444, p_norm: 1978.2741674025688, g_norm: 0.6423952013834074, lr:  0.000671, elapsed time:  128205
Step 139000, loss: 0.039950345987454054, acc: 99.47810709476471, p_norm: 1978.515174912412, g_norm: 0.5843717683124846, lr:  0.000670, elapsed time:  128296
Step 139100, loss: 0.04010802262462675, acc: 99.48461501300335, p_norm: 1978.7224672543098, g_norm: 0.5997480885220419, lr:  0.000670, elapsed time:  128385
Step 139200, loss: 0.04042394690215587, acc: 99.46857477724552, p_norm: 1978.9675979413018, g_norm: 0.5934964899758882, lr:  0.000670, elapsed time:  128477
Step 139300, loss: 0.042546809199266136, acc: 99.41474123299122, p_norm: 1979.2098460682182, g_norm: 0.74367335390888, lr:  0.000670, elapsed time:  128567
Step 139400, loss: 0.04122174090705812, acc: 99.44851770997047, p_norm: 1979.4345258359929, g_norm: 1.3836905917820936, lr:  0.000669, elapsed time:  128657
Step 139500, loss: 0.04150500586722046, acc: 99.44601348042488, p_norm: 1979.689513186951, g_norm: 0.7900872244848915, lr:  0.000669, elapsed time:  128751
Step 139600, loss: 0.04311623295303434, acc: 99.39226995408535, p_norm: 1979.9093195706455, g_norm: 0.6043217280137088, lr:  0.000669, elapsed time:  128839
Step 139700, loss: 0.042142364135943355, acc: 99.42380821704865, p_norm: 1980.1506553472, g_norm: 0.6172224360529157, lr:  0.000669, elapsed time:  128934
Step 139800, loss: 0.04087673052214086, acc: 99.46973113715649, p_norm: 1980.3692940175135, g_norm: 0.7418841743862765, lr:  0.000668, elapsed time:  129029
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 139900, loss: 0.04054936572946423, acc: 99.46037860059026, p_norm: 1980.5840251833515, g_norm: 0.5283224702418688, lr:  0.000668, elapsed time:  129125
Step 140000, loss: 0.04051435120869428, acc: 99.46382983028889, p_norm: 1980.8063268455687, g_norm: 0.6150101932951058, lr:  0.000668, elapsed time:  129217
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 140000, eval loss: 0.04796762945130466, eval acc: 99.4251480102539
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c 2 c ( O c 3 c c c c ( N C ( = O ) N c 4 c c ( C ( C ) ( C ) C ) o n 4 ) c 3 ) n c n c 2 c c 1 O C 1 C C N C C 1 _EOS
Predicted text: C O c 1 c c 2 c ( O c 3 c c c c ( N C ( = O ) N c 4 c c ( C ( C ) ( C ) C ) o n 4 ) c 3 ) n c n c 2 c c 1 O C 1 C C N C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C c 1 c ( C n 2 c c n c 2 - c 2 c c c c ( C # N ) n 2 ) n c n 2 n c n c 1 2 _EOS
Predicted text: C C C c 1 c ( C n 2 c c n c 2 - c 2 c c c c ( C # N ) n 2 ) n c n 2 n c n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C ( = O ) c 1 c c 2 c c c c c 2 n 1 C _EOS
Predicted text: C N C ( = O ) c 1 c c 2 c c c c c 2 n 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C O c 2 c ( c c c c 2 N 2 C C C C 2 ) C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C O c 2 c ( c c c c 2 N 2 C C C C 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c c 1 S ( = O ) ( = O ) N c 1 c c ( - c 2 c c n ( S ( = O ) ( = O ) N ( C ) C ) n 2 ) s c 1 C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C c 1 c c c c c 1 S ( = O ) ( = O ) N c 1 c c ( - c 2 c c n ( S ( = O ) ( = O ) N ( C ) C ) n 2 ) s c 1 C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 140000, eval acc (token): 0.9320513714439319, eval acc (sequence): 0.8711952487008167
Saving at step 140000
Step 140100, loss: 0.040888369684107605, acc: 99.46972219645977, p_norm: 1981.0481294573815, g_norm: 0.7350908995257511, lr:  0.000668, elapsed time:  129413
Step 140200, loss: 0.04085687203798443, acc: 99.45642121136189, p_norm: 1981.277510409348, g_norm: 0.5437213119830677, lr:  0.000667, elapsed time:  129504
Step 140300, loss: 0.04033074468839914, acc: 99.47711937129498, p_norm: 1981.5030275897009, g_norm: 0.6451570828645583, lr:  0.000667, elapsed time:  129595
Step 140400, loss: 0.04117866444401443, acc: 99.45864060521126, p_norm: 1981.723505896412, g_norm: 0.6321895766601088, lr:  0.000667, elapsed time:  129684
Step 140500, loss: 0.04053739957511425, acc: 99.46831165254116, p_norm: 1981.962580733642, g_norm: 0.5781761204152629, lr:  0.000667, elapsed time:  129785
Step 140600, loss: 0.04149800130166113, acc: 99.44286189973354, p_norm: 1982.1785207056205, g_norm: 0.6048210742154699, lr:  0.000667, elapsed time:  129877
Step 140700, loss: 0.04113219479098916, acc: 99.44573421776295, p_norm: 1982.4068642301208, g_norm: 0.661558621352521, lr:  0.000666, elapsed time:  129971
Step 140800, loss: 0.040920229922048745, acc: 99.4575826227665, p_norm: 1982.6368713635263, g_norm: 0.5648835168618569, lr:  0.000666, elapsed time:  130061
Step 140900, loss: 0.04168344373814761, acc: 99.44202196598053, p_norm: 1982.8900844988211, g_norm: 0.6970395471768586, lr:  0.000666, elapsed time:  130154
Step 141000, loss: 0.041709359376691284, acc: 99.42700305581093, p_norm: 1983.1259055460657, g_norm: 0.5278222010018901, lr:  0.000666, elapsed time:  130246
Step 141100, loss: 0.04164370363112539, acc: 99.44028586149216, p_norm: 1983.3630011015994, g_norm: 0.580810285494826, lr:  0.000665, elapsed time:  130341
Step 141200, loss: 0.040915555115789176, acc: 99.45465856790543, p_norm: 1983.6184727641723, g_norm: 0.6271976673171691, lr:  0.000665, elapsed time:  130432
Step 141300, loss: 0.04103594223037362, acc: 99.46017572283745, p_norm: 1983.8482269154495, g_norm: 0.653842523067694, lr:  0.000665, elapsed time:  130528
Step 141400, loss: 0.04106938876211643, acc: 99.46568398177624, p_norm: 1984.0828181057375, g_norm: 0.8511709273752448, lr:  0.000665, elapsed time:  130614
Step 141500, loss: 0.04065888956189156, acc: 99.47713090479374, p_norm: 1984.3012313360232, g_norm: 0.8227112997841485, lr:  0.000664, elapsed time:  130710
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 141600, loss: 0.040706097497315914, acc: 99.46842193603516, p_norm: 1984.5358110216655, g_norm: 0.8321217029882417, lr:  0.000664, elapsed time:  130804
Step 141700, loss: 0.04097766479011625, acc: 99.45486976206303, p_norm: 1984.7736397660437, g_norm: 0.49336635928241596, lr:  0.000664, elapsed time:  130896
Step 141800, loss: 0.040440441346727314, acc: 99.46469540894032, p_norm: 1984.9916847897503, g_norm: 0.4945727925851321, lr:  0.000664, elapsed time:  130988
Step 141900, loss: 0.0396808363776654, acc: 99.49114879965782, p_norm: 1985.188439232421, g_norm: 0.6664568165339569, lr:  0.000663, elapsed time:  131082
Step 142000, loss: 0.041578712272457775, acc: 99.4326041340828, p_norm: 1985.442353411191, g_norm: 0.6990086836778391, lr:  0.000663, elapsed time:  131168
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 142000, eval loss: 0.04587632885202764, eval acc: 99.46074676513672
Step 142100, loss: 0.04080762164667249, acc: 99.4733235090971, p_norm: 1985.7158543452692, g_norm: 0.5508153023840058, lr:  0.000663, elapsed time:  131277
Step 142200, loss: 0.04150508870370686, acc: 99.439686357975, p_norm: 1985.9568045401682, g_norm: 0.6160459672041477, lr:  0.000663, elapsed time:  131366
Step 142300, loss: 0.04081072054803372, acc: 99.46032111346722, p_norm: 1986.1842544145384, g_norm: 0.5750506122665373, lr:  0.000663, elapsed time:  131459
Step 142400, loss: 0.041441754032857714, acc: 99.44443470239639, p_norm: 1986.4157233881094, g_norm: 0.5960609469438797, lr:  0.000662, elapsed time:  131536
Step 142500, loss: 0.04075585843529552, acc: 99.4678513109684, p_norm: 1986.634855223219, g_norm: 0.6549285272184283, lr:  0.000662, elapsed time:  131605
Step 142600, loss: 0.040131704597733915, acc: 99.47710585594177, p_norm: 1986.8604559912694, g_norm: 0.6657911523637388, lr:  0.000662, elapsed time:  131676
Step 142700, loss: 0.041057107290253046, acc: 99.45714688301086, p_norm: 1987.0906353599653, g_norm: 0.6009285523834715, lr:  0.000662, elapsed time:  131749
Step 142800, loss: 0.04079378746449947, acc: 99.46403895318508, p_norm: 1987.3267901316347, g_norm: 0.7960306026146888, lr:  0.000661, elapsed time:  131840
Step 142900, loss: 0.04077208764385432, acc: 99.45463216304779, p_norm: 1987.5451645355672, g_norm: 0.6572522604080124, lr:  0.000661, elapsed time:  131929
Step 143000, loss: 0.040836711837910114, acc: 99.45826604962349, p_norm: 1987.78686999223, g_norm: 0.7176002492540676, lr:  0.000661, elapsed time:  132020
Step 143100, loss: 0.040675469557754695, acc: 99.45813556015491, p_norm: 1987.9991111705392, g_norm: 0.7089106298772931, lr:  0.000661, elapsed time:  132100
Step 143200, loss: 0.04102766720578074, acc: 99.44790579378605, p_norm: 1988.2309665673129, g_norm: 0.6534915088143455, lr:  0.000660, elapsed time:  132170
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 143300, loss: 0.03987718115170156, acc: 99.48080356600266, p_norm: 1988.4443832806292, g_norm: 0.6113285581752032, lr:  0.000660, elapsed time:  132240
Step 143400, loss: 0.039821578534319994, acc: 99.48019535839558, p_norm: 1988.6675736241073, g_norm: 0.5831712072337563, lr:  0.000660, elapsed time:  132310
Step 143500, loss: 0.0414168664906174, acc: 99.44344137609005, p_norm: 1988.9300390215226, g_norm: 0.5353023747955427, lr:  0.000660, elapsed time:  132377
Step 143600, loss: 0.041250042458996175, acc: 99.44330449402332, p_norm: 1989.167810071508, g_norm: 0.6651347546051176, lr:  0.000660, elapsed time:  132445
Step 143700, loss: 0.041021762709133325, acc: 99.44488336145878, p_norm: 1989.4165294274924, g_norm: 0.507162308497622, lr:  0.000659, elapsed time:  132521
Step 143800, loss: 0.04024980119429529, acc: 99.48494625091553, p_norm: 1989.6736379354402, g_norm: 0.6374195805828605, lr:  0.000659, elapsed time:  132611
Step 143900, loss: 0.040225451081059876, acc: 99.47728872299194, p_norm: 1989.8800745406525, g_norm: 0.5594569176666211, lr:  0.000659, elapsed time:  132702
Step 144000, loss: 0.04037593926303089, acc: 99.47515617311001, p_norm: 1990.1151384574282, g_norm: 0.6025422376214422, lr:  0.000659, elapsed time:  132794
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 144000, eval loss: 0.043524586074054246, eval acc: 99.4960708618164
Step 144100, loss: 0.0411290148133412, acc: 99.45592556893826, p_norm: 1990.3616304302168, g_norm: 0.7957312271963202, lr:  0.000658, elapsed time:  132903
Step 144200, loss: 0.04036432174965739, acc: 99.47075361013412, p_norm: 1990.5604721701625, g_norm: 0.9011844090164574, lr:  0.000658, elapsed time:  132991
Step 144300, loss: 0.04101358540356159, acc: 99.46245862543583, p_norm: 1990.7713529378473, g_norm: 0.6246664899830014, lr:  0.000658, elapsed time:  133084
Step 144400, loss: 0.04078415861353278, acc: 99.47283935546875, p_norm: 1991.0030788497338, g_norm: 0.5447185752612621, lr:  0.000658, elapsed time:  133177
Step 144500, loss: 0.04221190240699798, acc: 99.42716439068317, p_norm: 1991.2232593992956, g_norm: 0.7184941758326271, lr:  0.000657, elapsed time:  133271
Step 144600, loss: 0.0406103203818202, acc: 99.47630694508553, p_norm: 1991.4763923677665, g_norm: 0.4821384080922636, lr:  0.000657, elapsed time:  133355
Step 144700, loss: 0.0414099616650492, acc: 99.44641000032425, p_norm: 1991.6941207406549, g_norm: 0.7752627154330868, lr:  0.000657, elapsed time:  133442
Step 144800, loss: 0.0401680176332593, acc: 99.48723269999027, p_norm: 1991.9133586231867, g_norm: 0.5648152165695347, lr:  0.000657, elapsed time:  133532
Step 144900, loss: 0.04129312289878726, acc: 99.45609448850155, p_norm: 1992.136100894039, g_norm: 20.00000046106782, lr:  0.000657, elapsed time:  133618
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 145000, loss: 0.042584376261747506, acc: 99.44597314072603, p_norm: 1992.4014812327862, g_norm: 0.6203374807651731, lr:  0.000656, elapsed time:  133706
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( C c 1 c c c ( O C c 2 c c c ( F ) c c 2 ) c c 1 ) N c 1 n c ( = S ) s s 1 _EOS
Predicted text: O = C ( C c 1 c c c ( O C c 2 c c c ( F ) c c 2 ) c c 1 ) N c 1 n c ( = S ) s s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O N ( C ) C ( = O ) c 1 c c c 2 n c [nH] c 2 c 1 _EOS
Predicted text: C O N ( C ) C ( = O ) c 1 c c c 2 [nH] c n c 2 c 1 _EOS
acc_token: 0.92, acc_seq: False

Target text: C O c 1 c c 2 c ( c 3 c 1 O C ( C ) ( C ) C 3 ) C ( c 1 c c c c ( - c 3 c c c c ( N C ( C ) = O ) c 3 ) c 1 ) = N C ( C ) ( C ) C 2 = O _EOS
Predicted text: C O c 1 c c 2 c ( c 3 c 1 O C ( C ) ( C ) C 3 ) C ( c 1 c c c c ( - c 3 c c c c ( N C ( C ) = O ) c 3 ) c 1 ) = N C ( C ) ( C ) C 2 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c c ( S ( = O ) ( = O ) N c 2 n c n s 2 ) c c c 1 O c 1 c c c ( Cl ) c c 1 - c 1 c c n c ( N 2 C C N C C 2 ) n 1 _EOS
Predicted text: N # C c 1 c c ( S ( = O ) ( = O ) N c 2 n c n s 2 ) c c c 1 O c 1 c c c ( Cl ) c c 1 - c 1 c c n c ( N 2 C C N C C 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( N ) C ( = O ) N c 1 c c ( Cl ) c ( F ) c ( Cl ) c 1 _EOS
Predicted text: C C ( N ) C ( = O ) N c 1 c c ( Cl ) c ( F ) c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 145000, eval acc (token): 0.932371612225241, eval acc (sequence): 0.8744288064339243
Saving at step 145000
Step 145100, loss: 0.041887657893821595, acc: 99.45032341778278, p_norm: 1992.618050112259, g_norm: 0.5824826002476242, lr:  0.000656, elapsed time:  133882
Step 145200, loss: 0.041129410048015416, acc: 99.46700139343739, p_norm: 1992.8632774907492, g_norm: 0.5543043226730536, lr:  0.000656, elapsed time:  133977
Step 145300, loss: 0.04101149796508253, acc: 99.46987776458263, p_norm: 1993.0620405683464, g_norm: 0.7058069202508731, lr:  0.000656, elapsed time:  134068
Step 145400, loss: 0.0406926546478644, acc: 99.48021718859673, p_norm: 1993.2787896577208, g_norm: 0.6960869444375574, lr:  0.000655, elapsed time:  134164
Step 145500, loss: 0.04015747410710901, acc: 99.49159009754658, p_norm: 1993.4790944524696, g_norm: 0.4899393532172443, lr:  0.000655, elapsed time:  134252
Step 145600, loss: 0.040220397235825656, acc: 99.48491288721561, p_norm: 1993.675357157601, g_norm: 0.9740922159048485, lr:  0.000655, elapsed time:  134349
Step 145700, loss: 0.0399916004948318, acc: 99.49841131269932, p_norm: 1993.9135896608357, g_norm: 0.601529116305314, lr:  0.000655, elapsed time:  134440
Step 145800, loss: 0.041502673686482014, acc: 99.44117909669876, p_norm: 1994.1435548658083, g_norm: 0.6793876291901326, lr:  0.000655, elapsed time:  134528
Step 145900, loss: 0.04106277157086879, acc: 99.45043012499809, p_norm: 1994.3866290423114, g_norm: 0.6093661900662596, lr:  0.000654, elapsed time:  134617
Step 146000, loss: 0.040036174156703054, acc: 99.4877313375473, p_norm: 1994.603388620933, g_norm: 0.7462280964455777, lr:  0.000654, elapsed time:  134708
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 146000, eval loss: 0.04333062209188937, eval acc: 99.48344421386719
Step 146100, loss: 0.03959349473472685, acc: 99.50168341398239, p_norm: 1994.818546514769, g_norm: 0.4897088119546728, lr:  0.000654, elapsed time:  134820
Step 146200, loss: 0.04089976650197059, acc: 99.45482847094536, p_norm: 1995.0522360230257, g_norm: 0.7266611516480177, lr:  0.000654, elapsed time:  134916
Step 146300, loss: 0.04119210444390774, acc: 99.44469493627548, p_norm: 1995.2535388914084, g_norm: 0.5192991391032912, lr:  0.000653, elapsed time:  135010
Step 146400, loss: 0.04126650023739785, acc: 99.44248154759407, p_norm: 1995.4728165980366, g_norm: 0.4876476399244709, lr:  0.000653, elapsed time:  135098
Step 146500, loss: 0.041016694344580176, acc: 99.45300036668777, p_norm: 1995.7052271406549, g_norm: 0.6810196001354673, lr:  0.000653, elapsed time:  135185
Step 146600, loss: 0.0405220676260069, acc: 99.46530969440937, p_norm: 1995.9340395108816, g_norm: 0.5415512312923999, lr:  0.000653, elapsed time:  135276
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 146700, loss: 0.039659899955995344, acc: 99.49636087192232, p_norm: 1996.1688876966305, g_norm: 0.5806941144177674, lr:  0.000653, elapsed time:  135368
Step 146800, loss: 0.04016998255159706, acc: 99.4763053059578, p_norm: 1996.3668074285142, g_norm: 0.6334393705467412, lr:  0.000652, elapsed time:  135462
Step 146900, loss: 0.040452942536212504, acc: 99.47726862132549, p_norm: 1996.6022602912917, g_norm: 0.6472466748269632, lr:  0.000652, elapsed time:  135555
Step 147000, loss: 0.040604421501047906, acc: 99.46890151500702, p_norm: 1996.814069894617, g_norm: 0.4893426633401722, lr:  0.000652, elapsed time:  135642
Step 147100, loss: 0.04013219077605754, acc: 99.47726158797741, p_norm: 1997.0307694363155, g_norm: 0.5984773437565319, lr:  0.000652, elapsed time:  135733
Step 147200, loss: 0.04003874808549881, acc: 99.47306914627552, p_norm: 1997.2640977955277, g_norm: 0.6956304171433428, lr:  0.000651, elapsed time:  135823
Step 147300, loss: 0.040759691577404736, acc: 99.44816474616528, p_norm: 1997.501419458189, g_norm: 0.8418108290091293, lr:  0.000651, elapsed time:  135912
Step 147400, loss: 0.03958792534191161, acc: 99.48822623491287, p_norm: 1997.7073551739056, g_norm: 0.5121993215030508, lr:  0.000651, elapsed time:  136005
Step 147500, loss: 0.04088859663810581, acc: 99.46249060332775, p_norm: 1997.9359416005632, g_norm: 0.7565882537441581, lr:  0.000651, elapsed time:  136099
Step 147600, loss: 0.040747165093198416, acc: 99.46664375066757, p_norm: 1998.1646165468244, g_norm: 0.5936558130788675, lr:  0.000651, elapsed time:  136188
Step 147700, loss: 0.04071520795114338, acc: 99.47149167954922, p_norm: 1998.3875100797413, g_norm: 0.5639048759722838, lr:  0.000650, elapsed time:  136281
Step 147800, loss: 0.041006008116528395, acc: 99.45928047597408, p_norm: 1998.601954946938, g_norm: 0.5927983029195588, lr:  0.000650, elapsed time:  136381
Step 147900, loss: 0.04009004111867398, acc: 99.483676597476, p_norm: 1998.8217162621581, g_norm: 0.7886638450621677, lr:  0.000650, elapsed time:  136477
Step 148000, loss: 0.04043975081294775, acc: 99.46330927312374, p_norm: 1999.0509691077878, g_norm: 0.6113276893873183, lr:  0.000650, elapsed time:  136564
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 148000, eval loss: 0.042918298598378896, eval acc: 99.51244354248047
Step 148100, loss: 0.04026781867723912, acc: 99.47310657799244, p_norm: 1999.259771446468, g_norm: 0.7283285516194135, lr:  0.000649, elapsed time:  136683
Step 148200, loss: 0.04091500991024077, acc: 99.45725743472576, p_norm: 1999.5030274537985, g_norm: 0.8067012346445183, lr:  0.000649, elapsed time:  136776
Step 148300, loss: 0.04094698819331825, acc: 99.45254059135914, p_norm: 1999.7036284833298, g_norm: 0.5671938371573626, lr:  0.000649, elapsed time:  136867
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 148400, loss: 0.039815783865805296, acc: 99.47712424375283, p_norm: 1999.9136049227025, g_norm: 0.6736209341621925, lr:  0.000649, elapsed time:  136958
Step 148500, loss: 0.03948806954547763, acc: 99.49121597409248, p_norm: 2000.1151616723778, g_norm: 0.7176767281429239, lr:  0.000649, elapsed time:  137048
Step 148600, loss: 0.040340647902339696, acc: 99.46968556940556, p_norm: 2000.3409929178586, g_norm: 0.5354182254833106, lr:  0.000648, elapsed time:  137135
Step 148700, loss: 0.04039311576634645, acc: 99.47478991746902, p_norm: 2000.5668823913113, g_norm: 0.42816588458021, lr:  0.000648, elapsed time:  137228
Step 148800, loss: 0.039605564810335635, acc: 99.48569720983505, p_norm: 2000.7801531734715, g_norm: 0.5651303618753077, lr:  0.000648, elapsed time:  137326
Step 148900, loss: 0.040274128639139234, acc: 99.48360452055931, p_norm: 2000.9959443076411, g_norm: 0.7261064925445188, lr:  0.000648, elapsed time:  137416
Step 149000, loss: 0.03981987120117992, acc: 99.501465767622, p_norm: 2001.2157940874097, g_norm: 0.9849448126283175, lr:  0.000647, elapsed time:  137503
Step 149100, loss: 0.03982301509473473, acc: 99.47749899327755, p_norm: 2001.4586440589017, g_norm: 0.5000319841215891, lr:  0.000647, elapsed time:  137591
Step 149200, loss: 0.040624670130200685, acc: 99.46392065286636, p_norm: 2001.66222171302, g_norm: 0.597152636441762, lr:  0.000647, elapsed time:  137681
Step 149300, loss: 0.04041663471609354, acc: 99.48240192234516, p_norm: 2001.8734270041607, g_norm: 0.7653121797757328, lr:  0.000647, elapsed time:  137778
Step 149400, loss: 0.04321267561521381, acc: 99.44673281908035, p_norm: 2002.1260250277592, g_norm: 0.618639434846154, lr:  0.000647, elapsed time:  137866
Step 149500, loss: 0.07718887730967254, acc: 99.41687509417534, p_norm: 2002.3501899932944, g_norm: 0.5908727326298305, lr:  0.000646, elapsed time:  137953
Step 149600, loss: 0.04492997949011624, acc: 99.44890156388283, p_norm: 2002.5527118979303, g_norm: 0.6223715009981278, lr:  0.000646, elapsed time:  138043
Step 149700, loss: 0.04328439022880048, acc: 99.44330814480782, p_norm: 2002.7624762297664, g_norm: 1.049191719107174, lr:  0.000646, elapsed time:  138113
Step 149800, loss: 0.04339880908373743, acc: 99.45628733932972, p_norm: 2002.9970965809955, g_norm: 0.4576281488801627, lr:  0.000646, elapsed time:  138184
Step 149900, loss: 0.045771784298121926, acc: 99.45755071938038, p_norm: 2003.1996042839746, g_norm: 0.5700194207785593, lr:  0.000646, elapsed time:  138255
Step 150000, loss: 0.04309360195882619, acc: 99.45077255368233, p_norm: 2003.38199397767, g_norm: 0.7079690632834084, lr:  0.000645, elapsed time:  138325
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 150000, eval loss: 0.04802333625033498, eval acc: 99.45783996582031
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Target text: C O c 1 c c c ( C ( = O ) c 2 c ( C ) n ( C C O S ( = O ) ( = O ) c 3 c c c ( C ) c c 3 ) c 3 c c c c c 2 3 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C ( = O ) c 2 c ( C ) n ( C C O S ( = O ) ( = O ) c 3 c c c ( C ) c c 3 ) c 3 c c c c c 2 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O C 1 ( c 2 c c 3 n c ( Cl ) n c ( N 4 C C O C C 4 ) c 3 s 2 ) C C N ( C c 2 n c c s 2 ) C C 1 _EOS
Predicted text: O C 1 ( c 2 c c 3 n c ( Cl ) n c ( N 4 C C O C C 4 ) c 3 s 2 ) C C N ( C c 2 n c c s 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) S ( = O ) ( = O ) N C 1 C c 2 c c c ( I ) c c 2 C 1 _EOS
Predicted text: C C ( C ) S ( = O ) ( = O ) N C 1 C c 2 c c c ( I ) c c 2 C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 c c 2 c ( = O ) n ( C C ( = O ) c 3 c c n c c 3 ) c ( = O ) n ( C c 3 c c c ( - c 4 c c c c c 4 C # N ) c c 3 ) c 2 s 1 _EOS
Predicted text: C C c 1 c c 2 c ( = O ) n ( C C ( = O ) c 3 c c n c c 3 ) c ( = O ) n ( C c 3 c c c ( - c 4 c c c c c 4 C # N ) c c 3 ) c 2 s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C ( C ) = C = C c 1 c c c ( F ) c c 1 _EOS
Predicted text: C C O C ( = O ) C ( C ) = C ( O ) C c 1 c c c ( F ) c c 1 _EOS
acc_token: 0.5714285714285714, acc_seq: False

Evaluation (without teacher) at step 150000, eval acc (token): 0.9338170059593112, eval acc (sequence): 0.8719138667161686
Saving at step 150000
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 150100, loss: 0.04233392610887144, acc: 99.48029470798691, p_norm: 2003.5851533850337, g_norm: 0.459029675924111, lr:  0.000645, elapsed time:  138516
Step 150200, loss: 0.041514744465239346, acc: 99.51064467430115, p_norm: 2003.7657128811597, g_norm: 0.7459896448954174, lr:  0.000645, elapsed time:  138606
Step 150300, loss: 0.04387425675522536, acc: 99.43495278060436, p_norm: 2003.9822438873653, g_norm: 0.4993526814296079, lr:  0.000645, elapsed time:  138694
Step 150400, loss: 0.04266958906315267, acc: 99.461131721735, p_norm: 2004.20311189072, g_norm: 0.6067687595427236, lr:  0.000644, elapsed time:  138783
Step 150500, loss: 0.04357610306236893, acc: 99.4495959430933, p_norm: 2004.4038251281156, g_norm: 0.6512730137178561, lr:  0.000644, elapsed time:  138882
Step 150600, loss: 0.04231298372615129, acc: 99.47032041847706, p_norm: 2004.5795644991874, g_norm: 0.6142581532496404, lr:  0.000644, elapsed time:  138977
Step 150700, loss: 0.049690788085572424, acc: 99.45370894670486, p_norm: 2004.8173711603526, g_norm: 1.3874981012859189, lr:  0.000644, elapsed time:  139072
Step 150800, loss: 0.04461493562441319, acc: 99.4530890583992, p_norm: 2005.0744451854835, g_norm: 0.7876972847321811, lr:  0.000644, elapsed time:  139165
Step 150900, loss: 0.045068665607832376, acc: 99.46093435585499, p_norm: 2005.252436195492, g_norm: 0.7357108574768566, lr:  0.000643, elapsed time:  139260
Step 151000, loss: 0.04790697423741221, acc: 99.44902783632278, p_norm: 2005.4528887256488, g_norm: 0.9794458932101531, lr:  0.000643, elapsed time:  139345
Step 151100, loss: 0.04550677178427577, acc: 99.45008097589016, p_norm: 2005.7116116684717, g_norm: 0.6010316348839226, lr:  0.000643, elapsed time:  139434
Step 151200, loss: 1.213189707081765, acc: 99.41461069881916, p_norm: 2005.9371955092563, g_norm: 0.5544233053212422, lr:  0.000643, elapsed time:  139524
Step 151300, loss: 0.04579935711342841, acc: 99.4335056990385, p_norm: 2006.1336664776527, g_norm: 0.5578006370098493, lr:  0.000643, elapsed time:  139615
Step 151400, loss: 0.04335523033514619, acc: 99.47587223351002, p_norm: 2006.3081489285457, g_norm: 0.8225248549495271, lr:  0.000642, elapsed time:  139707
Step 151500, loss: 0.04289244791958481, acc: 99.45704162120819, p_norm: 2006.4882628979797, g_norm: 0.5293373938079725, lr:  0.000642, elapsed time:  139799
Step 151600, loss: 0.043872605711221695, acc: 99.43347661197186, p_norm: 2006.6871199067823, g_norm: 0.5650618884983587, lr:  0.000642, elapsed time:  139891
Step 151700, loss: 0.04123353498056531, acc: 99.48837786912918, p_norm: 2006.851037964214, g_norm: 0.5835782302474533, lr:  0.000642, elapsed time:  139979
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 151800, loss: 0.04094030757991611, acc: 99.47528620215859, p_norm: 2007.0502641352143, g_norm: 0.6524059896603496, lr:  0.000641, elapsed time:  140073
Step 151900, loss: 0.04059729706030339, acc: 99.48594382405281, p_norm: 2007.252560696946, g_norm: 1.6758070791757758, lr:  0.000641, elapsed time:  140162
Step 152000, loss: 0.040635573025792834, acc: 99.4872719347477, p_norm: 2007.4585706206983, g_norm: 0.6919371888570014, lr:  0.000641, elapsed time:  140254
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 152000, eval loss: 0.045561569053679724, eval acc: 99.45935821533203
Step 152100, loss: 0.041426360714249315, acc: 99.47181175649166, p_norm: 2007.6747804359766, g_norm: 0.46470990780826565, lr:  0.000641, elapsed time:  140359
Step 152200, loss: 0.04148070272989571, acc: 99.49146971106529, p_norm: 2007.897580559375, g_norm: 0.5709979045074238, lr:  0.000641, elapsed time:  140451
Step 152300, loss: 0.041408627475611866, acc: 99.4786219894886, p_norm: 2008.0824926485711, g_norm: 0.6326954049262173, lr:  0.000640, elapsed time:  140546
Step 152400, loss: 0.04113468105439097, acc: 99.47297105193138, p_norm: 2008.2835493616021, g_norm: 0.6053597763711321, lr:  0.000640, elapsed time:  140636
Step 152500, loss: 0.040380612169392406, acc: 99.48146949708462, p_norm: 2008.4835068844118, g_norm: 0.5657206779422548, lr:  0.000640, elapsed time:  140732
Step 152600, loss: 0.04020802217070013, acc: 99.47787836194038, p_norm: 2008.6674330090505, g_norm: 0.5686717759159552, lr:  0.000640, elapsed time:  140805
Step 152700, loss: 0.04069820004981011, acc: 99.47312954068184, p_norm: 2008.8882458098255, g_norm: 0.5827591886582136, lr:  0.000640, elapsed time:  140874
Step 152800, loss: 0.041287201642990115, acc: 99.46877151727676, p_norm: 2009.0946071253895, g_norm: 0.5794602880384341, lr:  0.000639, elapsed time:  140942
Step 152900, loss: 0.04048680705018341, acc: 99.47401435673237, p_norm: 2009.299872980144, g_norm: 0.6206116143976563, lr:  0.000639, elapsed time:  141013
Step 153000, loss: 0.03971090957522392, acc: 99.49349215626717, p_norm: 2009.5178759769371, g_norm: 0.7175967147686649, lr:  0.000639, elapsed time:  141085
Step 153100, loss: 0.04025109311100095, acc: 99.47960932552814, p_norm: 2009.750813739995, g_norm: 0.5147310424523136, lr:  0.000639, elapsed time:  141153
Step 153200, loss: 0.04361399294342846, acc: 99.44960261881351, p_norm: 2010.033206236191, g_norm: 0.5828194560770177, lr:  0.000639, elapsed time:  141224
Step 153300, loss: 0.04254314225632697, acc: 99.44020460546017, p_norm: 2010.241932043065, g_norm: 0.37410762643521556, lr:  0.000638, elapsed time:  141294
Step 153400, loss: 0.04091504101175815, acc: 99.46969805657864, p_norm: 2010.478083616795, g_norm: 0.6090727190138228, lr:  0.000638, elapsed time:  141365
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 153500, loss: 0.03978246250293835, acc: 99.50402432280794, p_norm: 2010.677544454324, g_norm: 0.671492190985944, lr:  0.000638, elapsed time:  141436
Step 153600, loss: 0.040298375296406445, acc: 99.46388138830662, p_norm: 2010.8849590924895, g_norm: 0.6318630556827451, lr:  0.000638, elapsed time:  141518
Step 153700, loss: 0.040207661404274404, acc: 99.47020353376865, p_norm: 2011.0910111650753, g_norm: 0.6771967689325521, lr:  0.000637, elapsed time:  141609
Step 153800, loss: 0.03972310497891158, acc: 99.4992837458849, p_norm: 2011.2938254444914, g_norm: 0.4906659323292015, lr:  0.000637, elapsed time:  141698
Step 153900, loss: 0.03965650197584182, acc: 99.49547432363033, p_norm: 2011.4795932189068, g_norm: 0.6086178822879519, lr:  0.000637, elapsed time:  141788
Step 154000, loss: 0.03924417621456087, acc: 99.50711891055107, p_norm: 2011.6836693458974, g_norm: 0.7361729626561971, lr:  0.000637, elapsed time:  141879
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 154000, eval loss: 0.04520371252670881, eval acc: 99.4697265625
Step 154100, loss: 0.039208941231481734, acc: 99.5012034624815, p_norm: 2011.8835212717117, g_norm: 0.5688550053999029, lr:  0.000637, elapsed time:  141987
Step 154200, loss: 0.03918720476794988, acc: 99.50135239958763, p_norm: 2012.0617433981135, g_norm: 0.6771513499380661, lr:  0.000636, elapsed time:  142079
Step 154300, loss: 0.04052581735886633, acc: 99.45984922349453, p_norm: 2012.293003690069, g_norm: 0.6530403016348946, lr:  0.000636, elapsed time:  142170
Step 154400, loss: 0.039769976069219413, acc: 99.49171422421932, p_norm: 2012.4965121392015, g_norm: 0.6592562289888667, lr:  0.000636, elapsed time:  142263
Step 154500, loss: 0.0394755308330059, acc: 99.49994340538979, p_norm: 2012.7231462899001, g_norm: 0.6021619778729682, lr:  0.000636, elapsed time:  142361
Step 154600, loss: 0.04033200261648744, acc: 99.46806067228317, p_norm: 2012.9329232799912, g_norm: 0.7868092095188701, lr:  0.000636, elapsed time:  142445
Step 154700, loss: 0.03957637381274253, acc: 99.49594947695732, p_norm: 2013.1370733842473, g_norm: 0.545262357196343, lr:  0.000635, elapsed time:  142540
Step 154800, loss: 0.040333949299529194, acc: 99.4805501550436, p_norm: 2013.3480470033737, g_norm: 0.6148238295708203, lr:  0.000635, elapsed time:  142627
Step 154900, loss: 0.040059527349658314, acc: 99.4798163920641, p_norm: 2013.5439503201073, g_norm: 0.5670191035453203, lr:  0.000635, elapsed time:  142715
Step 155000, loss: 0.0420335293142125, acc: 99.49616774916649, p_norm: 2013.7565336401, g_norm: 0.8414286202874944, lr:  0.000635, elapsed time:  142791
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Target text: C C N 1 C ( = O ) S C ( = C c 2 c n ( - c 3 c c c c c 3 ) n c 2 - c 2 c c ( F ) c c ( F ) c 2 ) C 1 = O _EOS
Predicted text: C C N 1 C ( = O ) S C ( = C c 2 c n ( - c 3 c c c c c 3 ) n c 2 - c 2 c c ( F ) c c ( F ) c 2 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 = C N ( C ( = O ) c 2 c c c ( F ) c c 2 ) C C c 2 c 1 [nH] c 1 c ( O C ) c c c c 2 1 _EOS
Predicted text: C C O C ( = O ) C 1 = C N ( C ( = O ) c 2 c c c ( F ) c c 2 ) C C c 2 c 1 [nH] c 1 c ( O C ) c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C # C C C ( C ) C ( C = C C 1 C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C ( O ) C 1 c 1 c c c c ( C C C C ( = O ) O C ) c 1 O C O C ) O [Si] ( C ) ( C ) C ( C ) ( C ) C _EOS
Predicted text: C C # C C C ( C ) C ( C = C C 1 C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C ( O ) C 1 c 1 c c c c ( C C C C ( = O ) O C ) c 1 O C O C ) O [Si] ( C ) ( C ) C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 n n ( C ) c 2 c 1 C C c 1 c n c ( N C 3 C C N ( C ( C ) = O ) C C 3 ) n c 1 - 2 _EOS
Predicted text: C C ( = O ) N 1 C C C ( N c 2 n c c 3 c ( n 2 ) - c 2 c ( c ( C ( = O ) O ) n n 2 C ) C C 3 ) C C 1 _EOS
acc_token: 0.1568627450980392, acc_seq: False

Target text: O = C 1 C = C C ( = O ) N 1 c 1 c c c c ( Br ) c 1 _EOS
Predicted text: O = C 1 C = C C ( = O ) N 1 c 1 c c c c ( Br ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 155000, eval acc (token): 0.9232388672557938, eval acc (sequence): 0.8630090304992333
Saving at step 155000
Step 155100, loss: 0.04248882623855024, acc: 99.45590637624264, p_norm: 2013.991873607193, g_norm: 0.701052626638698, lr:  0.000635, elapsed time:  142938
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6822
Step 155200, loss: 0.040825788745143574, acc: 99.4937114768821, p_norm: 2014.223033158363, g_norm: 0.5489770705935639, lr:  0.000634, elapsed time:  143009
Step 155300, loss: 0.04085019162390381, acc: 99.48046219348907, p_norm: 2014.4311139435815, g_norm: 0.6242566928050195, lr:  0.000634, elapsed time:  143088
Step 155400, loss: 0.040109507474116984, acc: 99.48405864834785, p_norm: 2014.6453855645789, g_norm: 0.5275501211843452, lr:  0.000634, elapsed time:  143182
Step 155500, loss: 0.03950218344572932, acc: 99.50688660144806, p_norm: 2014.8393763348347, g_norm: 0.5418160120808165, lr:  0.000634, elapsed time:  143275
Step 155600, loss: 0.04014520016498864, acc: 99.48164801299572, p_norm: 2015.041538784961, g_norm: 0.5812458086629706, lr:  0.000634, elapsed time:  143364
Step 155700, loss: 0.03950294938869774, acc: 99.49872744083405, p_norm: 2015.243876403965, g_norm: 0.6297991393452625, lr:  0.000633, elapsed time:  143453
Step 155800, loss: 0.039623390245251355, acc: 99.49078269302845, p_norm: 2015.4511568334738, g_norm: 0.6399942618631509, lr:  0.000633, elapsed time:  143546
Step 155900, loss: 0.039790684641338885, acc: 99.48953221738338, p_norm: 2015.6658878908088, g_norm: 0.5007719072230653, lr:  0.000633, elapsed time:  143638
Step 156000, loss: 0.03890464364551008, acc: 99.50814008712769, p_norm: 2015.8493094128269, g_norm: 0.6322300863646857, lr:  0.000633, elapsed time:  143730
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 156000, eval loss: 0.04428252318874002, eval acc: 99.48899841308594
Step 156100, loss: 0.03967414284590632, acc: 99.48272062838078, p_norm: 2016.0515873236252, g_norm: 0.489466255697995, lr:  0.000633, elapsed time:  143836
Step 156200, loss: 0.03945361065678298, acc: 99.4887233376503, p_norm: 2016.262632445, g_norm: 0.5454305537869911, lr:  0.000632, elapsed time:  143923
Step 156300, loss: 0.04135507161263376, acc: 99.45933490991592, p_norm: 2016.49438824358, g_norm: 0.5514550547525232, lr:  0.000632, elapsed time:  144013
Step 156400, loss: 0.040147500275634226, acc: 99.48723006248474, p_norm: 2016.6888148826042, g_norm: 0.7822400469471241, lr:  0.000632, elapsed time:  144105
Step 156500, loss: 0.040113882729783654, acc: 99.48287715017796, p_norm: 2016.8909454471914, g_norm: 0.6032698084601464, lr:  0.000632, elapsed time:  144193
Step 156600, loss: 0.040117392376996575, acc: 99.47994489967823, p_norm: 2017.1038477283062, g_norm: 0.6211200990436639, lr:  0.000632, elapsed time:  144291
Step 156700, loss: 0.039813689817674455, acc: 99.48141294717789, p_norm: 2017.2981209885886, g_norm: 0.6231103074523945, lr:  0.000631, elapsed time:  144385
Step 156800, loss: 0.03995954120066017, acc: 99.49364659190178, p_norm: 2017.5109767890997, g_norm: 0.6140431330830536, lr:  0.000631, elapsed time:  144476
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 156900, loss: 0.039465388612108146, acc: 99.4958846574992, p_norm: 2017.7097640221396, g_norm: 0.41396547668487177, lr:  0.000631, elapsed time:  144563
Step 157000, loss: 0.03856048827059567, acc: 99.52621160447598, p_norm: 2017.9194790990853, g_norm: 0.7021071408033968, lr:  0.000631, elapsed time:  144652
Step 157100, loss: 0.03969894130248577, acc: 99.48199759423733, p_norm: 2018.1119506877922, g_norm: 0.6963022362190124, lr:  0.000631, elapsed time:  144742
Step 157200, loss: 0.040502315857447686, acc: 99.46584941446781, p_norm: 2018.3298733293577, g_norm: 0.5385172603482491, lr:  0.000630, elapsed time:  144831
Step 157300, loss: 0.039222365696914493, acc: 99.50409366190434, p_norm: 2018.5497071085165, g_norm: 0.517839849982076, lr:  0.000630, elapsed time:  144921
Step 157400, loss: 0.03940458359196782, acc: 99.5045311152935, p_norm: 2018.758265445698, g_norm: 0.5680801453050802, lr:  0.000630, elapsed time:  145019
Step 157500, loss: 0.04012474718503654, acc: 99.47173880040646, p_norm: 2018.9544530998342, g_norm: 0.6799582392641625, lr:  0.000630, elapsed time:  145109
Step 157600, loss: 0.03881101548206061, acc: 99.5016767680645, p_norm: 2019.1735544412425, g_norm: 0.6296316207056916, lr:  0.000630, elapsed time:  145200
Step 157700, loss: 0.04053695586044341, acc: 99.46670319139957, p_norm: 2019.3953844912883, g_norm: 0.7875276064704972, lr:  0.000629, elapsed time:  145288
Step 157800, loss: 0.03935585676692426, acc: 99.49229437112808, p_norm: 2019.6000008289598, g_norm: 0.6850475876899239, lr:  0.000629, elapsed time:  145378
Step 157900, loss: 0.040076058595441284, acc: 99.47847911715508, p_norm: 2019.7879361954133, g_norm: 0.4446666717041071, lr:  0.000629, elapsed time:  145466
Step 158000, loss: 0.039259547763504085, acc: 99.50307789444923, p_norm: 2019.9805683262389, g_norm: 0.5786360838908318, lr:  0.000629, elapsed time:  145565
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 158000, eval loss: 0.04638685235753655, eval acc: 99.440673828125
Step 158100, loss: 0.0400292163528502, acc: 99.49100705981255, p_norm: 2020.1861260889796, g_norm: 0.489845370294336, lr:  0.000629, elapsed time:  145670
Step 158200, loss: 0.04005858911201358, acc: 99.48000161349773, p_norm: 2020.388324146078, g_norm: 0.556719541899386, lr:  0.000628, elapsed time:  145760
Step 158300, loss: 0.04066504244692624, acc: 99.45193023979664, p_norm: 2020.6218749054985, g_norm: 0.8542344335684431, lr:  0.000628, elapsed time:  145852
Step 158400, loss: 0.0393390410579741, acc: 99.49936939775944, p_norm: 2020.8214237854477, g_norm: 0.6554205173283688, lr:  0.000628, elapsed time:  145944
Step 158500, loss: 0.03953561611007899, acc: 99.49820582568645, p_norm: 2021.038010696743, g_norm: 0.5965900584236197, lr:  0.000628, elapsed time:  146037
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 158600, loss: 0.03901274993885957, acc: 99.50619323633204, p_norm: 2021.2349391411801, g_norm: 0.5583696444327088, lr:  0.000628, elapsed time:  146109
Step 158700, loss: 0.03934665733017027, acc: 99.50246851146221, p_norm: 2021.4268718409076, g_norm: 1.2160347784867422, lr:  0.000627, elapsed time:  146194
Step 158800, loss: 0.03925959383603186, acc: 99.50803023576736, p_norm: 2021.644094381377, g_norm: 0.7393394784855534, lr:  0.000627, elapsed time:  146286
Step 158900, loss: 0.03977396613918245, acc: 99.49127930402756, p_norm: 2021.850812008699, g_norm: 0.5091571927640399, lr:  0.000627, elapsed time:  146380
Step 159000, loss: 0.03898510058876127, acc: 99.50362096726894, p_norm: 2022.0936572192356, g_norm: 0.48714049134403914, lr:  0.000627, elapsed time:  146472
Step 159100, loss: 0.03916067159269005, acc: 99.50765807926655, p_norm: 2022.2652477622325, g_norm: 0.656475270270024, lr:  0.000627, elapsed time:  146567
Step 159200, loss: 0.038957718359306455, acc: 99.513786226511, p_norm: 2022.4451787535547, g_norm: 0.6523871140677151, lr:  0.000626, elapsed time:  146663
Step 159300, loss: 0.03964341311249882, acc: 99.48889563977718, p_norm: 2022.6300705629114, g_norm: 0.5560898282064283, lr:  0.000626, elapsed time:  146746
Step 159400, loss: 0.04017890912946313, acc: 99.47562131285667, p_norm: 2022.856173265489, g_norm: 0.7222243187428972, lr:  0.000626, elapsed time:  146835
Step 159500, loss: 0.03976407803595066, acc: 99.49002267420292, p_norm: 2023.05173463744, g_norm: 0.8165396281401617, lr:  0.000626, elapsed time:  146926
Step 159600, loss: 0.039185044979676606, acc: 99.50602746009827, p_norm: 2023.2522601873268, g_norm: 0.6912006311147396, lr:  0.000626, elapsed time:  147018
Step 159700, loss: 0.038703353465534746, acc: 99.51965349912643, p_norm: 2023.4573919272505, g_norm: 0.6914399285843453, lr:  0.000625, elapsed time:  147107
Step 159800, loss: 0.03895728266332298, acc: 99.51256895065308, p_norm: 2023.6739748398609, g_norm: 0.5193179785526254, lr:  0.000625, elapsed time:  147199
Step 159900, loss: 0.03962745902128518, acc: 99.4812898337841, p_norm: 2023.884542841342, g_norm: 0.5857870962183902, lr:  0.000625, elapsed time:  147293
Step 160000, loss: 0.03997149497736245, acc: 99.48260831832886, p_norm: 2024.0955143890142, g_norm: 0.6328325952958347, lr:  0.000625, elapsed time:  147382
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 160000, eval loss: 0.04247995106503366, eval acc: 99.53153991699219
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c c ( C N ( C 2 C C ( F ) ( F ) C C N C 2 = O ) S ( = O ) ( = O ) c 2 c c c ( Cl ) s 2 ) c n 1 _EOS
Predicted text: C O c 1 c c c ( C N ( C 2 C C ( F ) ( F ) C C N C 2 = O ) S ( = O ) ( = O ) c 2 c c c ( Cl ) s 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N c 1 n c c c ( N c 2 c c ( - c 3 c c ( Cl ) c c c 3 F ) n c 3 n c c c c 2 3 ) n 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N c 1 n c c c ( N c 2 c c ( - c 3 c c ( Cl ) c c c 3 F ) n c 3 n c c c c 2 3 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C ( O C C ) c 1 c c c ( C ( = O ) N C c 2 c c c ( O c 3 c c c c c 3 ) s 2 ) c ( N ) n 1 _EOS
Predicted text: C = C ( O C C ) c 1 c c c ( C ( = O ) N C c 2 c c c ( O c 3 c c c c c 3 ) s 2 ) c ( N ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C C O c 1 c c ( C ( = O ) N ( C C 2 C N ( C c 3 c c c c c 3 ) C C 2 C N ( C ( = O ) O C ( C ) ( C ) C ) C ( C ) C ) C ( C ) C ) c c c 1 O C _EOS
Predicted text: C O C C C O c 1 c c ( C ( = O ) N ( C C 2 C N ( C c 3 c c c c c 3 ) C C 2 C N ( C ( = O ) O C ( C ) ( C ) C ) C ( C ) C ) C ( C ) C ) c c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C C C O C ( = O ) C C ( = O ) C O C C ( F ) ( F ) F _EOS
Predicted text: C C O C ( = O ) C C ( = O ) C O C C ( F ) ( F ) F _EOS _PAD _PAD _PAD
acc_token: 0.20689655172413793, acc_seq: False

Evaluation (without teacher) at step 160000, eval acc (token): 0.9306478393359238, eval acc (sequence): 0.8735354927636113
Saving at step 160000
Step 160100, loss: 0.04118473550304771, acc: 99.44751094281673, p_norm: 2024.3264407256866, g_norm: 0.7639909613841629, lr:  0.000625, elapsed time:  147564
Step 160200, loss: 0.03988655854482204, acc: 99.48751842975616, p_norm: 2024.5228499018872, g_norm: 0.7932972350446376, lr:  0.000624, elapsed time:  147654
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 160300, loss: 0.03842340960229745, acc: 99.53702210492591, p_norm: 2024.722963084109, g_norm: 0.5747974010279078, lr:  0.000624, elapsed time:  147745
Step 160400, loss: 0.03882669189479202, acc: 99.5176347643137, p_norm: 2024.9199361221688, g_norm: 0.7245632029515788, lr:  0.000624, elapsed time:  147837
Step 160500, loss: 0.03872853807639331, acc: 99.52082645893097, p_norm: 2025.1201826163865, g_norm: 0.6521999192753644, lr:  0.000624, elapsed time:  147925
Step 160600, loss: 0.03883800595998764, acc: 99.51706072688103, p_norm: 2025.329165975219, g_norm: 0.6599989202598088, lr:  0.000624, elapsed time:  148015
Step 160700, loss: 0.039537135735154154, acc: 99.49777109920979, p_norm: 2025.5374677576053, g_norm: 0.8021414410954637, lr:  0.000623, elapsed time:  148105
Step 160800, loss: 0.039086054088547824, acc: 99.50067134201527, p_norm: 2025.7373553005843, g_norm: 0.6932081426941669, lr:  0.000623, elapsed time:  148195
Step 160900, loss: 0.0400417068041861, acc: 99.47700721025467, p_norm: 2025.9471806730642, g_norm: 0.6146856611754837, lr:  0.000623, elapsed time:  148285
Step 161000, loss: 0.03947907645720988, acc: 99.4964445233345, p_norm: 2026.1389986660142, g_norm: 0.7471270677878844, lr:  0.000623, elapsed time:  148375
Step 161100, loss: 0.03895559609401971, acc: 99.50526238977909, p_norm: 2026.3397763622402, g_norm: 0.6198445425776377, lr:  0.000623, elapsed time:  148465
Step 161200, loss: 0.040057643922045826, acc: 99.4780445843935, p_norm: 2026.5349985353448, g_norm: 1.0235399104770297, lr:  0.000622, elapsed time:  148555
Step 161300, loss: 0.03985496610403061, acc: 99.47625030577183, p_norm: 2026.7417697596409, g_norm: 0.5682613446540863, lr:  0.000622, elapsed time:  148646
Step 161400, loss: 0.03907718487083912, acc: 99.50119648873806, p_norm: 2026.9273950228685, g_norm: 0.6863370135228183, lr:  0.000622, elapsed time:  148736
Step 161500, loss: 0.03973866302985698, acc: 99.4842189848423, p_norm: 2027.128651035249, g_norm: 0.5256197304424186, lr:  0.000622, elapsed time:  148826
Step 161600, loss: 0.03994776275940239, acc: 99.4799939095974, p_norm: 2027.316934986421, g_norm: 0.5237146155102276, lr:  0.000622, elapsed time:  148912
Step 161700, loss: 0.03979626667220146, acc: 99.4973795413971, p_norm: 2027.5176187125444, g_norm: 0.5950001061429258, lr:  0.000622, elapsed time:  149003
Step 161800, loss: 0.04011201835703105, acc: 99.48043185472488, p_norm: 2027.7105847868877, g_norm: 0.5007280024350506, lr:  0.000621, elapsed time:  149091
Step 161900, loss: 0.03998399178031832, acc: 99.48106399178505, p_norm: 2027.901047169656, g_norm: 0.7061964768296517, lr:  0.000621, elapsed time:  149181
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 162000, loss: 0.03939840299708228, acc: 99.50410853840282, p_norm: 2028.1236795079888, g_norm: 0.699979870908476, lr:  0.000621, elapsed time:  149270
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 162000, eval loss: 0.04375100504606963, eval acc: 99.5013427734375
Step 162100, loss: 0.03853530878201127, acc: 99.51559092104435, p_norm: 2028.340704929205, g_norm: 0.6165852237314045, lr:  0.000621, elapsed time:  149374
Step 162200, loss: 0.038490884164348246, acc: 99.52909696102142, p_norm: 2028.5399049573089, g_norm: 0.552435126395306, lr:  0.000621, elapsed time:  149465
Step 162300, loss: 0.04019993321970105, acc: 99.49051363766193, p_norm: 2028.7497957437322, g_norm: 0.5467024413462618, lr:  0.000620, elapsed time:  149553
Step 162400, loss: 0.039760152092203495, acc: 99.49968734383583, p_norm: 2028.9650205275896, g_norm: 0.5373907842998834, lr:  0.000620, elapsed time:  149642
Step 162500, loss: 0.04037871739361435, acc: 99.5079844892025, p_norm: 2029.1499253913084, g_norm: 0.5384443568357287, lr:  0.000620, elapsed time:  149733
Step 162600, loss: 0.04162460978142917, acc: 99.4764648526907, p_norm: 2029.3449914936816, g_norm: 0.6900451352078835, lr:  0.000620, elapsed time:  149822
Step 162700, loss: 0.040215121456421914, acc: 99.49673072993755, p_norm: 2029.5054886060514, g_norm: 0.49951930780127063, lr:  0.000620, elapsed time:  149910
Step 162800, loss: 0.039556572139263155, acc: 99.51848247647285, p_norm: 2029.6910700923852, g_norm: 0.4743977455696736, lr:  0.000619, elapsed time:  149999
Step 162900, loss: 0.04005122520495206, acc: 99.49320736527443, p_norm: 2029.8793134145192, g_norm: 0.7613293083420298, lr:  0.000619, elapsed time:  150091
Step 163000, loss: 0.03996436850167811, acc: 99.49200010299683, p_norm: 2030.0645355508814, g_norm: 0.48227277243129263, lr:  0.000619, elapsed time:  150180
Step 163100, loss: 0.03965286247432232, acc: 99.49436521530151, p_norm: 2030.2440577890584, g_norm: 0.6694178643277908, lr:  0.000619, elapsed time:  150270
Step 163200, loss: 0.03937358869239688, acc: 99.50154913961887, p_norm: 2030.4230189257378, g_norm: 0.6125622076566606, lr:  0.000619, elapsed time:  150360
Step 163300, loss: 0.04018579217605293, acc: 99.49720817804337, p_norm: 2030.6150815350115, g_norm: 0.6250607388931563, lr:  0.000618, elapsed time:  150450
Step 163400, loss: 0.040285852625966075, acc: 99.4954077154398, p_norm: 2030.805977850058, g_norm: 0.64874655398734, lr:  0.000618, elapsed time:  150541
Step 163500, loss: 0.04138478948734701, acc: 99.48995596170425, p_norm: 2030.9968217813325, g_norm: 0.9034621163425512, lr:  0.000618, elapsed time:  150633
Step 163600, loss: 0.0412274717586115, acc: 99.48192523419857, p_norm: 2031.175282888757, g_norm: 1.2975233057498345, lr:  0.000618, elapsed time:  150720
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 163700, loss: 0.040805233531532155, acc: 99.48368699615706, p_norm: 2031.3792802665514, g_norm: 0.7473978489520066, lr:  0.000618, elapsed time:  150812
Step 163800, loss: 0.04000885953661054, acc: 99.51188923418522, p_norm: 2031.5701791851857, g_norm: 0.4866792375220508, lr:  0.000618, elapsed time:  150902
Step 163900, loss: 0.03906124040484429, acc: 99.51742881536484, p_norm: 2031.755184537311, g_norm: 0.5419126108783906, lr:  0.000617, elapsed time:  150990
Step 164000, loss: 0.03885619003325701, acc: 99.52735479176044, p_norm: 2031.9405027702023, g_norm: 0.6507464325461467, lr:  0.000617, elapsed time:  151082
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 164000, eval loss: 0.0444289389438927, eval acc: 99.47111511230469
Step 164100, loss: 0.040447646407410505, acc: 99.49690552055836, p_norm: 2032.1411165476775, g_norm: 0.47333066591896533, lr:  0.000617, elapsed time:  151186
Step 164200, loss: 0.04065434689167887, acc: 99.48906463384628, p_norm: 2032.3562848995728, g_norm: 0.5747241558820314, lr:  0.000617, elapsed time:  151275
Step 164300, loss: 0.039700380279682576, acc: 99.50386960804462, p_norm: 2032.5442783857445, g_norm: 0.473350917421857, lr:  0.000617, elapsed time:  151364
Step 164400, loss: 0.0392687926767394, acc: 99.50698044896126, p_norm: 2032.7364778396648, g_norm: 0.5243983179494104, lr:  0.000616, elapsed time:  151453
Step 164500, loss: 0.03968791861552745, acc: 99.49923287332058, p_norm: 2032.9192440971146, g_norm: 0.6301967854912638, lr:  0.000616, elapsed time:  151543
Step 164600, loss: 0.03941622786223888, acc: 99.49663174152374, p_norm: 2033.1382493450185, g_norm: 0.6616375701796311, lr:  0.000616, elapsed time:  151634
Step 164700, loss: 0.03998804771807045, acc: 99.48313754796982, p_norm: 2033.3576705851863, g_norm: 0.5802337807434592, lr:  0.000616, elapsed time:  151721
Step 164800, loss: 0.04088318872265518, acc: 99.47489334642887, p_norm: 2033.5586712747709, g_norm: 0.658320458025418, lr:  0.000616, elapsed time:  151810
Step 164900, loss: 0.03988358614034951, acc: 99.49812263250351, p_norm: 2033.7759379217994, g_norm: 0.5389227401068704, lr:  0.000615, elapsed time:  151899
Step 165000, loss: 0.03914368499070406, acc: 99.50606878101826, p_norm: 2033.9650391103216, g_norm: 0.8251538227464461, lr:  0.000615, elapsed time:  151993
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Target text: N c 1 n c c c c 1 - c 1 c c c ( O c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: N c 1 n c c c c 1 - c 1 c c c ( O c 2 c c c c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O C ( C ) ( C ( = O ) N c 1 c c c ( S c 2 c c c ( N C ( N ) = O ) c c 2 ) c c 1 Cl ) C ( F ) ( F ) F _EOS
Predicted text: C C ( = O ) O C ( C ) ( C ( = O ) N c 1 c c c ( S c 2 c c c ( N C ( N ) = O ) c c 2 ) c c 1 Cl ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C N C c 1 c c c 2 [nH] c c ( C C N C ( = O ) O C c 3 c c c c c 3 ) c 2 c 1 _EOS
Predicted text: O = C N C c 1 c c c 2 [nH] c c ( C C N C ( = O ) O C c 3 c c c c c 3 ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C ( C ) C ) c ( N C ( = O ) C N 2 C C N ( C C S c 3 n c 4 c c c c c 4 o 3 ) C C 2 ) c 1 C ( C ) C _EOS
Predicted text: C O c 1 c c c ( C ( C ) C ) c ( N C ( = O ) C N 2 C C N ( C C S c 3 n c 4 c c c c c 4 o 3 ) C C 2 ) c 1 C ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C C ( O ) C ( = O ) N C ( C ( = O ) O ) c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) C C ( O ) C ( = O ) N C ( C ( = O ) O ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 165000, eval acc (token): 0.9317885337268998, eval acc (sequence): 0.8725406330196749
Saving at step 165000
Step 165100, loss: 0.03918594223912805, acc: 99.49987982213497, p_norm: 2034.1367878290012, g_norm: 0.513188677042392, lr:  0.000615, elapsed time:  152163
Step 165200, loss: 0.039848622018471364, acc: 99.47981324791908, p_norm: 2034.3443885116887, g_norm: 0.5702652023772136, lr:  0.000615, elapsed time:  152252
Step 165300, loss: 0.039176057721488175, acc: 99.49284256994724, p_norm: 2034.539576941816, g_norm: 0.8263556616496787, lr:  0.000615, elapsed time:  152337
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 165400, loss: 0.03878654292310882, acc: 99.50459022675791, p_norm: 2034.742397495482, g_norm: 0.5847905198168954, lr:  0.000615, elapsed time:  152428
Step 165500, loss: 0.038170404150150716, acc: 99.52746863663197, p_norm: 2034.9340536912073, g_norm: 0.9473947956664144, lr:  0.000614, elapsed time:  152520
Step 165600, loss: 0.038578360076062385, acc: 99.50935506820679, p_norm: 2035.1186810838449, g_norm: 0.667975892646954, lr:  0.000614, elapsed time:  152612
Step 165700, loss: 0.03844833643641323, acc: 99.51108676195145, p_norm: 2035.3006597827289, g_norm: 0.485920062450701, lr:  0.000614, elapsed time:  152704
Step 165800, loss: 0.03937371240463108, acc: 99.49186725914478, p_norm: 2035.4977088731748, g_norm: 0.48263086816484824, lr:  0.000614, elapsed time:  152798
Step 165900, loss: 0.03840123873669654, acc: 99.52408918738365, p_norm: 2035.7117985667094, g_norm: 0.5570441189281248, lr:  0.000614, elapsed time:  152891
Step 166000, loss: 0.0392320368764922, acc: 99.50148417055607, p_norm: 2035.906019050644, g_norm: 0.5871118382893544, lr:  0.000613, elapsed time:  152979
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 166000, eval loss: 0.04442755786702037, eval acc: 99.48876190185547
Step 166100, loss: 0.03818519858177751, acc: 99.52612213790417, p_norm: 2036.0960838776477, g_norm: 0.4493208728374714, lr:  0.000613, elapsed time:  153091
Step 166200, loss: 0.03948135588783771, acc: 99.49446818232536, p_norm: 2036.2862316530213, g_norm: 0.6295870688919842, lr:  0.000613, elapsed time:  153185
Step 166300, loss: 0.04018495419062674, acc: 99.49483922123909, p_norm: 2036.4909330459377, g_norm: 1.092113620711483, lr:  0.000613, elapsed time:  153274
Step 166400, loss: 0.040076058567501606, acc: 99.51294162869453, p_norm: 2036.6748821966473, g_norm: 0.6759850930179848, lr:  0.000613, elapsed time:  153369
Step 166500, loss: 0.040212453119456766, acc: 99.48706823587418, p_norm: 2036.865504141184, g_norm: 0.5216967429957948, lr:  0.000612, elapsed time:  153452
Step 166600, loss: 0.039899386814795434, acc: 99.49969546496868, p_norm: 2037.0785644391328, g_norm: 0.6208617016135878, lr:  0.000612, elapsed time:  153545
Step 166700, loss: 0.039484075866639615, acc: 99.5017227679491, p_norm: 2037.278695912371, g_norm: 0.6988392490932773, lr:  0.000612, elapsed time:  153645
Step 166800, loss: 0.04192858521360904, acc: 99.47599837183952, p_norm: 2037.483689038592, g_norm: 0.6704959411054516, lr:  0.000612, elapsed time:  153736
Step 166900, loss: 0.040380869358778, acc: 99.50956885516644, p_norm: 2037.656527662776, g_norm: 0.6231679789214556, lr:  0.000612, elapsed time:  153827
Step 167000, loss: 0.04092523679602891, acc: 99.49374902248383, p_norm: 2037.8293140325443, g_norm: 0.7072787634449231, lr:  0.000612, elapsed time:  153912
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 167100, loss: 0.04030785156849457, acc: 99.49582646142191, p_norm: 2038.0272892107746, g_norm: 0.7001429807976643, lr:  0.000611, elapsed time:  154001
Step 167200, loss: 0.03873758451547474, acc: 99.53252203762531, p_norm: 2038.2094040558131, g_norm: 0.6437287520448125, lr:  0.000611, elapsed time:  154090
Step 167300, loss: 0.039160757157951594, acc: 99.51280596852303, p_norm: 2038.4037832879305, g_norm: 0.5418568173928723, lr:  0.000611, elapsed time:  154180
Step 167400, loss: 0.03883621674962342, acc: 99.51752510666847, p_norm: 2038.6263980749056, g_norm: 0.6751455102883894, lr:  0.000611, elapsed time:  154269
Step 167500, loss: 0.03874057976063341, acc: 99.51297895610332, p_norm: 2038.8093095021554, g_norm: 0.6907656722741596, lr:  0.000611, elapsed time:  154357
Step 167600, loss: 0.039775208211503925, acc: 99.49902953207493, p_norm: 2038.994468797803, g_norm: 0.48810642693104545, lr:  0.000610, elapsed time:  154447
Step 167700, loss: 0.03951066188514232, acc: 99.51229159533978, p_norm: 2039.1793652936324, g_norm: 0.7452389137752979, lr:  0.000610, elapsed time:  154535
Step 167800, loss: 0.040190232349559665, acc: 99.48819842934608, p_norm: 2039.3626506675487, g_norm: 0.7257811400883781, lr:  0.000610, elapsed time:  154625
Step 167900, loss: 0.03943253432866186, acc: 99.50413939356804, p_norm: 2039.5593129636477, g_norm: 0.6557278460271623, lr:  0.000610, elapsed time:  154718
Step 168000, loss: 0.03871181715745479, acc: 99.53574272990227, p_norm: 2039.7326909356468, g_norm: 0.4728715406815357, lr:  0.000610, elapsed time:  154807
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 168000, eval loss: 0.04403010658919811, eval acc: 99.50221252441406
Step 168100, loss: 0.03932678411714732, acc: 99.51105134189129, p_norm: 2039.9208209283593, g_norm: 0.6342467174906498, lr:  0.000610, elapsed time:  154911
Step 168200, loss: 0.03912643551360816, acc: 99.51490499079227, p_norm: 2040.111203771295, g_norm: 0.7338587159659197, lr:  0.000609, elapsed time:  155001
Step 168300, loss: 0.03918486250564456, acc: 99.50346624851227, p_norm: 2040.2902207585646, g_norm: 0.6057692369469483, lr:  0.000609, elapsed time:  155092
Step 168400, loss: 0.03952388412319124, acc: 99.48698402941227, p_norm: 2040.4839338149222, g_norm: 0.7024281015583753, lr:  0.000609, elapsed time:  155177
Step 168500, loss: 0.03898270171601325, acc: 99.50237710773945, p_norm: 2040.7109819971638, g_norm: 0.9835987368804574, lr:  0.000609, elapsed time:  155272
Step 168600, loss: 0.039439006494358185, acc: 99.4945795238018, p_norm: 2040.897193118105, g_norm: 0.5902161341261539, lr:  0.000609, elapsed time:  155359
Step 168700, loss: 0.03843234968371689, acc: 99.5228873193264, p_norm: 2041.076494765431, g_norm: 0.6240845479607633, lr:  0.000608, elapsed time:  155449
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 168800, loss: 0.03859951152990829, acc: 99.51966311736379, p_norm: 2041.2847929335674, g_norm: 0.7957623224853211, lr:  0.000608, elapsed time:  155542
Step 168900, loss: 0.03703091300558299, acc: 99.56708709895611, p_norm: 2041.4422735529547, g_norm: 0.6467885857654366, lr:  0.000608, elapsed time:  155637
Step 169000, loss: 0.03841727584600449, acc: 99.5147015452385, p_norm: 2041.6320587925375, g_norm: 0.49535530378733306, lr:  0.000608, elapsed time:  155705
Step 169100, loss: 0.038068497916683555, acc: 99.53658992052078, p_norm: 2041.8151347812495, g_norm: 0.5327404105836938, lr:  0.000608, elapsed time:  155792
Step 169200, loss: 0.03836313746403903, acc: 99.51618321239948, p_norm: 2042.0131220750552, g_norm: 0.5593788642543029, lr:  0.000608, elapsed time:  155891
Step 169300, loss: 0.03873125873040408, acc: 99.51859731972218, p_norm: 2042.2063880932474, g_norm: 0.5355762589495224, lr:  0.000607, elapsed time:  155980
Step 169400, loss: 0.03926735427230597, acc: 99.49971367418766, p_norm: 2042.3964754050696, g_norm: 0.5754061454956289, lr:  0.000607, elapsed time:  156073
Step 169500, loss: 0.03891509539913386, acc: 99.52076350152493, p_norm: 2042.5866964416439, g_norm: 0.5829713136528387, lr:  0.000607, elapsed time:  156165
Step 169600, loss: 0.03909934781026095, acc: 99.50412410497665, p_norm: 2042.7790679307416, g_norm: 0.4667974712742884, lr:  0.000607, elapsed time:  156254
Step 169700, loss: 0.03830755083356053, acc: 99.52167151868343, p_norm: 2042.971329692757, g_norm: 0.7061207214880895, lr:  0.000607, elapsed time:  156345
Step 169800, loss: 0.03943371601402759, acc: 99.49380886554718, p_norm: 2043.1644940020574, g_norm: 0.6746169334451193, lr:  0.000607, elapsed time:  156435
Step 169900, loss: 0.03955341015011072, acc: 99.48363180458546, p_norm: 2043.364269915084, g_norm: 0.6561645297375683, lr:  0.000606, elapsed time:  156525
Step 170000, loss: 0.03911510471720248, acc: 99.51445616781712, p_norm: 2043.5809858349824, g_norm: 0.9062957368266988, lr:  0.000606, elapsed time:  156615
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 170000, eval loss: 0.04372498027980327, eval acc: 99.48474884033203
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( N ) C C S ( = O ) ( = O ) O c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) ( N ) C C S ( = O ) ( = O ) O c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: Cl c 1 c c ( - c 2 c c c c 3 c c s c 2 3 ) c c n 1 _EOS
Predicted text: Cl c 1 c c ( - c 2 c c c c 3 c c s c 2 3 ) c c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N 1 C ( C ) C N ( c 2 c c c 3 c ( n 2 ) - c 2 s c ( - c 4 n c n n 4 - c 4 c c c ( F ) c c 4 F ) c c 2 C C O 3 ) C C 1 C _EOS
Predicted text: C C ( = O ) N 1 C ( C ) C N ( c 2 c c c 3 c ( n 2 ) - c 2 s c ( - c 4 n c n n 4 - c 4 c c c ( F ) c c 4 F ) c c 2 C C O 3 ) C C 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = S ( = O ) ( O ) c 1 c c c ( C = [N+] ( [O-] ) C 2 3 C C 4 C C ( C C ( C 4 ) C 2 ) C 3 ) o 1 _EOS
Predicted text: O = S ( = O ) ( O ) c 1 c c c ( C = [N+] ( [O-] ) C 2 3 C C 4 C C ( C C ( C 4 ) C 2 ) C 3 ) o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C C C C # C C N 1 C ( = O ) c 2 c c c c c 2 C 1 = O _EOS
Predicted text: O = C ( O ) C C C C # C C N 1 C ( = O ) c 2 c c c c c 2 C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 170000, eval acc (token): 0.934847437144291, eval acc (sequence): 0.87715967343839
Saving at step 170000
Step 170100, loss: 0.03889338914770633, acc: 99.51064343750477, p_norm: 2043.770125587982, g_norm: 0.6377885019298604, lr:  0.000606, elapsed time:  156806
Step 170200, loss: 0.03849400311242789, acc: 99.51335518062115, p_norm: 2043.9539558609874, g_norm: 0.5643945603753976, lr:  0.000606, elapsed time:  156906
Step 170300, loss: 0.038489402309060096, acc: 99.52293722331524, p_norm: 2044.1435544993967, g_norm: 0.5022064622847836, lr:  0.000606, elapsed time:  156997
Step 170400, loss: 0.038832119423896076, acc: 99.51973356306553, p_norm: 2044.330663708202, g_norm: 0.48882775607992635, lr:  0.000605, elapsed time:  157088
Step 170500, loss: 0.03937844434287399, acc: 99.49145901203156, p_norm: 2044.5136543052313, g_norm: 0.4800168404025441, lr:  0.000605, elapsed time:  157176
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 170600, loss: 0.03851113691648685, acc: 99.52539556079704, p_norm: 2044.6820042428858, g_norm: 0.6739608789984549, lr:  0.000605, elapsed time:  157269
Step 170700, loss: 0.03887245841789991, acc: 99.5120765119791, p_norm: 2044.8720416651977, g_norm: 0.680924046714604, lr:  0.000605, elapsed time:  157336
Step 170800, loss: 0.038791857319884, acc: 99.51490265130997, p_norm: 2045.0948788258079, g_norm: 0.6911023799869995, lr:  0.000605, elapsed time:  157406
Step 170900, loss: 0.038320860699750485, acc: 99.52325983345509, p_norm: 2045.2872929406005, g_norm: 0.6115642297913737, lr:  0.000605, elapsed time:  157477
Step 171000, loss: 0.039193056407384574, acc: 99.50512582063675, p_norm: 2045.4653828085377, g_norm: 0.589226233213825, lr:  0.000604, elapsed time:  157546
Step 171100, loss: 0.03847546334378421, acc: 99.52519854903221, p_norm: 2045.6621588633236, g_norm: 0.6083183560421718, lr:  0.000604, elapsed time:  157638
Step 171200, loss: 0.038924510553479195, acc: 99.51072829961777, p_norm: 2045.8489401052523, g_norm: 0.6005827737378915, lr:  0.000604, elapsed time:  157732
Step 171300, loss: 0.03923785877879709, acc: 99.49725663661957, p_norm: 2046.0509601972585, g_norm: 0.43342405196298095, lr:  0.000604, elapsed time:  157825
Step 171400, loss: 0.03809030236210674, acc: 99.52895238995552, p_norm: 2046.2406843453434, g_norm: 0.7163741105483411, lr:  0.000604, elapsed time:  157918
Step 171500, loss: 0.03923156393691898, acc: 99.49211955070496, p_norm: 2046.4332713940576, g_norm: 0.6164404584216128, lr:  0.000604, elapsed time:  158005
Step 171600, loss: 0.03870083195623011, acc: 99.51722295582294, p_norm: 2046.6171028251456, g_norm: 0.8692128124159942, lr:  0.000603, elapsed time:  158094
Step 171700, loss: 0.038972911541350186, acc: 99.51422728598118, p_norm: 2046.8005632858135, g_norm: 0.7792760079037813, lr:  0.000603, elapsed time:  158186
Step 171800, loss: 0.037842063163407144, acc: 99.53999149799347, p_norm: 2046.982132120845, g_norm: 0.6090341202927877, lr:  0.000603, elapsed time:  158280
Step 171900, loss: 0.03916982896160334, acc: 99.4956822693348, p_norm: 2047.1546369379707, g_norm: 0.5995711606442005, lr:  0.000603, elapsed time:  158368
Step 172000, loss: 0.03881089572794735, acc: 99.5141889154911, p_norm: 2047.3534787063752, g_norm: 0.5969748887875203, lr:  0.000603, elapsed time:  158459
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 172000, eval loss: 0.04380937134847044, eval acc: 99.49861907958984
Step 172100, loss: 0.038747275928035375, acc: 99.51801812648773, p_norm: 2047.5357621530407, g_norm: 0.5585111371466676, lr:  0.000602, elapsed time:  158567
Step 172200, loss: 0.03829210504423827, acc: 99.53043456375599, p_norm: 2047.7166885463637, g_norm: 0.4837152742447925, lr:  0.000602, elapsed time:  158657
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 172300, loss: 0.03780617124444941, acc: 99.53291185440555, p_norm: 2047.8944651626418, g_norm: 0.5863281251721534, lr:  0.000602, elapsed time:  158749
Step 172400, loss: 0.038665513079613446, acc: 99.51497063040733, p_norm: 2048.0778849689227, g_norm: 0.5384732184909484, lr:  0.000602, elapsed time:  158851
Step 172500, loss: 0.037870582351461055, acc: 99.53133046627045, p_norm: 2048.2590235763646, g_norm: 0.5709887130352667, lr:  0.000602, elapsed time:  158938
Step 172600, loss: 0.038674142607487735, acc: 99.5135073363781, p_norm: 2048.4434244180693, g_norm: 0.6389524039532511, lr:  0.000602, elapsed time:  159028
Step 172700, loss: 0.03791047954466194, acc: 99.53058888018131, p_norm: 2048.628081576262, g_norm: 0.6496567593849992, lr:  0.000601, elapsed time:  159120
Step 172800, loss: 0.03875337703619152, acc: 99.51330733299255, p_norm: 2048.830532941726, g_norm: 0.596630338628362, lr:  0.000601, elapsed time:  159219
Step 172900, loss: 0.03784204652998596, acc: 99.54261772334576, p_norm: 2049.016576098087, g_norm: 0.5404901268798818, lr:  0.000601, elapsed time:  159311
Step 173000, loss: 0.03864932056516409, acc: 99.51442140340805, p_norm: 2049.2031505789496, g_norm: 0.6075711652398409, lr:  0.000601, elapsed time:  159404
Step 173100, loss: 0.03890131828840822, acc: 99.50496688485146, p_norm: 2049.39392982759, g_norm: 0.7446640656076796, lr:  0.000601, elapsed time:  159498
Step 173200, loss: 0.03867653185036033, acc: 99.51398254930973, p_norm: 2049.574488715937, g_norm: 0.5039957689438925, lr:  0.000601, elapsed time:  159589
Step 173300, loss: 0.038836797899566594, acc: 99.5161422342062, p_norm: 2049.763022067597, g_norm: 0.5933116140962278, lr:  0.000600, elapsed time:  159684
Step 173400, loss: 0.03925967912189662, acc: 99.50204733014107, p_norm: 2049.9315851223637, g_norm: 0.5872260676820168, lr:  0.000600, elapsed time:  159776
Step 173500, loss: 0.03994155051652342, acc: 99.49583673477173, p_norm: 2050.160812401135, g_norm: 0.6636695299777698, lr:  0.000600, elapsed time:  159874
Step 173600, loss: 0.03985060964245349, acc: 99.48971611261368, p_norm: 2050.359910706184, g_norm: 0.5909014725271068, lr:  0.000600, elapsed time:  159966
Step 173700, loss: 0.03919821240473539, acc: 99.50501728057861, p_norm: 2050.535412713104, g_norm: 0.49910704438612163, lr:  0.000600, elapsed time:  160058
Step 173800, loss: 0.038550923219881954, acc: 99.51272486150265, p_norm: 2050.7192575587537, g_norm: 0.6736170314785894, lr:  0.000599, elapsed time:  160153
Step 173900, loss: 0.03853678367100656, acc: 99.51937635242939, p_norm: 2050.8953854162387, g_norm: 0.6905209820839211, lr:  0.000599, elapsed time:  160243
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 174000, loss: 0.038190867409812604, acc: 99.53515082967489, p_norm: 2051.0848210061577, g_norm: 0.905457721608629, lr:  0.000599, elapsed time:  160334
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 174000, eval loss: 0.04368616372346877, eval acc: 99.50767517089844
Step 174100, loss: 0.038244052473455664, acc: 99.52564761042595, p_norm: 2051.2619466839406, g_norm: 0.5425343125051838, lr:  0.000599, elapsed time:  160440
Step 174200, loss: 0.03844963287003338, acc: 99.52329474687576, p_norm: 2051.4388958340346, g_norm: 0.5358964245594805, lr:  0.000599, elapsed time:  160528
Step 174300, loss: 0.03805610643234104, acc: 99.52799038589, p_norm: 2051.6323363990514, g_norm: 0.5686868612060155, lr:  0.000599, elapsed time:  160619
Step 174400, loss: 0.24315100223757327, acc: 99.52105069160461, p_norm: 2051.8601841804843, g_norm: 0.5832939723935595, lr:  0.000598, elapsed time:  160708
Step 174500, loss: 1.6955242727743463, acc: 99.50377523899078, p_norm: 2052.032576371951, g_norm: 0.4826128397631645, lr:  0.000598, elapsed time:  160795
Step 174600, loss: 0.04197456828318536, acc: 99.49374072253704, p_norm: 2052.1771881529844, g_norm: 0.5532371425027243, lr:  0.000598, elapsed time:  160885
Step 174700, loss: 0.040391078242100774, acc: 99.51079401373863, p_norm: 2052.3496446098634, g_norm: 0.5916994217085304, lr:  0.000598, elapsed time:  160975
Step 174800, loss: 0.039642487606033686, acc: 99.51913267374039, p_norm: 2052.5211668431175, g_norm: 0.6771762665673398, lr:  0.000598, elapsed time:  161065
Step 174900, loss: 0.038991032843478025, acc: 99.53280794620514, p_norm: 2052.7022941402975, g_norm: 0.5309285974714483, lr:  0.000598, elapsed time:  161156
Step 175000, loss: 0.03902197835035622, acc: 99.51846951246262, p_norm: 2052.901487736944, g_norm: 0.7117563136458905, lr:  0.000597, elapsed time:  161249
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c c 2 c ( c 1 ) C 1 ( C C 1 c 1 c c c 3 c ( - c 4 c c c ( C 5 C C N ( C ( = O ) O C ( C ) ( C ) C ) C C 5 ) c c 4 ) n [nH] c 3 c 1 ) C ( = O ) N 2 _EOS
Predicted text: C O c 1 c c c 2 c ( c 1 ) C 1 ( C C 1 c 1 c c c 3 c ( - c 4 c c c ( C 5 C C N ( C ( = O ) O C ( C ) ( C ) C ) C C 5 ) c c 4 ) n [nH] c 3 c 1 ) C ( = O ) N 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: [N-] = [N+] = N C c 1 c c c c c 1 - c 1 c c n c c 1 _EOS
Predicted text: [N-] = [N+] = N C c 1 c c c c c 1 - c 1 c c n c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( N 2 C C N ( C ( = O ) c 3 c c c ( N 4 C C O C 4 = O ) c c 3 C 3 C C 3 ) C C 2 ) c ( C ) c 1 _EOS
Predicted text: C c 1 c c c ( N 2 C C N ( C ( = O ) c 3 c c c ( N 4 C C O C 4 = O ) c c 3 C 3 C C 3 ) C C 2 ) c ( C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) N c 1 c ( C ) c c ( Cl ) c c 1 C ( = O ) O _EOS
Predicted text: C C O C ( = O ) N c 1 c ( C ) c c c c 1 C ( = O ) O _EOS _PAD _PAD _PAD
acc_token: 0.5666666666666667, acc_seq: False

Target text: C C O C ( = O ) N c 1 n c ( F ) c c c 1 C # C [Si] ( C ) ( C ) C _EOS
Predicted text: C C O C ( = O ) N c 1 n c ( F ) c c c 1 C # C [Si] ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 175000, eval acc (token): 0.9299293012280607, eval acc (sequence): 0.8696419971102906
Saving at step 175000
Step 175100, loss: 0.03922960184514523, acc: 99.50806419551373, p_norm: 2053.0715758137103, g_norm: 0.5681786548853409, lr:  0.000597, elapsed time:  161417
Step 175200, loss: 0.03863396275788546, acc: 99.51684430241585, p_norm: 2053.2246248699366, g_norm: 0.7415468313021778, lr:  0.000597, elapsed time:  161504
Step 175300, loss: 0.037857973664067686, acc: 99.53853859007359, p_norm: 2053.4070722437596, g_norm: 0.5391295389410368, lr:  0.000597, elapsed time:  161594
Step 175400, loss: 0.03898665989749134, acc: 99.50689573585987, p_norm: 2053.5967790532245, g_norm: 0.6409744731822136, lr:  0.000597, elapsed time:  161682
Step 175500, loss: 0.038500755173154176, acc: 99.51735515892506, p_norm: 2053.7851250691897, g_norm: 0.4766217886662177, lr:  0.000597, elapsed time:  161775
Step 175600, loss: 0.03848293036688119, acc: 99.52026444673538, p_norm: 2053.965845216308, g_norm: 0.7035785753637194, lr:  0.000596, elapsed time:  161863
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 175700, loss: 0.03865347080284832, acc: 99.51879493336179, p_norm: 2054.161519984535, g_norm: 0.6456209996397663, lr:  0.000596, elapsed time:  161957
Step 175800, loss: 0.038154178294353185, acc: 99.53133265674114, p_norm: 2054.3391754873846, g_norm: 0.7245236332116607, lr:  0.000596, elapsed time:  162045
Step 175900, loss: 0.037405077773146334, acc: 99.55082428455353, p_norm: 2054.5193528478953, g_norm: 0.5681215467362957, lr:  0.000596, elapsed time:  162133
Step 176000, loss: 0.0372278357995674, acc: 99.5580590069294, p_norm: 2054.6538499079657, g_norm: 0.9254172276568028, lr:  0.000596, elapsed time:  162225
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 176000, eval loss: 0.04528597587719562, eval acc: 99.46272277832031
Step 176100, loss: 0.038284872835502026, acc: 99.5253574103117, p_norm: 2054.877788717769, g_norm: 0.7844843344425406, lr:  0.000596, elapsed time:  162330
Step 176200, loss: 0.03794996567070484, acc: 99.54294119775295, p_norm: 2055.0751908356983, g_norm: 0.5915190877341338, lr:  0.000595, elapsed time:  162421
Step 176300, loss: 0.03885420715436339, acc: 99.51016688346863, p_norm: 2055.2641526123166, g_norm: 18.677942140967115, lr:  0.000595, elapsed time:  162511
Step 176400, loss: 0.04050462118349969, acc: 99.5178632736206, p_norm: 2055.4537538931936, g_norm: 0.6039132796621799, lr:  0.000595, elapsed time:  162598
Step 176500, loss: 0.04026800883468241, acc: 99.5093924999237, p_norm: 2055.676400683119, g_norm: 0.572384524867268, lr:  0.000595, elapsed time:  162688
Step 176600, loss: 0.04257811260409653, acc: 99.48228639364243, p_norm: 2055.8568436184382, g_norm: 0.5876916904396844, lr:  0.000595, elapsed time:  162776
Step 176700, loss: 0.041583670978434385, acc: 99.47335210442543, p_norm: 2056.0268144731476, g_norm: 0.6204111133147981, lr:  0.000595, elapsed time:  162869
Step 176800, loss: 0.20936051787342877, acc: 99.51419785618782, p_norm: 2056.201082645162, g_norm: 0.6997641498455365, lr:  0.000594, elapsed time:  162967
Step 176900, loss: 0.04052013128530234, acc: 99.48180900514126, p_norm: 2056.3738375148805, g_norm: 0.5663356343950723, lr:  0.000594, elapsed time:  163063
Step 177000, loss: 0.039424723256379364, acc: 99.50798453390598, p_norm: 2056.5574102768555, g_norm: 0.5546432794653077, lr:  0.000594, elapsed time:  163158
Step 177100, loss: 0.03857420971617102, acc: 99.52895085513592, p_norm: 2056.7142270943887, g_norm: 0.7051603954668446, lr:  0.000594, elapsed time:  163250
Step 177200, loss: 0.038534127068705855, acc: 99.52739748358727, p_norm: 2056.888789908025, g_norm: 0.7779151164874669, lr:  0.000594, elapsed time:  163325
Step 177300, loss: 0.038808202631771566, acc: 99.51436994969845, p_norm: 2057.0623140493162, g_norm: 0.5122288413760837, lr:  0.000594, elapsed time:  163394
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 177400, loss: 0.03795807425015913, acc: 99.53808073074588, p_norm: 2057.2231216278255, g_norm: 0.6744666291483733, lr:  0.000593, elapsed time:  163466
Step 177500, loss: 0.03808036577887833, acc: 99.52591827511787, p_norm: 2057.3903314953595, g_norm: 0.4928810433190841, lr:  0.000593, elapsed time:  163538
Step 177600, loss: 0.038433458553627134, acc: 99.51454578340054, p_norm: 2057.5715705972534, g_norm: 0.5749433845809291, lr:  0.000593, elapsed time:  163609
Step 177700, loss: 0.03773874975275248, acc: 99.53826899826527, p_norm: 2057.743381540811, g_norm: 0.7023645152951484, lr:  0.000593, elapsed time:  163699
Step 177800, loss: 0.037327117128297685, acc: 99.54496347904205, p_norm: 2057.9251564685574, g_norm: 0.6546944486314964, lr:  0.000593, elapsed time:  163792
Step 177900, loss: 0.03762226377148181, acc: 99.54164429008961, p_norm: 2058.104224773892, g_norm: 0.5193930590547783, lr:  0.000593, elapsed time:  163882
Step 178000, loss: 0.03924521032720804, acc: 99.49342343211174, p_norm: 2058.284728338509, g_norm: 0.6969302135619536, lr:  0.000592, elapsed time:  163975
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 178000, eval loss: 0.04390270363539459, eval acc: 99.50821685791016
Step 178100, loss: 0.0388385744811967, acc: 99.52285204827785, p_norm: 2058.462274379963, g_norm: 0.5533096900441989, lr:  0.000592, elapsed time:  164083
Step 178200, loss: 0.03796138407662511, acc: 99.53662896156311, p_norm: 2058.647309472076, g_norm: 0.5757295565458996, lr:  0.000592, elapsed time:  164174
Step 178300, loss: 0.038634936497546735, acc: 99.52120004594326, p_norm: 2058.8260090307663, g_norm: 0.5688239081748547, lr:  0.000592, elapsed time:  164269
Step 178400, loss: 0.03843020749744028, acc: 99.51353615522385, p_norm: 2059.019250721616, g_norm: 0.5513079314703198, lr:  0.000592, elapsed time:  164362
Step 178500, loss: 0.03825599696021527, acc: 99.52835740149021, p_norm: 2059.2071806993126, g_norm: 0.6958977883055513, lr:  0.000592, elapsed time:  164456
Step 178600, loss: 0.03811431393027306, acc: 99.52485030889511, p_norm: 2059.3663253704235, g_norm: 0.6061100132964369, lr:  0.000591, elapsed time:  164548
Step 178700, loss: 0.0381781527493149, acc: 99.52621954679489, p_norm: 2059.5428681979347, g_norm: 0.74473494990631, lr:  0.000591, elapsed time:  164641
Step 178800, loss: 0.0392343588732183, acc: 99.5068191587925, p_norm: 2059.729225222659, g_norm: 0.6205861601592478, lr:  0.000591, elapsed time:  164745
Step 178900, loss: 0.03840515010524541, acc: 99.53332532942295, p_norm: 2059.903130016593, g_norm: 0.4330873537179688, lr:  0.000591, elapsed time:  164848
Step 179000, loss: 0.038578464104793965, acc: 99.52111203968525, p_norm: 2060.0787224329492, g_norm: 0.5648914550767901, lr:  0.000591, elapsed time:  164943
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 179100, loss: 0.038265234920478876, acc: 99.52185161374695, p_norm: 2060.261966702732, g_norm: 0.45061472436183597, lr:  0.000591, elapsed time:  165031
Step 179200, loss: 0.03864467528183013, acc: 99.53891232609749, p_norm: 2060.4367313252696, g_norm: 0.8751029512037063, lr:  0.000590, elapsed time:  165121
Step 179300, loss: 0.03908208703622222, acc: 99.51766334474087, p_norm: 2060.611337648209, g_norm: 0.636524012497936, lr:  0.000590, elapsed time:  165211
Step 179400, loss: 0.03813291030935943, acc: 99.5341516584158, p_norm: 2060.7802713243523, g_norm: 0.6675327495796816, lr:  0.000590, elapsed time:  165299
Step 179500, loss: 0.03840883513446897, acc: 99.52336068451405, p_norm: 2060.965636278913, g_norm: 0.5854501508119335, lr:  0.000590, elapsed time:  165391
Step 179600, loss: 0.0375815062597394, acc: 99.54587306082249, p_norm: 2061.1358841267997, g_norm: 0.534243848595544, lr:  0.000590, elapsed time:  165483
Step 179700, loss: 0.038224170175381, acc: 99.51568403840065, p_norm: 2061.314963642493, g_norm: 0.5889693053166531, lr:  0.000590, elapsed time:  165574
Step 179800, loss: 0.03810625101905316, acc: 99.52532242238522, p_norm: 2061.4903542605734, g_norm: 0.604098092464726, lr:  0.000589, elapsed time:  165664
Step 179900, loss: 0.038184496834874154, acc: 99.52854564785957, p_norm: 2061.683947335037, g_norm: 0.8587298232356138, lr:  0.000589, elapsed time:  165753
Step 180000, loss: 0.03807433203794062, acc: 99.53288306295872, p_norm: 2061.869872468394, g_norm: 0.5224854974691955, lr:  0.000589, elapsed time:  165841
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 180000, eval loss: 0.0428539821319282, eval acc: 99.52599334716797
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) c 1 c c ( C N 2 C C C ( c 3 c n ( C c 4 c c c ( Cl ) s 4 ) c 4 c n c c c 3 4 ) C C 2 ) c c c 1 O C _EOS
Predicted text: C C O C ( = O ) c 1 c c ( C N 2 C C C ( c 3 c n ( C c 4 c c c ( Cl ) s 4 ) c 4 c n c c c 3 4 ) C C 2 ) c c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 c c ( N C ( = O ) N C C 2 C N ( C C c 3 c c c ( F ) c c 3 ) C C C 2 C C ) c c ( - c 2 n n n n 2 C ) c 1 _EOS
Predicted text: C C c 1 c c ( N C ( = O ) N C C 2 C N ( C C c 3 c c c ( F ) c c 3 ) C C C 2 C C ) c c ( - c 2 n n n n 2 C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N S ( = O ) ( = O ) c 1 c c c c ( C 2 N c 3 c c c ( C ( = O ) O C ) c c 3 C C 2 ( C ) C ) c 1 _EOS
Predicted text: C N S ( = O ) ( = O ) c 1 c c c c ( C 2 N c 3 c c c ( C ( = O ) O C ) c c 3 C C 2 ( C ) C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c c c 1 C 1 S C C ( C ( = O ) O C ( C ) ( C ) C ) N 1 C ( = O ) C N C ( = O ) N c 1 c c c c ( C C ( = O ) O ) c 1 _EOS
Predicted text: C O c 1 c c c c c 1 C 1 S C C ( C ( = O ) O C ( C ) ( C ) C ) N 1 C ( = O ) C N C ( = O ) N c 1 c c c c ( C C ( = O ) O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C C C ( O ) = N O ) c 1 c c c s 1 _EOS
Predicted text: O = C ( O ) C C C ( = N O ) c 1 c c c s 1 _EOS
acc_token: 0.7727272727272727, acc_seq: False

Evaluation (without teacher) at step 180000, eval acc (token): 0.9329641311808095, eval acc (sequence): 0.8781111489942038
Saving at step 180000
Step 180100, loss: 0.03832333720754832, acc: 99.52712099254131, p_norm: 2062.033128564783, g_norm: 0.611397797424022, lr:  0.000589, elapsed time:  166024
Step 180200, loss: 0.03898552750237286, acc: 99.50758771598339, p_norm: 2062.2171207190454, g_norm: 0.6447542963890228, lr:  0.000589, elapsed time:  166112
Step 180300, loss: 0.04216637569013983, acc: 99.52822770178318, p_norm: 2062.4055194051193, g_norm: 0.5874101850514549, lr:  0.000589, elapsed time:  166204
Step 180400, loss: 0.038496728693135085, acc: 99.52939967811108, p_norm: 2062.603244023899, g_norm: 0.5538726746328977, lr:  0.000588, elapsed time:  166292
Step 180500, loss: 0.03857482035644352, acc: 99.52424250543118, p_norm: 2062.790178452685, g_norm: 0.5389204957385213, lr:  0.000588, elapsed time:  166380
Step 180600, loss: 0.03873162540141493, acc: 99.51499727368355, p_norm: 2062.9690398079706, g_norm: 0.6651621615995212, lr:  0.000588, elapsed time:  166470
Step 180700, loss: 0.03786504096351564, acc: 99.53772646188736, p_norm: 2063.137556324902, g_norm: 0.6296110574313688, lr:  0.000588, elapsed time:  166561
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 180800, loss: 0.03796340824007543, acc: 99.53536887963612, p_norm: 2063.322677524393, g_norm: 0.5921027919366403, lr:  0.000588, elapsed time:  166652
Step 180900, loss: 0.03799581282306463, acc: 99.53455047309399, p_norm: 2063.50022461797, g_norm: 0.7192046583166034, lr:  0.000588, elapsed time:  166742
Step 181000, loss: 0.0382177267363295, acc: 99.52980940043926, p_norm: 2063.687957690375, g_norm: 0.7561895780888634, lr:  0.000587, elapsed time:  166836
Step 181100, loss: 0.03787328201346099, acc: 99.53650045394897, p_norm: 2063.8657777462, g_norm: 0.6026766595514298, lr:  0.000587, elapsed time:  166929
Step 181200, loss: 0.039422540301457046, acc: 99.50113490223885, p_norm: 2064.0680216792084, g_norm: 0.9128319819494197, lr:  0.000587, elapsed time:  167020
Step 181300, loss: 0.039088912163861095, acc: 99.53933569788933, p_norm: 2064.2238459373402, g_norm: 0.4462391179336665, lr:  0.000587, elapsed time:  167108
Step 181400, loss: 0.03979701888747513, acc: 99.50229449570179, p_norm: 2064.3808210895722, g_norm: 0.5505596624763139, lr:  0.000587, elapsed time:  167181
Step 181500, loss: 0.038405759003944696, acc: 99.53682072460651, p_norm: 2064.5605930986167, g_norm: 1.0554174979724578, lr:  0.000587, elapsed time:  167275
Step 181600, loss: 0.03857946016360074, acc: 99.53357219696045, p_norm: 2064.705080093007, g_norm: 0.6207414053154283, lr:  0.000586, elapsed time:  167365
Step 181700, loss: 0.03822683225385845, acc: 99.53939843177795, p_norm: 2064.907815135229, g_norm: 0.5936943129922877, lr:  0.000586, elapsed time:  167464
Step 181800, loss: 0.038345532496459785, acc: 99.53192307054996, p_norm: 2065.088798828995, g_norm: 0.4973635493208336, lr:  0.000586, elapsed time:  167560
Step 181900, loss: 0.03739483481738717, acc: 99.55741319060326, p_norm: 2065.245790119566, g_norm: 0.7394748019612019, lr:  0.000586, elapsed time:  167651
Step 182000, loss: 0.03785784953739494, acc: 99.54333534836769, p_norm: 2065.4190932474003, g_norm: 0.647927438919681, lr:  0.000586, elapsed time:  167745
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 182000, eval loss: 0.044763946309685713, eval acc: 99.47857666015625
Step 182100, loss: 0.03879929116461426, acc: 99.50189988315105, p_norm: 2065.595927984825, g_norm: 0.6739909294821257, lr:  0.000586, elapsed time:  167856
Step 182200, loss: 0.03839478671085089, acc: 99.51851436495781, p_norm: 2065.772876657975, g_norm: 0.7743213079778168, lr:  0.000586, elapsed time:  167952
Step 182300, loss: 0.0383790376689285, acc: 99.52421164512634, p_norm: 2065.968378755063, g_norm: 1.0286186784598517, lr:  0.000585, elapsed time:  168045
Step 182400, loss: 0.04000471562612802, acc: 99.49556322395802, p_norm: 2066.157069578587, g_norm: 0.7410217833992864, lr:  0.000585, elapsed time:  168140
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 182500, loss: 0.037768072612750024, acc: 99.53925145175262, p_norm: 2066.3260316540386, g_norm: 0.6128933621485534, lr:  0.000585, elapsed time:  168234
Step 182600, loss: 0.03802376710809767, acc: 99.53498780727386, p_norm: 2066.4913299680297, g_norm: 0.6143936314033257, lr:  0.000585, elapsed time:  168328
Step 182700, loss: 0.03717898248694837, acc: 99.5570752620697, p_norm: 2066.657303522897, g_norm: 0.7246244156868429, lr:  0.000585, elapsed time:  168423
Step 182800, loss: 0.03746856488287449, acc: 99.5368589758873, p_norm: 2066.852177416752, g_norm: 0.675761137460471, lr:  0.000585, elapsed time:  168516
Step 182900, loss: 0.03827502365689725, acc: 99.52513614296913, p_norm: 2067.027203508288, g_norm: 0.5278839028047226, lr:  0.000584, elapsed time:  168610
Step 183000, loss: 0.038089639362879096, acc: 99.52622185647488, p_norm: 2067.1961271187633, g_norm: 0.50522311902486, lr:  0.000584, elapsed time:  168704
Step 183100, loss: 0.03766134063247591, acc: 99.53274370729923, p_norm: 2067.358719663928, g_norm: 0.5760679113394793, lr:  0.000584, elapsed time:  168799
Step 183200, loss: 0.03838921754155308, acc: 99.51193556189537, p_norm: 2067.519827693355, g_norm: 0.589972946556949, lr:  0.000584, elapsed time:  168887
Step 183300, loss: 0.037263354579918084, acc: 99.55388493835926, p_norm: 2067.6844171442176, g_norm: 0.9448108504808916, lr:  0.000584, elapsed time:  168980
Step 183400, loss: 0.03738497390877456, acc: 99.55284188687801, p_norm: 2067.8515247680953, g_norm: 0.6238981826355584, lr:  0.000584, elapsed time:  169069
Step 183500, loss: 0.03776314643677324, acc: 99.5446226298809, p_norm: 2068.0297272576067, g_norm: 0.5726661732824422, lr:  0.000583, elapsed time:  169163
Step 183600, loss: 0.03875846521463245, acc: 99.515201613307, p_norm: 2068.1995896377884, g_norm: 0.5871817337668844, lr:  0.000583, elapsed time:  169257
Step 183700, loss: 0.03795122006442398, acc: 99.53140361607075, p_norm: 2068.3840206442324, g_norm: 0.4978302880289094, lr:  0.000583, elapsed time:  169357
Step 183800, loss: 0.038301033801399174, acc: 99.52014198899269, p_norm: 2068.557838543189, g_norm: 0.4953423932745312, lr:  0.000583, elapsed time:  169445
Step 183900, loss: 0.038391063562594356, acc: 99.52691259980202, p_norm: 2068.7438890621174, g_norm: 0.5474036225634952, lr:  0.000583, elapsed time:  169533
Step 184000, loss: 0.037848952673375603, acc: 99.53817436099052, p_norm: 2068.9221223038876, g_norm: 0.5812103215264378, lr:  0.000583, elapsed time:  169621
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 184000, eval loss: 0.04193903803825379, eval acc: 99.5350570678711
Step 184100, loss: 0.03882554162293673, acc: 99.50814366340637, p_norm: 2069.081823923759, g_norm: 0.5601445132559735, lr:  0.000582, elapsed time:  169727
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6823
Step 184200, loss: 0.03754881165792274, acc: 99.54615014954182, p_norm: 2069.268845036942, g_norm: 0.467181354023451, lr:  0.000582, elapsed time:  169819
Step 184300, loss: 0.036823546537198125, acc: 99.56765185296535, p_norm: 2069.43505873398, g_norm: 0.608596555158455, lr:  0.000582, elapsed time:  169912
Step 184400, loss: 0.038104442502371966, acc: 99.55049873888493, p_norm: 2069.6062535650576, g_norm: 0.6398764698921838, lr:  0.000582, elapsed time:  170000
Step 184500, loss: 0.038592121894471344, acc: 99.52412913739681, p_norm: 2069.780625577693, g_norm: 0.5036138770589901, lr:  0.000582, elapsed time:  170086
Step 184600, loss: 0.038047444270923735, acc: 99.5336524695158, p_norm: 2069.9627029365606, g_norm: 0.5646769048764071, lr:  0.000582, elapsed time:  170179
Step 184700, loss: 0.03749633188825101, acc: 99.55601325631142, p_norm: 2070.136715973772, g_norm: 0.5839231909368848, lr:  0.000582, elapsed time:  170268
Step 184800, loss: 0.03827258869539946, acc: 99.52861602604389, p_norm: 2070.3017017396915, g_norm: 0.5801509886440098, lr:  0.000581, elapsed time:  170357
Step 184900, loss: 0.03807744524441659, acc: 99.53130850195885, p_norm: 2070.4779502761085, g_norm: 0.528398545523769, lr:  0.000581, elapsed time:  170451
Step 185000, loss: 0.03752623178530484, acc: 99.54449111223221, p_norm: 2070.660373176807, g_norm: 0.9687670579389547, lr:  0.000581, elapsed time:  170551
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: N c 1 n c ( C ( = N O C c 2 c c ( = O ) c ( O ) c o 2 ) C ( = O ) N C 2 C ( = O ) N 3 C ( C ( = O ) O ) = C ( C S c 4 c c ( - c 5 c c c ( O ) c ( O ) c 5 ) n c 5 c c n n 4 5 ) C S C 2 3 ) c s 1 _EOS
Predicted text: N c 1 n c ( C ( = N O C c 2 c c ( = O ) c ( O ) c o 2 ) C ( = O ) N C 2 C ( = O ) N 3 C ( C ( = O ) O ) = C ( C S c 4 c c ( - c 5 c c c ( O ) c ( O ) c 5 ) n c 5 c c n n 4 5 ) C S C 2 3 ) c s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c ( - c 2 c c c ( Cl ) c c 2 Cl ) c ( C C ) n c 1 N C 1 c 2 c c ( O C ) c c c 2 C C 1 C C _EOS
Predicted text: C C c 1 n c ( - c 2 c c c ( Cl ) c c 2 Cl ) c ( C C ) n c 1 N C 1 c 2 c c ( O C ) c c c 2 C C 1 C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c ( O C ) c ( N C ( = O ) N 2 C C N ( c 3 c c ( O C ) c ( O C ) c ( O C ) c 3 ) C C 2 ) c c 1 C ( = O ) N C ( C ) C ( = O ) N c 1 c c ( C O ) c c ( N c 2 c 3 c c c c c 3 n c 3 c c c c c 2 3 ) c 1 _EOS
Predicted text: C C c 1 n c ( O C ) c ( N C ( = O ) N 2 C C N ( c 3 c c ( O C ) c ( O C ) c ( O C ) c 3 ) C C 2 ) c c 1 C ( = O ) N C ( C ) C ( = O ) N c 1 c c ( C O ) c c ( N c 2 c 3 c c c c c 3 n c 3 c c c c c 2 3 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C N ( c 2 c [nH] c 3 n c c c c 2 3 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C N ( c 2 c [nH] c 3 n c c c c 2 3 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) C ( = O ) N 1 C C c 2 c ( [nH] c 3 c c c c c 2 3 ) C 1 _EOS
Predicted text: C C ( C ) ( C ) C ( = O ) N 1 C C c 2 c ( [nH] c 3 c c c c c 2 3 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 185000, eval acc (token): 0.9291791830828907, eval acc (sequence): 0.8700917431192661
Saving at step 185000
Step 185100, loss: 0.03948871954344213, acc: 99.49803301692009, p_norm: 2070.8521588418325, g_norm: 0.5862514299604846, lr:  0.000581, elapsed time:  170735
Step 185200, loss: 0.038276235139928755, acc: 99.53019660711288, p_norm: 2071.0211026751094, g_norm: 0.556484021907288, lr:  0.000581, elapsed time:  170825
Step 185300, loss: 0.03791741932276636, acc: 99.53648795187473, p_norm: 2071.1936958908577, g_norm: 0.7774990231419191, lr:  0.000581, elapsed time:  170916
Step 185400, loss: 0.03855567965190858, acc: 99.5200294405222, p_norm: 2071.371707904096, g_norm: 0.8440306628561168, lr:  0.000580, elapsed time:  171004
Step 185500, loss: 0.03767561748623848, acc: 99.54341021180153, p_norm: 2071.5425959906793, g_norm: 0.579305991200461, lr:  0.000580, elapsed time:  171095
Step 185600, loss: 0.037375480434857306, acc: 99.55181708931923, p_norm: 2071.700534872551, g_norm: 0.6018890387748416, lr:  0.000580, elapsed time:  171188
Step 185700, loss: 0.037626089840196074, acc: 99.54703103005886, p_norm: 2071.8752337584174, g_norm: 0.5718505364548734, lr:  0.000580, elapsed time:  171278
Step 185800, loss: 0.03740136338863522, acc: 99.54664640128613, p_norm: 2072.0480352002432, g_norm: 0.6552993184768391, lr:  0.000580, elapsed time:  171369
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 185900, loss: 0.0371071050595261, acc: 99.55757591623822, p_norm: 2072.224747425747, g_norm: 0.48518020252540045, lr:  0.000580, elapsed time:  171461
Step 186000, loss: 0.037172596203163266, acc: 99.5507809817791, p_norm: 2072.388262592166, g_norm: 0.3832568111958049, lr:  0.000580, elapsed time:  171559
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 186000, eval loss: 0.04779975922778247, eval acc: 99.40923309326172
Step 186100, loss: 0.03834906657692045, acc: 99.53125277161598, p_norm: 2072.5668587242126, g_norm: 0.6444521789867813, lr:  0.000579, elapsed time:  171663
Step 186200, loss: 0.03775726002641022, acc: 99.555489808321, p_norm: 2072.726424636814, g_norm: 0.6022736090765018, lr:  0.000579, elapsed time:  171753
Step 186300, loss: 0.03784886815585196, acc: 99.53998810052872, p_norm: 2072.889858849931, g_norm: 0.5779926007426295, lr:  0.000579, elapsed time:  171842
Step 186400, loss: 0.03724604564253241, acc: 99.56020835042, p_norm: 2073.0363870286787, g_norm: 0.45804933163893496, lr:  0.000579, elapsed time:  171930
Step 186500, loss: 0.037307969289831815, acc: 99.54495584964752, p_norm: 2073.1990352290177, g_norm: 0.4827332303094152, lr:  0.000579, elapsed time:  172017
Step 186600, loss: 0.03762628849595785, acc: 99.53624653816223, p_norm: 2073.3863257924345, g_norm: 0.5829641089565755, lr:  0.000579, elapsed time:  172109
Step 186700, loss: 0.038512028967961666, acc: 99.54629376530647, p_norm: 2073.568193111539, g_norm: 0.7710855662602655, lr:  0.000578, elapsed time:  172199
Step 186800, loss: 0.03934255656786263, acc: 99.51855850219727, p_norm: 2073.7365482611785, g_norm: 0.7132282145747845, lr:  0.000578, elapsed time:  172290
Step 186900, loss: 0.03866081043612212, acc: 99.52762846648693, p_norm: 2073.9034088866983, g_norm: 0.6264818912888337, lr:  0.000578, elapsed time:  172379
Step 187000, loss: 0.03850676110945642, acc: 99.51560290157795, p_norm: 2074.066356532851, g_norm: 0.5370873882169821, lr:  0.000578, elapsed time:  172469
Step 187100, loss: 0.038028411245904864, acc: 99.52836784720421, p_norm: 2074.238830919647, g_norm: 0.5904646747824476, lr:  0.000578, elapsed time:  172557
Step 187200, loss: 0.038066993919201195, acc: 99.54578860104084, p_norm: 2074.421353921462, g_norm: 0.7071096090303802, lr:  0.000578, elapsed time:  172654
Step 187300, loss: 0.038251511440612375, acc: 99.52679024636745, p_norm: 2074.5941439778117, g_norm: 0.5602607038693412, lr:  0.000577, elapsed time:  172745
Step 187400, loss: 0.03834953546058387, acc: 99.52519941329956, p_norm: 2074.771993782135, g_norm: 0.611757114503229, lr:  0.000577, elapsed time:  172831
Step 187500, loss: 0.037608562237583104, acc: 99.53940545022488, p_norm: 2074.941737535606, g_norm: 0.6378010768976193, lr:  0.000577, elapsed time:  172924
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 187600, loss: 0.038087041609488406, acc: 99.53239280591828, p_norm: 2075.119144764178, g_norm: 0.5432292335089196, lr:  0.000577, elapsed time:  173016
Step 187700, loss: 0.037930560102686285, acc: 99.52863037586212, p_norm: 2075.2845081458368, g_norm: 0.6619480369468291, lr:  0.000577, elapsed time:  173101
Step 187800, loss: 0.03709916561376304, acc: 99.55132818222046, p_norm: 2075.4598729580757, g_norm: 0.6130434073982052, lr:  0.000577, elapsed time:  173193
Step 187900, loss: 0.03651091509498656, acc: 99.5735754519701, p_norm: 2075.6287102787996, g_norm: 0.632249771280806, lr:  0.000577, elapsed time:  173286
Step 188000, loss: 0.037970451209694146, acc: 99.53382954001427, p_norm: 2075.809908774763, g_norm: 0.5833257455071462, lr:  0.000576, elapsed time:  173376
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 188000, eval loss: 0.04279538925737145, eval acc: 99.51571655273438
Step 188100, loss: 0.037801927807740866, acc: 99.53293047845364, p_norm: 2075.9828214401005, g_norm: 0.5347655022781558, lr:  0.000576, elapsed time:  173481
Step 188200, loss: 0.03776961037889123, acc: 99.5391049683094, p_norm: 2076.1455608538085, g_norm: 0.5517091392589363, lr:  0.000576, elapsed time:  173570
Step 188300, loss: 0.0375194787280634, acc: 99.54091264307499, p_norm: 2076.3063746172334, g_norm: 0.5735683311919919, lr:  0.000576, elapsed time:  173661
Step 188400, loss: 0.03745305445510894, acc: 99.54323732852936, p_norm: 2076.459169242885, g_norm: 0.5683205814764277, lr:  0.000576, elapsed time:  173751
Step 188500, loss: 0.0373734423937276, acc: 99.5382652580738, p_norm: 2076.625564948307, g_norm: 0.6043704935540467, lr:  0.000576, elapsed time:  173850
Step 188600, loss: 0.03770670257974416, acc: 99.53935638070107, p_norm: 2076.8027913738542, g_norm: 0.61133930307447, lr:  0.000575, elapsed time:  173942
Step 188700, loss: 0.03790334742050618, acc: 99.53917622566223, p_norm: 2076.965154256739, g_norm: 0.5631491072627564, lr:  0.000575, elapsed time:  174030
Step 188800, loss: 0.03711966140661389, acc: 99.5596529841423, p_norm: 2077.121399417482, g_norm: 0.6742852595595626, lr:  0.000575, elapsed time:  174121
Step 188900, loss: 0.03840199813246727, acc: 99.51948256790638, p_norm: 2077.2984406877777, g_norm: 0.7232639186888654, lr:  0.000575, elapsed time:  174210
Step 189000, loss: 0.037151038968004285, acc: 99.55782768130302, p_norm: 2077.4669294934974, g_norm: 0.483365617282524, lr:  0.000575, elapsed time:  174304
Step 189100, loss: 0.03775278462097049, acc: 99.53662626445293, p_norm: 2077.6432386173383, g_norm: 0.5062293050706974, lr:  0.000575, elapsed time:  174393
Step 189200, loss: 0.0375737567897886, acc: 99.54884895682335, p_norm: 2077.8197586238252, g_norm: 0.5099296843100711, lr:  0.000575, elapsed time:  174489
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6822
Step 189300, loss: 0.037986869574813335, acc: 99.5323570875021, p_norm: 2077.9984576088327, g_norm: 0.5594063401979609, lr:  0.000574, elapsed time:  174579
Step 189400, loss: 0.03711768557783216, acc: 99.55571919679642, p_norm: 2078.1570751106547, g_norm: 0.49230160556999597, lr:  0.000574, elapsed time:  174669
Step 189500, loss: 0.03759075720794499, acc: 99.54093167185783, p_norm: 2078.3225868154354, g_norm: 0.6441068562997307, lr:  0.000574, elapsed time:  174757
Step 189600, loss: 0.03745245663449168, acc: 99.54614019393921, p_norm: 2078.495431480638, g_norm: 0.6390068324805425, lr:  0.000574, elapsed time:  174849
Step 189700, loss: 0.037065244587138294, acc: 99.55111302435398, p_norm: 2078.671688420884, g_norm: 0.5396308431374478, lr:  0.000574, elapsed time:  174936
Step 189800, loss: 0.03747400920372456, acc: 99.54842753708363, p_norm: 2078.862664360425, g_norm: 0.6386293144547832, lr:  0.000574, elapsed time:  175026
Step 189900, loss: 0.039267564523033795, acc: 99.54376266896725, p_norm: 2079.039763162868, g_norm: 0.5844178354059834, lr:  0.000574, elapsed time:  175116
Step 190000, loss: 0.04454010310582816, acc: 99.53098674118519, p_norm: 2079.2239445986916, g_norm: 0.5561428388556529, lr:  0.000573, elapsed time:  175211
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 190000, eval loss: 0.0461310040950775, eval acc: 99.476806640625
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: Cl _EOS
Predicted text: C C ( C ) ( C ) N 1 C C ( [N+] ( = O ) [O-] ) ( [N+] ( = O ) [O-] ) C 1 _EOS
acc_token: 0.0, acc_seq: False

Target text: C O C ( = O ) c 1 c c c c ( C ( = O ) N S ( C ) ( = O ) = O ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c c ( C ( = O ) N S ( C ) ( = O ) = O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) C ( N C ( = O ) O C c 1 c c c c c 1 ) C ( = O ) N 1 C C 2 C C 1 C N 2 C ( = O ) c 1 c c c ( - c 2 c c c c c 2 ) c n 1 _EOS
Predicted text: C C ( C ) ( C ) C ( N C ( = O ) O C c 1 c c c c c 1 ) C ( = O ) N 1 C C 2 C C 1 C N 2 C ( = O ) c 1 c c c ( - c 2 c c c c c 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C ) c ( B 2 O C ( C ) ( C ) C ( C ) ( C ) O 2 ) c ( C O C C ( = O ) O C ( C ) ( C ) C ) c 1 _EOS
Predicted text: C O c 1 c c ( C ) c ( B 2 O C ( C ) ( C ) C ( C ) ( C ) O 2 ) c ( C O C C ( = O ) O C ( C ) ( C ) C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c c c 1 C = C 1 C C c 2 c 1 o c 1 c c c ( C ( = O ) O ) c c 1 c 2 = O _EOS
Predicted text: C O c 1 c c c c c 1 C = C 1 C C c 2 c 1 o c 1 c c c ( C ( = O ) O ) c c 1 c 2 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 190000, eval acc (token): 0.9346630022324799, eval acc (sequence): 0.8775546790964504
Saving at step 190000
Step 190100, loss: 0.039118545134551826, acc: 99.51526835560799, p_norm: 2079.3868288987715, g_norm: 0.6961578020418218, lr:  0.000573, elapsed time:  175399
Step 190200, loss: 0.03766299471724779, acc: 99.54877743124962, p_norm: 2079.548307587195, g_norm: 0.481562323002958, lr:  0.000573, elapsed time:  175490
Step 190300, loss: 0.038434972134418786, acc: 99.522106975317, p_norm: 2079.7133540854475, g_norm: 0.5197985779883484, lr:  0.000573, elapsed time:  175585
Step 190400, loss: 0.03752823281101882, acc: 99.55126650631428, p_norm: 2079.877141705074, g_norm: 0.6111624135754288, lr:  0.000573, elapsed time:  175675
Step 190500, loss: 0.037362061198800804, acc: 99.55859181284904, p_norm: 2080.0304428574773, g_norm: 0.5680402647816889, lr:  0.000573, elapsed time:  175768
Step 190600, loss: 0.03816049843095243, acc: 99.54527375102043, p_norm: 2080.207096723092, g_norm: 2.656686208501793, lr:  0.000572, elapsed time:  175866
Step 190700, loss: 0.03822659926023334, acc: 99.53118331730366, p_norm: 2080.3798257864532, g_norm: 0.6616767040649796, lr:  0.000572, elapsed time:  175957
Step 190800, loss: 0.03821179590653628, acc: 99.53329539299011, p_norm: 2080.5402976308756, g_norm: 0.707576714715831, lr:  0.000572, elapsed time:  176046
Step 190900, loss: 0.03766554561443627, acc: 99.54131883382797, p_norm: 2080.719290025535, g_norm: 0.5020398217007409, lr:  0.000572, elapsed time:  176137
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 191000, loss: 0.03761553896396463, acc: 99.54468917787372, p_norm: 2080.8844798946957, g_norm: 0.4639906158744915, lr:  0.000572, elapsed time:  176231
Step 191100, loss: 0.03731801958754659, acc: 99.55161887407303, p_norm: 2081.0340080660876, g_norm: 0.5295013965495116, lr:  0.000572, elapsed time:  176319
Step 191200, loss: 0.036789840012788774, acc: 99.56827318668365, p_norm: 2081.1858633091483, g_norm: 0.3796902469542649, lr:  0.000572, elapsed time:  176412
Step 191300, loss: 0.03722165631130338, acc: 99.55348494648933, p_norm: 2081.367426527337, g_norm: 0.7287844934769513, lr:  0.000571, elapsed time:  176500
Step 191400, loss: 0.036834439379163086, acc: 99.56966179609299, p_norm: 2081.5237866274765, g_norm: 1.2054023479318836, lr:  0.000571, elapsed time:  176589
Step 191500, loss: 0.038460527150891724, acc: 99.52020165324211, p_norm: 2081.7031613104787, g_norm: 0.5604736152506519, lr:  0.000571, elapsed time:  176682
Step 191600, loss: 0.03783949050121009, acc: 99.5365922152996, p_norm: 2081.873015468222, g_norm: 0.7935927745599146, lr:  0.000571, elapsed time:  176772
Step 191700, loss: 0.03857003235258162, acc: 99.52525095641613, p_norm: 2082.03897099081, g_norm: 0.8456883015989853, lr:  0.000571, elapsed time:  176864
Step 191800, loss: 0.038091652048751715, acc: 99.55202120542526, p_norm: 2082.220007622747, g_norm: 0.6840436415153507, lr:  0.000571, elapsed time:  176955
Step 191900, loss: 0.0378653410775587, acc: 99.55105745792389, p_norm: 2082.3806642517857, g_norm: 0.521982153359714, lr:  0.000571, elapsed time:  177045
Step 192000, loss: 0.037887649023905394, acc: 99.54075674712658, p_norm: 2082.530102923864, g_norm: 0.6359568785948337, lr:  0.000570, elapsed time:  177134
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 192000, eval loss: 0.043797510471194984, eval acc: 99.50511169433594
Step 192100, loss: 0.0376701835449785, acc: 99.55281119048595, p_norm: 2082.715018855014, g_norm: 0.7936997432721238, lr:  0.000570, elapsed time:  177240
Step 192200, loss: 0.037811570628546176, acc: 99.54191912710667, p_norm: 2082.8777826640744, g_norm: 0.450747993395287, lr:  0.000570, elapsed time:  177328
Step 192300, loss: 0.03804507415741682, acc: 99.5502640902996, p_norm: 2083.0329551407167, g_norm: 0.7379404881105281, lr:  0.000570, elapsed time:  177416
Step 192400, loss: 0.037376909120939675, acc: 99.5527565330267, p_norm: 2083.180433055769, g_norm: 0.5374101152563197, lr:  0.000570, elapsed time:  177506
Step 192500, loss: 0.0373488048883155, acc: 99.54947105050087, p_norm: 2083.3618632714865, g_norm: 0.4506774571607598, lr:  0.000570, elapsed time:  177596
Step 192600, loss: 0.03832599795889109, acc: 99.52575619518757, p_norm: 2083.524491445402, g_norm: 0.540353370363405, lr:  0.000569, elapsed time:  177682
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 192700, loss: 0.038586989888430234, acc: 99.53788538180774, p_norm: 2083.709544443209, g_norm: 0.6827947899002297, lr:  0.000569, elapsed time:  177772
Step 192800, loss: 0.03780345655512065, acc: 99.55629172921181, p_norm: 2083.855824126083, g_norm: 0.6872809936463394, lr:  0.000569, elapsed time:  177860
Step 192900, loss: 0.0377149261534214, acc: 99.56194253265858, p_norm: 2084.020361560171, g_norm: 0.5534972434833142, lr:  0.000569, elapsed time:  177950
Step 193000, loss: 0.037426666328683494, acc: 99.55336211621761, p_norm: 2084.177647749881, g_norm: 0.5950007879630036, lr:  0.000569, elapsed time:  178038
Step 193100, loss: 0.03753149978816509, acc: 99.55630205571651, p_norm: 2084.3383181495333, g_norm: 0.5344585177985244, lr:  0.000569, elapsed time:  178126
Step 193200, loss: 0.03754411090631038, acc: 99.54921621084213, p_norm: 2084.503497953237, g_norm: 0.3778326999085217, lr:  0.000569, elapsed time:  178213
Step 193300, loss: 0.037201436585746706, acc: 99.55698397755623, p_norm: 2084.6586699685545, g_norm: 0.4698855272790268, lr:  0.000568, elapsed time:  178303
Step 193400, loss: 0.03741250094026327, acc: 99.55216102302074, p_norm: 2084.8309390248705, g_norm: 0.4384499888886531, lr:  0.000568, elapsed time:  178395
Step 193500, loss: 0.0375846037035808, acc: 99.54248750209808, p_norm: 2085.001960947282, g_norm: 0.4668528699007359, lr:  0.000568, elapsed time:  178486
Step 193600, loss: 0.03783540779259056, acc: 99.53048393130302, p_norm: 2085.169541539292, g_norm: 0.5194676268528315, lr:  0.000568, elapsed time:  178575
Step 193700, loss: 0.03828112609684467, acc: 99.53162491321564, p_norm: 2085.3396150127014, g_norm: 0.5432843401217128, lr:  0.000568, elapsed time:  178663
Step 193800, loss: 0.037441908176988364, acc: 99.560766980052, p_norm: 2085.5012734272577, g_norm: 0.8032061135728431, lr:  0.000568, elapsed time:  178754
Step 193900, loss: 0.03728552237153053, acc: 99.5474852770567, p_norm: 2085.6749403523754, g_norm: 0.7758719450235497, lr:  0.000568, elapsed time:  178847
Step 194000, loss: 0.038128827014006675, acc: 99.53366504609585, p_norm: 2085.8321095454926, g_norm: 0.4770193563692755, lr:  0.000567, elapsed time:  178934
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 194000, eval loss: 0.043496317695826285, eval acc: 99.5009765625
Step 194100, loss: 0.03810641932301223, acc: 99.53711080551147, p_norm: 2086.0010170676564, g_norm: 0.7384441330504542, lr:  0.000567, elapsed time:  179036
Step 194200, loss: 0.03764206538908184, acc: 99.54794199764729, p_norm: 2086.167764449163, g_norm: 0.6216346018675591, lr:  0.000567, elapsed time:  179130
Step 194300, loss: 0.03936343575362116, acc: 99.53823022544384, p_norm: 2086.372427316618, g_norm: 0.6098343261511093, lr:  0.000567, elapsed time:  179222
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 194400, loss: 0.038327807653232, acc: 99.54795904123961, p_norm: 2086.532898878608, g_norm: 0.4835427449027313, lr:  0.000567, elapsed time:  179315
Step 194500, loss: 0.03820378249976784, acc: 99.53600244224072, p_norm: 2086.685272456078, g_norm: 0.5387370604280555, lr:  0.000567, elapsed time:  179404
Step 194600, loss: 0.037879002108238635, acc: 99.54790863394737, p_norm: 2086.8452666579624, g_norm: 0.6106809014962772, lr:  0.000567, elapsed time:  179494
Step 194700, loss: 0.038183182906359435, acc: 99.55855213105679, p_norm: 2086.9737218281284, g_norm: 0.8441054701696327, lr:  0.000566, elapsed time:  179584
Step 194800, loss: 0.03767122169025242, acc: 99.55936428904533, p_norm: 2087.1423366194904, g_norm: 0.5474934202005938, lr:  0.000566, elapsed time:  179673
Step 194900, loss: 0.038444556440226735, acc: 99.52782873809338, p_norm: 2087.318061933335, g_norm: 0.505921921858961, lr:  0.000566, elapsed time:  179758
Step 195000, loss: 0.03732715716585517, acc: 99.55426876246929, p_norm: 2087.469331944107, g_norm: 0.5879125235113595, lr:  0.000566, elapsed time:  179850
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Target text: C = C C O C ( = O ) C C C ( N C ( = O ) N c 1 c c c ( C O C ( = O ) O c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 ) c c 1 ) C ( = O ) O C C = C _EOS
Predicted text: C = C C O C ( = O ) C C C ( N C ( = O ) N c 1 c c c ( C O C ( = O ) O c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 ) c c 1 ) C ( = O ) O C C = C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( Br ) c 1 c c ( - c 2 n c c ( C ( F ) ( F ) F ) c c 2 Cl ) n 2 n c n c 2 n 1 _EOS
Predicted text: C C c 1 n c 2 n c n n 2 c ( - c 2 n c c ( C ( F ) ( F ) F ) c c 2 Cl ) c 1 Br _EOS _PAD _PAD
acc_token: 0.14634146341463414, acc_seq: False

Target text: C C C C [Sn] ( C C C C ) ( C C C C ) c 1 c n ( - c 2 n c ( C ) c c ( - c 3 c c c ( Cl ) c c 3 ) n 2 ) c n 1 _EOS
Predicted text: C C C C [Sn] ( C C C C ) ( C C C C ) c 1 c n ( - c 2 n c ( C ) c c ( - c 3 c c c ( Cl ) c c 3 ) n 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( O c 1 n c c n 1 - c 1 c c c ( O C C ( F ) ( F ) C ( F ) F ) c c 1 ) C 1 ( c 2 c c c ( F ) c c 2 F ) C O 1 _EOS
Predicted text: C C ( n 1 c c n ( - c 2 c c c ( O C C ( F ) ( F ) C ( F ) F ) c c 2 ) c 1 = O ) C 1 ( c 2 c c c ( F ) c c 2 F ) C O 1 _EOS
acc_token: 0.14035087719298245, acc_seq: False

Target text: O = C 1 C C ( C ( F ) ( F ) F ) C C ( = O ) N 1 c 1 c c ( O S ( = O ) ( = O ) c 2 c c c c c 2 ) c ( Cl ) c c 1 F _EOS
Predicted text: O = C 1 C C ( C ( F ) ( F ) F ) C C ( = O ) N 1 c 1 c c ( O S ( = O ) ( = O ) c 2 c c c c c 2 ) c ( Cl ) c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 195000, eval acc (token): 0.9337942441845911, eval acc (sequence): 0.8772868484639282
Saving at step 195000
Step 195100, loss: 0.03714506897609681, acc: 99.56042295694351, p_norm: 2087.6525255998677, g_norm: 0.5637557336175884, lr:  0.000566, elapsed time:  180022
Step 195200, loss: 0.03749793065711856, acc: 99.55117861926556, p_norm: 2087.8146262456976, g_norm: 0.5496891159199389, lr:  0.000566, elapsed time:  180109
Step 195300, loss: 0.03760959565639496, acc: 99.54498790204525, p_norm: 2087.9821804991693, g_norm: 0.6491968908253997, lr:  0.000566, elapsed time:  180201
Step 195400, loss: 0.037036346043460074, acc: 99.5618007928133, p_norm: 2088.132597674953, g_norm: 0.41847446457388837, lr:  0.000565, elapsed time:  180291
Step 195500, loss: 0.03644003053195775, acc: 99.57212606072426, p_norm: 2088.2809907852647, g_norm: 0.6810612722038717, lr:  0.000565, elapsed time:  180380
Step 195600, loss: 0.03815814159810543, acc: 99.52624422311783, p_norm: 2088.462248162724, g_norm: 0.7058854072790917, lr:  0.000565, elapsed time:  180465
Step 195700, loss: 0.0380421611526981, acc: 99.52932442724705, p_norm: 2088.6349369089958, g_norm: 0.5385415992470565, lr:  0.000565, elapsed time:  180557
Step 195800, loss: 0.037359824245795606, acc: 99.54762053489685, p_norm: 2088.800888817979, g_norm: 0.4739216907042296, lr:  0.000565, elapsed time:  180647
Step 195900, loss: 0.037922207349911335, acc: 99.53972125053406, p_norm: 2088.958770822644, g_norm: 0.625636755494434, lr:  0.000565, elapsed time:  180738
Step 196000, loss: 0.03747430534567684, acc: 99.54754835367203, p_norm: 2089.132494623124, g_norm: 0.7466713711325759, lr:  0.000565, elapsed time:  180828
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 196000, eval loss: 0.04449772534891963, eval acc: 99.48694610595703
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 196100, loss: 0.03662180522021221, acc: 99.56626733440665, p_norm: 2089.2754355550023, g_norm: 0.4908942161135552, lr:  0.000564, elapsed time:  180936
Step 196200, loss: 0.03645587807986885, acc: 99.57575869560242, p_norm: 2089.4274364119688, g_norm: 0.5356860824077968, lr:  0.000564, elapsed time:  181025
Step 196300, loss: 0.03672100817319006, acc: 99.56998178362846, p_norm: 2089.5620683940865, g_norm: 0.6040113209780746, lr:  0.000564, elapsed time:  181113
Step 196400, loss: 0.03648580195847899, acc: 99.57226805388927, p_norm: 2089.72889907882, g_norm: 0.49178456604635185, lr:  0.000564, elapsed time:  181204
Step 196500, loss: 0.03683230714872479, acc: 99.5555956363678, p_norm: 2089.8987039748426, g_norm: 0.5179442600440765, lr:  0.000564, elapsed time:  181298
Step 196600, loss: 0.036898940009996294, acc: 99.55308635532856, p_norm: 2090.0595213006463, g_norm: 0.6700189543788202, lr:  0.000564, elapsed time:  181388
Step 196700, loss: 0.03672557447571308, acc: 99.5756658911705, p_norm: 2090.2268691245895, g_norm: 0.617021020804848, lr:  0.000564, elapsed time:  181477
Step 196800, loss: 0.03801612670533359, acc: 99.53741250932217, p_norm: 2090.388186730566, g_norm: 0.5205611642191792, lr:  0.000563, elapsed time:  181565
Step 196900, loss: 0.03796197372023016, acc: 99.53032706677914, p_norm: 2090.55381358891, g_norm: 0.6787623143785576, lr:  0.000563, elapsed time:  181653
Step 197000, loss: 0.03803020674735308, acc: 99.54352103173733, p_norm: 2090.7319709239223, g_norm: 0.7319007466010619, lr:  0.000563, elapsed time:  181741
Step 197100, loss: 0.03736754917073995, acc: 99.56550480425358, p_norm: 2090.897590569151, g_norm: 0.5338666875667245, lr:  0.000563, elapsed time:  181832
Step 197200, loss: 0.03696822312660515, acc: 99.55716516077518, p_norm: 2091.044467371866, g_norm: 0.5052583520437135, lr:  0.000563, elapsed time:  181920
Step 197300, loss: 0.03702261651866138, acc: 99.5584764033556, p_norm: 2091.220546560177, g_norm: 0.5848630498164387, lr:  0.000563, elapsed time:  182012
Step 197400, loss: 0.03751741852611303, acc: 99.54457347095013, p_norm: 2091.3919875732095, g_norm: 0.6729315064662125, lr:  0.000563, elapsed time:  182101
Step 197500, loss: 0.037806087154895064, acc: 99.54000754654408, p_norm: 2091.563290360461, g_norm: 0.8285114917367572, lr:  0.000562, elapsed time:  182191
Step 197600, loss: 0.037906330949626865, acc: 99.53401143848896, p_norm: 2091.741753137945, g_norm: 0.6226650229925915, lr:  0.000562, elapsed time:  182280
Step 197700, loss: 0.03695131602697074, acc: 99.56398469209671, p_norm: 2091.9115555459957, g_norm: 0.6172962784580068, lr:  0.000562, elapsed time:  182373
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 197800, loss: 0.037334113693784546, acc: 99.55643090065892, p_norm: 2092.0657641644098, g_norm: 0.5797977051412074, lr:  0.000562, elapsed time:  182462
Step 197900, loss: 0.036987298619933426, acc: 99.55049233138561, p_norm: 2092.2154505475664, g_norm: 0.5886031851685465, lr:  0.000562, elapsed time:  182551
Step 198000, loss: 0.0374797568609938, acc: 99.55326929688454, p_norm: 2092.384543357649, g_norm: 0.5682076628268784, lr:  0.000562, elapsed time:  182641
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 198000, eval loss: 0.046515695806592726, eval acc: 99.45061492919922
Step 198100, loss: 0.036706615248695014, acc: 99.57095389068127, p_norm: 2092.535425768033, g_norm: 0.6243328329832262, lr:  0.000562, elapsed time:  182745
Step 198200, loss: 0.03620770539157093, acc: 99.58026376366615, p_norm: 2092.6811046468033, g_norm: 0.6607839188294526, lr:  0.000561, elapsed time:  182838
Step 198300, loss: 0.037604715013876557, acc: 99.53991214931011, p_norm: 2092.834898540671, g_norm: 0.5391839490421274, lr:  0.000561, elapsed time:  182927
Step 198400, loss: 0.03751704490277916, acc: 99.54470171034336, p_norm: 2093.0025914424737, g_norm: 0.5549917082659551, lr:  0.000561, elapsed time:  183017
Step 198500, loss: 0.03669639647938311, acc: 99.56019280850887, p_norm: 2093.1594277785093, g_norm: 0.46120739423157625, lr:  0.000561, elapsed time:  183108
Step 198600, loss: 0.037207841109484434, acc: 99.55090780556202, p_norm: 2093.321152763568, g_norm: 0.534693106931354, lr:  0.000561, elapsed time:  183199
Step 198700, loss: 0.0364467806648463, acc: 99.58398920297623, p_norm: 2093.4561134718897, g_norm: 0.5023475503364733, lr:  0.000561, elapsed time:  183287
Step 198800, loss: 0.03732849126216024, acc: 99.54899033904076, p_norm: 2093.6011374368522, g_norm: 0.7105403123961305, lr:  0.000561, elapsed time:  183375
Step 198900, loss: 0.03688777978066355, acc: 99.56308163702488, p_norm: 2093.7563526929634, g_norm: 0.7000070385625051, lr:  0.000560, elapsed time:  183465
Step 199000, loss: 0.03691657726187259, acc: 99.56922006607056, p_norm: 2093.9165260997374, g_norm: 0.858287617218895, lr:  0.000560, elapsed time:  183555
Step 199100, loss: 0.037721141120418904, acc: 99.5359403938055, p_norm: 2094.0652452167424, g_norm: 0.7442573448125037, lr:  0.000560, elapsed time:  183643
Step 199200, loss: 0.03732665027491748, acc: 99.55537739396095, p_norm: 2094.22750240056, g_norm: 0.847713101375367, lr:  0.000560, elapsed time:  183732
Step 199300, loss: 0.03733544029761106, acc: 99.54652923345566, p_norm: 2094.3837852296915, g_norm: 0.5143042281699006, lr:  0.000560, elapsed time:  183823
Step 199400, loss: 0.03756114014890045, acc: 99.54780238866806, p_norm: 2094.550040998768, g_norm: 0.6731262023171997, lr:  0.000560, elapsed time:  183913
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 199500, loss: 0.038243303958224895, acc: 99.53134064343077, p_norm: 2094.740501573773, g_norm: 0.5120147442436465, lr:  0.000560, elapsed time:  184002
Step 199600, loss: 0.03696542553603649, acc: 99.57095348834991, p_norm: 2094.891582206789, g_norm: 0.6067865544794298, lr:  0.000559, elapsed time:  184093
Step 199700, loss: 0.03633373075630516, acc: 99.5846336632967, p_norm: 2095.0624011561385, g_norm: 0.7948716337230315, lr:  0.000559, elapsed time:  184184
Step 199800, loss: 0.03791812347713858, acc: 99.53907498717308, p_norm: 2095.2094329420343, g_norm: 0.6842688058520352, lr:  0.000559, elapsed time:  184273
Step 199900, loss: 0.03745754826348275, acc: 99.55429884791374, p_norm: 2095.390168660335, g_norm: 0.561610662272176, lr:  0.000559, elapsed time:  184361
Step 200000, loss: 0.036661767764016986, acc: 99.56896226108074, p_norm: 2095.5478782736536, g_norm: 0.6699267411966932, lr:  0.000559, elapsed time:  184451
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 200000, eval loss: 0.04476198868826032, eval acc: 99.47325897216797
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: N c 1 n c n n 2 c ( C C N 3 C C O C C 3 ) c c ( - c 3 c c c ( N C ( = O ) N c 4 c c ( C ( F ) ( F ) F ) c c c 4 F ) c ( F ) c 3 ) c 1 2 _EOS
Predicted text: N c 1 n c n n 2 c ( C C N 3 C C O C C 3 ) c c ( - c 3 c c c ( N C ( = O ) N c 4 c c ( C ( F ) ( F ) F ) c c c 4 F ) c ( F ) c 3 ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c 2 c ( C 3 C C C C C 3 ) c 3 n ( c 2 c 1 ) C C ( C O ) C O c 1 c c c c c 1 - 3 _EOS
Predicted text: C O C ( = O ) c 1 c c c 2 c ( C 3 C C C C C 3 ) c 3 n ( c 2 c 1 ) C C ( C O ) C O c 1 c c c c c 1 - 3 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C ( C ) c 1 n n ( C C ( = O ) O C C ) c ( C ) c 1 Cl _EOS
Predicted text: C = C ( C ) c 1 n n ( C C ( = O ) O C C ) c ( C ) c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C C 1 C C c 2 c c ( N C ( C ) = O ) c c c 2 O 1 _EOS
Predicted text: C C O C ( = O ) C C 1 C C c 2 c c ( N C ( C ) = O ) c c c 2 O 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N ( C C ) C ( = O ) C C C c 1 c c ( - c 2 c c c c c 2 ) n c 2 c c c c c 1 2 _EOS
Predicted text: C C N ( C C ) C ( = O ) C C C c 1 c c ( - c 2 c c c c c 2 ) n c 2 c c c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 200000, eval acc (token): 0.9391249095421339, eval acc (sequence): 0.8854205607476635
Saving at step 200000
Step 200100, loss: 0.03789592450018972, acc: 99.53873881697655, p_norm: 2095.710116921185, g_norm: 0.5561348015020188, lr:  0.000559, elapsed time:  184639
Step 200200, loss: 0.03696603299118578, acc: 99.5620900541544, p_norm: 2095.871291519395, g_norm: 0.6423801157633293, lr:  0.000559, elapsed time:  184730
Step 200300, loss: 0.036758464807644484, acc: 99.56157450377941, p_norm: 2096.0156764076164, g_norm: 0.7039093784560049, lr:  0.000558, elapsed time:  184823
Step 200400, loss: 0.037258893442340194, acc: 99.55232129991055, p_norm: 2096.1937975861847, g_norm: 0.6608755462049667, lr:  0.000558, elapsed time:  184914
Step 200500, loss: 0.037385964575223626, acc: 99.54382400214672, p_norm: 2096.349011590916, g_norm: 0.8126263879290301, lr:  0.000558, elapsed time:  185001
Step 200600, loss: 0.03791671358048916, acc: 99.53357987105846, p_norm: 2096.508305952188, g_norm: 0.5707988322078574, lr:  0.000558, elapsed time:  185092
Step 200700, loss: 0.036172436107881366, acc: 99.5870520323515, p_norm: 2096.6424802687757, g_norm: 0.7628303740269526, lr:  0.000558, elapsed time:  185184
Step 200800, loss: 0.0365436135744676, acc: 99.56496924161911, p_norm: 2096.80357594951, g_norm: 0.5031939298264826, lr:  0.000558, elapsed time:  185273
Step 200900, loss: 0.03697194785345346, acc: 99.56044861674309, p_norm: 2096.9668602645957, g_norm: 0.7460337453796515, lr:  0.000558, elapsed time:  185364
Step 201000, loss: 0.038476108741015196, acc: 99.52226835489273, p_norm: 2097.135626497752, g_norm: 0.593912137742126, lr:  0.000557, elapsed time:  185452
Step 201100, loss: 0.03776936254929751, acc: 99.5387894809246, p_norm: 2097.2754576887005, g_norm: 0.39968368384695285, lr:  0.000557, elapsed time:  185540
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 201200, loss: 0.036931540974168564, acc: 99.56121051281913, p_norm: 2097.4441349903796, g_norm: 0.5383670323484707, lr:  0.000557, elapsed time:  185629
Step 201300, loss: 0.0360331682022661, acc: 99.58785329759121, p_norm: 2097.5954036804587, g_norm: 0.5440290748255822, lr:  0.000557, elapsed time:  185720
Step 201400, loss: 0.03568615023978054, acc: 99.59908492863178, p_norm: 2097.7413121493364, g_norm: 0.6188344406839381, lr:  0.000557, elapsed time:  185815
Step 201500, loss: 0.03792089473921806, acc: 99.55974362790585, p_norm: 2097.9026393473796, g_norm: 0.5111426560086583, lr:  0.000557, elapsed time:  185906
Step 201600, loss: 0.03723104432690889, acc: 99.58440406620502, p_norm: 2098.0463052833793, g_norm: 0.7439715604447286, lr:  0.000557, elapsed time:  186006
Step 201700, loss: 0.03759042723570019, acc: 99.56802016496658, p_norm: 2098.19484514105, g_norm: 0.5421863820302291, lr:  0.000556, elapsed time:  186093
Step 201800, loss: 0.03841118290554732, acc: 99.54661867022514, p_norm: 2098.3699692079736, g_norm: 0.5294527136576904, lr:  0.000556, elapsed time:  186183
Step 201900, loss: 0.038448891253210604, acc: 99.53451511263847, p_norm: 2098.513407538957, g_norm: 0.5488734670981146, lr:  0.000556, elapsed time:  186270
Step 202000, loss: 0.037072179075330496, acc: 99.56894026696682, p_norm: 2098.661274272641, g_norm: 0.5557840350852388, lr:  0.000556, elapsed time:  186360
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 202000, eval loss: 0.04331052171066402, eval acc: 99.508544921875
Step 202100, loss: 0.03729644008912146, acc: 99.56439456343651, p_norm: 2098.8218687083877, g_norm: 0.5149856425023945, lr:  0.000556, elapsed time:  186470
Step 202200, loss: 0.03670350665226579, acc: 99.56954301893711, p_norm: 2098.9519144324577, g_norm: 0.6843766938461702, lr:  0.000556, elapsed time:  186560
Step 202300, loss: 0.03691302726045251, acc: 99.55622485280037, p_norm: 2099.109825757326, g_norm: 0.5727663591871571, lr:  0.000556, elapsed time:  186650
Step 202400, loss: 0.037555281668901444, acc: 99.54439552128315, p_norm: 2099.2728226654453, g_norm: 0.6213190406658867, lr:  0.000556, elapsed time:  186741
Step 202500, loss: 0.03711785254534334, acc: 99.55882167816162, p_norm: 2099.4309934653534, g_norm: 0.6597528281389565, lr:  0.000555, elapsed time:  186832
Step 202600, loss: 0.03726484385784715, acc: 99.54939858615398, p_norm: 2099.583664725681, g_norm: 0.6582112320027025, lr:  0.000555, elapsed time:  186922
Step 202700, loss: 0.03820637425407767, acc: 99.53311567008495, p_norm: 2099.740503066824, g_norm: 0.5957860095752266, lr:  0.000555, elapsed time:  187010
Step 202800, loss: 0.036997144371271135, acc: 99.55859951674938, p_norm: 2099.8922069525556, g_norm: 0.5577597031251947, lr:  0.000555, elapsed time:  187101
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 202900, loss: 0.037357063853082524, acc: 99.54911229332387, p_norm: 2100.0607024685637, g_norm: 0.8141253038676897, lr:  0.000555, elapsed time:  187194
Step 203000, loss: 0.0366896751197055, acc: 99.57102656364441, p_norm: 2100.2288409108287, g_norm: 0.5926265305413319, lr:  0.000555, elapsed time:  187284
Step 203100, loss: 0.037294526104815304, acc: 99.54532000422478, p_norm: 2100.401329895745, g_norm: 0.5743702737206426, lr:  0.000555, elapsed time:  187373
Step 203200, loss: 0.03617912902031094, acc: 99.58114355802536, p_norm: 2100.5408932799573, g_norm: 1.5228466635144928, lr:  0.000554, elapsed time:  187463
Step 203300, loss: 0.03662429017014802, acc: 99.56988516449928, p_norm: 2100.720368013676, g_norm: 0.75645447096966, lr:  0.000554, elapsed time:  187553
Step 203400, loss: 0.036695292154327035, acc: 99.56388422846794, p_norm: 2100.866049230594, g_norm: 0.6468943888035661, lr:  0.000554, elapsed time:  187643
Step 203500, loss: 0.036975761144422, acc: 99.56356784701347, p_norm: 2101.011640369141, g_norm: 0.5156996164990361, lr:  0.000554, elapsed time:  187735
Step 203600, loss: 0.03642063504084945, acc: 99.5722579061985, p_norm: 2101.1602687381674, g_norm: 0.7357092721701192, lr:  0.000554, elapsed time:  187822
Step 203700, loss: 0.0373595961695537, acc: 99.56957334280014, p_norm: 2101.302185547095, g_norm: 0.46480075818916883, lr:  0.000554, elapsed time:  187912
Step 203800, loss: 0.03763760436791927, acc: 99.55612978339195, p_norm: 2101.460131629738, g_norm: 0.6297156522208165, lr:  0.000554, elapsed time:  188004
Step 203900, loss: 0.037423547990620136, acc: 99.55241100490093, p_norm: 2101.597768550911, g_norm: 0.6441438078293258, lr:  0.000553, elapsed time:  188093
Step 204000, loss: 0.037381632141768935, acc: 99.55896219611168, p_norm: 2101.743914329965, g_norm: 0.6871436814460783, lr:  0.000553, elapsed time:  188180
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 204000, eval loss: 0.047769015412777636, eval acc: 99.41328430175781
Step 204100, loss: 0.0365813916688785, acc: 99.57509158551693, p_norm: 2101.9022657311402, g_norm: 0.547904746251204, lr:  0.000553, elapsed time:  188285
Step 204200, loss: 0.036825243667699396, acc: 99.56430307030678, p_norm: 2102.0587992029514, g_norm: 0.5804311117986976, lr:  0.000553, elapsed time:  188373
Step 204300, loss: 0.03718965864274651, acc: 99.55692349374294, p_norm: 2102.2023615379267, g_norm: 0.5766280606312425, lr:  0.000553, elapsed time:  188461
Step 204400, loss: 0.03759452186990529, acc: 99.54589965939522, p_norm: 2102.383566622655, g_norm: 0.923143077802772, lr:  0.000553, elapsed time:  188553
Step 204500, loss: 0.03775974138174206, acc: 99.54214860498905, p_norm: 2102.544386423901, g_norm: 0.6073853238931547, lr:  0.000553, elapsed time:  188641
Step 204600, loss: 0.0380249299434945, acc: 99.54038459062576, p_norm: 2102.7027492156244, g_norm: 0.6230955100026887, lr:  0.000553, elapsed time:  188734
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 204700, loss: 0.037376529645757106, acc: 99.55367555393475, p_norm: 2102.8643937367588, g_norm: 0.6824832002390593, lr:  0.000552, elapsed time:  188823
Step 204800, loss: 0.03660964947193861, acc: 99.5896446108818, p_norm: 2102.996856695512, g_norm: 0.4997798817011571, lr:  0.000552, elapsed time:  188915
Step 204900, loss: 0.03886279602535069, acc: 99.54166249930859, p_norm: 2103.1437507276323, g_norm: 0.5477597451210868, lr:  0.000552, elapsed time:  189000
Step 205000, loss: 0.037291537341661754, acc: 99.58045995235443, p_norm: 2103.292331252138, g_norm: 0.5709077529608304, lr:  0.000552, elapsed time:  189089
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Target text: C C ( C ) C ( = O ) N c 1 n [nH] c 2 c n c ( - c 3 c c c c ( F ) c 3 F ) c c 1 2 _EOS
Predicted text: C C ( C ) C ( = O ) N c 1 n [nH] c 2 c n c ( - c 3 c c c c ( F ) c 3 F ) c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C ( C ) ( C ) C C C C C ( = O ) C C C C ( C ) ( C ) C ( = O ) O _EOS
Predicted text: C C O C ( = O ) C ( C ) ( C ) C C C C C ( = O ) C C C C ( C ) ( C ) C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C O c 1 c c c ( C C N S ( = O ) ( = O ) c 2 c c c c c 2 ) c c 1 [N+] ( = O ) [O-] _EOS
Predicted text: O = C ( O ) C O c 1 c c c ( C C N S ( = O ) ( = O ) c 2 c c c c c 2 ) c c 1 [N+] ( = O ) [O-] _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C O c 1 c c c 2 c c ( - c 3 c c 4 c c n n 4 c ( N c 4 c c c ( N C ( = O ) c 5 c c c ( C N C ( = O ) O C ( C ) ( C ) C ) c c 5 ) c c 4 ) n 3 ) c c c 2 c 1 _EOS
Predicted text: C O C C O c 1 c c c 2 c c ( - c 3 c c 4 c c n n 4 c ( N c 4 c c c ( N C ( = O ) c 5 c c c ( C N C ( = O ) O C ( C ) ( C ) C ) c c 5 ) c c 4 ) n 3 ) c c c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N 1 C C C ( C ( = O ) N 2 C C ( S ( = O ) ( = O ) c 3 c c c c c 3 Cl ) C C 2 C ( = O ) N C 2 ( C # N ) C C 2 ) C C 1 _EOS
Predicted text: C N 1 C C C ( C ( = O ) N 2 C C ( S ( = O ) ( = O ) c 3 c c c c c 3 Cl ) C C 2 C ( = O ) N C 2 ( C # N ) C C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 205000, eval acc (token): 0.9303536746096741, eval acc (sequence): 0.8731084776663628
Saving at step 205000
Step 205100, loss: 0.03802039300091565, acc: 99.54215689003468, p_norm: 2103.440394274226, g_norm: 1.127630052125633, lr:  0.000552, elapsed time:  189262
Step 205200, loss: 0.036588975386694075, acc: 99.5686471760273, p_norm: 2103.585309385042, g_norm: 0.5975616227993308, lr:  0.000552, elapsed time:  189354
Step 205300, loss: 0.03655653468798846, acc: 99.57660479843616, p_norm: 2103.7403809727903, g_norm: 0.8087650377245753, lr:  0.000552, elapsed time:  189443
Step 205400, loss: 0.03656308487989009, acc: 99.5732057094574, p_norm: 2103.8931495407546, g_norm: 0.6960125219096266, lr:  0.000551, elapsed time:  189533
Step 205500, loss: 0.036511489944532516, acc: 99.57082512974739, p_norm: 2104.0327823145167, g_norm: 0.6608745578543346, lr:  0.000551, elapsed time:  189622
Step 205600, loss: 0.036331443069502714, acc: 99.57126571238041, p_norm: 2104.179207844579, g_norm: 0.6325626922501477, lr:  0.000551, elapsed time:  189714
Step 205700, loss: 0.037209834717214105, acc: 99.54988831281662, p_norm: 2104.338502044185, g_norm: 0.4801500829095013, lr:  0.000551, elapsed time:  189805
Step 205800, loss: 0.03711122637614608, acc: 99.55415181815624, p_norm: 2104.500436030189, g_norm: 0.5976087484618446, lr:  0.000551, elapsed time:  189893
Step 205900, loss: 0.03744698359165341, acc: 99.5476476252079, p_norm: 2104.659975799254, g_norm: 0.6398937099672308, lr:  0.000551, elapsed time:  189984
Step 206000, loss: 0.03725018259137869, acc: 99.55099798738956, p_norm: 2104.824322445978, g_norm: 0.6348116199264858, lr:  0.000551, elapsed time:  190075
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 206000, eval loss: 0.045628354735672456, eval acc: 99.44108581542969
Step 206100, loss: 0.036854066532105205, acc: 99.56167642772198, p_norm: 2104.98885958195, g_norm: 0.561142011495386, lr:  0.000551, elapsed time:  190181
Step 206200, loss: 0.03620917757973075, acc: 99.57937702536583, p_norm: 2105.1355751290093, g_norm: 1.0606100581217035, lr:  0.000550, elapsed time:  190272
Step 206300, loss: 0.038149584750644866, acc: 99.5370978564024, p_norm: 2105.291321213336, g_norm: 0.5760257488324945, lr:  0.000550, elapsed time:  190360
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 206400, loss: 0.03641844881392682, acc: 99.57633298724446, p_norm: 2105.4339506675874, g_norm: 0.6034612045134401, lr:  0.000550, elapsed time:  190449
Step 206500, loss: 0.03596348636317998, acc: 99.59869016706944, p_norm: 2105.5983483766145, g_norm: 0.7323821399831866, lr:  0.000550, elapsed time:  190543
Step 206600, loss: 0.03615026345476508, acc: 99.58356672525406, p_norm: 2105.7388999914588, g_norm: 0.5892176591877271, lr:  0.000550, elapsed time:  190634
Step 206700, loss: 0.03635329492390156, acc: 99.57735148072243, p_norm: 2105.873208732499, g_norm: 0.5815461087991861, lr:  0.000550, elapsed time:  190723
Step 206800, loss: 0.03655005587264895, acc: 99.57828518748283, p_norm: 2106.0240864610696, g_norm: 0.5538907255384269, lr:  0.000550, elapsed time:  190812
Step 206900, loss: 0.03719330697786063, acc: 99.55766293406487, p_norm: 2106.1783727168877, g_norm: 0.5561998318684583, lr:  0.000549, elapsed time:  190899
Step 207000, loss: 0.03641923074610531, acc: 99.57039538025856, p_norm: 2106.3217608495006, g_norm: 0.723991622937994, lr:  0.000549, elapsed time:  190989
Step 207100, loss: 0.03697823096998036, acc: 99.56236732006073, p_norm: 2106.469537019076, g_norm: 0.5499178584461425, lr:  0.000549, elapsed time:  191080
Step 207200, loss: 0.037074143253266814, acc: 99.56612139940262, p_norm: 2106.649829627134, g_norm: 1.0491892973118173, lr:  0.000549, elapsed time:  191167
Step 207300, loss: 0.03716438314411789, acc: 99.56185099482536, p_norm: 2106.7946875632483, g_norm: 1.0319239687037334, lr:  0.000549, elapsed time:  191256
Step 207400, loss: 0.03748927056789398, acc: 99.54447722434998, p_norm: 2106.945618088104, g_norm: 0.5820638381548229, lr:  0.000549, elapsed time:  191346
Step 207500, loss: 0.037915314571000634, acc: 99.53192695975304, p_norm: 2107.1097410079424, g_norm: 0.9356274814694764, lr:  0.000549, elapsed time:  191436
Step 207600, loss: 0.03696274966467172, acc: 99.55972598493099, p_norm: 2107.269017768334, g_norm: 0.4354160469014001, lr:  0.000549, elapsed time:  191526
Step 207700, loss: 0.036868099514395, acc: 99.55895592272282, p_norm: 2107.4030079949484, g_norm: 0.6048075840418599, lr:  0.000548, elapsed time:  191615
Step 207800, loss: 0.037285100501030684, acc: 99.54552771151066, p_norm: 2107.5493241232325, g_norm: 0.7892833595162989, lr:  0.000548, elapsed time:  191713
Step 207900, loss: 0.03681437318213284, acc: 99.56142465770245, p_norm: 2107.7098476987235, g_norm: 0.7120719320355092, lr:  0.000548, elapsed time:  191804
Step 208000, loss: 0.03638724885415286, acc: 99.57791881263256, p_norm: 2107.8571572980322, g_norm: 0.6218038880379978, lr:  0.000548, elapsed time:  191902
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 208000, eval loss: 0.04362897558137773, eval acc: 99.49688720703125
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 208100, loss: 0.036039757341257396, acc: 99.5896756944822, p_norm: 2107.9940706661714, g_norm: 0.6200357381429602, lr:  0.000548, elapsed time:  192015
Step 208200, loss: 0.03709490220993757, acc: 99.55263839662075, p_norm: 2108.1525600884875, g_norm: 0.5234091077355729, lr:  0.000548, elapsed time:  192108
Step 208300, loss: 0.036482047853060064, acc: 99.56998334825039, p_norm: 2108.3013259277795, g_norm: 0.6098473124106725, lr:  0.000548, elapsed time:  192204
Step 208400, loss: 0.03635706037282944, acc: 99.57891884446144, p_norm: 2108.456395778944, g_norm: 0.43983115106162174, lr:  0.000547, elapsed time:  192298
Step 208500, loss: 0.03623960309661925, acc: 99.58345687389374, p_norm: 2108.598556514159, g_norm: 0.5808649278185439, lr:  0.000547, elapsed time:  192388
Step 208600, loss: 0.03588327050674707, acc: 99.58317446708679, p_norm: 2108.734711785109, g_norm: 0.6478708811428382, lr:  0.000547, elapsed time:  192480
Step 208700, loss: 0.036562095819972454, acc: 99.5748587846756, p_norm: 2108.8876913131216, g_norm: 0.738279524277961, lr:  0.000547, elapsed time:  192570
Step 208800, loss: 0.036366864051669834, acc: 99.57852955162525, p_norm: 2109.042063528011, g_norm: 0.5813850679940381, lr:  0.000547, elapsed time:  192666
Step 208900, loss: 0.03636098282411695, acc: 99.57760421931744, p_norm: 2109.19211367718, g_norm: 0.5316536138457165, lr:  0.000547, elapsed time:  192761
Step 209000, loss: 0.036049089403823016, acc: 99.5913067907095, p_norm: 2109.335104595969, g_norm: 0.5527768370755919, lr:  0.000547, elapsed time:  192852
Step 209100, loss: 0.036371168377809224, acc: 99.57948143780231, p_norm: 2109.4982805977584, g_norm: 0.5571638713093504, lr:  0.000547, elapsed time:  192942
Step 209200, loss: 0.03684553813189268, acc: 99.55984291434288, p_norm: 2109.6532439071702, g_norm: 0.5981560671697649, lr:  0.000546, elapsed time:  193030
Step 209300, loss: 0.03657433060463518, acc: 99.5738682448864, p_norm: 2109.789871738247, g_norm: 0.7713153204383189, lr:  0.000546, elapsed time:  193118
Step 209400, loss: 0.037082269797101615, acc: 99.56421598792076, p_norm: 2109.9742996604537, g_norm: 0.5359798393896574, lr:  0.000546, elapsed time:  193209
Step 209500, loss: 0.037702650036662816, acc: 99.54400090873241, p_norm: 2110.122035720677, g_norm: 0.6338262336379944, lr:  0.000546, elapsed time:  193296
Step 209600, loss: 0.037781187086366116, acc: 99.54225441813469, p_norm: 2110.2625467472517, g_norm: 0.8436294308696496, lr:  0.000546, elapsed time:  193386
Step 209700, loss: 0.037695980831049386, acc: 99.52926649153233, p_norm: 2110.4128062047453, g_norm: 0.47250720585561623, lr:  0.000546, elapsed time:  193474
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 209800, loss: 0.03593158928524915, acc: 99.59341957610535, p_norm: 2110.5600650578044, g_norm: 0.5438225363539908, lr:  0.000546, elapsed time:  193566
Step 209900, loss: 0.036023295572958886, acc: 99.58848245441914, p_norm: 2110.6899128087375, g_norm: 0.5008135922738417, lr:  0.000546, elapsed time:  193656
Step 210000, loss: 0.036796486442908644, acc: 99.55506505072117, p_norm: 2110.8386105918617, g_norm: 0.5903582131287403, lr:  0.000545, elapsed time:  193746
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 210000, eval loss: 0.043620127867907296, eval acc: 99.49644470214844
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C = C c 1 s c ( N C ( = O ) O C ( C ) ( C ) C ) n c 1 C ( = O ) O C P ( = O ) ( O C C ) O C C _EOS
Predicted text: C = C c 1 s c ( N C ( = O ) O C ( C ) ( C ) C ) n c 1 C ( = O ) O C P ( = O ) ( O C C ) O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C c 1 n c ( C O C ) n ( C c 2 c c c c c 2 ) c ( = O ) c 1 C c 1 c c c ( - c 2 c c c c c 2 C # N ) c c 1 _EOS
Predicted text: C C C C c 1 n c ( C O C ) n ( C c 2 c c c c c 2 ) c ( = O ) c 1 C c 1 c c c ( - c 2 c c c c c 2 C # N ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C O c 1 c c c ( S c 2 c c ( C # C C O C ) c c ( O C C C N 3 C C O C C 3 ) c 2 ) c c 1 Cl _EOS
Predicted text: C C O C ( = O ) C O c 1 c c c ( S c 2 c c ( C # C C O C ) c c ( O C C C N 3 C C O C C 3 ) c 2 ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( C c 2 c c c ( O C ( F ) ( F ) F ) c c 2 ) C ( = O ) N ( c 2 c c ( Cl ) c c ( Cl ) c 2 ) c 2 n c c ( S ( = O ) ( = O ) N 3 C C C C 3 C ( = O ) N C C O ) n 2 1 _EOS
Predicted text: C C 1 ( C c 2 c c c ( O C ( F ) ( F ) F ) c c 2 ) C ( = O ) N ( c 2 c c ( Cl ) c c ( Cl ) c 2 ) c 2 n c c ( S ( = O ) ( = O ) N 3 C C C C 3 C ( = O ) N C C O ) n 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N c 1 c c c ( C 2 3 C C 2 C ( = O ) N ( C ) C 3 = O ) c c 1 _EOS
Predicted text: C C ( = O ) N c 1 c c c ( C 2 3 C C 2 C ( = O ) N ( C ) C 3 = O ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 210000, eval acc (token): 0.9342037839133065, eval acc (sequence): 0.8748455428067079
Saving at step 210000
Step 210100, loss: 0.03687602447345853, acc: 99.56172733008862, p_norm: 2110.9952222782254, g_norm: 0.6325649880827771, lr:  0.000545, elapsed time:  193934
Step 210200, loss: 0.03703728288412094, acc: 99.55769108235836, p_norm: 2111.136598084783, g_norm: 0.6884198332384097, lr:  0.000545, elapsed time:  194025
Step 210300, loss: 0.03694725139066577, acc: 99.5617029517889, p_norm: 2111.2855935118346, g_norm: 0.6655799162585085, lr:  0.000545, elapsed time:  194117
Step 210400, loss: 0.03603987119160593, acc: 99.58980277180672, p_norm: 2111.4377457209366, g_norm: 0.674252278394606, lr:  0.000545, elapsed time:  194214
Step 210500, loss: 0.03628574334084988, acc: 99.57581439614296, p_norm: 2111.577220946988, g_norm: 0.6644805092808587, lr:  0.000545, elapsed time:  194304
Step 210600, loss: 0.035988894584588704, acc: 99.586873665452, p_norm: 2111.7225975702327, g_norm: 0.6998614957992518, lr:  0.000545, elapsed time:  194394
Step 210700, loss: 0.036514198710210624, acc: 99.58247898519039, p_norm: 2111.874953520343, g_norm: 0.6813184051645503, lr:  0.000544, elapsed time:  194485
Step 210800, loss: 0.03633392238523811, acc: 99.5753124654293, p_norm: 2112.025411854664, g_norm: 0.6983159719334094, lr:  0.000544, elapsed time:  194578
Step 210900, loss: 0.03657335955183953, acc: 99.57132822275162, p_norm: 2112.174059520558, g_norm: 0.5473123462827671, lr:  0.000544, elapsed time:  194670
Step 211000, loss: 0.03681008899118751, acc: 99.56967176496983, p_norm: 2112.3265013586015, g_norm: 0.5362761437606097, lr:  0.000544, elapsed time:  194758
Step 211100, loss: 0.03727890915237367, acc: 99.55098913609982, p_norm: 2112.4787794506988, g_norm: 0.5492625251893056, lr:  0.000544, elapsed time:  194852
Step 211200, loss: 0.03727601399179548, acc: 99.5561693906784, p_norm: 2112.627134235238, g_norm: 0.5043380679807068, lr:  0.000544, elapsed time:  194943
Step 211300, loss: 0.03763507783412933, acc: 99.54177936911583, p_norm: 2112.788184157753, g_norm: 0.49252359838280474, lr:  0.000544, elapsed time:  195035
Step 211400, loss: 0.03637755708768964, acc: 99.58702419698238, p_norm: 2112.9398555954017, g_norm: 0.5473991759989205, lr:  0.000544, elapsed time:  195125
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6823
Step 211500, loss: 0.03642679544318255, acc: 99.5759849808648, p_norm: 2113.0956162754965, g_norm: 0.5472970055410017, lr:  0.000543, elapsed time:  195199
Step 211600, loss: 0.03606597411911935, acc: 99.58355762064457, p_norm: 2113.231706176577, g_norm: 0.5975707581797784, lr:  0.000543, elapsed time:  195267
Step 211700, loss: 0.03684420747682452, acc: 99.55848576128483, p_norm: 2113.3759903862415, g_norm: 0.607817202897993, lr:  0.000543, elapsed time:  195352
Step 211800, loss: 0.03623529660049826, acc: 99.57811649143696, p_norm: 2113.5525216273077, g_norm: 0.5091279750759504, lr:  0.000543, elapsed time:  195442
Step 211900, loss: 0.03670286217704415, acc: 99.57468330860138, p_norm: 2113.7145946910837, g_norm: 0.7284419877815672, lr:  0.000543, elapsed time:  195531
Step 212000, loss: 0.03651783108711243, acc: 99.57095140218735, p_norm: 2113.858746284317, g_norm: 0.5623620409439165, lr:  0.000543, elapsed time:  195622
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 212000, eval loss: 0.047746247351169606, eval acc: 99.43946075439453
Step 212100, loss: 0.03604950322303921, acc: 99.58485142886639, p_norm: 2114.005709984185, g_norm: 0.5659016695792078, lr:  0.000543, elapsed time:  195727
Step 212200, loss: 0.03574818828608841, acc: 99.58406563103199, p_norm: 2114.151475430847, g_norm: 0.6719640807740648, lr:  0.000543, elapsed time:  195818
Step 212300, loss: 0.0368335580220446, acc: 99.5609654635191, p_norm: 2114.2916611804067, g_norm: 0.7098277249584062, lr:  0.000542, elapsed time:  195906
Step 212400, loss: 0.036169304912909865, acc: 99.5822526216507, p_norm: 2114.4551078324644, g_norm: 0.5295029916924523, lr:  0.000542, elapsed time:  196001
Step 212500, loss: 0.03702338129747659, acc: 99.55688536167145, p_norm: 2114.612235476799, g_norm: 0.6179887172614941, lr:  0.000542, elapsed time:  196090
Step 212600, loss: 0.03725542651955038, acc: 99.56017382442951, p_norm: 2114.7478234866003, g_norm: 0.6596249794694816, lr:  0.000542, elapsed time:  196182
Step 212700, loss: 0.03690755901858211, acc: 99.5678488612175, p_norm: 2114.8969578384094, g_norm: 0.7598932900665041, lr:  0.000542, elapsed time:  196278
Step 212800, loss: 0.03678734339773655, acc: 99.56472662091255, p_norm: 2115.043091644869, g_norm: 0.6768956730060798, lr:  0.000542, elapsed time:  196369
Step 212900, loss: 0.03637696787249297, acc: 99.57594338059425, p_norm: 2115.1877732776366, g_norm: 0.7530139360121753, lr:  0.000542, elapsed time:  196462
Step 213000, loss: 0.03568566971458495, acc: 99.59922358393669, p_norm: 2115.3391064313737, g_norm: 0.5883201210074268, lr:  0.000542, elapsed time:  196558
Step 213100, loss: 0.03617704376578331, acc: 99.58478520810604, p_norm: 2115.513256970721, g_norm: 0.5564583975561243, lr:  0.000541, elapsed time:  196655
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 213200, loss: 0.036498663286047596, acc: 99.5757448022478, p_norm: 2115.629094196038, g_norm: 0.5823244281068831, lr:  0.000541, elapsed time:  196745
Step 213300, loss: 0.03611537515651435, acc: 99.59763105213642, p_norm: 2115.76850028883, g_norm: 0.6674531483508638, lr:  0.000541, elapsed time:  196834
Step 213400, loss: 0.0363254304882139, acc: 99.5997717231512, p_norm: 2115.913457875499, g_norm: 0.5634237321036608, lr:  0.000541, elapsed time:  196923
Step 213500, loss: 0.03662389895413071, acc: 99.59209629893303, p_norm: 2116.060764589614, g_norm: 0.422812233825482, lr:  0.000541, elapsed time:  197017
Step 213600, loss: 0.03644665514118969, acc: 99.59376014769077, p_norm: 2116.209886552026, g_norm: 0.5904040053784707, lr:  0.000541, elapsed time:  197111
Step 213700, loss: 0.03705068520735949, acc: 99.5675776898861, p_norm: 2116.3542545502028, g_norm: 0.6369320528722451, lr:  0.000541, elapsed time:  197203
Step 213800, loss: 0.03699808535631746, acc: 99.56861591339111, p_norm: 2116.505503420488, g_norm: 0.6187734806950673, lr:  0.000541, elapsed time:  197292
Step 213900, loss: 0.03719960081391036, acc: 99.55245165526867, p_norm: 2116.646615721994, g_norm: 0.6445515034164345, lr:  0.000540, elapsed time:  197380
Step 214000, loss: 0.03645184602122754, acc: 99.57931503653526, p_norm: 2116.8001170530515, g_norm: 0.5767689791319384, lr:  0.000540, elapsed time:  197471
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 214000, eval loss: 0.04510827684774994, eval acc: 99.45372009277344
Step 214100, loss: 0.03680873460136354, acc: 99.56083992123604, p_norm: 2116.947579006575, g_norm: 0.4736060607450183, lr:  0.000540, elapsed time:  197574
Step 214200, loss: 0.037644852930679915, acc: 99.53599426150322, p_norm: 2117.1023788886278, g_norm: 0.6622644917987428, lr:  0.000540, elapsed time:  197670
Step 214300, loss: 0.03619016167707741, acc: 99.58961769938469, p_norm: 2117.277723714898, g_norm: 0.7703705416599939, lr:  0.000540, elapsed time:  197764
Step 214400, loss: 0.03666349138133228, acc: 99.56863443553448, p_norm: 2117.4251147789014, g_norm: 0.6882370108973718, lr:  0.000540, elapsed time:  197857
Step 214500, loss: 0.036325264032930134, acc: 99.5732735991478, p_norm: 2117.5624096153156, g_norm: 0.6075298268108167, lr:  0.000540, elapsed time:  197948
Step 214600, loss: 0.03693608716130257, acc: 99.55665364861488, p_norm: 2117.7100644074976, g_norm: 0.5533766120394575, lr:  0.000540, elapsed time:  198037
Step 214700, loss: 0.03663516906090081, acc: 99.5598673671484, p_norm: 2117.8572459775737, g_norm: 0.5809684303889897, lr:  0.000539, elapsed time:  198130
Step 214800, loss: 0.03655807654839009, acc: 99.56517739593983, p_norm: 2118.0005457563902, g_norm: 0.5436826702345647, lr:  0.000539, elapsed time:  198229
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 214900, loss: 0.03627193139041241, acc: 99.57917823423794, p_norm: 2118.1497300648184, g_norm: 0.6256717800439102, lr:  0.000539, elapsed time:  198321
Step 215000, loss: 0.03595237113069743, acc: 99.5886603295803, p_norm: 2118.29292754121, g_norm: 1.0465513374248778, lr:  0.000539, elapsed time:  198414
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: [N-] = [N+] = N c 1 c c c ( C ( = O ) N C c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: [N-] = [N+] = N c 1 c c c ( C ( = O ) N C c 2 c c c c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C O c 1 c c c ( - c 2 s c 3 c c ( O C c 4 c c c c c 4 ) c c c 3 c 2 C c 2 c c c ( C N 3 C C C C 3 ) c ( O C ) c 2 ) c c 1 ) N C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C O C ( = O ) C ( C O c 1 c c c ( - c 2 s c 3 c c ( O C c 4 c c c c c 4 ) c c c 3 c 2 C c 2 c c c ( C N 3 C C C C 3 ) c ( O C ) c 2 ) c c 1 ) N C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n o c ( C ) c 1 C O _EOS
Predicted text: C c 1 n o c ( C ) c 1 C O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) c 1 c c c ( C C ( = O ) N C ( C ) c 2 c c c ( N C C ( F ) ( F ) F ) c n 2 ) c c 1 _EOS
Predicted text: C C ( C ) c 1 c c c ( C C ( = O ) N C ( C ) c 2 c c c ( N C C ( F ) ( F ) F ) c n 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C C n 1 c n c 2 c c ( - c 3 n c 4 c c c ( C 5 ( c 6 c c c c c 6 ) C C 5 ) n c 4 s 3 ) c c c 2 1 _EOS
Predicted text: C C O C ( = O ) C C n 1 c n c 2 c c ( - c 3 n c 4 c c c ( C 5 ( c 6 c c c c c 6 ) C C 5 ) n c 4 s 3 ) c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 215000, eval acc (token): 0.9308564561947191, eval acc (sequence): 0.876663254861822
Saving at step 215000
Step 215100, loss: 0.03609591926448047, acc: 99.59344138205051, p_norm: 2118.4261925073047, g_norm: 0.5940234594914594, lr:  0.000539, elapsed time:  198595
Step 215200, loss: 0.03583156478125602, acc: 99.58359952270985, p_norm: 2118.5737897720323, g_norm: 0.5558054708149377, lr:  0.000539, elapsed time:  198670
Step 215300, loss: 0.03609278411604464, acc: 99.57452477514744, p_norm: 2118.7143007017335, g_norm: 0.5997974261858597, lr:  0.000539, elapsed time:  198761
Step 215400, loss: 0.03662025255151093, acc: 99.57466597855091, p_norm: 2118.8663708512845, g_norm: 0.5401795923127415, lr:  0.000539, elapsed time:  198853
Step 215500, loss: 0.03619985509198159, acc: 99.58189629018307, p_norm: 2118.999108044462, g_norm: 0.6600013326563513, lr:  0.000538, elapsed time:  198948
Step 215600, loss: 0.03889949642587453, acc: 99.56387338042259, p_norm: 2119.1445549468976, g_norm: 0.7507769703202586, lr:  0.000538, elapsed time:  199039
Step 215700, loss: 0.037741757705807684, acc: 99.5676748752594, p_norm: 2119.269304083431, g_norm: 0.5791140365940204, lr:  0.000538, elapsed time:  199129
Step 215800, loss: 0.03642072525806725, acc: 99.60307681560516, p_norm: 2119.4046029225847, g_norm: 0.699436275498548, lr:  0.000538, elapsed time:  199227
Step 215900, loss: 0.03704934036824852, acc: 99.57077123224735, p_norm: 2119.5367957925623, g_norm: 0.5010591175039105, lr:  0.000538, elapsed time:  199314
Step 216000, loss: 0.036553379073739053, acc: 99.58852145075798, p_norm: 2119.6672449426305, g_norm: 0.6288566872201279, lr:  0.000538, elapsed time:  199403
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 216000, eval loss: 0.042701246831566106, eval acc: 99.53368377685547
Step 216100, loss: 0.03611448851414025, acc: 99.59157854318619, p_norm: 2119.7951250054175, g_norm: 0.6867483973493476, lr:  0.000538, elapsed time:  199511
Step 216200, loss: 0.0372485395334661, acc: 99.56050339341164, p_norm: 2119.945372501924, g_norm: 0.514677301118664, lr:  0.000538, elapsed time:  199598
Step 216300, loss: 0.03677261012606323, acc: 99.5644699037075, p_norm: 2120.0887117252296, g_norm: 0.6447670235023913, lr:  0.000537, elapsed time:  199688
Step 216400, loss: 0.036686876784078774, acc: 99.57169982790947, p_norm: 2120.2559093807836, g_norm: 0.6722893538455899, lr:  0.000537, elapsed time:  199777
Step 216500, loss: 0.036679422720335426, acc: 99.56048838794231, p_norm: 2120.3901834853423, g_norm: 0.6775915327046897, lr:  0.000537, elapsed time:  199867
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 216600, loss: 0.035707272292666174, acc: 99.59356270322752, p_norm: 2120.537790442454, g_norm: 0.6010763344144715, lr:  0.000537, elapsed time:  199958
Step 216700, loss: 0.03597526087425649, acc: 99.57976600527763, p_norm: 2120.665830733891, g_norm: 1.2292337697676918, lr:  0.000537, elapsed time:  200046
Step 216800, loss: 0.03695357517339289, acc: 99.56272508203983, p_norm: 2120.8134289525733, g_norm: 0.5699355340218822, lr:  0.000537, elapsed time:  200136
Step 216900, loss: 0.03543469356838614, acc: 99.59968341886997, p_norm: 2120.9557500324504, g_norm: 0.4774789355890307, lr:  0.000537, elapsed time:  200226
Step 217000, loss: 0.03590116384904832, acc: 99.5837237238884, p_norm: 2121.1089294664826, g_norm: 0.6200713294454733, lr:  0.000537, elapsed time:  200318
Step 217100, loss: 0.03569961968809366, acc: 99.59348572790623, p_norm: 2121.27169419324, g_norm: 0.58334458417674, lr:  0.000536, elapsed time:  200408
Step 217200, loss: 0.03754426108673215, acc: 99.56141975522041, p_norm: 2121.4506342758086, g_norm: 0.5406537827061935, lr:  0.000536, elapsed time:  200495
Step 217300, loss: 0.03694129256997258, acc: 99.56241200864315, p_norm: 2121.591876865403, g_norm: 0.4437270380631713, lr:  0.000536, elapsed time:  200585
Step 217400, loss: 0.03630558072589338, acc: 99.58087956905365, p_norm: 2121.751198522612, g_norm: 1.3458657032202788, lr:  0.000536, elapsed time:  200673
Step 217500, loss: 0.03598908540327102, acc: 99.5907046943903, p_norm: 2121.8934698661, g_norm: 0.5290526080841368, lr:  0.000536, elapsed time:  200762
Step 217600, loss: 0.036256920457817615, acc: 99.58106222748756, p_norm: 2122.0384644244095, g_norm: 1.1533497447789345, lr:  0.000536, elapsed time:  200851
Step 217700, loss: 0.035832846160046755, acc: 99.584218531847, p_norm: 2122.17617539395, g_norm: 0.5822849632062704, lr:  0.000536, elapsed time:  200945
Step 217800, loss: 0.036872988529503346, acc: 99.55510100722313, p_norm: 2122.316356476568, g_norm: 0.56667271775293, lr:  0.000536, elapsed time:  201035
Step 217900, loss: 0.03660225580446422, acc: 99.57188312709332, p_norm: 2122.471705215871, g_norm: 0.6852993813878976, lr:  0.000535, elapsed time:  201129
Step 218000, loss: 0.03612133922055363, acc: 99.58163486421108, p_norm: 2122.6115105153526, g_norm: 0.6456321481660157, lr:  0.000535, elapsed time:  201219
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 218000, eval loss: 0.043278475813567634, eval acc: 99.51715850830078
Step 218100, loss: 0.03767276328522712, acc: 99.56012545526028, p_norm: 2122.769765243456, g_norm: 0.6424279689010974, lr:  0.000535, elapsed time:  201319
Step 218200, loss: 0.03868940874468535, acc: 99.56150397658348, p_norm: 2122.914563195959, g_norm: 0.569235170657056, lr:  0.000535, elapsed time:  201407
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 218300, loss: 0.03662876789423431, acc: 99.58836729118309, p_norm: 2123.038911716338, g_norm: 0.5087774376836549, lr:  0.000535, elapsed time:  201496
Step 218400, loss: 0.03701575419399887, acc: 99.56828193366528, p_norm: 2123.1729958978685, g_norm: 0.46556477347460956, lr:  0.000535, elapsed time:  201584
Step 218500, loss: 0.0359766592271626, acc: 99.59706158936024, p_norm: 2123.299907287613, g_norm: 0.6304017710186416, lr:  0.000535, elapsed time:  201671
Step 218600, loss: 0.036000178353860976, acc: 99.58660097420216, p_norm: 2123.430193320241, g_norm: 0.5455883435279574, lr:  0.000535, elapsed time:  201762
Step 218700, loss: 0.03661868402734399, acc: 99.57738490402699, p_norm: 2123.5787387643622, g_norm: 0.6479721442062474, lr:  0.000534, elapsed time:  201853
Step 218800, loss: 0.03669510225299746, acc: 99.57121758162975, p_norm: 2123.7314145635546, g_norm: 0.7637350234489743, lr:  0.000534, elapsed time:  201938
Step 218900, loss: 0.03645389754325151, acc: 99.57068964838982, p_norm: 2123.874759825887, g_norm: 0.6468793213811803, lr:  0.000534, elapsed time:  202027
Step 219000, loss: 0.03574643258936703, acc: 99.59707075357437, p_norm: 2124.017584532028, g_norm: 0.645161286011101, lr:  0.000534, elapsed time:  202117
Step 219100, loss: 0.036125546963885424, acc: 99.59626787900925, p_norm: 2124.147561133913, g_norm: 0.516702854051482, lr:  0.000534, elapsed time:  202206
Step 219200, loss: 0.0363740884559229, acc: 99.57911621034145, p_norm: 2124.2828716652875, g_norm: 0.5979338944660573, lr:  0.000534, elapsed time:  202297
Step 219300, loss: 0.03693329212721437, acc: 99.55620132386684, p_norm: 2124.4272398130615, g_norm: 0.5221766676624553, lr:  0.000534, elapsed time:  202387
Step 219400, loss: 0.03784690726082772, acc: 99.58578425645828, p_norm: 2124.5714257909794, g_norm: 0.5156380259107515, lr:  0.000534, elapsed time:  202477
Step 219500, loss: 0.036538017326965926, acc: 99.57877844572067, p_norm: 2124.722590594021, g_norm: 0.5357722545318153, lr:  0.000533, elapsed time:  202568
Step 219600, loss: 0.03635417168959975, acc: 99.57778203487396, p_norm: 2124.8696944976414, g_norm: 0.6483933708728652, lr:  0.000533, elapsed time:  202659
Step 219700, loss: 0.037175965374335644, acc: 99.55726119875908, p_norm: 2125.008401079522, g_norm: 0.582032196135943, lr:  0.000533, elapsed time:  202747
Step 219800, loss: 0.03613687955774367, acc: 99.58893878757954, p_norm: 2125.1332477239416, g_norm: 0.6009416867382757, lr:  0.000533, elapsed time:  202840
Step 219900, loss: 0.03600557339377701, acc: 99.59116478264332, p_norm: 2125.266044336986, g_norm: 0.5333827642326967, lr:  0.000533, elapsed time:  202929
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 220000, loss: 0.03569846619706296, acc: 99.60130867236306, p_norm: 2125.4215184848385, g_norm: 0.6644635369134525, lr:  0.000533, elapsed time:  203024
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 220000, eval loss: 0.04516303401440381, eval acc: 99.49063110351562
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c 2 c ( N 3 C C C ( n 4 c ( = O ) c 5 c c ( C ) c c c 5 n ( C ) c 4 = O ) C C 3 ) n c n c 2 c c 1 O C c 1 c c c c c 1 _EOS
Predicted text: C O c 1 c c 2 c ( N 3 C C C ( n 4 c ( = O ) c 5 c c ( C ) c c c 5 n ( C ) c 4 = O ) C C 3 ) n c n c 2 c c 1 O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) C c 1 c c c 2 n c c ( O ) c c 2 c 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) C c 1 c c c 2 n c c ( O ) c c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C O C ( = O ) N C ( C C ( = O ) O C ( C ) ( C ) C ) C ( O ) C c 1 c c c c c 1 _EOS
Predicted text: C = C C O C ( = O ) N C ( C C ( = O ) O C ( C ) ( C ) C ) C ( O ) C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 ( C ( = O ) O C C ) C C N ( C ( = O ) c 2 c c c ( O C ) c c 2 ) C 1 _EOS
Predicted text: C C O C ( = O ) C 1 ( C ( = O ) O C C ) C C N ( C ( = O ) c 2 c c c ( O C ) c c 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C ( = C c 1 c c c c c 1 Cl ) C ( = O ) C ( O C C ) O C C _EOS
Predicted text: C C O C ( = O ) C ( = C c 1 c c c c c 1 Cl ) C ( = O ) C ( O C C ) O C C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 220000, eval acc (token): 0.9344052077009782, eval acc (sequence): 0.8768152228342514
Saving at step 220000
Step 220100, loss: 0.03534560665488243, acc: 99.60676297545433, p_norm: 2125.563752449417, g_norm: 0.5260193116368173, lr:  0.000533, elapsed time:  203209
Step 220200, loss: 0.036356588024646044, acc: 99.56881420314312, p_norm: 2125.7080317119685, g_norm: 0.5310363337799863, lr:  0.000533, elapsed time:  203299
Step 220300, loss: 0.03589427660685032, acc: 99.59543891251087, p_norm: 2125.842034494424, g_norm: 0.5792556836844727, lr:  0.000532, elapsed time:  203387
Step 220400, loss: 0.03631505692843348, acc: 99.5841710716486, p_norm: 2125.988225723095, g_norm: 0.5317131840793141, lr:  0.000532, elapsed time:  203477
Step 220500, loss: 0.0361311303358525, acc: 99.58659043908119, p_norm: 2126.117018319772, g_norm: 0.6227191224709598, lr:  0.000532, elapsed time:  203564
Step 220600, loss: 0.036071071051992476, acc: 99.58584278821945, p_norm: 2126.274120766204, g_norm: 0.7793762383718924, lr:  0.000532, elapsed time:  203655
Step 220700, loss: 0.035771296336315574, acc: 99.5847494751215, p_norm: 2126.412916130394, g_norm: 0.4776983652384075, lr:  0.000532, elapsed time:  203746
Step 220800, loss: 0.03656095654703677, acc: 99.58531518280506, p_norm: 2126.569503628452, g_norm: 0.6412311584549816, lr:  0.000532, elapsed time:  203835
Step 220900, loss: 0.037030937178060414, acc: 99.56697116792202, p_norm: 2126.718917563975, g_norm: 0.6652013007682442, lr:  0.000532, elapsed time:  203923
Step 221000, loss: 0.03595165670849383, acc: 99.59216555953026, p_norm: 2126.8493806010483, g_norm: 1.227603325447629, lr:  0.000532, elapsed time:  204012
Step 221100, loss: 0.03645206972025335, acc: 99.57786682248116, p_norm: 2126.993464288568, g_norm: 0.6005764707382468, lr:  0.000532, elapsed time:  204100
Step 221200, loss: 0.036067384695634246, acc: 99.58257260918617, p_norm: 2127.130759068516, g_norm: 0.5371706670010868, lr:  0.000531, elapsed time:  204189
Step 221300, loss: 0.03636555520817637, acc: 99.56649507582188, p_norm: 2127.2814075061046, g_norm: 0.7044867676791369, lr:  0.000531, elapsed time:  204278
Step 221400, loss: 0.035507398354820904, acc: 99.60135161876678, p_norm: 2127.432495835864, g_norm: 0.6062924745056762, lr:  0.000531, elapsed time:  204368
Step 221500, loss: 0.03637024567462504, acc: 99.57694099843502, p_norm: 2127.567927606503, g_norm: 0.5485009302885787, lr:  0.000531, elapsed time:  204459
Step 221600, loss: 0.03609960882924497, acc: 99.58632606267929, p_norm: 2127.7119738678016, g_norm: 0.5080380914294974, lr:  0.000531, elapsed time:  204547
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 221700, loss: 0.03554603975933435, acc: 99.59856031545952, p_norm: 2127.865164452365, g_norm: 0.9309021298874005, lr:  0.000531, elapsed time:  204625
Step 221800, loss: 0.03543415603693575, acc: 99.60120593011379, p_norm: 2128.0050359049815, g_norm: 0.4689513273886844, lr:  0.000531, elapsed time:  204717
Step 221900, loss: 0.035672232480719684, acc: 99.59379324316978, p_norm: 2128.159450661378, g_norm: 0.5960080315956593, lr:  0.000531, elapsed time:  204808
Step 222000, loss: 0.03620986785273999, acc: 99.584741294384, p_norm: 2128.3108943648817, g_norm: 0.5686415270402242, lr:  0.000530, elapsed time:  204898
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 222000, eval loss: 0.046003967393189654, eval acc: 99.46612548828125
Step 222100, loss: 0.03533084803260863, acc: 99.60489448904991, p_norm: 2128.4392837343576, g_norm: 0.6125955169324315, lr:  0.000530, elapsed time:  205004
Step 222200, loss: 0.03577324040234089, acc: 99.5941711962223, p_norm: 2128.584458760861, g_norm: 0.6109508599772947, lr:  0.000530, elapsed time:  205094
Step 222300, loss: 0.036290613091550766, acc: 99.58104938268661, p_norm: 2128.745248585279, g_norm: 0.5427615676982954, lr:  0.000530, elapsed time:  205185
Step 222400, loss: 0.0356736636441201, acc: 99.59795336425304, p_norm: 2128.898827400544, g_norm: 0.47675977298422595, lr:  0.000530, elapsed time:  205271
Step 222500, loss: 0.03561593158170581, acc: 99.5999685227871, p_norm: 2129.0180085533725, g_norm: 0.4412583306780184, lr:  0.000530, elapsed time:  205354
Step 222600, loss: 0.036773020713590086, acc: 99.57044477760792, p_norm: 2129.16252343428, g_norm: 0.49385929000496703, lr:  0.000530, elapsed time:  205439
Step 222700, loss: 0.035470952829346064, acc: 99.59676441550255, p_norm: 2129.2857107799837, g_norm: 0.5737894625108085, lr:  0.000530, elapsed time:  205521
Step 222800, loss: 0.03610456264112145, acc: 99.58344654738903, p_norm: 2129.450651382081, g_norm: 0.5732299209137159, lr:  0.000529, elapsed time:  205612
Step 222900, loss: 0.03644428545143455, acc: 99.57313691079617, p_norm: 2129.587596241576, g_norm: 0.5461638960712131, lr:  0.000529, elapsed time:  205704
Step 223000, loss: 0.03653548367787152, acc: 99.57162556052208, p_norm: 2129.7290445766976, g_norm: 0.5590772268287774, lr:  0.000529, elapsed time:  205794
Step 223100, loss: 0.03684900807682425, acc: 99.56157031655312, p_norm: 2129.880291439811, g_norm: 0.5139705566106075, lr:  0.000529, elapsed time:  205883
Step 223200, loss: 0.03698547998443246, acc: 99.55569957196712, p_norm: 2130.024297567031, g_norm: 0.5478975960503984, lr:  0.000529, elapsed time:  205973
Step 223300, loss: 0.036123653193935755, acc: 99.5783873796463, p_norm: 2130.1576866212677, g_norm: 0.6010027745434188, lr:  0.000529, elapsed time:  206061
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 223400, loss: 0.0353815955139937, acc: 99.60332672590062, p_norm: 2130.29636724916, g_norm: 0.48109764267764815, lr:  0.000529, elapsed time:  206152
Step 223500, loss: 0.035816207928583026, acc: 99.58720478415489, p_norm: 2130.438007636849, g_norm: 0.6406978218449445, lr:  0.000529, elapsed time:  206242
Step 223600, loss: 0.03570346785709262, acc: 99.58784271776676, p_norm: 2130.583382259906, g_norm: 0.859702426915502, lr:  0.000529, elapsed time:  206333
Step 223700, loss: 0.036004807888530194, acc: 99.57983593642712, p_norm: 2130.723422418681, g_norm: 0.6883473912793276, lr:  0.000528, elapsed time:  206423
Step 223800, loss: 0.03513084337580949, acc: 99.60679021477699, p_norm: 2130.863108487693, g_norm: 0.5634431842592335, lr:  0.000528, elapsed time:  206516
Step 223900, loss: 0.03552573964931071, acc: 99.59557710587978, p_norm: 2131.0100442528405, g_norm: 0.47605708411414865, lr:  0.000528, elapsed time:  206610
Step 224000, loss: 0.03617703192401677, acc: 99.57143966853619, p_norm: 2131.14365795921, g_norm: 0.6198741447791373, lr:  0.000528, elapsed time:  206702
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 224000, eval loss: 0.04591209597885611, eval acc: 99.47212219238281
Step 224100, loss: 0.03638050766661763, acc: 99.58049739897251, p_norm: 2131.2711989069717, g_norm: 0.6884057974132131, lr:  0.000528, elapsed time:  206809
Step 224200, loss: 0.0363814305793494, acc: 99.57472950220108, p_norm: 2131.4135549655484, g_norm: 0.4684129197030492, lr:  0.000528, elapsed time:  206897
Step 224300, loss: 0.037264162548817696, acc: 99.54962359368801, p_norm: 2131.556364093316, g_norm: 0.5860493393095124, lr:  0.000528, elapsed time:  206987
Step 224400, loss: 0.036362035418860614, acc: 99.58530034124851, p_norm: 2131.7310415218717, g_norm: 0.5890702160554, lr:  0.000528, elapsed time:  207077
Step 224500, loss: 0.036488859709352256, acc: 99.58103168010712, p_norm: 2131.866978152781, g_norm: 0.56670700728818, lr:  0.000527, elapsed time:  207167
Step 224600, loss: 0.036290533212013545, acc: 99.57582904398441, p_norm: 2131.9992646152646, g_norm: 0.6813416487246234, lr:  0.000527, elapsed time:  207261
Step 224700, loss: 0.035864569270052014, acc: 99.58500902354717, p_norm: 2132.129824497329, g_norm: 0.5682441424014532, lr:  0.000527, elapsed time:  207352
Step 224800, loss: 0.035838560569100085, acc: 99.59120824933052, p_norm: 2132.267232069871, g_norm: 0.6580635099913723, lr:  0.000527, elapsed time:  207442
Step 224900, loss: 0.035657009137794377, acc: 99.59731423854828, p_norm: 2132.4034703662364, g_norm: 0.6348183181242659, lr:  0.000527, elapsed time:  207537
Step 225000, loss: 0.03569819004740566, acc: 99.59435547888279, p_norm: 2132.556320516512, g_norm: 0.5819062240547298, lr:  0.000527, elapsed time:  207627
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( N C C 1 2 C C 3 C C ( C C ( C 3 ) C 1 ) C 2 ) c 1 c c ( C N 2 C C C 3 ( C C 2 ) C O 3 ) c c c 1 Cl _EOS
Predicted text: O = C ( N C C 1 2 C C 3 C C ( C C ( C 3 ) C 1 ) C 2 ) c 1 c c ( C N 2 C C C 3 ( C C 2 ) C O 3 ) c c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) c 1 c c c c ( O C ( = O ) O c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 ) c 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c c c ( O C ( = O ) O c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C ( O c 1 c c c ( - n 2 c c ( C ( F ) ( F ) F ) c n 2 ) c c 1 C ) c 1 c c c ( C ( = O ) N C C C ( = O ) O C C ) c c 1 _EOS
Predicted text: C C C C ( O c 1 c c c ( - n 2 c c ( C ( F ) ( F ) F ) c n 2 ) c c 1 C ) c 1 c c c ( C ( = O ) N C C C ( = O ) O C C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( - c 2 c c n c c 2 ) c c 1 - c 1 c c c c c 1 _EOS
Predicted text: C O c 1 c c c ( - c 2 c c n c c 2 ) c c 1 - c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c n n ( C c 2 c c ( - c 3 c c c c ( C ( F ) ( F ) F ) c 3 ) o c 2 C ) c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c n n ( C c 2 c c ( - c 3 c c c c ( C ( F ) ( F ) F ) c 3 ) o c 2 C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 225000, eval acc (token): 0.937350338106334, eval acc (sequence): 0.8851414652426457
Saving at step 225000
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 225100, loss: 0.0363040911172753, acc: 99.56678685857288, p_norm: 2132.6968162788776, g_norm: 0.8831624445680347, lr:  0.000527, elapsed time:  207798
Step 225200, loss: 0.03518366271164268, acc: 99.61402952671051, p_norm: 2132.8450163117827, g_norm: 0.56519690191983, lr:  0.000527, elapsed time:  207890
Step 225300, loss: 0.0360613572364673, acc: 99.5843425989151, p_norm: 2132.9964193484275, g_norm: 0.6727467328858, lr:  0.000527, elapsed time:  207984
Step 225400, loss: 0.036707781683653594, acc: 99.56574214994907, p_norm: 2133.1482171445246, g_norm: 0.5826960933692605, lr:  0.000526, elapsed time:  208072
Step 225500, loss: 0.03631358167156577, acc: 99.58040800690651, p_norm: 2133.2859123516823, g_norm: 0.5526373558370447, lr:  0.000526, elapsed time:  208164
Step 225600, loss: 0.035539071885868904, acc: 99.60035961866379, p_norm: 2133.3900532214234, g_norm: 0.5923267618112406, lr:  0.000526, elapsed time:  208257
Step 225700, loss: 0.036314677195623514, acc: 99.57101517915726, p_norm: 2133.5357335155427, g_norm: 0.5962076257331633, lr:  0.000526, elapsed time:  208346
Step 225800, loss: 0.03525544014759362, acc: 99.61234529316425, p_norm: 2133.6619246353093, g_norm: 0.48260247108610993, lr:  0.000526, elapsed time:  208439
Step 225900, loss: 0.035964079997502264, acc: 99.58445423841476, p_norm: 2133.8088011848736, g_norm: 0.5915545735612171, lr:  0.000526, elapsed time:  208529
Step 226000, loss: 0.03618179820943624, acc: 99.5890467017889, p_norm: 2133.946794341404, g_norm: 0.5853816034512548, lr:  0.000526, elapsed time:  208624
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 226000, eval loss: 0.043930026665329934, eval acc: 99.50921630859375
Step 226100, loss: 0.036409618090838196, acc: 99.57367131114006, p_norm: 2134.0864284065615, g_norm: 0.8502698005076654, lr:  0.000526, elapsed time:  208729
Step 226200, loss: 0.036211300985887644, acc: 99.58161473274231, p_norm: 2134.244398006951, g_norm: 0.5905160463775053, lr:  0.000525, elapsed time:  208819
Step 226300, loss: 0.0364040393428877, acc: 99.57454717159271, p_norm: 2134.38813971328, g_norm: 0.6893037728330634, lr:  0.000525, elapsed time:  208912
Step 226400, loss: 0.0356738352868706, acc: 99.5967954993248, p_norm: 2134.507766583691, g_norm: 0.4564661010070746, lr:  0.000525, elapsed time:  209001
Step 226500, loss: 0.036600776193663476, acc: 99.57770602405071, p_norm: 2134.655251256081, g_norm: 0.6197305106269851, lr:  0.000525, elapsed time:  209090
Step 226600, loss: 0.03588654924649745, acc: 99.59745199978352, p_norm: 2134.789535519683, g_norm: 0.6933683842251664, lr:  0.000525, elapsed time:  209184
Step 226700, loss: 0.03620212508365512, acc: 99.58306638896465, p_norm: 2134.9332464882345, g_norm: 0.5365845537018138, lr:  0.000525, elapsed time:  209280
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 226800, loss: 0.036275694332090186, acc: 99.58092043945446, p_norm: 2135.062730267268, g_norm: 0.5096557033647936, lr:  0.000525, elapsed time:  209369
Step 226900, loss: 0.03525123840663582, acc: 99.60904142260551, p_norm: 2135.207413033373, g_norm: 0.6240636384236787, lr:  0.000525, elapsed time:  209457
Step 227000, loss: 0.03587545205838978, acc: 99.59890301525593, p_norm: 2135.346585466905, g_norm: 0.544545637205195, lr:  0.000525, elapsed time:  209547
Step 227100, loss: 0.0370135524822399, acc: 99.5529765933752, p_norm: 2135.4795075336856, g_norm: 0.7373983399138143, lr:  0.000524, elapsed time:  209635
Step 227200, loss: 0.03608031760435551, acc: 99.57955802977085, p_norm: 2135.625106765552, g_norm: 0.5716311493108359, lr:  0.000524, elapsed time:  209728
Step 227300, loss: 0.03534494271036238, acc: 99.59807874262333, p_norm: 2135.7748055591705, g_norm: 0.5514680202068938, lr:  0.000524, elapsed time:  209817
Step 227400, loss: 0.03598822836764157, acc: 99.59081998467445, p_norm: 2135.9136497419304, g_norm: 0.4538488175197944, lr:  0.000524, elapsed time:  209905
Step 227500, loss: 0.03687916177790612, acc: 99.59912990033627, p_norm: 2136.037351424489, g_norm: 0.5362041837129585, lr:  0.000524, elapsed time:  209996
Step 227600, loss: 0.040137180970050396, acc: 99.57010915875435, p_norm: 2136.1558130013077, g_norm: 0.5266567055424128, lr:  0.000524, elapsed time:  210091
Step 227700, loss: 0.03836590531282127, acc: 99.5742767304182, p_norm: 2136.283924275463, g_norm: 0.5703350050033322, lr:  0.000524, elapsed time:  210178
Step 227800, loss: 0.037884979168884454, acc: 99.58233515918255, p_norm: 2136.416218223329, g_norm: 0.6129849070504638, lr:  0.000524, elapsed time:  210268
Step 227900, loss: 0.03711028621997684, acc: 99.58779399096966, p_norm: 2136.546639388728, g_norm: 0.5417858789353586, lr:  0.000524, elapsed time:  210359
Step 228000, loss: 0.03724656704813242, acc: 99.57562437653542, p_norm: 2136.6785517068, g_norm: 0.5656820173798478, lr:  0.000523, elapsed time:  210451
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 228000, eval loss: 0.04365176159888507, eval acc: 99.51678466796875
Step 228100, loss: 0.03760106143541634, acc: 99.5690828859806, p_norm: 2136.8058555345556, g_norm: 1.0096884081966562, lr:  0.000523, elapsed time:  210557
Step 228200, loss: 0.036519621522165834, acc: 99.58799128234386, p_norm: 2136.9232196306893, g_norm: 0.6481583046519032, lr:  0.000523, elapsed time:  210649
Step 228300, loss: 0.03614100219681859, acc: 99.58667208254337, p_norm: 2137.0723377524287, g_norm: 1.3867055394660892, lr:  0.000523, elapsed time:  210717
Step 228400, loss: 0.035786592913791535, acc: 99.58969484269619, p_norm: 2137.207265101623, g_norm: 0.6253019548841535, lr:  0.000523, elapsed time:  210789
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 228500, loss: 0.036259293662782625, acc: 99.57415494159679, p_norm: 2137.332710951707, g_norm: 0.6671092698968197, lr:  0.000523, elapsed time:  210870
Step 228600, loss: 0.03573434866964817, acc: 99.5912522226572, p_norm: 2137.448742532644, g_norm: 0.6382823597665039, lr:  0.000523, elapsed time:  210959
Step 228700, loss: 0.035494239032268525, acc: 99.59714405238628, p_norm: 2137.5769840454595, g_norm: 0.5691176874787506, lr:  0.000523, elapsed time:  211050
Step 228800, loss: 0.03615080482326448, acc: 99.57540813088417, p_norm: 2137.706157923516, g_norm: 0.5385835161542868, lr:  0.000522, elapsed time:  211137
Step 228900, loss: 0.03584994751028717, acc: 99.58715651929379, p_norm: 2137.845384269621, g_norm: 0.670878873857313, lr:  0.000522, elapsed time:  211226
Step 229000, loss: 0.03561456638853997, acc: 99.59980735182762, p_norm: 2137.9889874316664, g_norm: 0.5725251355659045, lr:  0.000522, elapsed time:  211322
Step 229100, loss: 0.03481584889348596, acc: 99.61637769639492, p_norm: 2138.1166312060677, g_norm: 0.4447014960122805, lr:  0.000522, elapsed time:  211417
Step 229200, loss: 0.035325474557466804, acc: 99.59953038394451, p_norm: 2138.2591900697375, g_norm: 0.5097088557032707, lr:  0.000522, elapsed time:  211504
Step 229300, loss: 0.036351902764290574, acc: 99.57523331046104, p_norm: 2138.4121869192254, g_norm: 0.5807129627817438, lr:  0.000522, elapsed time:  211595
Step 229400, loss: 0.03535683541093022, acc: 99.59909303486347, p_norm: 2138.5624826532285, g_norm: 0.4510407692342952, lr:  0.000522, elapsed time:  211686
Step 229500, loss: 0.036147818192839624, acc: 99.58543905615807, p_norm: 2138.7030664745275, g_norm: 0.509032691358714, lr:  0.000522, elapsed time:  211776
Step 229600, loss: 0.03552177734673023, acc: 99.59827706217766, p_norm: 2138.834942260397, g_norm: 0.5508120868476771, lr:  0.000522, elapsed time:  211864
Step 229700, loss: 0.03570952441543341, acc: 99.58546552062035, p_norm: 2138.9590250931583, g_norm: 0.547406398688969, lr:  0.000521, elapsed time:  211953
Step 229800, loss: 0.03546307848766446, acc: 99.5942911207676, p_norm: 2139.0966383432014, g_norm: 0.6632321346465802, lr:  0.000521, elapsed time:  212040
Step 229900, loss: 0.03556420397479087, acc: 99.60291926562786, p_norm: 2139.256891629647, g_norm: 0.6451734195829731, lr:  0.000521, elapsed time:  212134
Step 230000, loss: 0.0357962764846161, acc: 99.59117928147316, p_norm: 2139.3941634114612, g_norm: 0.4706184732734691, lr:  0.000521, elapsed time:  212226
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 230000, eval loss: 0.045660441927611824, eval acc: 99.478515625
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C N 1 C ( = O ) C ( c 2 c c c ( O C ( F ) F ) c c 2 ) ( c 2 c c c c ( C = C C 3 C C 3 ) c 2 ) N = C 1 N _EOS
Predicted text: C N 1 C ( = O ) C ( c 2 c c c ( O C ( F ) F ) c c 2 ) ( c 2 c c c c ( C = C C 3 C C 3 ) c 2 ) N = C 1 N _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C O C ( = O ) C O c 1 c c c ( C ( = O ) N c 2 c c c c ( Cl ) c 2 Cl ) c c 1 _EOS
Predicted text: C C C C O C ( = O ) C O c 1 c c c ( C ( = O ) N c 2 c c c c ( Cl ) c 2 Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( N 2 C C ( C ) N C ( C ) C 2 ) c c 1 N S ( = O ) ( = O ) c 1 c c c ( - c 2 c c c c c 2 F ) s 1 _EOS
Predicted text: C O c 1 c c c ( N 2 C C ( C ) N C ( C ) C 2 ) c c 1 N S ( = O ) ( = O ) c 1 c c c ( - c 2 c c c c c 2 F ) s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C 2 O C C ( C ) ( C ) C O 2 ) c c c 1 C 1 ( O ) C ( = O ) N c 2 c c c ( Cl ) c c 2 1 _EOS
Predicted text: C O c 1 c c ( C 2 O C C ( C ) ( C ) C O 2 ) c c c 1 C 1 ( O ) C ( = O ) N c 2 c c c ( Cl ) c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C C 1 C N ( c 2 c c c ( - n 3 c c c c ( C C O ) c 3 = O ) c ( Cl ) c 2 ) C ( = O ) O 1 ) c 1 c c c ( Cl ) s 1 _EOS
Predicted text: O = C ( N C C 1 C N ( c 2 c c c ( - n 3 c c c c ( C C O ) c 3 = O ) c ( Cl ) c 2 ) C ( = O ) O 1 ) c 1 c c c ( Cl ) s 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 230000, eval acc (token): 0.9371410383736469, eval acc (sequence): 0.8828861493836113
Saving at step 230000
Step 230100, loss: 0.03515864758286625, acc: 99.60727943480015, p_norm: 2139.526430145198, g_norm: 0.6318314364955036, lr:  0.000521, elapsed time:  212415
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 230200, loss: 0.03596706168994827, acc: 99.58652781313332, p_norm: 2139.663424308718, g_norm: 0.6768306294755329, lr:  0.000521, elapsed time:  212506
Step 230300, loss: 0.03488040047697723, acc: 99.62003834545612, p_norm: 2139.814957847787, g_norm: 0.569318324043442, lr:  0.000521, elapsed time:  212597
Step 230400, loss: 0.03501160498708487, acc: 99.61211754381657, p_norm: 2139.9424029982115, g_norm: 0.5018986337379986, lr:  0.000521, elapsed time:  212688
Step 230500, loss: 0.035066911741159855, acc: 99.60640116035938, p_norm: 2140.066681358585, g_norm: 0.6278802686142019, lr:  0.000521, elapsed time:  212776
Step 230600, loss: 0.03463677684776485, acc: 99.61982549726963, p_norm: 2140.190745731953, g_norm: 0.7025487028082997, lr:  0.000520, elapsed time:  212867
Step 230700, loss: 0.0351236881269142, acc: 99.60871729254723, p_norm: 2140.3283889721556, g_norm: 0.7042932450051195, lr:  0.000520, elapsed time:  212954
Step 230800, loss: 0.03556769324466586, acc: 99.59691920876503, p_norm: 2140.4786459753714, g_norm: 0.5238374980220294, lr:  0.000520, elapsed time:  213049
Step 230900, loss: 0.036266198493540285, acc: 99.5760114043951, p_norm: 2140.6215135668067, g_norm: 0.5619938041221626, lr:  0.000520, elapsed time:  213135
Step 231000, loss: 0.035816241488792006, acc: 99.59196616709232, p_norm: 2140.753536539414, g_norm: 0.6294852430890446, lr:  0.000520, elapsed time:  213224
Step 231100, loss: 0.03608055797871202, acc: 99.58753898739815, p_norm: 2140.8840626785186, g_norm: 0.46155869265034083, lr:  0.000520, elapsed time:  213315
Step 231200, loss: 0.03568959181662649, acc: 99.59174095094204, p_norm: 2141.0217211854592, g_norm: 0.5365135090755458, lr:  0.000520, elapsed time:  213405
Step 231300, loss: 0.036184122930280865, acc: 99.5785081088543, p_norm: 2141.1582837389233, g_norm: 0.6853712250610462, lr:  0.000520, elapsed time:  213491
Step 231400, loss: 0.035937858279794455, acc: 99.58598051965237, p_norm: 2141.2935665337104, g_norm: 0.6232418951085944, lr:  0.000520, elapsed time:  213581
Step 231500, loss: 0.03559886155184358, acc: 99.60310836136341, p_norm: 2141.4136659576675, g_norm: 0.5291596153733902, lr:  0.000519, elapsed time:  213669
Step 231600, loss: 0.03621560221537948, acc: 99.58052134513855, p_norm: 2141.5461373294543, g_norm: 0.6668088301202386, lr:  0.000519, elapsed time:  213753
Step 231700, loss: 0.036045636660419406, acc: 99.57923647761345, p_norm: 2141.686190089486, g_norm: 0.664531401716801, lr:  0.000519, elapsed time:  213844
Step 231800, loss: 0.03592863839119673, acc: 99.59514811635017, p_norm: 2141.841268392853, g_norm: 0.7897228504013123, lr:  0.000519, elapsed time:  213936
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 231900, loss: 0.036674198699160596, acc: 99.56616548756462, p_norm: 2141.9884736872364, g_norm: 0.7128509265527938, lr:  0.000519, elapsed time:  214030
Step 232000, loss: 0.03501759720034897, acc: 99.60733659565449, p_norm: 2142.1267214517234, g_norm: 0.5456465867502671, lr:  0.000519, elapsed time:  214120
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 232000, eval loss: 0.043306806273758415, eval acc: 99.53021240234375
Step 232100, loss: 0.035416721072979274, acc: 99.60700087249279, p_norm: 2142.2676906918064, g_norm: 0.5291507257605037, lr:  0.000519, elapsed time:  214223
Step 232200, loss: 0.03556561007164419, acc: 99.59761852025986, p_norm: 2142.3964073023794, g_norm: 0.4815665258138665, lr:  0.000519, elapsed time:  214312
Step 232300, loss: 0.034886640384793284, acc: 99.61593027412891, p_norm: 2142.545340627718, g_norm: 0.5086143419075316, lr:  0.000519, elapsed time:  214403
Step 232400, loss: 0.03595336464699358, acc: 99.5920712351799, p_norm: 2142.6823915309155, g_norm: 0.5287622411758417, lr:  0.000518, elapsed time:  214493
Step 232500, loss: 0.03604135389905423, acc: 99.58113226294518, p_norm: 2142.8241402454564, g_norm: 0.6543954242283776, lr:  0.000518, elapsed time:  214584
Step 232600, loss: 0.035860465536825356, acc: 99.59342727065086, p_norm: 2142.9454849661306, g_norm: 0.8163334872640313, lr:  0.000518, elapsed time:  214670
Step 232700, loss: 0.035572028104215864, acc: 99.58920231461525, p_norm: 2143.0845441546803, g_norm: 0.6516162791506531, lr:  0.000518, elapsed time:  214760
Step 232800, loss: 0.03580502104479819, acc: 99.59742407500744, p_norm: 2143.233616689031, g_norm: 0.5963772336221178, lr:  0.000518, elapsed time:  214852
Step 232900, loss: 0.03623753314372152, acc: 99.58873549103737, p_norm: 2143.361562789221, g_norm: 0.5792684070106152, lr:  0.000518, elapsed time:  214943
Step 233000, loss: 0.035628180387429896, acc: 99.59651224315166, p_norm: 2143.486177818492, g_norm: 0.8114273672019651, lr:  0.000518, elapsed time:  215033
Step 233100, loss: 0.036097393915988506, acc: 99.58359853923321, p_norm: 2143.6173465409966, g_norm: 0.5265962713092115, lr:  0.000518, elapsed time:  215123
Step 233200, loss: 0.03650442929007113, acc: 99.57695981860161, p_norm: 2143.755107032766, g_norm: 0.3790183152618761, lr:  0.000518, elapsed time:  215211
Step 233300, loss: 0.03554479358717799, acc: 99.58505657315254, p_norm: 2143.8915282265884, g_norm: 0.43146731156517104, lr:  0.000517, elapsed time:  215302
Step 233400, loss: 0.035160434055142104, acc: 99.60707251727581, p_norm: 2144.0233159105705, g_norm: 0.6449432976689559, lr:  0.000517, elapsed time:  215372
Step 233500, loss: 0.035221381476148964, acc: 99.6133265197277, p_norm: 2144.1620970230097, g_norm: 0.6707457773165413, lr:  0.000517, elapsed time:  215444
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 233600, loss: 0.03585843737723667, acc: 99.59591754633396, p_norm: 2144.3119905179724, g_norm: 0.7974890687147146, lr:  0.000517, elapsed time:  215530
Step 233700, loss: 0.035655206488445404, acc: 99.5906778126955, p_norm: 2144.4378976347525, g_norm: 0.7105693489388674, lr:  0.000517, elapsed time:  215621
Step 233800, loss: 0.03557437675073743, acc: 99.59930312633514, p_norm: 2144.570628879704, g_norm: 0.5547994203228382, lr:  0.000517, elapsed time:  215718
Step 233900, loss: 0.03531512213870883, acc: 99.60638579726219, p_norm: 2144.724073107601, g_norm: 0.49058992110975236, lr:  0.000517, elapsed time:  215809
Step 234000, loss: 0.03561014880891889, acc: 99.60727439820766, p_norm: 2144.852791470868, g_norm: 0.6094754795669829, lr:  0.000517, elapsed time:  215897
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 234000, eval loss: 0.04168725047260525, eval acc: 99.55571746826172
Step 234100, loss: 0.035637752059847115, acc: 99.59781566262245, p_norm: 2145.0033042117193, g_norm: 0.6276013729224806, lr:  0.000517, elapsed time:  216004
Step 234200, loss: 0.03533987268805504, acc: 99.60039857029915, p_norm: 2145.125387395044, g_norm: 0.5809423372711683, lr:  0.000516, elapsed time:  216099
Step 234300, loss: 0.0357493570074439, acc: 99.59425915777683, p_norm: 2145.2530248889266, g_norm: 0.6708630996408869, lr:  0.000516, elapsed time:  216187
Step 234400, loss: 0.035893752560950815, acc: 99.58164303004742, p_norm: 2145.391538837279, g_norm: 0.6559237436355637, lr:  0.000516, elapsed time:  216286
Step 234500, loss: 0.035878735706210134, acc: 99.58020077645779, p_norm: 2145.513189115655, g_norm: 0.5647643840049438, lr:  0.000516, elapsed time:  216383
Step 234600, loss: 0.03606697508599609, acc: 99.57943148911, p_norm: 2145.659145712226, g_norm: 0.44619818633929975, lr:  0.000516, elapsed time:  216476
Step 234700, loss: 0.03611563155427575, acc: 99.59332613646984, p_norm: 2145.8146597927757, g_norm: 0.5309168502538587, lr:  0.000516, elapsed time:  216568
Step 234800, loss: 0.035669833263382314, acc: 99.6011665314436, p_norm: 2145.94496060522, g_norm: 0.5224361854921078, lr:  0.000516, elapsed time:  216658
Step 234900, loss: 0.03578894522972405, acc: 99.60173320770264, p_norm: 2146.077293723921, g_norm: 0.5731271076710822, lr:  0.000516, elapsed time:  216749
Step 235000, loss: 0.03594887090846896, acc: 99.58596237003803, p_norm: 2146.2001914786174, g_norm: 0.5330954109704674, lr:  0.000516, elapsed time:  216842
Calling G2SDataset.batch()
Done, time:  0.05 s, total batches: 527
Target text: C C 1 C c 2 c ( F ) c ( F ) c c 3 c ( = O ) c ( C ( = O ) O ) c n ( c 2 3 ) N 1 C _EOS
Predicted text: C C 1 C c 2 c ( F ) c ( F ) c c 3 c ( = O ) c ( C ( = O ) O ) c n ( c 2 3 ) N 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C [Sn] ( C ) ( C ) c 1 c n c 2 n c c c n 1 2 _EOS
Predicted text: C [Sn] ( C ) ( C ) c 1 c n c 2 n c c c n 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C ( C c 1 c c c ( O C C = C ( C ) c 2 c c c ( - c 3 c c c c c 3 ) c c 2 ) c c 1 ) O C C _EOS
Predicted text: C C O C ( = O ) C ( C c 1 c c c ( O C C = C ( C ) c 2 c c c ( - c 3 c c c c c 3 ) c c 2 ) c c 1 ) O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C S C C ( C ) ( C ) N _EOS
Predicted text: C C C C C C C C S C C ( C ) ( C ) N _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 N C N ( c 2 c c c c c 2 ) C 1 2 C C N ( C C C n 1 c ( = O ) [nH] c 3 c c c c ( Cl ) c 3 1 ) C C 2 _EOS
Predicted text: O = C 1 N C N ( c 2 c c c c c 2 ) C 1 2 C C N ( C C C n 1 c ( = O ) [nH] c 3 c c c c ( Cl ) c 3 1 ) C C 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 235000, eval acc (token): 0.9355929893227907, eval acc (sequence): 0.8803898893110854
Saving at step 235000
Step 235100, loss: 0.0354169019497931, acc: 99.60157108306885, p_norm: 2146.3316288025962, g_norm: 0.6775148191087682, lr:  0.000515, elapsed time:  217003
Step 235200, loss: 0.03534457261674106, acc: 99.60132463276386, p_norm: 2146.4727109425603, g_norm: 0.5228186848272146, lr:  0.000515, elapsed time:  217094
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 235300, loss: 0.039019980733617954, acc: 99.55154127873499, p_norm: 2146.631149765905, g_norm: 0.6661135999490547, lr:  0.000515, elapsed time:  217183
Step 235400, loss: 0.03525501480791718, acc: 99.61975084245205, p_norm: 2146.751493306425, g_norm: 0.4497924939191482, lr:  0.000515, elapsed time:  217271
Step 235500, loss: 0.035677724601700905, acc: 99.59430937469006, p_norm: 2146.879187850423, g_norm: 0.7396027716413327, lr:  0.000515, elapsed time:  217355
Step 235600, loss: 0.03570602818392217, acc: 99.59475408494473, p_norm: 2147.02119823967, g_norm: 0.6468014071290114, lr:  0.000515, elapsed time:  217442
Step 235700, loss: 0.035978348660282794, acc: 99.5951936095953, p_norm: 2147.1535406720573, g_norm: 0.6564802742483029, lr:  0.000515, elapsed time:  217532
Step 235800, loss: 0.03635958604514599, acc: 99.57529589533806, p_norm: 2147.2868663843915, g_norm: 0.5697401973698059, lr:  0.000515, elapsed time:  217623
Step 235900, loss: 0.03525719033554196, acc: 99.608611702919, p_norm: 2147.4104714089385, g_norm: 0.45798429094325677, lr:  0.000515, elapsed time:  217717
Step 236000, loss: 0.03519058779813349, acc: 99.60848693549633, p_norm: 2147.5372626633484, g_norm: 0.5101621558735525, lr:  0.000514, elapsed time:  217806
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 236000, eval loss: 0.044901228584349154, eval acc: 99.49815368652344
Step 236100, loss: 0.03516366950236261, acc: 99.60297027230263, p_norm: 2147.6654011818114, g_norm: 0.5118972321509356, lr:  0.000514, elapsed time:  217914
Step 236200, loss: 0.03525360275059938, acc: 99.60984483361244, p_norm: 2147.8000472549047, g_norm: 0.6268945217201863, lr:  0.000514, elapsed time:  218004
Step 236300, loss: 0.03589944730978459, acc: 99.58835627138615, p_norm: 2147.931384829328, g_norm: 0.5542763785803403, lr:  0.000514, elapsed time:  218093
Step 236400, loss: 0.03552859268616885, acc: 99.5934494137764, p_norm: 2148.062781788458, g_norm: 0.6640811157078591, lr:  0.000514, elapsed time:  218177
Step 236500, loss: 0.035040297685191034, acc: 99.61530575156212, p_norm: 2148.1912246255715, g_norm: 0.5465459842336307, lr:  0.000514, elapsed time:  218269
Step 236600, loss: 0.035601718802936375, acc: 99.61144982278347, p_norm: 2148.3132765755704, g_norm: 0.46063022570281953, lr:  0.000514, elapsed time:  218368
Step 236700, loss: 0.03740829011891037, acc: 99.58174300193787, p_norm: 2148.4390221595145, g_norm: 0.5507022843456105, lr:  0.000514, elapsed time:  218456
Step 236800, loss: 0.0384222306124866, acc: 99.57434602081776, p_norm: 2148.55725837825, g_norm: 0.6225966206683736, lr:  0.000514, elapsed time:  218546
Step 236900, loss: 0.03636142236646265, acc: 99.59956340491772, p_norm: 2148.6689191366145, g_norm: 0.5844607316922493, lr:  0.000513, elapsed time:  218635
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 237000, loss: 0.035516666489379914, acc: 99.6146981840703, p_norm: 2148.7909562157943, g_norm: 0.5887216635808272, lr:  0.000513, elapsed time:  218731
Step 237100, loss: 0.03575141762383282, acc: 99.60447888076305, p_norm: 2148.9159683532503, g_norm: 0.8090309610999757, lr:  0.000513, elapsed time:  218819
Step 237200, loss: 0.035148252975195644, acc: 99.6096346527338, p_norm: 2149.0428122610756, g_norm: 0.9407007890155337, lr:  0.000513, elapsed time:  218909
Step 237300, loss: 0.03554385880474001, acc: 99.59953790903091, p_norm: 2149.168910961895, g_norm: 0.6629553389384225, lr:  0.000513, elapsed time:  218999
Step 237400, loss: 0.03571256976108998, acc: 99.58783966302872, p_norm: 2149.30039947918, g_norm: 0.7292970969027555, lr:  0.000513, elapsed time:  219087
Step 237500, loss: 0.034922310267575085, acc: 99.61043155193329, p_norm: 2149.415681049009, g_norm: 0.6738978666679445, lr:  0.000513, elapsed time:  219176
Step 237600, loss: 0.034677151422947645, acc: 99.62080712616444, p_norm: 2149.5411117364415, g_norm: 0.6123023172468202, lr:  0.000513, elapsed time:  219265
Step 237700, loss: 0.034969611233100294, acc: 99.61203917860985, p_norm: 2149.661795641115, g_norm: 0.636173121593724, lr:  0.000513, elapsed time:  219350
Step 237800, loss: 0.03530512709636241, acc: 99.61359222233295, p_norm: 2149.799734696976, g_norm: 0.6758783985398445, lr:  0.000513, elapsed time:  219442
Step 237900, loss: 0.0364676865329966, acc: 99.56598968803883, p_norm: 2149.947963585145, g_norm: 0.6279670708200727, lr:  0.000512, elapsed time:  219535
Step 238000, loss: 0.035282169682905075, acc: 99.60669207572937, p_norm: 2150.0751653873226, g_norm: 0.6043957125501785, lr:  0.000512, elapsed time:  219627
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 238000, eval loss: 0.04268016584217546, eval acc: 99.53337097167969
Step 238100, loss: 0.03504081649240107, acc: 99.60537780821323, p_norm: 2150.2183340511456, g_norm: 0.49585476252376265, lr:  0.000512, elapsed time:  219738
Step 238200, loss: 0.04742603795137256, acc: 99.58982798457146, p_norm: 2150.3479978178466, g_norm: 0.6613070931569226, lr:  0.000512, elapsed time:  219830
Step 238300, loss: 0.03697686533909291, acc: 99.59502224624157, p_norm: 2150.4741611658656, g_norm: 0.7129813742203739, lr:  0.000512, elapsed time:  219922
Step 238400, loss: 0.03609773977659643, acc: 99.60797557234764, p_norm: 2150.6095257976476, g_norm: 0.8113928007531054, lr:  0.000512, elapsed time:  220013
Step 238500, loss: 0.03673395913559943, acc: 99.58882586658001, p_norm: 2150.7564069908976, g_norm: 0.8856176037603685, lr:  0.000512, elapsed time:  220102
Step 238600, loss: 0.03623763893265277, acc: 99.58969862759113, p_norm: 2150.879200869853, g_norm: 0.4267410904103162, lr:  0.000512, elapsed time:  220190
Step 238700, loss: 0.03525252992752939, acc: 99.61816935241222, p_norm: 2150.9905755404266, g_norm: 0.7092698913919249, lr:  0.000512, elapsed time:  220281
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 238800, loss: 0.03495168844445911, acc: 99.622092797206, p_norm: 2151.12721332026, g_norm: 0.660107749000779, lr:  0.000511, elapsed time:  220351
Step 238900, loss: 0.034657094050198796, acc: 99.62497924268246, p_norm: 2151.2447269600852, g_norm: 0.9436974208020401, lr:  0.000511, elapsed time:  220419
Step 239000, loss: 0.035296889706514775, acc: 99.60798721015453, p_norm: 2151.3875401617274, g_norm: 0.6399548940824555, lr:  0.000511, elapsed time:  220492
Step 239100, loss: 0.03558901198208332, acc: 99.59774608910084, p_norm: 2151.5353642345126, g_norm: 0.5803270566920563, lr:  0.000511, elapsed time:  220561
Step 239200, loss: 0.03588892317842692, acc: 99.59379579126835, p_norm: 2151.6697661560793, g_norm: 0.5983735731386806, lr:  0.000511, elapsed time:  220642
Step 239300, loss: 0.03562481978908181, acc: 99.59407372772694, p_norm: 2151.805447090183, g_norm: 0.5342678932900954, lr:  0.000511, elapsed time:  220732
Step 239400, loss: 0.035144356358796355, acc: 99.61166113615036, p_norm: 2151.925671511032, g_norm: 0.7955809192170777, lr:  0.000511, elapsed time:  220823
Step 239500, loss: 0.03579151127487421, acc: 99.59225772321224, p_norm: 2152.064440546196, g_norm: 0.6863442543367629, lr:  0.000511, elapsed time:  220912
Step 239600, loss: 0.03476009473204613, acc: 99.62042416632175, p_norm: 2152.1846244647973, g_norm: 0.49735284058248963, lr:  0.000511, elapsed time:  221008
Step 239700, loss: 0.03497722215950489, acc: 99.61257234215736, p_norm: 2152.32248468084, g_norm: 0.5468818476895426, lr:  0.000510, elapsed time:  221108
Step 239800, loss: 0.03513500849250704, acc: 99.60767748951912, p_norm: 2152.442946902385, g_norm: 0.7011813070232508, lr:  0.000510, elapsed time:  221205
Step 239900, loss: 0.035386773720383645, acc: 99.60461397469044, p_norm: 2152.563513009484, g_norm: 0.5240807476389544, lr:  0.000510, elapsed time:  221297
Step 240000, loss: 0.035525694172829386, acc: 99.589489325881, p_norm: 2152.6903455939946, g_norm: 0.6416939738879913, lr:  0.000510, elapsed time:  221387
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 240000, eval loss: 0.045318228900432585, eval acc: 99.47761535644531
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C c 1 c c ( C ( = O ) N 2 C C c 3 n c ( C ) n ( C c 4 c c c c c 4 ) c 3 - c 3 c c c c c 3 2 ) c c c 1 C N C ( = O ) C 1 C C 1 _EOS
Predicted text: C c 1 c c ( C ( = O ) N 2 C C c 3 n c ( C ) n ( C c 4 c c c c c 4 ) c 3 - c 3 c c c c c 3 2 ) c c c 1 C N C ( = O ) C 1 C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C ( C C ) ( c 1 c c c ( O C C ( O ) C ( C ) ( C ) C ) c ( C ) c 1 ) c 1 c c 2 c c c ( C ( = O ) O ) c c 2 o 1 _EOS
Predicted text: C C C ( C C ) ( c 1 c c c ( O C C ( O ) C ( C ) ( C ) C ) c ( C ) c 1 ) c 1 c c 2 c c c ( C ( = O ) O ) c c 2 o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( F ) c ( F ) c c 1 - c 1 c c c ( O C c 2 c c c c ( [N+] ( = O ) [O-] ) c 2 ) c c 1 _EOS
Predicted text: C O c 1 c c ( F ) c ( F ) c c 1 - c 1 c c c ( O C c 2 c c c c ( [N+] ( = O ) [O-] ) c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N C ( = O ) N 1 C C N ( C 2 C C c 3 c c c ( O C ) c c 3 2 ) C C 1 _EOS
Predicted text: C C N C ( = O ) N 1 C C N ( C 2 C C c 3 c c c ( O C ) c c 3 2 ) C C 1 . O = C ( O ) C = C C ( = O ) O _EOS
acc_token: 0.9722222222222222, acc_seq: False

Target text: C N ( C ) C ( = O ) O c 1 c c c [n+] ( C O C ( = O ) c 2 c c c c c 2 ) c 1 . [Cl-] _EOS
Predicted text: C N ( C ) C ( = O ) O c 1 c c c [n+] ( C O C ( = O ) c 2 c c c c c 2 ) c 1 . [Cl-] _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 240000, eval acc (token): 0.9372269844192437, eval acc (sequence): 0.8850634672230916
Saving at step 240000
Step 240100, loss: 0.035483856196515264, acc: 99.60317614674568, p_norm: 2152.8415378678415, g_norm: 0.4484239811099682, lr:  0.000510, elapsed time:  221574
Step 240200, loss: 0.035596116129308936, acc: 99.60289695858955, p_norm: 2152.9823354372725, g_norm: 0.6860248206806213, lr:  0.000510, elapsed time:  221662
Step 240300, loss: 0.03636405996978283, acc: 99.57508765161037, p_norm: 2153.112048056059, g_norm: 0.6325777044065785, lr:  0.000510, elapsed time:  221755
Step 240400, loss: 0.035947295897640286, acc: 99.59261021018028, p_norm: 2153.245168265241, g_norm: 0.4101035972725739, lr:  0.000510, elapsed time:  221843
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 240500, loss: 0.03483378673180309, acc: 99.62327390095732, p_norm: 2153.3824430281584, g_norm: 0.47086906140596185, lr:  0.000510, elapsed time:  221932
Step 240600, loss: 0.03524965440388769, acc: 99.60105620324612, p_norm: 2153.5031987318175, g_norm: 0.7175533432414987, lr:  0.000510, elapsed time:  222022
Step 240700, loss: 0.03484424438327551, acc: 99.6225265711546, p_norm: 2153.608880271855, g_norm: 0.6238394862659823, lr:  0.000509, elapsed time:  222113
Step 240800, loss: 0.03526076356880367, acc: 99.60482558608055, p_norm: 2153.7448638191186, g_norm: 0.5530738659931281, lr:  0.000509, elapsed time:  222200
Step 240900, loss: 0.03531773992814124, acc: 99.6071874499321, p_norm: 2153.870800954009, g_norm: 0.5398361812507653, lr:  0.000509, elapsed time:  222293
Step 241000, loss: 0.03551699218340218, acc: 99.6019038259983, p_norm: 2154.0002632779588, g_norm: 0.6632751527754339, lr:  0.000509, elapsed time:  222383
Step 241100, loss: 0.03514278899412602, acc: 99.60780066251755, p_norm: 2154.1332968716015, g_norm: 0.7061009002417853, lr:  0.000509, elapsed time:  222474
Step 241200, loss: 0.03541806122753769, acc: 99.60035343468189, p_norm: 2154.2639433962395, g_norm: 0.6187587511896258, lr:  0.000509, elapsed time:  222573
Step 241300, loss: 0.03466183212120086, acc: 99.62202145159245, p_norm: 2154.407232533128, g_norm: 0.5868232583142589, lr:  0.000509, elapsed time:  222665
Step 241400, loss: 0.035094168642535804, acc: 99.60723996162415, p_norm: 2154.5334877197724, g_norm: 0.5276784077648405, lr:  0.000509, elapsed time:  222756
Step 241500, loss: 0.035063596367836, acc: 99.61271111667156, p_norm: 2154.6562654019426, g_norm: 0.464487881962858, lr:  0.000509, elapsed time:  222854
Step 241600, loss: 0.03525691192597151, acc: 99.60558706521988, p_norm: 2154.789106529802, g_norm: 0.65051827146831, lr:  0.000508, elapsed time:  222945
Step 241700, loss: 0.03621089838910848, acc: 99.57254911959171, p_norm: 2154.921853557293, g_norm: 0.6073896593355951, lr:  0.000508, elapsed time:  223035
Step 241800, loss: 0.03569826167542487, acc: 99.58658649027348, p_norm: 2155.044820269246, g_norm: 0.6685437507683275, lr:  0.000508, elapsed time:  223125
Step 241900, loss: 0.03591137027833611, acc: 99.584304317832, p_norm: 2155.1873345673043, g_norm: 1.1832334224268346, lr:  0.000508, elapsed time:  223214
Step 242000, loss: 0.03570908072870225, acc: 99.59778280556202, p_norm: 2155.3139498462883, g_norm: 0.5391654955410916, lr:  0.000508, elapsed time:  223307
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 242000, eval loss: 0.04522932408377528, eval acc: 99.49777221679688
Step 242100, loss: 0.035979861891828474, acc: 99.59814204275608, p_norm: 2155.4569598571898, g_norm: 0.5991101015188784, lr:  0.000508, elapsed time:  223415
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 242200, loss: 0.03450320277446257, acc: 99.63176504849795, p_norm: 2155.592154175564, g_norm: 0.7054887438437887, lr:  0.000508, elapsed time:  223509
Step 242300, loss: 0.034695689757354556, acc: 99.617307305336, p_norm: 2155.7220426519525, g_norm: 0.4873981233966116, lr:  0.000508, elapsed time:  223599
Step 242400, loss: 0.0356096348259598, acc: 99.59645979106426, p_norm: 2155.8683732889094, g_norm: 0.8496992683740093, lr:  0.000508, elapsed time:  223689
Step 242500, loss: 0.03543891593348235, acc: 99.59286695718765, p_norm: 2155.98459020266, g_norm: 0.5284409460136995, lr:  0.000508, elapsed time:  223783
Step 242600, loss: 0.03504610175266862, acc: 99.61325931549072, p_norm: 2156.113155116059, g_norm: 0.9878376149986308, lr:  0.000507, elapsed time:  223876
Step 242700, loss: 0.03604616563767195, acc: 99.58654557168484, p_norm: 2156.2471238641638, g_norm: 0.5293486420127499, lr:  0.000507, elapsed time:  223968
Step 242800, loss: 0.03504226788878441, acc: 99.60404469072819, p_norm: 2156.3619849935712, g_norm: 0.539461192677996, lr:  0.000507, elapsed time:  224064
Step 242900, loss: 0.0356455791182816, acc: 99.59508210420609, p_norm: 2156.492007134133, g_norm: 0.441242866430572, lr:  0.000507, elapsed time:  224151
Step 243000, loss: 0.035346197178587314, acc: 99.60142578184605, p_norm: 2156.616068548744, g_norm: 0.4345256763413011, lr:  0.000507, elapsed time:  224239
Step 243100, loss: 0.03513891806360334, acc: 99.60390841960907, p_norm: 2156.737356284119, g_norm: 0.6323357616540526, lr:  0.000507, elapsed time:  224327
Step 243200, loss: 0.034903435967862606, acc: 99.61210411787033, p_norm: 2156.8754088186292, g_norm: 0.9735337019582633, lr:  0.000507, elapsed time:  224421
Step 243300, loss: 0.03529104352463037, acc: 99.6030505746603, p_norm: 2157.005269073988, g_norm: 0.6248683398266791, lr:  0.000507, elapsed time:  224508
Step 243400, loss: 0.035485605676658455, acc: 99.59879139065742, p_norm: 2157.126720320676, g_norm: 0.6879229482388103, lr:  0.000507, elapsed time:  224598
Step 243500, loss: 0.0351874178275466, acc: 99.60969586670399, p_norm: 2157.2605727669816, g_norm: 0.5218800407001969, lr:  0.000506, elapsed time:  224686
Step 243600, loss: 0.03480443647596985, acc: 99.61768612265587, p_norm: 2157.3806246719687, g_norm: 0.5479047650494284, lr:  0.000506, elapsed time:  224776
Step 243700, loss: 0.03458478910848498, acc: 99.62478540837765, p_norm: 2157.5127068310467, g_norm: 0.4544310951106839, lr:  0.000506, elapsed time:  224868
Step 243800, loss: 0.03622100993990898, acc: 99.58473436534405, p_norm: 2157.6496223824834, g_norm: 0.5242674967399865, lr:  0.000506, elapsed time:  224958
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 243900, loss: 0.03494243615246679, acc: 99.6151351958365, p_norm: 2157.771546393341, g_norm: 0.4804653132189544, lr:  0.000506, elapsed time:  225050
Step 244000, loss: 0.03523839199915528, acc: 99.6124047189951, p_norm: 2157.9010715514896, g_norm: 0.528671184692322, lr:  0.000506, elapsed time:  225137
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 244000, eval loss: 0.04315505849197507, eval acc: 99.5323486328125
Step 244100, loss: 0.03528525459580124, acc: 99.60158067941666, p_norm: 2158.0293783324646, g_norm: 0.7425816400259142, lr:  0.000506, elapsed time:  225241
Step 244200, loss: 0.03478418577928096, acc: 99.62188917398453, p_norm: 2158.140219913281, g_norm: 0.7043134912566221, lr:  0.000506, elapsed time:  225331
Step 244300, loss: 0.03523460722528398, acc: 99.61613261699677, p_norm: 2158.2728550798333, g_norm: 0.48488012840783884, lr:  0.000506, elapsed time:  225421
Step 244400, loss: 0.03554074492771178, acc: 99.59701681137085, p_norm: 2158.3977052032064, g_norm: 0.674675276998821, lr:  0.000506, elapsed time:  225517
Step 244500, loss: 0.03438074229750782, acc: 99.6262425929308, p_norm: 2158.524720621956, g_norm: 0.5398616694039297, lr:  0.000505, elapsed time:  225610
Step 244600, loss: 0.03456966953817755, acc: 99.62479177117348, p_norm: 2158.6550162107983, g_norm: 0.5648471777048402, lr:  0.000505, elapsed time:  225705
Step 244700, loss: 0.03509770646225661, acc: 99.6055263876915, p_norm: 2158.7844318864227, g_norm: 1.0953276164444345, lr:  0.000505, elapsed time:  225797
Step 244800, loss: 0.036220521172508596, acc: 99.5728181451559, p_norm: 2158.9287508076277, g_norm: 0.6342045099067953, lr:  0.000505, elapsed time:  225895
Step 244900, loss: 0.03498144120443612, acc: 99.61135396361351, p_norm: 2159.048091533828, g_norm: 0.5805298084207061, lr:  0.000505, elapsed time:  225987
Step 245000, loss: 0.03557469787076115, acc: 99.59850238263607, p_norm: 2159.181909013303, g_norm: 0.5346754097205463, lr:  0.000505, elapsed time:  226077
Calling G2SDataset.batch()
Done, time:  0.05 s, total batches: 527
Target text: C C N 1 C C C ( N ( C = O ) C 2 C C 2 ) c 2 c c c c ( C O ) c 2 1 _EOS
Predicted text: C C N 1 C C C ( N ( C = O ) C 2 C C 2 ) c 2 c c c c ( C O ) c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( N c 2 n c c c ( C ( F ) ( F ) F ) n 2 ) c c ( - c 2 c n c ( C ( O ) C ( F ) ( F ) F ) s 2 ) c 1 _EOS
Predicted text: C c 1 c c ( N c 2 n c c c ( C ( F ) ( F ) F ) n 2 ) c c ( - c 2 c n c ( C ( O ) C ( F ) ( F ) F ) s 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C O c 1 c ( - c 2 c c c c 3 s c ( C ( C ) = C C ( = O ) O C C ) c c 2 3 ) c c ( C ( C ) C ) c c 1 C ( C ) C _EOS
Predicted text: C C C C O c 1 c ( - c 2 c c c c 3 s c ( C ( C ) = C C ( = O ) O C C ) c c 2 3 ) c c ( C ( C ) C ) c c 1 C ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C N 1 C C N C C 1 ) c 1 c c c ( Cl ) c c 1 _EOS
Predicted text: C C ( C ( = O ) c 1 c c c ( Cl ) c c 1 ) N 1 C C N ( C C ( = O ) c 2 c c c ( Cl ) c c 2 ) C C 1 _EOS
acc_token: 0.07692307692307693, acc_seq: False

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C C ( N c 2 c c c 3 [nH] c c c 3 c 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C C ( N c 2 c c c 3 [nH] c c c 3 c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 245000, eval acc (token): 0.9378463410620663, eval acc (sequence): 0.8844584569732937
Saving at step 245000
Step 245100, loss: 0.0348748118756339, acc: 99.62508425116539, p_norm: 2159.316738805535, g_norm: 0.6361369142383819, lr:  0.000505, elapsed time:  226237
Step 245200, loss: 0.03579401752445847, acc: 99.59051042795181, p_norm: 2159.466820923066, g_norm: 0.6879573426701373, lr:  0.000505, elapsed time:  226326
Step 245300, loss: 0.035120971156284216, acc: 99.61547164618969, p_norm: 2159.583443442311, g_norm: 0.9419059168925379, lr:  0.000505, elapsed time:  226417
Step 245400, loss: 0.03525870140176266, acc: 99.61151652038097, p_norm: 2159.698478562427, g_norm: 0.6731298283026128, lr:  0.000505, elapsed time:  226508
Step 245500, loss: 0.03536958584561944, acc: 99.59498082101345, p_norm: 2159.8216718464714, g_norm: 0.5655732540894006, lr:  0.000504, elapsed time:  226595
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 245600, loss: 0.03402745558720812, acc: 99.63384431881585, p_norm: 2159.9442631462957, g_norm: 0.7661974204971247, lr:  0.000504, elapsed time:  226681
Step 245700, loss: 0.03484325569588691, acc: 99.61791472136974, p_norm: 2160.063833804682, g_norm: 0.7275247479767198, lr:  0.000504, elapsed time:  226767
Step 245800, loss: 0.03483454171568155, acc: 99.6132285296917, p_norm: 2160.2004190641997, g_norm: 0.5170318657436905, lr:  0.000504, elapsed time:  226857
Step 245900, loss: 0.03460390956606716, acc: 99.6225761026144, p_norm: 2160.328960147933, g_norm: 0.6275739032307914, lr:  0.000504, elapsed time:  226947
Step 246000, loss: 0.036055461447685955, acc: 99.5878299921751, p_norm: 2160.4643967596858, g_norm: 0.954409275585745, lr:  0.000504, elapsed time:  227040
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 246000, eval loss: 0.041878341045230597, eval acc: 99.54643249511719
Step 246100, loss: 0.03590722222812474, acc: 99.59345981478691, p_norm: 2160.6049488708354, g_norm: 0.7201653829583412, lr:  0.000504, elapsed time:  227152
Step 246200, loss: 0.03568263649009168, acc: 99.59797947108746, p_norm: 2160.740758876942, g_norm: 0.5841466913961681, lr:  0.000504, elapsed time:  227244
Step 246300, loss: 0.03474983383435756, acc: 99.62228134274483, p_norm: 2160.8570524632855, g_norm: 0.47781830405594317, lr:  0.000504, elapsed time:  227341
Step 246400, loss: 0.034975219899788496, acc: 99.61419560015202, p_norm: 2160.9758970406774, g_norm: 0.6876024923897236, lr:  0.000503, elapsed time:  227439
Step 246500, loss: 0.03473751517478377, acc: 99.6235441416502, p_norm: 2161.1075309535, g_norm: 0.4449587235984556, lr:  0.000503, elapsed time:  227532
Step 246600, loss: 0.03517174973152578, acc: 99.6149090975523, p_norm: 2161.235574902961, g_norm: 0.7358197905592538, lr:  0.000503, elapsed time:  227622
Step 246700, loss: 0.035416968958452345, acc: 99.60220727324486, p_norm: 2161.363522874242, g_norm: 0.5994602065436389, lr:  0.000503, elapsed time:  227713
Step 246800, loss: 0.03676725571509451, acc: 99.59138123691082, p_norm: 2161.4916271991697, g_norm: 0.4094711198739364, lr:  0.000503, elapsed time:  227810
Step 246900, loss: 0.036870163860730824, acc: 99.59162430465221, p_norm: 2161.6193266172863, g_norm: 0.5372181198174176, lr:  0.000503, elapsed time:  227904
Step 247000, loss: 0.03638480683788657, acc: 99.60694938898087, p_norm: 2161.7483460405497, g_norm: 0.6142020632918457, lr:  0.000503, elapsed time:  227995
Step 247100, loss: 0.03628310069907457, acc: 99.58436438441277, p_norm: 2161.855771799684, g_norm: 0.6134363727944107, lr:  0.000503, elapsed time:  228088
Step 247200, loss: 0.03545540340710431, acc: 99.60955607891083, p_norm: 2161.976026686932, g_norm: 0.5248979345279464, lr:  0.000503, elapsed time:  228179
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 247300, loss: 0.03493412084433784, acc: 99.61321935168567, p_norm: 2162.080953847857, g_norm: 0.5916018554815496, lr:  0.000503, elapsed time:  228271
Step 247400, loss: 0.03458042335230857, acc: 99.62407806515694, p_norm: 2162.2021450373604, g_norm: 0.6672581800579515, lr:  0.000502, elapsed time:  228361
Step 247500, loss: 0.03493493021465838, acc: 99.6069884300232, p_norm: 2162.340318211423, g_norm: 0.8138215538773894, lr:  0.000502, elapsed time:  228450
Step 247600, loss: 0.03443580656312406, acc: 99.62592278420925, p_norm: 2162.466274987974, g_norm: 0.4207173931871114, lr:  0.000502, elapsed time:  228540
Step 247700, loss: 0.035387111720629034, acc: 99.59944993257523, p_norm: 2162.60100835046, g_norm: 0.6921833467888596, lr:  0.000502, elapsed time:  228630
Step 247800, loss: 0.03576170878484845, acc: 99.58658835291862, p_norm: 2162.734747141115, g_norm: 0.549799546545259, lr:  0.000502, elapsed time:  228721
Step 247900, loss: 0.03508257543668151, acc: 99.61681579053402, p_norm: 2162.904182995707, g_norm: 0.5887677064337582, lr:  0.000502, elapsed time:  228813
Step 248000, loss: 0.03525557950604707, acc: 99.61005781590939, p_norm: 2163.03344645872, g_norm: 0.6510705562425809, lr:  0.000502, elapsed time:  228904
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 248000, eval loss: 0.044259994160383946, eval acc: 99.49738311767578
Step 248100, loss: 0.03530782861169428, acc: 99.60665860772133, p_norm: 2163.156909300852, g_norm: 0.6620028401782068, lr:  0.000502, elapsed time:  229010
Step 248200, loss: 0.034340383745729924, acc: 99.63114388287067, p_norm: 2163.2786387307674, g_norm: 0.5511868044781052, lr:  0.000502, elapsed time:  229105
Step 248300, loss: 0.03439291059039533, acc: 99.62409122288227, p_norm: 2163.4013080388468, g_norm: 1.0913722512105812, lr:  0.000502, elapsed time:  229195
Step 248400, loss: 0.035380092053674164, acc: 99.60609342157841, p_norm: 2163.5192548256323, g_norm: 0.4953653189102864, lr:  0.000501, elapsed time:  229287
Step 248500, loss: 0.0353017088258639, acc: 99.60278743505478, p_norm: 2163.6463789923187, g_norm: 0.70306288874071, lr:  0.000501, elapsed time:  229381
Step 248600, loss: 0.03556655976455659, acc: 99.59928454458714, p_norm: 2163.7771910408364, g_norm: 0.5728109035756709, lr:  0.000501, elapsed time:  229470
Step 248700, loss: 0.0354326111311093, acc: 99.598793014884, p_norm: 2163.9078717943844, g_norm: 0.5948542866998646, lr:  0.000501, elapsed time:  229563
Step 248800, loss: 0.03523863779846579, acc: 99.60629765689373, p_norm: 2164.0279703216524, g_norm: 0.6531712020169145, lr:  0.000501, elapsed time:  229658
Step 248900, loss: 0.035529830385930834, acc: 99.59733307361603, p_norm: 2164.1526028426283, g_norm: 0.5492966007557792, lr:  0.000501, elapsed time:  229748
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 249000, loss: 0.0347177400889231, acc: 99.61663993357429, p_norm: 2164.2770132280602, g_norm: 0.6733390412620143, lr:  0.000501, elapsed time:  229841
Step 249100, loss: 0.034409281741827724, acc: 99.62716004252434, p_norm: 2164.3915879025735, g_norm: 0.5888210790008397, lr:  0.000501, elapsed time:  229936
Step 249200, loss: 0.03542178553529084, acc: 99.59546659886837, p_norm: 2164.5178862478942, g_norm: 0.4880918388256252, lr:  0.000501, elapsed time:  230025
Step 249300, loss: 0.03482626730576158, acc: 99.61763124167919, p_norm: 2164.6488465896628, g_norm: 0.751552166182388, lr:  0.000501, elapsed time:  230114
Step 249400, loss: 0.03484867047984153, acc: 99.61468476057053, p_norm: 2164.788173225981, g_norm: 0.5402366429061254, lr:  0.000500, elapsed time:  230203
Step 249500, loss: 0.03531642376910895, acc: 99.59625644981861, p_norm: 2164.92097890437, g_norm: 0.5340327649029811, lr:  0.000500, elapsed time:  230293
Step 249600, loss: 0.03521781614515931, acc: 99.59826047718525, p_norm: 2165.040066428853, g_norm: 0.5953456366113395, lr:  0.000500, elapsed time:  230390
Step 249700, loss: 0.034757005595602096, acc: 99.61695499718189, p_norm: 2165.1744674308466, g_norm: 0.5070825453024329, lr:  0.000500, elapsed time:  230477
Step 249800, loss: 0.03480426735710353, acc: 99.6217623502016, p_norm: 2165.292246357949, g_norm: 0.6754432746586767, lr:  0.000500, elapsed time:  230567
Step 249900, loss: 0.03559363279957324, acc: 99.59720030426979, p_norm: 2165.4088640723444, g_norm: 0.595662930468405, lr:  0.000500, elapsed time:  230653
Step 250000, loss: 0.035835571573115885, acc: 99.596794500947, p_norm: 2165.5393284718425, g_norm: 0.49933057702623596, lr:  0.000500, elapsed time:  230744
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 250000, eval loss: 0.044368816036731006, eval acc: 99.51660919189453
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( N C ( C c 1 c c c c ( S ( = O ) ( = O ) C ( F ) ( F ) F ) c 1 ) C ( O ) c 1 c c c ( F ) c c 1 ) c 1 c c c c 2 c 1 C = C C C C 2 _EOS
Predicted text: O = C ( N C ( C c 1 c c c c ( S ( = O ) ( = O ) C ( F ) ( F ) F ) c 1 ) C ( O ) c 1 c c c ( F ) c c 1 ) c 1 c c c c 2 c 1 C = C C C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: c 1 c c c ( C c 2 c c c 3 o c c c 3 c 2 ) n c 1 _EOS
Predicted text: Br C ( c 1 c c c 2 o c c c 2 c 1 ) c 1 c c c c n 1 _EOS
acc_token: 0.28, acc_seq: False

Target text: O = C 1 N c 2 c c c ( O c 3 c c ( F ) c ( C ( F ) ( F ) F ) c ( Cl ) c 3 ) c c 2 C 1 2 C C 2 _EOS
Predicted text: O = C 1 N c 2 c c c ( O c 3 c c ( F ) c ( C ( F ) ( F ) F ) c ( Cl ) c 3 ) c c 2 C 1 2 C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: c 1 c c c 2 c ( c 1 ) C C C O 2 _EOS
Predicted text: c 1 c c c 2 c ( c 1 ) C C C O 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( N c 2 n c ( C ( = O ) O ) c ( C ) s 2 ) c c 1 O C _EOS
Predicted text: C O c 1 c c c ( N c 2 n c ( C ( = O ) O ) c ( C ) s 2 ) c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 250000, eval acc (token): 0.9334743834992192, eval acc (sequence): 0.8795180722891566
Saving at step 250000
Step 250100, loss: 0.03578833926934749, acc: 99.59078423678875, p_norm: 2165.677052117256, g_norm: 0.5527249462835044, lr:  0.000500, elapsed time:  230928
Step 250200, loss: 0.03477538036182523, acc: 99.6284967660904, p_norm: 2165.80216235523, g_norm: 0.5985297988340843, lr:  0.000500, elapsed time:  231021
Step 250300, loss: 0.034262605421245096, acc: 99.63775135576725, p_norm: 2165.9189430817482, g_norm: 0.4382180312701401, lr:  0.000500, elapsed time:  231111
Step 250400, loss: 0.034891076292842625, acc: 99.61866596341133, p_norm: 2166.026130641796, g_norm: 0.6987720528307022, lr:  0.000499, elapsed time:  231199
Step 250500, loss: 0.03477298404090107, acc: 99.61909686028957, p_norm: 2166.1510323556327, g_norm: 0.7627607062415338, lr:  0.000499, elapsed time:  231289
Step 250600, loss: 0.0349526963243261, acc: 99.61659364402294, p_norm: 2166.2883505225586, g_norm: 0.5536015166790467, lr:  0.000499, elapsed time:  231378
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 250700, loss: 0.0343504983737658, acc: 99.62493700365866, p_norm: 2166.4068833843544, g_norm: 0.7011335797740403, lr:  0.000499, elapsed time:  231471
Step 250800, loss: 0.03472921015229076, acc: 99.6209367364645, p_norm: 2166.517487353241, g_norm: 0.5960626549552118, lr:  0.000499, elapsed time:  231561
Step 250900, loss: 0.034532090183347464, acc: 99.61533315479755, p_norm: 2166.6519098732165, g_norm: 0.5368135219865823, lr:  0.000499, elapsed time:  231648
Step 251000, loss: 0.03498587873764336, acc: 99.61265367269516, p_norm: 2166.7834596322737, g_norm: 0.7341094362364107, lr:  0.000499, elapsed time:  231744
Step 251100, loss: 0.03539188413415104, acc: 99.59697344899178, p_norm: 2166.9190904040383, g_norm: 0.6764390622528329, lr:  0.000499, elapsed time:  231840
Step 251200, loss: 0.03483809947967529, acc: 99.61927917599678, p_norm: 2167.0331719751352, g_norm: 0.5736481031381163, lr:  0.000499, elapsed time:  231933
Step 251300, loss: 0.03512475425843149, acc: 99.60570392012596, p_norm: 2167.16524203128, g_norm: 0.5313255761382073, lr:  0.000499, elapsed time:  232014
Step 251400, loss: 0.03501052164472639, acc: 99.60674595832825, p_norm: 2167.2976778952884, g_norm: 0.6211528118339785, lr:  0.000498, elapsed time:  232113
Step 251500, loss: 0.03423578800167888, acc: 99.63967955112457, p_norm: 2167.4132232813167, g_norm: 0.5556878660144865, lr:  0.000498, elapsed time:  232203
Step 251600, loss: 0.03422659280709922, acc: 99.64456464350224, p_norm: 2167.5339969814586, g_norm: 0.8469688083760245, lr:  0.000498, elapsed time:  232293
Step 251700, loss: 0.03533639188390225, acc: 99.60654875636101, p_norm: 2167.6500913569575, g_norm: 0.7066391508353763, lr:  0.000498, elapsed time:  232383
Step 251800, loss: 0.03529100820887834, acc: 99.6086115539074, p_norm: 2167.784206538737, g_norm: 0.555945078148, lr:  0.000498, elapsed time:  232476
Step 251900, loss: 0.035751016465947034, acc: 99.60163083672523, p_norm: 2167.915213076084, g_norm: 0.7109590777868324, lr:  0.000498, elapsed time:  232564
Step 252000, loss: 0.03499261249322444, acc: 99.61352954804897, p_norm: 2168.0365587989427, g_norm: 0.6689335459409148, lr:  0.000498, elapsed time:  232651
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 252000, eval loss: 0.046248820573091515, eval acc: 99.46699523925781
Step 252100, loss: 0.035728011541068555, acc: 99.59659306704998, p_norm: 2168.158408813402, g_norm: 0.6831433947818535, lr:  0.000498, elapsed time:  232765
Step 252200, loss: 0.034824524163268505, acc: 99.61841456592083, p_norm: 2168.2810269351125, g_norm: 0.6163143277666208, lr:  0.000498, elapsed time:  232858
Step 252300, loss: 0.03450491044204682, acc: 99.63333481550217, p_norm: 2168.4238962547533, g_norm: 0.8318368805965002, lr:  0.000498, elapsed time:  232941
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6822
Step 252400, loss: 0.0353929476293536, acc: 99.59556555273521, p_norm: 2168.545261049746, g_norm: 0.5313876613914715, lr:  0.000497, elapsed time:  233010
Step 252500, loss: 0.03520200373604894, acc: 99.60576087236404, p_norm: 2168.6730338912134, g_norm: 0.6279285224103832, lr:  0.000497, elapsed time:  233081
Step 252600, loss: 0.03442573498003185, acc: 99.62179753184319, p_norm: 2168.7834867093225, g_norm: 0.7602922154182054, lr:  0.000497, elapsed time:  233173
Step 252700, loss: 0.03449362099636346, acc: 99.63163141906261, p_norm: 2168.909034478546, g_norm: 0.5431620934833873, lr:  0.000497, elapsed time:  233261
Step 252800, loss: 0.034338984871283174, acc: 99.63303771615028, p_norm: 2169.0226977755565, g_norm: 0.5082066988311683, lr:  0.000497, elapsed time:  233354
Step 252900, loss: 0.03475420471280813, acc: 99.61598731577396, p_norm: 2169.1397088708004, g_norm: 0.648782603906248, lr:  0.000497, elapsed time:  233454
Step 253000, loss: 0.03547634246293455, acc: 99.59874767065048, p_norm: 2169.2538720010257, g_norm: 0.6243380634116475, lr:  0.000497, elapsed time:  233545
Step 253100, loss: 0.034711901741102336, acc: 99.62468487024307, p_norm: 2169.3854368349394, g_norm: 0.6379524315896471, lr:  0.000497, elapsed time:  233635
Step 253200, loss: 0.03454515056684613, acc: 99.6236957013607, p_norm: 2169.5159888229023, g_norm: 0.6093390793532159, lr:  0.000497, elapsed time:  233726
Step 253300, loss: 0.0351538697257638, acc: 99.6022229641676, p_norm: 2169.6380738250346, g_norm: 0.497181012769724, lr:  0.000497, elapsed time:  233818
Step 253400, loss: 0.035207132203504445, acc: 99.6092122644186, p_norm: 2169.755910240341, g_norm: 0.7314174510654068, lr:  0.000496, elapsed time:  233906
Step 253500, loss: 0.035356482244096696, acc: 99.60399070382118, p_norm: 2169.8913597341925, g_norm: 0.4693241936876457, lr:  0.000496, elapsed time:  234005
Step 253600, loss: 0.03512314517516643, acc: 99.61118820309639, p_norm: 2170.0215974048665, g_norm: 0.5566099699847341, lr:  0.000496, elapsed time:  234089
Step 253700, loss: 0.03517499989829957, acc: 99.61190801858902, p_norm: 2170.154618442729, g_norm: 0.6169645391659768, lr:  0.000496, elapsed time:  234181
Step 253800, loss: 0.034792724638246, acc: 99.6193497478962, p_norm: 2170.2823384822386, g_norm: 0.7700697942180268, lr:  0.000496, elapsed time:  234272
Step 253900, loss: 0.03481679858174175, acc: 99.62227587401867, p_norm: 2170.4025888524384, g_norm: 0.5740466381241164, lr:  0.000496, elapsed time:  234366
Step 254000, loss: 0.03571895783301443, acc: 99.61143183708191, p_norm: 2170.5397307003436, g_norm: 0.7591165425455537, lr:  0.000496, elapsed time:  234456
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 254000, eval loss: 0.046938588656485064, eval acc: 99.5098876953125
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 254100, loss: 0.03594942242648471, acc: 99.61006946824676, p_norm: 2170.6586922578135, g_norm: 0.44450184784790875, lr:  0.000496, elapsed time:  234562
Step 254200, loss: 0.03545489835552871, acc: 99.6134093105793, p_norm: 2170.785682271503, g_norm: 0.4878228602569311, lr:  0.000496, elapsed time:  234656
Step 254300, loss: 0.03510842471849173, acc: 99.61535120010376, p_norm: 2170.8996120352012, g_norm: 0.731678644787284, lr:  0.000496, elapsed time:  234745
Step 254400, loss: 0.0346532434085384, acc: 99.62712094187737, p_norm: 2171.025217670912, g_norm: 0.5701786536335566, lr:  0.000496, elapsed time:  234839
Step 254500, loss: 0.034318050048314036, acc: 99.63534715771675, p_norm: 2171.1402498090047, g_norm: 0.5425974212988854, lr:  0.000495, elapsed time:  234931
Step 254600, loss: 0.03411876718513668, acc: 99.64131546020508, p_norm: 2171.2707104990677, g_norm: 0.7221267008705796, lr:  0.000495, elapsed time:  235022
Step 254700, loss: 0.03495546534657478, acc: 99.624710470438, p_norm: 2171.4152710509184, g_norm: 0.7534795378719359, lr:  0.000495, elapsed time:  235113
Step 254800, loss: 0.034722835579887035, acc: 99.61732859909534, p_norm: 2171.536100496045, g_norm: 0.531093901614299, lr:  0.000495, elapsed time:  235198
Step 254900, loss: 0.035330906938761474, acc: 99.5962460488081, p_norm: 2171.6423463442943, g_norm: 0.6830203619788809, lr:  0.000495, elapsed time:  235265
Step 255000, loss: 0.034517616247758266, acc: 99.6285435706377, p_norm: 2171.7705606236905, g_norm: 0.6598008665085717, lr:  0.000495, elapsed time:  235343
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Target text: C C O C ( = O ) c 1 c c c ( - c 2 n n c ( - c 3 c c c c c 3 N ) o 2 ) c c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c c c ( - c 2 n n c ( - c 3 c c c c c 3 N ) o 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C N ( C ( C ) ( C ) C O ) C C 3 ) n ( C ) c 2 n 1 _EOS
Predicted text: C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C N ( C ( C ) ( C ) C O ) C C 3 ) n ( C ) c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C c 1 c ( O C C C O c 2 c c c ( C ) c ( N C ( = O ) C ( = O ) O C ) c 2 ) c c c ( C ( C ) = O ) c 1 O _EOS
Predicted text: C C C c 1 c ( O C C C O c 2 c c c ( C ) c ( N C ( = O ) C ( = O ) O C ) c 2 ) c c c ( C ( C ) = O ) c 1 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C 4 C C 3 C N 4 S ( C ) ( = O ) = O ) n ( C ) c 2 n 1 _EOS
Predicted text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C 4 C C 3 C N 4 S ( C ) ( = O ) = O ) n ( C ) c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C # C C O c 1 c c ( C c 2 c c c c c 2 Br ) n c n 1 _EOS
Predicted text: C C # C C O c 1 c c ( C c 2 c c c c c 2 Br ) n c n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 255000, eval acc (token): 0.9353294718745441, eval acc (sequence): 0.8835922156757722
Saving at step 255000
Step 255100, loss: 0.035431425240822136, acc: 99.60104730725288, p_norm: 2171.885073803949, g_norm: 0.6504428143916754, lr:  0.000495, elapsed time:  235509
Step 255200, loss: 0.035441123354248705, acc: 99.59975431859493, p_norm: 2172.0023171372222, g_norm: 0.5115654401671774, lr:  0.000495, elapsed time:  235598
Step 255300, loss: 0.034619145984761415, acc: 99.6283617913723, p_norm: 2172.110232390283, g_norm: 0.5138302633372869, lr:  0.000495, elapsed time:  235688
Step 255400, loss: 0.0345297543797642, acc: 99.62552253901958, p_norm: 2172.2226257218736, g_norm: 0.5141244636945318, lr:  0.000495, elapsed time:  235780
Step 255500, loss: 0.03492704491131007, acc: 99.61460770666599, p_norm: 2172.346404208998, g_norm: 0.718802369478367, lr:  0.000494, elapsed time:  235868
Step 255600, loss: 0.034342441614717244, acc: 99.63929535448551, p_norm: 2172.4654588306257, g_norm: 0.6473405092790396, lr:  0.000494, elapsed time:  235966
Step 255700, loss: 0.0354980487935245, acc: 99.60101348161697, p_norm: 2172.6039625052954, g_norm: 0.5634281122952347, lr:  0.000494, elapsed time:  236058
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 255800, loss: 0.035013782285690014, acc: 99.61006060131726, p_norm: 2172.7163983329947, g_norm: 0.7399724798349767, lr:  0.000494, elapsed time:  236148
Step 255900, loss: 0.03433283740654588, acc: 99.63549244403839, p_norm: 2172.8343350480854, g_norm: 0.47064416039981427, lr:  0.000494, elapsed time:  236245
Step 256000, loss: 0.034687656136229636, acc: 99.62299090623856, p_norm: 2172.93928814241, g_norm: 0.48549408524823917, lr:  0.000494, elapsed time:  236342
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 256000, eval loss: 0.043606738746166225, eval acc: 99.54092407226562
Step 256100, loss: 0.035570942340418694, acc: 99.62515185773373, p_norm: 2173.0690790904887, g_norm: 0.5074804300157144, lr:  0.000494, elapsed time:  236446
Step 256200, loss: 0.037325143641792236, acc: 99.5981806665659, p_norm: 2173.193475428423, g_norm: 0.6732178043864249, lr:  0.000494, elapsed time:  236536
Step 256300, loss: 0.03601255588699132, acc: 99.62351895868778, p_norm: 2173.2932843350445, g_norm: 0.7087715690059473, lr:  0.000494, elapsed time:  236628
Step 256400, loss: 0.03531763915903866, acc: 99.62890402972698, p_norm: 2173.3970335154695, g_norm: 0.6352406578970428, lr:  0.000494, elapsed time:  236719
Step 256500, loss: 0.03515566679649055, acc: 99.63129460811615, p_norm: 2173.505230872949, g_norm: 0.5691750583814563, lr:  0.000493, elapsed time:  236812
Step 256600, loss: 0.03503331054467708, acc: 99.62674660980701, p_norm: 2173.6220971632138, g_norm: 0.5790035566126214, lr:  0.000493, elapsed time:  236905
Step 256700, loss: 0.035874482276849445, acc: 99.61900140345097, p_norm: 2173.7391070294925, g_norm: 0.6207702877234895, lr:  0.000493, elapsed time:  236995
Step 256800, loss: 0.03589445922058076, acc: 99.60720354318619, p_norm: 2173.8520362391123, g_norm: 0.5637730712412321, lr:  0.000493, elapsed time:  237092
Step 256900, loss: 0.0353602293273434, acc: 99.61761179566383, p_norm: 2173.965592262051, g_norm: 0.7800943946986343, lr:  0.000493, elapsed time:  237185
Step 257000, loss: 0.03505438069347292, acc: 99.61816437542439, p_norm: 2174.0852461732834, g_norm: 0.4252092762697215, lr:  0.000493, elapsed time:  237277
Step 257100, loss: 0.03573812207672745, acc: 99.60545994341373, p_norm: 2174.202971084029, g_norm: 0.5522357433322879, lr:  0.000493, elapsed time:  237369
Step 257200, loss: 0.03541667292825878, acc: 99.6047885119915, p_norm: 2174.3333227468156, g_norm: 0.5091521722519936, lr:  0.000493, elapsed time:  237460
Step 257300, loss: 0.035151383350603284, acc: 99.61514329910278, p_norm: 2174.4418056181926, g_norm: 0.6116165291728561, lr:  0.000493, elapsed time:  237551
Step 257400, loss: 0.03527514855377376, acc: 99.61552852392197, p_norm: 2174.565738681389, g_norm: 0.6257039047310388, lr:  0.000493, elapsed time:  237639
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 257500, loss: 0.03568330513909644, acc: 99.59591811998902, p_norm: 2174.6949741264307, g_norm: 0.7038870026041829, lr:  0.000493, elapsed time:  237728
Step 257600, loss: 0.03467461813241243, acc: 99.62001605331898, p_norm: 2174.830258266827, g_norm: 0.753050336120766, lr:  0.000492, elapsed time:  237818
Step 257700, loss: 0.03522619853261858, acc: 99.61125339567661, p_norm: 2174.952261966776, g_norm: 0.5068230251640921, lr:  0.000492, elapsed time:  237910
Step 257800, loss: 0.034108698945492504, acc: 99.64478228986263, p_norm: 2175.066260705958, g_norm: 0.7716236058299802, lr:  0.000492, elapsed time:  238004
Step 257900, loss: 0.0339347694022581, acc: 99.63865967094898, p_norm: 2175.1818890921277, g_norm: 0.7409943253118142, lr:  0.000492, elapsed time:  238096
Step 258000, loss: 0.03459915468469262, acc: 99.61965842545033, p_norm: 2175.3097332579287, g_norm: 0.6323752378044745, lr:  0.000492, elapsed time:  238188
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 258000, eval loss: 0.047105668596923334, eval acc: 99.45848846435547
Step 258100, loss: 0.035389321288093925, acc: 99.60708399116993, p_norm: 2175.4564550611044, g_norm: 0.5833189996455723, lr:  0.000492, elapsed time:  238298
Step 258200, loss: 0.03470132186543196, acc: 99.61720889806747, p_norm: 2175.5736481107097, g_norm: 0.6161548069215341, lr:  0.000492, elapsed time:  238389
Step 258300, loss: 0.03410789856221527, acc: 99.6354324221611, p_norm: 2175.687597993568, g_norm: 0.5965226195236468, lr:  0.000492, elapsed time:  238480
Step 258400, loss: 0.035092079760506746, acc: 99.60441583395004, p_norm: 2175.8023310251833, g_norm: 0.6511846211170377, lr:  0.000492, elapsed time:  238569
Step 258500, loss: 0.03496170958969742, acc: 99.61350792646408, p_norm: 2175.93042516599, g_norm: 0.7300504360087896, lr:  0.000492, elapsed time:  238655
Step 258600, loss: 0.0343939755577594, acc: 99.63756485283375, p_norm: 2176.0545893052367, g_norm: 0.5643459063520218, lr:  0.000491, elapsed time:  238744
Step 258700, loss: 0.034411016935482625, acc: 99.62514777481556, p_norm: 2176.1699584566677, g_norm: 0.7199886993290873, lr:  0.000491, elapsed time:  238835
Step 258800, loss: 0.03481706004124135, acc: 99.6167143881321, p_norm: 2176.2896254663647, g_norm: 0.5310095399066052, lr:  0.000491, elapsed time:  238925
Step 258900, loss: 0.03483409842476249, acc: 99.62245652079582, p_norm: 2176.415306443524, g_norm: 0.5996258265583434, lr:  0.000491, elapsed time:  239000
Step 259000, loss: 0.03420189884025603, acc: 99.63599461317062, p_norm: 2176.5490872860414, g_norm: 0.5336475971703862, lr:  0.000491, elapsed time:  239070
Step 259100, loss: 0.034718393455259504, acc: 99.6188695281744, p_norm: 2176.6700851910555, g_norm: 0.49065824282271686, lr:  0.000491, elapsed time:  239141
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6822
Step 259200, loss: 0.03427717515003326, acc: 99.63931364206532, p_norm: 2176.7812286284757, g_norm: 0.5985796014052122, lr:  0.000491, elapsed time:  239210
Step 259300, loss: 0.03399791060015559, acc: 99.63512261211872, p_norm: 2176.904151629699, g_norm: 0.4949341281266595, lr:  0.000491, elapsed time:  239283
Step 259400, loss: 0.03425840842537582, acc: 99.6345975548029, p_norm: 2177.0240506724476, g_norm: 0.6143257851169766, lr:  0.000491, elapsed time:  239353
Step 259500, loss: 0.034124740394763646, acc: 99.63973794877529, p_norm: 2177.1340503670685, g_norm: 0.6967481639882501, lr:  0.000491, elapsed time:  239423
Step 259600, loss: 0.034602785385213795, acc: 99.62129645049572, p_norm: 2177.251805053972, g_norm: 0.5908936576357376, lr:  0.000491, elapsed time:  239489
Step 259700, loss: 0.03394284137524664, acc: 99.64611934125423, p_norm: 2177.3707107038863, g_norm: 0.695938982086455, lr:  0.000490, elapsed time:  239559
Step 259800, loss: 0.03465354930143803, acc: 99.61727492511272, p_norm: 2177.4831611667337, g_norm: 0.555049605978849, lr:  0.000490, elapsed time:  239630
Step 259900, loss: 0.03843523861840367, acc: 99.60871857404709, p_norm: 2177.650104950057, g_norm: 0.6454373698691028, lr:  0.000490, elapsed time:  239697
Step 260000, loss: 0.036515468540601434, acc: 99.59159816801548, p_norm: 2177.7555877453733, g_norm: 0.7177883054756602, lr:  0.000490, elapsed time:  239765
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 260000, eval loss: 0.04780913341790437, eval acc: 99.44496154785156
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C N ( C ) C C C n 1 c c ( C 2 = C ( c 3 c [nH] c 4 c c c c c 3 4 ) C ( = O ) N ( C ) C 2 = O ) c 2 c c c c c 2 1 _EOS
Predicted text: C N ( C ) C C C n 1 c c ( C 2 = C ( c 3 c [nH] c 4 c c c c c 3 4 ) C ( = O ) N ( C ) C 2 = O ) c 2 c c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C 1 ( C = C ) C C C ( C O C ( c 2 c c c c c 2 ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) O 1 _EOS
Predicted text: C = C C ( O ) ( C = C ) C C C ( C O C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 ) O S ( = O ) ( = O ) c 1 c c c c c 1 C _EOS
acc_token: 0.42857142857142855, acc_seq: False

Target text: C O c 1 c c c ( C ( = O ) c 2 [nH] c ( C ) c c 2 C ) c c 1 O C _EOS
Predicted text: C O c 1 c c c ( C ( = O ) c 2 [nH] c ( C ) c c 2 C ) c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( c 1 c c c n c 1 ) n 1 c ( = O ) n ( C ( = O ) O C ( C ) ( C ) C ) c 2 c c c ( N c 3 c c ( C # N ) c c c 3 [N+] ( = O ) [O-] ) n c 2 1 _EOS
Predicted text: C C ( c 1 c c c n c 1 ) n 1 c ( = O ) n ( C ( = O ) O C ( C ) ( C ) C ) c 2 c c c ( N c 3 c c ( C # N ) c c c 3 [N+] ( = O ) [O-] ) n c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( O C C N 2 C C N ( C ) C C 2 ) c n 2 n c n c ( O c 3 c c c ( N C ( = O ) c 4 c c c n ( - c 5 c c c ( F ) c c 5 ) c 4 = O ) c c 3 F ) c 1 2 _EOS
Predicted text: C c 1 c ( O C C N 2 C C N ( C ) C C 2 ) c n 2 n c n c ( O c 3 c c c ( N C ( = O ) c 4 c c c n ( - c 5 c c c ( F ) c c 5 ) c 4 = O ) c c 3 F ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 260000, eval acc (token): 0.9351510613669841, eval acc (sequence): 0.8790597523775345
Saving at step 260000
Step 260100, loss: 0.03515071905683726, acc: 99.62930718064308, p_norm: 2177.8696424241953, g_norm: 0.5469767108593111, lr:  0.000490, elapsed time:  239943
Step 260200, loss: 0.035428094347007576, acc: 99.61530710756779, p_norm: 2177.9809750577797, g_norm: 0.7364327467040029, lr:  0.000490, elapsed time:  240032
Step 260300, loss: 0.0364560519112274, acc: 99.63129517436028, p_norm: 2178.0983689036516, g_norm: 0.5000698805249627, lr:  0.000490, elapsed time:  240123
Step 260400, loss: 0.036138171227648855, acc: 99.61280415952206, p_norm: 2178.212283439441, g_norm: 0.6846513027081634, lr:  0.000490, elapsed time:  240212
Step 260500, loss: 0.03591650995891541, acc: 99.59905558824539, p_norm: 2178.3313175265057, g_norm: 0.6441380308171837, lr:  0.000490, elapsed time:  240301
Step 260600, loss: 0.03523606290575117, acc: 99.60614322125912, p_norm: 2178.4498072576325, g_norm: 0.5919150139695193, lr:  0.000490, elapsed time:  240392
Step 260700, loss: 0.034978443514555695, acc: 99.61574302613735, p_norm: 2178.561311532973, g_norm: 0.6238810396296668, lr:  0.000489, elapsed time:  240482
Step 260800, loss: 0.03510575550608337, acc: 99.61051821708679, p_norm: 2178.6706947613684, g_norm: 0.5590001087758956, lr:  0.000489, elapsed time:  240570
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 260900, loss: 0.03510947788680964, acc: 99.60401261327279, p_norm: 2178.792503605894, g_norm: 0.48004799621444627, lr:  0.000489, elapsed time:  240665
Step 261000, loss: 0.03407474636100233, acc: 99.62696596980095, p_norm: 2178.9172728386293, g_norm: 0.7489345568849449, lr:  0.000489, elapsed time:  240754
Step 261100, loss: 0.03462576994672418, acc: 99.62543679773808, p_norm: 2179.032961700603, g_norm: 0.6619668769656195, lr:  0.000489, elapsed time:  240844
Step 261200, loss: 0.034231643616221843, acc: 99.63134191930294, p_norm: 2179.1435604851204, g_norm: 0.5048053215689117, lr:  0.000489, elapsed time:  240935
Step 261300, loss: 0.03455177415162325, acc: 99.61978243291378, p_norm: 2179.2664204707876, g_norm: 0.5078697101032662, lr:  0.000489, elapsed time:  241028
Step 261400, loss: 0.03404373089317232, acc: 99.63691008090973, p_norm: 2179.3777636420054, g_norm: 0.57929427013226, lr:  0.000489, elapsed time:  241118
Step 261500, loss: 0.03492978333029896, acc: 99.61013242602348, p_norm: 2179.5014869200218, g_norm: 0.8624360496712982, lr:  0.000489, elapsed time:  241208
Step 261600, loss: 0.03431560886092484, acc: 99.63324889540672, p_norm: 2179.6365792738475, g_norm: 0.46806675718480023, lr:  0.000489, elapsed time:  241295
Step 261700, loss: 0.03455766045488417, acc: 99.63007685542107, p_norm: 2179.751593840719, g_norm: 0.6682016480751646, lr:  0.000489, elapsed time:  241387
Step 261800, loss: 0.03499294462613761, acc: 99.60967041552067, p_norm: 2179.875595504648, g_norm: 0.7633788746102547, lr:  0.000488, elapsed time:  241476
Step 261900, loss: 0.03442428385373205, acc: 99.63662573695183, p_norm: 2179.988219531212, g_norm: 0.6223282520763544, lr:  0.000488, elapsed time:  241569
Step 262000, loss: 0.03448229299392551, acc: 99.6340055167675, p_norm: 2180.107190835265, g_norm: 0.6395525206916484, lr:  0.000488, elapsed time:  241656
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 262000, eval loss: 0.0446403846517205, eval acc: 99.51483154296875
Step 262100, loss: 0.03562832501251251, acc: 99.5940937101841, p_norm: 2180.243989090782, g_norm: 0.5781883064062646, lr:  0.000488, elapsed time:  241758
Step 262200, loss: 0.03495983758475631, acc: 99.61723962426186, p_norm: 2180.3674436497727, g_norm: 0.37301907865241596, lr:  0.000488, elapsed time:  241847
Step 262300, loss: 0.03505696199834347, acc: 99.61142233014107, p_norm: 2180.4858761617415, g_norm: 0.49580008121763247, lr:  0.000488, elapsed time:  241933
Step 262400, loss: 0.03421615119092167, acc: 99.64346930384636, p_norm: 2180.6006110959993, g_norm: 0.5905658488836637, lr:  0.000488, elapsed time:  242026
Step 262500, loss: 0.03551873230375349, acc: 99.59199713170528, p_norm: 2180.7204104973666, g_norm: 0.602339175279921, lr:  0.000488, elapsed time:  242112
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 262600, loss: 0.034503289943199546, acc: 99.63033313478404, p_norm: 2180.8399242981836, g_norm: 0.6442092440957845, lr:  0.000488, elapsed time:  242202
Step 262700, loss: 0.03479141349904239, acc: 99.62529046833515, p_norm: 2180.9636203397154, g_norm: 0.6634650355596424, lr:  0.000488, elapsed time:  242294
Step 262800, loss: 0.03447747444733977, acc: 99.62116003036499, p_norm: 2181.0806063479317, g_norm: 0.6753904289250744, lr:  0.000488, elapsed time:  242384
Step 262900, loss: 0.03415278889238835, acc: 99.63373504579067, p_norm: 2181.1991096043635, g_norm: 0.7840418102262373, lr:  0.000487, elapsed time:  242478
Step 263000, loss: 0.03411304680630565, acc: 99.63536775112152, p_norm: 2181.3123232327466, g_norm: 0.534534929438918, lr:  0.000487, elapsed time:  242574
Step 263100, loss: 0.034256054675206545, acc: 99.62551030516624, p_norm: 2181.425970654443, g_norm: 0.6300086986527137, lr:  0.000487, elapsed time:  242668
Step 263200, loss: 0.03418888822663575, acc: 99.63072866201401, p_norm: 2181.5516895470237, g_norm: 0.45412181227551757, lr:  0.000487, elapsed time:  242758
Step 263300, loss: 0.034541830266825856, acc: 99.61412443220615, p_norm: 2181.6684823671785, g_norm: 0.6508295098186866, lr:  0.000487, elapsed time:  242845
Step 263400, loss: 0.03420723972842097, acc: 99.63079857826233, p_norm: 2181.7795803491063, g_norm: 0.6737989622101667, lr:  0.000487, elapsed time:  242936
Step 263500, loss: 0.03558760138228536, acc: 99.59589214622974, p_norm: 2181.9088171165977, g_norm: 0.5727134557612705, lr:  0.000487, elapsed time:  243027
Step 263600, loss: 0.03424072085879743, acc: 99.63447842001915, p_norm: 2182.0357376913917, g_norm: 0.501769484709443, lr:  0.000487, elapsed time:  243113
Step 263700, loss: 0.03426403670106083, acc: 99.63418944180012, p_norm: 2182.1611256193164, g_norm: 0.6593231715928262, lr:  0.000487, elapsed time:  243211
Step 263800, loss: 0.03473876584786922, acc: 99.62424173951149, p_norm: 2182.2608397615577, g_norm: 0.6430549797184033, lr:  0.000487, elapsed time:  243302
Step 263900, loss: 0.035542693785391745, acc: 99.59601390361786, p_norm: 2182.390285612334, g_norm: 0.8631574798610885, lr:  0.000487, elapsed time:  243382
Step 264000, loss: 0.03452586018480361, acc: 99.61831387877464, p_norm: 2182.515001693289, g_norm: 0.5516618563907355, lr:  0.000486, elapsed time:  243470
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 264000, eval loss: 0.04450796822085978, eval acc: 99.51808166503906
Step 264100, loss: 0.0342270746640861, acc: 99.63251475989819, p_norm: 2182.6428451532342, g_norm: 0.6297041381032237, lr:  0.000486, elapsed time:  243578
Step 264200, loss: 0.035101435915566984, acc: 99.61363781988621, p_norm: 2182.758116877518, g_norm: 0.6765210198140063, lr:  0.000486, elapsed time:  243659
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 264300, loss: 0.03488528651760766, acc: 99.62307781202918, p_norm: 2182.8586227914293, g_norm: 0.6250791528146025, lr:  0.000486, elapsed time:  243740
Step 264400, loss: 0.03439963038545102, acc: 99.63635344803333, p_norm: 2182.969843497365, g_norm: 0.7019862044939367, lr:  0.000486, elapsed time:  243830
Step 264500, loss: 0.03351742566097528, acc: 99.6546919643879, p_norm: 2183.0961843180385, g_norm: 0.5753796246491789, lr:  0.000486, elapsed time:  243922
Step 264600, loss: 0.03407985398545861, acc: 99.63882544636726, p_norm: 2183.2054961610293, g_norm: 0.6225368071174665, lr:  0.000486, elapsed time:  244019
Step 264700, loss: 0.03469163659028709, acc: 99.6179896146059, p_norm: 2183.3113151772864, g_norm: 0.7455217225697787, lr:  0.000486, elapsed time:  244102
Step 264800, loss: 0.03445039002690464, acc: 99.62285141646862, p_norm: 2183.426716576489, g_norm: 0.6753828781044552, lr:  0.000486, elapsed time:  244195
Step 264900, loss: 0.033857039958238605, acc: 99.64110012352467, p_norm: 2183.536222596072, g_norm: 0.47665352037056075, lr:  0.000486, elapsed time:  244288
Step 265000, loss: 0.0341905117360875, acc: 99.6338108330965, p_norm: 2183.640936976133, g_norm: 0.5114115260357353, lr:  0.000486, elapsed time:  244381
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Target text: C c 1 c c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) n c ( - n 2 c n c ( - c 3 c c c ( N ) n c 3 ) n 2 ) n 1 _EOS
Predicted text: C c 1 c c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) n c ( - n 2 c n c ( - c 3 c c c ( N ) n c 3 ) n 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C C N ( C c 2 c c c ( C ( O ) ( C ( F ) ( F ) F ) C ( F ) ( F ) F ) c c 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C C N ( C c 2 c c c ( C ( O ) ( C ( F ) ( F ) F ) C ( F ) ( F ) F ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C ( C 1 C C C C C 1 ) C ( O ) ( c 1 c c c ( F ) c c 1 ) c 1 c c c ( F ) c c 1 _EOS
Predicted text: C C O C ( = O ) C ( C 1 C C C C C 1 ) C ( O ) ( c 1 c c c ( F ) c c 1 ) c 1 c c c ( F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) C C O C C C c 1 c [nH] c n 1 _EOS
Predicted text: C C ( C ) ( C ) C C n 1 c n c ( C C C O ) c 1 _EOS
acc_token: 0.5, acc_seq: False

Target text: C C 1 ( C ) C O c 2 c c ( O ) c ( C 3 ( O ) C ( = O ) N ( C ( c 4 c c c c c 4 ) c 4 c c c c c 4 ) c 4 c c c c c 4 3 ) c c 2 1 _EOS
Predicted text: C C 1 ( C ) C O c 2 c c ( O ) c ( C 3 ( O ) C ( = O ) N ( C ( c 4 c c c c c 4 ) c 4 c c c c c 4 ) c 4 c c c c c 4 3 ) c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 265000, eval acc (token): 0.9357663200057763, eval acc (sequence): 0.8810243642183888
Saving at step 265000
Step 265100, loss: 0.03527534268796444, acc: 99.59316179156303, p_norm: 2183.7681711393575, g_norm: 0.5005758909890393, lr:  0.000485, elapsed time:  244534
Step 265200, loss: 0.03467337770853192, acc: 99.62365792691708, p_norm: 2183.8894564927577, g_norm: 0.5448820040044233, lr:  0.000485, elapsed time:  244619
Step 265300, loss: 0.03465606654528528, acc: 99.62375937402248, p_norm: 2184.01155507453, g_norm: 0.8253194532292258, lr:  0.000485, elapsed time:  244708
Step 265400, loss: 0.035443015075288714, acc: 99.60451555252075, p_norm: 2184.1488487288143, g_norm: 0.5905164872524878, lr:  0.000485, elapsed time:  244780
Step 265500, loss: 0.03464169668965042, acc: 99.6168919056654, p_norm: 2184.2728586957573, g_norm: 0.5508025889489769, lr:  0.000485, elapsed time:  244854
Step 265600, loss: 0.03523923691362143, acc: 99.61497497558594, p_norm: 2184.3916204831153, g_norm: 0.4764912038346649, lr:  0.000485, elapsed time:  244944
Step 265700, loss: 0.034187037562951446, acc: 99.6350262016058, p_norm: 2184.494408308239, g_norm: 0.5983993034347881, lr:  0.000485, elapsed time:  245038
Step 265800, loss: 0.03437777461484075, acc: 99.6297612041235, p_norm: 2184.607194134505, g_norm: 0.5702067997539432, lr:  0.000485, elapsed time:  245132
Step 265900, loss: 0.03464245212264359, acc: 99.61884714663029, p_norm: 2184.7334743086417, g_norm: 0.5071665993785274, lr:  0.000485, elapsed time:  245224
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 266000, loss: 0.03418470865979828, acc: 99.6399972042434, p_norm: 2184.840712467116, g_norm: 0.45226137392914206, lr:  0.000485, elapsed time:  245320
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 266000, eval loss: 0.04456959225237369, eval acc: 99.51541900634766
Step 266100, loss: 0.03376973820384592, acc: 99.64933502674103, p_norm: 2184.952905410237, g_norm: 1.440288717826697, lr:  0.000484, elapsed time:  245425
Step 266200, loss: 0.03482587715610862, acc: 99.61730773746967, p_norm: 2185.06570801504, g_norm: 0.6127507622521031, lr:  0.000484, elapsed time:  245513
Step 266300, loss: 0.03447875259444118, acc: 99.62549039721489, p_norm: 2185.1961594155723, g_norm: 0.6508516677518099, lr:  0.000484, elapsed time:  245606
Step 266400, loss: 0.03430642426945269, acc: 99.62910225987434, p_norm: 2185.300677282122, g_norm: 0.6087935182727459, lr:  0.000484, elapsed time:  245689
Step 266500, loss: 0.03436366337351501, acc: 99.63271416723728, p_norm: 2185.4182190498727, g_norm: 0.5880909340382505, lr:  0.000484, elapsed time:  245761
Step 266600, loss: 0.03430360535159707, acc: 99.63155503571033, p_norm: 2185.5522440299096, g_norm: 0.5233477613636037, lr:  0.000484, elapsed time:  245832
Step 266700, loss: 0.03405387475155294, acc: 99.64370110630989, p_norm: 2185.6666978212047, g_norm: 0.6509575550763999, lr:  0.000484, elapsed time:  245900
Step 266800, loss: 0.03462106501683593, acc: 99.6182187795639, p_norm: 2185.78165773629, g_norm: 0.4893681646146814, lr:  0.000484, elapsed time:  245965
Step 266900, loss: 0.03510675317142159, acc: 99.60379210114479, p_norm: 2185.892421388927, g_norm: 0.5069513787111667, lr:  0.000484, elapsed time:  246034
Step 267000, loss: 0.03429149930831045, acc: 99.62325973808765, p_norm: 2186.0279894833793, g_norm: 0.7910016783473717, lr:  0.000484, elapsed time:  246105
Step 267100, loss: 0.034990965682081876, acc: 99.61063569784164, p_norm: 2186.1515135356512, g_norm: 0.671666355407458, lr:  0.000484, elapsed time:  246174
Step 267200, loss: 0.03393916233908385, acc: 99.64364989101887, p_norm: 2186.254851501466, g_norm: 0.6547659245156776, lr:  0.000483, elapsed time:  246244
Step 267300, loss: 0.0344150470662862, acc: 99.63185085356236, p_norm: 2186.3708623449984, g_norm: 0.5519291931913596, lr:  0.000483, elapsed time:  246314
Step 267400, loss: 0.034245445406995714, acc: 99.6300079524517, p_norm: 2186.474486521952, g_norm: 0.6359797407512867, lr:  0.000483, elapsed time:  246385
Step 267500, loss: 0.034322261502966286, acc: 99.6320459395647, p_norm: 2186.5834590599834, g_norm: 0.6644844757592495, lr:  0.000483, elapsed time:  246455
Step 267600, loss: 0.03440481973346323, acc: 99.62860976159573, p_norm: 2186.6939493304667, g_norm: 0.8010372307535526, lr:  0.000483, elapsed time:  246524
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 267700, loss: 0.03456389276653676, acc: 99.62070050524243, p_norm: 2186.817787929307, g_norm: 0.5604521143561083, lr:  0.000483, elapsed time:  246613
Step 267800, loss: 0.034089270434342324, acc: 99.62985141575336, p_norm: 2186.9354138656754, g_norm: 0.5762702310704099, lr:  0.000483, elapsed time:  246703
Step 267900, loss: 0.033892964804545046, acc: 99.6383395344019, p_norm: 2187.04397838269, g_norm: 0.7247820537724744, lr:  0.000483, elapsed time:  246786
Step 268000, loss: 0.034611946195364, acc: 99.62368190288544, p_norm: 2187.173809495602, g_norm: 0.5972350461022685, lr:  0.000483, elapsed time:  246853
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 268000, eval loss: 0.0460847476311028, eval acc: 99.4749526977539
Step 268100, loss: 0.034345907848328354, acc: 99.6329999268055, p_norm: 2187.3048135766135, g_norm: 0.6740513879657544, lr:  0.000483, elapsed time:  246934
Step 268200, loss: 0.034401047988794745, acc: 99.63316257297993, p_norm: 2187.4215236833984, g_norm: 0.792711702946297, lr:  0.000483, elapsed time:  247004
Step 268300, loss: 0.03537286673206836, acc: 99.60535562038422, p_norm: 2187.5373658373514, g_norm: 0.6242166765727609, lr:  0.000483, elapsed time:  247071
Step 268400, loss: 0.03413022581022233, acc: 99.63448411226273, p_norm: 2187.6426298864217, g_norm: 0.5438095440987643, lr:  0.000482, elapsed time:  247149
Step 268500, loss: 0.034579050610773265, acc: 99.61888052523136, p_norm: 2187.769398804167, g_norm: 0.5662947351226948, lr:  0.000482, elapsed time:  247236
Step 268600, loss: 0.034266963680274785, acc: 99.63694286346436, p_norm: 2187.8937568512124, g_norm: 0.6700387493729957, lr:  0.000482, elapsed time:  247320
Step 268700, loss: 0.03393488912843168, acc: 99.6429083943367, p_norm: 2188.0047186184997, g_norm: 0.5957871629477315, lr:  0.000482, elapsed time:  247413
Step 268800, loss: 0.03373668383806944, acc: 99.64490231871605, p_norm: 2188.1141445692165, g_norm: 0.4967569804542397, lr:  0.000482, elapsed time:  247512
Step 268900, loss: 0.0337177918292582, acc: 99.64778299629688, p_norm: 2188.22065154478, g_norm: 0.656426151826592, lr:  0.000482, elapsed time:  247604
Step 269000, loss: 0.03472939722239971, acc: 99.61123560369015, p_norm: 2188.3268810633194, g_norm: 0.5794586289299783, lr:  0.000482, elapsed time:  247693
Step 269100, loss: 0.03457016132306308, acc: 99.62309756875038, p_norm: 2188.441564981227, g_norm: 0.4275117501317207, lr:  0.000482, elapsed time:  247786
Step 269200, loss: 0.03499721428379417, acc: 99.61094006896019, p_norm: 2188.5657154716255, g_norm: 0.6698918984980212, lr:  0.000482, elapsed time:  247875
Step 269300, loss: 0.03543860695324838, acc: 99.60357758402824, p_norm: 2188.684215006308, g_norm: 0.6321280399188958, lr:  0.000482, elapsed time:  247962
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 269400, loss: 0.034608653361969326, acc: 99.6167099149666, p_norm: 2188.8077344101735, g_norm: 0.5900335743741075, lr:  0.000482, elapsed time:  248051
Step 269500, loss: 0.0340266343858093, acc: 99.63599294424057, p_norm: 2188.9181937371836, g_norm: 0.6353281626818528, lr:  0.000481, elapsed time:  248138
Step 269600, loss: 0.03407772838603705, acc: 99.63960960507393, p_norm: 2189.0357470655727, g_norm: 0.8563329832452572, lr:  0.000481, elapsed time:  248229
Step 269700, loss: 0.03485405120998621, acc: 99.61997503042221, p_norm: 2189.1514504786373, g_norm: 0.5821944134248767, lr:  0.000481, elapsed time:  248321
Step 269800, loss: 0.03401852807030082, acc: 99.63849292695522, p_norm: 2189.260703550466, g_norm: 0.5698516608518183, lr:  0.000481, elapsed time:  248410
Step 269900, loss: 0.0364658524049446, acc: 99.62457954883575, p_norm: 2189.3947998794365, g_norm: 0.6201632389930481, lr:  0.000481, elapsed time:  248504
Step 270000, loss: 0.035905086202546954, acc: 99.62864874303341, p_norm: 2189.517334644059, g_norm: 0.5626950028892449, lr:  0.000481, elapsed time:  248595
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 270000, eval loss: 0.04749332562088965, eval acc: 99.4513931274414
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C N C 1 = C ( C # N ) C ( c 2 c c c ( Cl ) c ( [N+] ( = O ) [O-] ) c 2 ) c 2 c c c 3 c c c c c 3 c 2 O 1 _EOS
Predicted text: C N C 1 = C ( C # N ) C ( c 2 c c c ( Cl ) c ( [N+] ( = O ) [O-] ) c 2 ) c 2 c c c 3 c c c c c 3 c 2 O 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) c 1 c c c ( - c 2 c c ( C # N ) c ( O C c 3 c c c c c 3 ) n c 2 - c 2 c c c ( F ) c c 2 ) c c 1 _EOS
Predicted text: C S ( = O ) ( = O ) c 1 c c c ( - c 2 c c ( C # N ) c ( O C c 3 c c c c c 3 ) n c 2 - c 2 c c c ( F ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) N 1 C C C ( O c 2 c c c ( C 3 ( C N ) C C O C C 3 ) c c 2 ) C C 1 _EOS
Predicted text: C C ( C ) N 1 C C C ( O c 2 c c c ( C 3 ( C N ) C C O C C 3 ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c c c c c 1 N C ( = O ) C = C c 1 c c n ( S ( = O ) ( = O ) c 2 c c c ( - c 3 c c c n c 3 ) c c 2 ) c 1 _EOS
Predicted text: N c 1 c c c c c 1 N C ( = O ) C = C c 1 c c n ( S ( = O ) ( = O ) c 2 c c c ( - c 3 c c c n c 3 ) c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C N 2 C C ( Cl ) = N c 3 c c c ( C ( C ) C ) c c 3 C 2 = O ) c ( O C ) c 1 _EOS
Predicted text: C O c 1 c c c ( C N 2 C C ( Cl ) = N c 3 c c c ( C ( C ) C ) c c 3 C 2 = O ) c ( O C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 270000, eval acc (token): 0.9342156920409702, eval acc (sequence): 0.8836967808930426
Saving at step 270000
Step 270100, loss: 0.035285194022580985, acc: 99.63484838604927, p_norm: 2189.630891641273, g_norm: 0.5900331817400887, lr:  0.000481, elapsed time:  248783
Step 270200, loss: 0.035068251993507146, acc: 99.62623988091946, p_norm: 2189.7372135383143, g_norm: 0.5583469299486812, lr:  0.000481, elapsed time:  248872
Step 270300, loss: 0.0348075474286452, acc: 99.62751896679401, p_norm: 2189.83526115915, g_norm: 0.5723685154983937, lr:  0.000481, elapsed time:  248965
Step 270400, loss: 0.03572912416420877, acc: 99.61485715210438, p_norm: 2189.9877107195616, g_norm: 0.598898871950446, lr:  0.000481, elapsed time:  249057
Step 270500, loss: 0.03629076802637428, acc: 99.60923214256763, p_norm: 2190.0858498999933, g_norm: 0.6761811113828242, lr:  0.000481, elapsed time:  249146
Step 270600, loss: 0.035385838523507115, acc: 99.6264206469059, p_norm: 2190.1904342121566, g_norm: 0.5015772581123177, lr:  0.000480, elapsed time:  249237
Step 270700, loss: 0.03490503830369562, acc: 99.63568398356438, p_norm: 2190.29436029488, g_norm: 0.4732021205913742, lr:  0.000480, elapsed time:  249329
Step 270800, loss: 0.03481411561369896, acc: 99.62816992402077, p_norm: 2190.4055012166896, g_norm: 0.5714622174318131, lr:  0.000480, elapsed time:  249426
Step 270900, loss: 0.03498723361175507, acc: 99.61506307125092, p_norm: 2190.518318345046, g_norm: 0.6188104420826751, lr:  0.000480, elapsed time:  249524
Step 271000, loss: 0.03492837123107165, acc: 99.6119809448719, p_norm: 2190.6362797788324, g_norm: 0.6620506320360945, lr:  0.000480, elapsed time:  249614
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 271100, loss: 0.034387814486514845, acc: 99.62837839540714, p_norm: 2190.756186990597, g_norm: 0.5793331453370197, lr:  0.000480, elapsed time:  249707
Step 271200, loss: 0.033809709013439715, acc: 99.64250530302525, p_norm: 2190.859745781985, g_norm: 0.48713624908632236, lr:  0.000480, elapsed time:  249799
Step 271300, loss: 0.0341095009399578, acc: 99.63317634165287, p_norm: 2190.976825735999, g_norm: 0.5809773187519568, lr:  0.000480, elapsed time:  249894
Step 271400, loss: 0.033955756523646415, acc: 99.63230027258396, p_norm: 2191.0952432828303, g_norm: 0.594136588516454, lr:  0.000480, elapsed time:  249985
Step 271500, loss: 0.033978241868317126, acc: 99.62681852281094, p_norm: 2191.204787316646, g_norm: 0.7514215790062089, lr:  0.000480, elapsed time:  250074
Step 271600, loss: 0.03411471154075116, acc: 99.63358628749847, p_norm: 2191.3171330927994, g_norm: 0.5947959384299729, lr:  0.000480, elapsed time:  250162
Step 271700, loss: 0.03364195868372917, acc: 99.64608305692673, p_norm: 2191.431690405133, g_norm: 0.519635833816386, lr:  0.000479, elapsed time:  250254
Step 271800, loss: 0.034090984519571065, acc: 99.642871722579, p_norm: 2191.553823791151, g_norm: 0.6267225943662919, lr:  0.000479, elapsed time:  250345
Step 271900, loss: 0.03446001837030053, acc: 99.63143953680992, p_norm: 2191.666011486492, g_norm: 0.7341568088493828, lr:  0.000479, elapsed time:  250434
Step 272000, loss: 0.03395127145573497, acc: 99.63826715946198, p_norm: 2191.7642794821377, g_norm: 0.7480182380491139, lr:  0.000479, elapsed time:  250521
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 272000, eval loss: 0.04548599947243928, eval acc: 99.49217224121094
Step 272100, loss: 0.033648573257960376, acc: 99.64892865717411, p_norm: 2191.8910662577173, g_norm: 0.530508332290777, lr:  0.000479, elapsed time:  250629
Step 272200, loss: 0.034163775560446086, acc: 99.63622894883156, p_norm: 2191.9952768603457, g_norm: 0.6288681235017839, lr:  0.000479, elapsed time:  250720
Step 272300, loss: 0.034540151157416404, acc: 99.62164194881916, p_norm: 2192.123302138289, g_norm: 0.5791480811088388, lr:  0.000479, elapsed time:  250810
Step 272400, loss: 0.033828179193660615, acc: 99.64243693649769, p_norm: 2192.2382486629017, g_norm: 0.746428517244756, lr:  0.000479, elapsed time:  250903
Step 272500, loss: 0.03430195753928274, acc: 99.63420252501965, p_norm: 2192.3544996821597, g_norm: 0.7099314284972668, lr:  0.000479, elapsed time:  250997
Step 272600, loss: 0.034746464509516954, acc: 99.61663971841335, p_norm: 2192.467980813018, g_norm: 0.4723503675540013, lr:  0.000479, elapsed time:  251085
Step 272700, loss: 0.03499254253227264, acc: 99.61041988432407, p_norm: 2192.59144485526, g_norm: 0.6341546944144886, lr:  0.000479, elapsed time:  251182
Step 272800, loss: 0.034409866579808296, acc: 99.62877762317657, p_norm: 2192.715790455068, g_norm: 0.5338057826456084, lr:  0.000479, elapsed time:  251277
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 272900, loss: 0.033624076423471545, acc: 99.65014807620452, p_norm: 2192.821462799743, g_norm: 0.49762649123900216, lr:  0.000478, elapsed time:  251368
Step 273000, loss: 0.03403770911507308, acc: 99.63390631973743, p_norm: 2192.933973654767, g_norm: 0.49742962100410804, lr:  0.000478, elapsed time:  251459
Step 273100, loss: 0.033913272731006146, acc: 99.64335875213146, p_norm: 2193.0448402701218, g_norm: 0.7982778366460433, lr:  0.000478, elapsed time:  251552
Step 273200, loss: 0.03419480705168098, acc: 99.63457146286964, p_norm: 2193.153143504492, g_norm: 0.7042466304339624, lr:  0.000478, elapsed time:  251640
Step 273300, loss: 0.03391229453962296, acc: 99.63846665620804, p_norm: 2193.273348954279, g_norm: 0.6810016490982701, lr:  0.000478, elapsed time:  251730
Step 273400, loss: 0.03389210161287338, acc: 99.64076234400272, p_norm: 2193.3868918013236, g_norm: 0.6049911614642677, lr:  0.000478, elapsed time:  251828
Step 273500, loss: 0.03404641454573721, acc: 99.6347541809082, p_norm: 2193.4888029435992, g_norm: 0.5340609512267426, lr:  0.000478, elapsed time:  251919
Step 273600, loss: 0.034789510210976, acc: 99.61700415611267, p_norm: 2193.603215270395, g_norm: 0.48371028769038943, lr:  0.000478, elapsed time:  252010
Step 273700, loss: 0.035255213771015405, acc: 99.61106361448765, p_norm: 2193.712355366197, g_norm: 0.5605193409945801, lr:  0.000478, elapsed time:  252098
Step 273800, loss: 0.03466255268547684, acc: 99.62205258011818, p_norm: 2193.816879371781, g_norm: 0.5002519227687261, lr:  0.000478, elapsed time:  252187
Step 273900, loss: 0.03400484279729426, acc: 99.63732327520847, p_norm: 2193.9251447603037, g_norm: 0.556742909101251, lr:  0.000478, elapsed time:  252278
Step 274000, loss: 0.03391976589336991, acc: 99.63713091611862, p_norm: 2194.041389192101, g_norm: 0.6868678948388617, lr:  0.000477, elapsed time:  252369
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 274000, eval loss: 0.04234457597136498, eval acc: 99.54618835449219
Step 274100, loss: 0.03414193732198328, acc: 99.63433155417442, p_norm: 2194.169971679031, g_norm: 0.4286655197974812, lr:  0.000477, elapsed time:  252476
Step 274200, loss: 0.034345507728867235, acc: 99.62561075389385, p_norm: 2194.2740497571967, g_norm: 0.7371737125376049, lr:  0.000477, elapsed time:  252564
Step 274300, loss: 0.034038247014395895, acc: 99.63638281822205, p_norm: 2194.386223437308, g_norm: 0.5538961122520585, lr:  0.000477, elapsed time:  252655
Step 274400, loss: 0.03423438233789056, acc: 99.62588159739971, p_norm: 2194.4915755219936, g_norm: 0.5814981959071434, lr:  0.000477, elapsed time:  252741
Step 274500, loss: 0.03405711257830262, acc: 99.6427280753851, p_norm: 2194.613468097017, g_norm: 0.4869972992879066, lr:  0.000477, elapsed time:  252829
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 274600, loss: 0.033798842297042185, acc: 99.648059986124, p_norm: 2194.7323731766924, g_norm: 0.6280307088162369, lr:  0.000477, elapsed time:  252922
Step 274700, loss: 0.0340220132516697, acc: 99.63940219581127, p_norm: 2194.8391526010514, g_norm: 0.4189189144212351, lr:  0.000477, elapsed time:  253012
Step 274800, loss: 0.034485745104029776, acc: 99.62798762321472, p_norm: 2194.968604138871, g_norm: 0.577284980829486, lr:  0.000477, elapsed time:  253100
Step 274900, loss: 0.03394819632172585, acc: 99.63993781805038, p_norm: 2195.078804878232, g_norm: 0.5546577239241486, lr:  0.000477, elapsed time:  253189
Step 275000, loss: 0.03391172159463167, acc: 99.64553427696228, p_norm: 2195.193305021858, g_norm: 0.5990117761011412, lr:  0.000477, elapsed time:  253279
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C 1 C C c 2 n c n c ( N 3 C C N ( C ( = O ) C ( C N ( C ( = O ) O C ( C ) ( C ) C ) C ( C ) C ) c 4 c c c ( Cl ) c c 4 ) C C 3 ) c 2 1 _EOS
Predicted text: C C 1 C C c 2 n c n c ( N 3 C C N ( C ( = O ) C ( C N ( C ( = O ) O C ( C ) ( C ) C ) C ( C ) C ) c 4 c c c ( Cl ) c c 4 ) C C 3 ) c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: Br C C C O c 1 c c c ( I ) c c 1 _EOS
Predicted text: Br C C C O c 1 c c c ( I ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C n 2 c c c 3 c c ( - c 4 c c ( C ( = O ) N C 5 C C 5 ) c c c 4 C ) c c c 3 c 2 = O ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C n 2 c c c 3 c c ( - c 4 c c ( C ( = O ) N C 5 C C 5 ) c c c 4 C ) c c c 3 c 2 = O ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C c 1 n c c ( C = C 2 C ( = O ) N ( C C C C ) C ( = O ) N 2 C c 2 c ( C ) n o c 2 C ) n 1 C c 1 c c c ( C ( = O ) O C ) c c 1 . Cl _EOS
Predicted text: C C C C c 1 n c c ( C = C 2 C ( = O ) N ( C C C C ) C ( = O ) N 2 C c 2 c ( C ) n o c 2 C ) n 1 C c 1 c c c ( C ( = O ) O C ) c c 1 . Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C c 1 c c ( C ( = O ) O C ) c c c 1 - c 1 c c c c c 1 C _EOS
Predicted text: C O C c 1 c c ( C ( = O ) O C ) c c c 1 - c 1 c c c c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 275000, eval acc (token): 0.9420831131734276, eval acc (sequence): 0.8922065727699531
Saving at step 275000
Step 275100, loss: 0.03387903711758554, acc: 99.63920278847218, p_norm: 2195.304640075254, g_norm: 0.5408388775433636, lr:  0.000477, elapsed time:  253454
Step 275200, loss: 0.035089887036010625, acc: 99.60615128278732, p_norm: 2195.421499591287, g_norm: 0.6272543383785378, lr:  0.000476, elapsed time:  253541
Step 275300, loss: 0.03380710992496461, acc: 99.65019634366035, p_norm: 2195.543443163105, g_norm: 0.6345611869116357, lr:  0.000476, elapsed time:  253631
Step 275400, loss: 0.03387750799302012, acc: 99.64769066870213, p_norm: 2195.644337400447, g_norm: 0.5253308873896569, lr:  0.000476, elapsed time:  253722
Step 275500, loss: 0.0342125692917034, acc: 99.63453085720539, p_norm: 2195.7539672121525, g_norm: 0.5466328205706552, lr:  0.000476, elapsed time:  253811
Step 275600, loss: 0.03475702772382647, acc: 99.61971046030521, p_norm: 2195.8594010635225, g_norm: 0.6936146472468149, lr:  0.000476, elapsed time:  253896
Step 275700, loss: 0.03428037254605442, acc: 99.62912471592426, p_norm: 2195.973848438483, g_norm: 0.6226055437835638, lr:  0.000476, elapsed time:  253984
Step 275800, loss: 0.03335911788977683, acc: 99.65088427066803, p_norm: 2196.087455508791, g_norm: 0.5800944656853175, lr:  0.000476, elapsed time:  254077
Step 275900, loss: 0.03436469164211303, acc: 99.62435673177242, p_norm: 2196.1864298068076, g_norm: 0.570947086823743, lr:  0.000476, elapsed time:  254166
Step 276000, loss: 0.03420679664239287, acc: 99.63475987315178, p_norm: 2196.2836716660804, g_norm: 0.728161946693014, lr:  0.000476, elapsed time:  254256
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 276000, eval loss: 0.04282629447057844, eval acc: 99.54511260986328
Step 276100, loss: 0.034735038168728354, acc: 99.62097388505936, p_norm: 2196.4187780385305, g_norm: 0.649025973948124, lr:  0.000476, elapsed time:  254362
Step 276200, loss: 0.03429339564871043, acc: 99.63170129060745, p_norm: 2196.5320046993666, g_norm: 0.7088141703485883, lr:  0.000476, elapsed time:  254454
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 276300, loss: 0.034036181278675054, acc: 99.63514818184412, p_norm: 2196.648656182348, g_norm: 0.6602103030200245, lr:  0.000475, elapsed time:  254544
Step 276400, loss: 0.033449120381847025, acc: 99.64729319512844, p_norm: 2196.754498236869, g_norm: 0.5030919561733164, lr:  0.000475, elapsed time:  254633
Step 276500, loss: 0.034976745313033464, acc: 99.6393121778965, p_norm: 2196.8677982099302, g_norm: 0.7486214318500778, lr:  0.000475, elapsed time:  254721
Step 276600, loss: 0.0357209102390334, acc: 99.63268356025219, p_norm: 2196.9649253529674, g_norm: 0.5123001681098033, lr:  0.000475, elapsed time:  254811
Step 276700, loss: 0.036011290582828225, acc: 99.61376005411148, p_norm: 2197.092759051169, g_norm: 0.5976471099410591, lr:  0.000475, elapsed time:  254899
Step 276800, loss: 0.03513503777328879, acc: 99.64425826072693, p_norm: 2197.2001713633817, g_norm: 0.43475618617298545, lr:  0.000475, elapsed time:  254988
Step 276900, loss: 0.03454281771555543, acc: 99.6433988660574, p_norm: 2197.3044645933824, g_norm: 0.728071841301109, lr:  0.000475, elapsed time:  255079
Step 277000, loss: 0.0345474608708173, acc: 99.64166387915611, p_norm: 2197.4184743106252, g_norm: 0.6401122262937626, lr:  0.000475, elapsed time:  255168
Step 277100, loss: 0.03422535964753479, acc: 99.63905747234821, p_norm: 2197.5272432284864, g_norm: 0.6299712472772584, lr:  0.000475, elapsed time:  255259
Step 277200, loss: 0.03458359424956143, acc: 99.62838964164257, p_norm: 2197.6232718779042, g_norm: 0.6084900865701358, lr:  0.000475, elapsed time:  255348
Step 277300, loss: 0.0340434151282534, acc: 99.64294083416462, p_norm: 2197.747024828401, g_norm: 0.4801474802438435, lr:  0.000475, elapsed time:  255438
Step 277400, loss: 0.03354752858635038, acc: 99.65955075621605, p_norm: 2197.86302470656, g_norm: 0.6649081850983559, lr:  0.000475, elapsed time:  255531
Step 277500, loss: 0.03472787362057716, acc: 99.62071856856346, p_norm: 2197.983675176373, g_norm: 0.5871712150535239, lr:  0.000474, elapsed time:  255621
Step 277600, loss: 0.03416200446896255, acc: 99.6348992139101, p_norm: 2198.0983327450367, g_norm: 0.6081118880383424, lr:  0.000474, elapsed time:  255714
Step 277700, loss: 0.034348367815837264, acc: 99.62979079782963, p_norm: 2198.202050136221, g_norm: 0.7168813144684136, lr:  0.000474, elapsed time:  255800
Step 277800, loss: 0.034060464296489956, acc: 99.63186818361282, p_norm: 2198.311353357436, g_norm: 0.5112557172542178, lr:  0.000474, elapsed time:  255889
Step 277900, loss: 0.03456621382385492, acc: 99.6175372749567, p_norm: 2198.419577307912, g_norm: 0.5441928280406775, lr:  0.000474, elapsed time:  255979
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 278000, loss: 0.03434364333582427, acc: 99.63372979803061, p_norm: 2198.564850242076, g_norm: 1.1204931773736944, lr:  0.000474, elapsed time:  256071
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 278000, eval loss: 0.045054806619882606, eval acc: 99.48211669921875
Step 278100, loss: 0.03417177189141512, acc: 99.62954019010067, p_norm: 2198.694561782431, g_norm: 0.7996330113725075, lr:  0.000474, elapsed time:  256177
Step 278200, loss: 0.03352343403734267, acc: 99.65333253145218, p_norm: 2198.8002719012284, g_norm: 0.5570387437392081, lr:  0.000474, elapsed time:  256267
Step 278300, loss: 0.03413487907499075, acc: 99.63438978791237, p_norm: 2198.9056568939386, g_norm: 0.7840265995449726, lr:  0.000474, elapsed time:  256353
Step 278400, loss: 0.03373057586606592, acc: 99.64288492500782, p_norm: 2199.0105764412974, g_norm: 0.7382069056168673, lr:  0.000474, elapsed time:  256441
Step 278500, loss: 0.033750868681818244, acc: 99.65053810179234, p_norm: 2199.110416939218, g_norm: 0.5126710302254325, lr:  0.000474, elapsed time:  256528
Step 278600, loss: 0.0336108355037868, acc: 99.65200923383236, p_norm: 2199.2183021367523, g_norm: 0.4921267159897295, lr:  0.000474, elapsed time:  256618
Step 278700, loss: 0.03410681300796568, acc: 99.63724310696125, p_norm: 2199.3297870503384, g_norm: 0.6977022290226544, lr:  0.000473, elapsed time:  256707
Step 278800, loss: 0.034098366936668754, acc: 99.63911573588848, p_norm: 2199.4460269386136, g_norm: 0.519384405465582, lr:  0.000473, elapsed time:  256796
Step 278900, loss: 0.03511756146326661, acc: 99.59895537793636, p_norm: 2199.5577540916747, g_norm: 0.7695213486466586, lr:  0.000473, elapsed time:  256886
Step 279000, loss: 0.034354556822218, acc: 99.64036086201668, p_norm: 2199.6830748227094, g_norm: 0.6662712046340605, lr:  0.000473, elapsed time:  256979
Step 279100, loss: 0.03363734217360616, acc: 99.64652788639069, p_norm: 2199.7885498012192, g_norm: 0.5388461248299243, lr:  0.000473, elapsed time:  257067
Step 279200, loss: 0.03393081088550389, acc: 99.64264748990536, p_norm: 2199.9002370684043, g_norm: 0.638202774376566, lr:  0.000473, elapsed time:  257158
Step 279300, loss: 0.03377836098428816, acc: 99.64113318920135, p_norm: 2200.019908133785, g_norm: 0.8183969005377483, lr:  0.000473, elapsed time:  257249
Step 279400, loss: 0.03431004063691944, acc: 99.63369911909103, p_norm: 2200.1286659772964, g_norm: 0.4646452629235909, lr:  0.000473, elapsed time:  257339
Step 279500, loss: 0.03424738904926926, acc: 99.6347354054451, p_norm: 2200.236363579187, g_norm: 0.6007484072816419, lr:  0.000473, elapsed time:  257427
Step 279600, loss: 0.03423776233103126, acc: 99.63823445141315, p_norm: 2200.355273810078, g_norm: 0.6661345664971298, lr:  0.000473, elapsed time:  257519
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 279700, loss: 0.03367157149781932, acc: 99.64937152554147, p_norm: 2200.4529725516863, g_norm: 0.6530379265170345, lr:  0.000473, elapsed time:  257610
Step 279800, loss: 0.03403916904702783, acc: 99.64319948852062, p_norm: 2200.5713840070875, g_norm: 0.7001145251923677, lr:  0.000472, elapsed time:  257700
Step 279900, loss: 0.034633339857682584, acc: 99.6243437230587, p_norm: 2200.695065182532, g_norm: 0.549017790184412, lr:  0.000472, elapsed time:  257788
Step 280000, loss: 0.034332514451816676, acc: 99.63128265738487, p_norm: 2200.805156227833, g_norm: 0.5662957758386951, lr:  0.000472, elapsed time:  257875
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 280000, eval loss: 0.047105171028524635, eval acc: 99.45207977294922
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C N C ( = O ) c 1 n c ( - c 2 c n c c ( C ( = O ) N C c 3 c c c c c 3 ) c 2 ) c n c 1 N _EOS
Predicted text: C N C ( = O ) c 1 n c ( - c 2 c n c c ( C ( = O ) N C c 3 c c c c c 3 ) c 2 ) c n c 1 N _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) N 1 C C N ( C ( = O ) C ( C C C ( = O ) O C ( C ) ( C ) C ) N C ( = O ) c 2 c c ( C 3 C C 3 ) n c ( - c 3 c c c c c 3 ) n 2 ) C C 1 _EOS
Predicted text: C C O C ( = O ) N 1 C C N ( C ( = O ) C ( C C C ( = O ) O C ( C ) ( C ) C ) N C ( = O ) c 2 c c ( C 3 C C 3 ) n c ( - c 3 c c c c c 3 ) n 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 c c c ( N c 2 n c 3 c c ( O c 4 c c n c ( C ( = O ) O ) c 4 ) c c c 3 n 2 C ) c c 1 _EOS
Predicted text: C C c 1 c c c ( N c 2 n c 3 c c ( O c 4 c c n c ( C ( = O ) O ) c 4 ) c c c 3 n 2 C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: F C ( F ) ( F ) c 1 c c 2 c ( c c 1 Cl ) C ( Cl ) C c 1 c c c c c 1 S 2 _EOS
Predicted text: F C ( F ) ( F ) c 1 c c ( S c 2 c c c c c 2 C Cl ) c c c 1 Cl _EOS _PAD _PAD _PAD _PAD _PAD
acc_token: 0.4166666666666667, acc_seq: False

Target text: C C O C ( = O ) c 1 c ( F ) c c ( N 2 C C C ( N C ( = O ) O C ( C ) ( C ) C ) C 2 ) c ( F ) c 1 N C 1 C C 1 _EOS
Predicted text: C C O C ( = O ) c 1 c ( N C 2 C C 2 ) c c ( N 2 C C C ( N C ( = O ) O C ( C ) ( C ) C ) C 2 ) c ( F ) c 1 F _EOS
acc_token: 0.34545454545454546, acc_seq: False

Evaluation (without teacher) at step 280000, eval acc (token): 0.9360739196604854, eval acc (sequence): 0.8838623835772667
Saving at step 280000
Step 280100, loss: 0.03302997919730842, acc: 99.67146071791649, p_norm: 2200.903495593404, g_norm: 0.636706867875162, lr:  0.000472, elapsed time:  258064
Step 280200, loss: 0.033506599455140534, acc: 99.65278340876102, p_norm: 2201.0104584546602, g_norm: 0.5544090452339742, lr:  0.000472, elapsed time:  258154
Step 280300, loss: 0.03411923132371157, acc: 99.6371990442276, p_norm: 2201.118928636731, g_norm: 0.6971990124438041, lr:  0.000472, elapsed time:  258243
Step 280400, loss: 0.03349516733549535, acc: 99.65537895262241, p_norm: 2201.242265971576, g_norm: 0.6353315204269782, lr:  0.000472, elapsed time:  258334
Step 280500, loss: 0.03336966306902468, acc: 99.65815038979053, p_norm: 2201.350974660707, g_norm: 0.5065918208668756, lr:  0.000472, elapsed time:  258423
Step 280600, loss: 0.03370851607061923, acc: 99.6434730887413, p_norm: 2201.4708491873153, g_norm: 0.6950745723562483, lr:  0.000472, elapsed time:  258513
Step 280700, loss: 0.03459333072882145, acc: 99.62438280880451, p_norm: 2201.5813708723363, g_norm: 0.5163027087539452, lr:  0.000472, elapsed time:  258603
Step 280800, loss: 0.034080028934404254, acc: 99.63322262465954, p_norm: 2201.698562774494, g_norm: 0.5063138602618174, lr:  0.000472, elapsed time:  258693
Step 280900, loss: 0.0343718863138929, acc: 99.63018251955509, p_norm: 2201.8176911484707, g_norm: 0.5040726851578153, lr:  0.000472, elapsed time:  258781
Step 281000, loss: 0.033338815225288275, acc: 99.65919820964336, p_norm: 2201.9126453202143, g_norm: 0.5340244660204484, lr:  0.000471, elapsed time:  258874
Step 281100, loss: 0.03465059801004827, acc: 99.61916710436344, p_norm: 2202.0174750077476, g_norm: 0.670520671941424, lr:  0.000471, elapsed time:  258961
Step 281200, loss: 0.03452082857489586, acc: 99.62373022735119, p_norm: 2202.1144370999586, g_norm: 0.9381187976872131, lr:  0.000471, elapsed time:  259051
Step 281300, loss: 0.034744605547748504, acc: 99.62264592945576, p_norm: 2202.250285889903, g_norm: 0.5087268766976049, lr:  0.000471, elapsed time:  259143
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 281400, loss: 0.03387760595691886, acc: 99.6500878191706, p_norm: 2202.3613227290157, g_norm: 0.6807538811901781, lr:  0.000471, elapsed time:  259235
Step 281500, loss: 0.03403508821036667, acc: 99.63910007476807, p_norm: 2202.4850680153186, g_norm: 0.6664442692744236, lr:  0.000471, elapsed time:  259324
Step 281600, loss: 0.033727820883505046, acc: 99.64903335273266, p_norm: 2202.587998623353, g_norm: 0.6025565027181667, lr:  0.000471, elapsed time:  259415
Step 281700, loss: 0.033061181334778665, acc: 99.67275513708591, p_norm: 2202.6960073709497, g_norm: 0.5817604320985342, lr:  0.000471, elapsed time:  259503
Step 281800, loss: 0.03347358995582908, acc: 99.66137652099133, p_norm: 2202.7850904961274, g_norm: 0.7501553591056621, lr:  0.000471, elapsed time:  259595
Step 281900, loss: 0.03357918881811202, acc: 99.65066201984882, p_norm: 2202.8925123897016, g_norm: 0.5829216448267451, lr:  0.000471, elapsed time:  259685
Step 282000, loss: 0.03404873619787395, acc: 99.63842864334583, p_norm: 2203.0143364445707, g_norm: 0.7390087281773403, lr:  0.000471, elapsed time:  259776
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 282000, eval loss: 0.043331029526889324, eval acc: 99.53971862792969
Step 282100, loss: 0.03447523443028331, acc: 99.62889383733273, p_norm: 2203.115806038206, g_norm: 0.7291719237586587, lr:  0.000471, elapsed time:  259876
Step 282200, loss: 0.03355687986593694, acc: 99.6548662930727, p_norm: 2203.2239006810396, g_norm: 0.48826818321665044, lr:  0.000470, elapsed time:  259965
Step 282300, loss: 0.033616543114185334, acc: 99.64813686907291, p_norm: 2203.327397788381, g_norm: 0.6808468296213548, lr:  0.000470, elapsed time:  260054
Step 282400, loss: 0.034067059233784676, acc: 99.63725762069225, p_norm: 2203.446481799327, g_norm: 0.5935034813469469, lr:  0.000470, elapsed time:  260143
Step 282500, loss: 0.03351908618118614, acc: 99.6623985171318, p_norm: 2203.553712808857, g_norm: 0.7949477176795378, lr:  0.000470, elapsed time:  260233
Step 282600, loss: 0.03410944548901171, acc: 99.64042618870735, p_norm: 2203.6763805661517, g_norm: 0.44082631887164847, lr:  0.000470, elapsed time:  260322
Step 282700, loss: 0.034097702810540795, acc: 99.63774548470974, p_norm: 2203.7806380716447, g_norm: 0.8167069166796693, lr:  0.000470, elapsed time:  260418
Step 282800, loss: 0.03441548336762935, acc: 99.62540501356125, p_norm: 2203.911045088566, g_norm: 0.6170105164995797, lr:  0.000470, elapsed time:  260507
Step 282900, loss: 0.03481254706624895, acc: 99.61739103496075, p_norm: 2204.013841690972, g_norm: 0.4807767138884373, lr:  0.000470, elapsed time:  260593
Step 283000, loss: 0.03416392156854272, acc: 99.63395385444164, p_norm: 2204.128129433825, g_norm: 2.4042810727560764, lr:  0.000470, elapsed time:  260684
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 283100, loss: 0.035853195228329665, acc: 99.62445612876645, p_norm: 2204.2367328800174, g_norm: 0.6711853465461215, lr:  0.000470, elapsed time:  260772
Step 283200, loss: 0.0345767438178882, acc: 99.6532718539238, p_norm: 2204.3326763734685, g_norm: 0.5315976285338221, lr:  0.000470, elapsed time:  260861
Step 283300, loss: 0.03499902898911387, acc: 99.62932424247265, p_norm: 2204.428128716628, g_norm: 0.644684735372616, lr:  0.000470, elapsed time:  260953
Step 283400, loss: 0.03447048756293952, acc: 99.63416887819767, p_norm: 2204.543119325518, g_norm: 0.6036828534720309, lr:  0.000469, elapsed time:  261041
Step 283500, loss: 0.0338585394481197, acc: 99.66284906864166, p_norm: 2204.6579338108068, g_norm: 0.5805032453586145, lr:  0.000469, elapsed time:  261132
Step 283600, loss: 0.03388917265925556, acc: 99.64105239510536, p_norm: 2204.7620382514024, g_norm: 0.4960848834180025, lr:  0.000469, elapsed time:  261222
Step 283700, loss: 0.034441700731404123, acc: 99.62563936412334, p_norm: 2204.871340341345, g_norm: 0.5434886421455477, lr:  0.000469, elapsed time:  261313
Step 283800, loss: 0.0328862002119422, acc: 99.67127813398838, p_norm: 2204.983231482982, g_norm: 0.390723135529762, lr:  0.000469, elapsed time:  261405
Step 283900, loss: 0.03700184596702456, acc: 99.57857111096382, p_norm: 2205.1360302827993, g_norm: 0.7377272430926747, lr:  0.000469, elapsed time:  261495
Step 284000, loss: 0.03458768432959914, acc: 99.62427872419357, p_norm: 2205.236623218776, g_norm: 0.6502376022862066, lr:  0.000469, elapsed time:  261588
Calling G2SDataset.batch()
Done, time:  0.05 s, total batches: 527
Evaluation (with teacher) at step 284000, eval loss: 0.045370263699442165, eval acc: 99.45388793945312
Step 284100, loss: 0.0342455028090626, acc: 99.63066639006138, p_norm: 2205.3400199827643, g_norm: 0.5366725396901278, lr:  0.000469, elapsed time:  261674
Step 284200, loss: 0.034228698830120266, acc: 99.626294657588, p_norm: 2205.4705784476755, g_norm: 0.6221010783871395, lr:  0.000469, elapsed time:  261749
Step 284300, loss: 0.034589084638282655, acc: 99.61788709461689, p_norm: 2205.59362775181, g_norm: 0.4142721678704524, lr:  0.000469, elapsed time:  261820
Step 284400, loss: 0.03325674920808524, acc: 99.66343504190445, p_norm: 2205.6920196983665, g_norm: 0.8064178567376916, lr:  0.000469, elapsed time:  261895
Step 284500, loss: 0.03454409842379391, acc: 99.62106962502003, p_norm: 2205.786619880124, g_norm: 0.6108870639771845, lr:  0.000469, elapsed time:  261964
Step 284600, loss: 0.033591405963525174, acc: 99.64341442286968, p_norm: 2205.8915202228186, g_norm: 0.6297352763886145, lr:  0.000468, elapsed time:  262040
Step 284700, loss: 0.03445253811310977, acc: 99.62042012810707, p_norm: 2206.0056342696394, g_norm: 0.608335503079927, lr:  0.000468, elapsed time:  262110
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 284800, loss: 0.03360354882334509, acc: 99.6484405793268, p_norm: 2206.113576718126, g_norm: 0.6141909670801937, lr:  0.000468, elapsed time:  262180
Step 284900, loss: 0.03419728062581271, acc: 99.62669965624809, p_norm: 2206.2255046003856, g_norm: 0.6084225665189911, lr:  0.000468, elapsed time:  262251
Step 285000, loss: 0.03369126527570188, acc: 99.64466927945614, p_norm: 2206.319256178664, g_norm: 0.5212344618867623, lr:  0.000468, elapsed time:  262320
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Target text: C C O C ( = O ) C n 1 c c n c ( N C 2 C O C C 2 O C C 2 C C 2 ) c 1 = O _EOS
Predicted text: C C O C ( = O ) C n 1 c c n c ( N C 2 C O C C 2 O C C 2 C C 2 ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c ( - c 2 c c ( C ) c ( O C C C c 3 c n c 4 c c c c c 4 c 3 ) c ( C ) c 2 ) n o 1 _EOS
Predicted text: C c 1 n c ( - c 2 c c ( C ) c ( O C C C c 3 c n c 4 c c c c c 4 c 3 ) c ( C ) c 2 ) n o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C C = C C ( = O ) N 1 C C c 2 c ( o c 3 n c n c ( N c 4 c c c ( Cl ) c ( Cl ) c 4 ) c 2 3 ) C 1 _EOS
Predicted text: C N ( C ) C C = C C ( = O ) N 1 C C c 2 c ( o c 3 n c n c ( N c 4 c c c ( Cl ) c ( Cl ) c 4 ) c 2 3 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c 2 c ( O c 3 c c c 4 [nH] c ( C ) c c 4 c 3 F ) n c n c 2 c c 1 O _EOS
Predicted text: C O c 1 c c 2 c ( O c 3 c c c 4 [nH] c ( C ) c c 4 c 3 F ) n c n c 2 c c 1 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C N ( C C 1 C C N ( C ( = O ) O C ( C ) ( C ) C ) C C 1 ) C 1 C C c 2 c c c ( O C ) c c 2 C 1 _EOS
Predicted text: C C C N ( C C 1 C C N ( C ( = O ) O C ( C ) ( C ) C ) C C 1 ) C 1 C C c 2 c c c ( O C ) c c 2 C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 285000, eval acc (token): 0.9419696880716435, eval acc (sequence): 0.8898782482282391
Saving at step 285000
Step 285100, loss: 0.033191646737977865, acc: 99.66135860979557, p_norm: 2206.4102637521078, g_norm: 0.47592018364785615, lr:  0.000468, elapsed time:  262503
Step 285200, loss: 0.03298093731049448, acc: 99.66735289990902, p_norm: 2206.522668186444, g_norm: 0.5501291905149784, lr:  0.000468, elapsed time:  262601
Step 285300, loss: 0.034701422452926636, acc: 99.61867141723633, p_norm: 2206.6292202261006, g_norm: 0.4990064192624272, lr:  0.000468, elapsed time:  262696
Step 285400, loss: 0.033563122181221844, acc: 99.6568042486906, p_norm: 2206.729734676088, g_norm: 0.6802911855703251, lr:  0.000468, elapsed time:  262789
Step 285500, loss: 0.03383295562583953, acc: 99.63950930535793, p_norm: 2206.8449992777364, g_norm: 0.5434192229695975, lr:  0.000468, elapsed time:  262884
Step 285600, loss: 0.03370339815504849, acc: 99.64497689902782, p_norm: 2206.9509492187954, g_norm: 0.678642848351158, lr:  0.000468, elapsed time:  262981
Step 285700, loss: 0.033758222009055316, acc: 99.64316825568676, p_norm: 2207.06555167454, g_norm: 0.5210651751360825, lr:  0.000468, elapsed time:  263078
Step 285800, loss: 0.03383794905152172, acc: 99.64426954090595, p_norm: 2207.167596548638, g_norm: 0.6525179513924725, lr:  0.000467, elapsed time:  263170
Step 285900, loss: 0.03406745576765388, acc: 99.63616143167019, p_norm: 2207.284290904739, g_norm: 0.5929634850090978, lr:  0.000467, elapsed time:  263261
Step 286000, loss: 0.03335415312089026, acc: 99.66037425398827, p_norm: 2207.3863202426155, g_norm: 0.5505739248096048, lr:  0.000467, elapsed time:  263355
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 286000, eval loss: 0.04325133707374336, eval acc: 99.5496597290039
Step 286100, loss: 0.03438631487078965, acc: 99.63084203004837, p_norm: 2207.495709595885, g_norm: 0.48773064718500825, lr:  0.000467, elapsed time:  263465
Step 286200, loss: 0.03384295458439737, acc: 99.64138828217983, p_norm: 2207.5983378869078, g_norm: 0.7401946155576152, lr:  0.000467, elapsed time:  263565
Step 286300, loss: 0.03418366667348891, acc: 99.63532328605652, p_norm: 2207.702268895687, g_norm: 0.5655889753639672, lr:  0.000467, elapsed time:  263661
Step 286400, loss: 0.0341274192975834, acc: 99.63518695533276, p_norm: 2207.81145570768, g_norm: 0.6819193450215385, lr:  0.000467, elapsed time:  263753
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 286500, loss: 0.033555040400086056, acc: 99.65128937170873, p_norm: 2207.922820981867, g_norm: 0.49249435366712585, lr:  0.000467, elapsed time:  263847
Step 286600, loss: 0.03374599650967866, acc: 99.6441925317049, p_norm: 2208.0347399588836, g_norm: 0.5277873336911402, lr:  0.000467, elapsed time:  263941
Step 286700, loss: 0.03364795643370599, acc: 99.64930254220963, p_norm: 2208.133604989211, g_norm: 0.6627319994649601, lr:  0.000467, elapsed time:  264029
Step 286800, loss: 0.033513104780577126, acc: 99.65009418129921, p_norm: 2208.2392326708896, g_norm: 0.5037923322086391, lr:  0.000467, elapsed time:  264122
Step 286900, loss: 0.03432297133374959, acc: 99.62466098368168, p_norm: 2208.365319776863, g_norm: 0.5999836255355745, lr:  0.000467, elapsed time:  264211
Step 287000, loss: 0.03467934770043939, acc: 99.61466236412525, p_norm: 2208.485654122984, g_norm: 0.49848234307030903, lr:  0.000467, elapsed time:  264303
Step 287100, loss: 0.033957496313378216, acc: 99.64529889822006, p_norm: 2208.58804545288, g_norm: 0.5125791004395561, lr:  0.000466, elapsed time:  264393
Step 287200, loss: 0.03386532512959093, acc: 99.63979594409466, p_norm: 2208.6886006496243, g_norm: 0.5487039069852258, lr:  0.000466, elapsed time:  264484
Step 287300, loss: 0.03393855147063732, acc: 99.63646307587624, p_norm: 2208.7795863404563, g_norm: 0.6064060916679356, lr:  0.000466, elapsed time:  264572
Step 287400, loss: 0.033873178493231536, acc: 99.64472694694996, p_norm: 2208.8834051173008, g_norm: 0.4613869636654009, lr:  0.000466, elapsed time:  264660
Step 287500, loss: 0.033639353923499586, acc: 99.64332459867, p_norm: 2208.9999975131564, g_norm: 0.42253880754545975, lr:  0.000466, elapsed time:  264755
Step 287600, loss: 0.033086353591643275, acc: 99.66394299268723, p_norm: 2209.0925876714728, g_norm: 0.5929349643133676, lr:  0.000466, elapsed time:  264850
Step 287700, loss: 0.033427592376247046, acc: 99.66275936365128, p_norm: 2209.2144843522483, g_norm: 0.6197639803897249, lr:  0.000466, elapsed time:  264942
Step 287800, loss: 0.03424752166029066, acc: 99.64238019287586, p_norm: 2209.3123466980824, g_norm: 0.8018296203941008, lr:  0.000466, elapsed time:  265011
Step 287900, loss: 0.03398583541624248, acc: 99.64910206198692, p_norm: 2209.414182739692, g_norm: 0.8240555590382532, lr:  0.000466, elapsed time:  265083
Step 288000, loss: 0.033710491103120147, acc: 99.64522126317024, p_norm: 2209.5279922309346, g_norm: 0.48771627776549215, lr:  0.000466, elapsed time:  265169
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 288000, eval loss: 0.045307928621768946, eval acc: 99.48072814941406
Step 288100, loss: 0.03372243513353169, acc: 99.65015313029289, p_norm: 2209.6347502291724, g_norm: 0.5498502765274546, lr:  0.000466, elapsed time:  265277
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 288200, loss: 0.033948784846599876, acc: 99.63462401560459, p_norm: 2209.730013884736, g_norm: 0.4909736162690383, lr:  0.000466, elapsed time:  265366
Step 288300, loss: 0.03333585939835757, acc: 99.65407778322697, p_norm: 2209.8293685108656, g_norm: 0.5200518188370172, lr:  0.000465, elapsed time:  265454
Step 288400, loss: 0.03273279502056539, acc: 99.66655410826206, p_norm: 2209.9350866948485, g_norm: 0.6712345926076376, lr:  0.000465, elapsed time:  265546
Step 288500, loss: 0.033277964531444014, acc: 99.65772335231304, p_norm: 2210.0415732607535, g_norm: 0.4667870755358508, lr:  0.000465, elapsed time:  265636
Step 288600, loss: 0.03382768305949867, acc: 99.64112223684788, p_norm: 2210.159227461512, g_norm: 0.6490440569008101, lr:  0.000465, elapsed time:  265732
Step 288700, loss: 0.03355827843770385, acc: 99.6522423774004, p_norm: 2210.2693865114584, g_norm: 0.7184314821433657, lr:  0.000465, elapsed time:  265827
Step 288800, loss: 0.034045111769810316, acc: 99.64328619837761, p_norm: 2210.3968013825956, g_norm: 0.6439193960896135, lr:  0.000465, elapsed time:  265905
Step 288900, loss: 0.03483461490366608, acc: 99.63528726994991, p_norm: 2210.502598128671, g_norm: 0.49084584174923457, lr:  0.000465, elapsed time:  265975
Step 289000, loss: 0.03511746833100915, acc: 99.6428337842226, p_norm: 2210.6070926379584, g_norm: 0.777967274360754, lr:  0.000465, elapsed time:  266055
Step 289100, loss: 0.03615627828985453, acc: 99.61866199970245, p_norm: 2210.7017034714927, g_norm: 0.5003507083418075, lr:  0.000465, elapsed time:  266145
Step 289200, loss: 0.03500761108472943, acc: 99.63042835891247, p_norm: 2210.789555361102, g_norm: 0.5088677560499824, lr:  0.000465, elapsed time:  266234
Step 289300, loss: 0.03363484895788133, acc: 99.65950249135494, p_norm: 2210.907087919065, g_norm: 0.6451073923484881, lr:  0.000465, elapsed time:  266327
Step 289400, loss: 0.03411820759996772, acc: 99.6421510875225, p_norm: 2211.007337579075, g_norm: 0.49649204316853396, lr:  0.000465, elapsed time:  266422
Step 289500, loss: 0.03453253820538521, acc: 99.6329578012228, p_norm: 2211.108334068176, g_norm: 0.6585092118127549, lr:  0.000465, elapsed time:  266516
Step 289600, loss: 0.035628800513222814, acc: 99.6295174062252, p_norm: 2211.201470927215, g_norm: 0.39510912031563516, lr:  0.000464, elapsed time:  266609
Step 289700, loss: 0.03653293921612203, acc: 99.63377933204174, p_norm: 2211.3098874088587, g_norm: 0.4634173796320185, lr:  0.000464, elapsed time:  266699
Step 289800, loss: 0.03547589045483619, acc: 99.65122742950916, p_norm: 2211.4069609252674, g_norm: 0.4997889529296559, lr:  0.000464, elapsed time:  266790
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 289900, loss: 0.035789423520255145, acc: 99.63380156168297, p_norm: 2211.4933959952477, g_norm: 0.5942572499429281, lr:  0.000464, elapsed time:  266876
Step 290000, loss: 0.03415778330061585, acc: 99.6594987809658, p_norm: 2211.601959743734, g_norm: 0.3822308875598354, lr:  0.000464, elapsed time:  266967
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 290000, eval loss: 0.043816142249852426, eval acc: 99.52256774902344
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c c c c 1 N C ( = O ) N c 1 c c c ( C C ( = O ) O C ( C ) ( C ) C ) c c 1 C _EOS
Predicted text: C O c 1 c c c c c 1 N C ( = O ) N c 1 c c c ( C C ( = O ) O C ( C ) ( C ) C ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 n c c ( N C ( = O ) C N C ( = O ) O C ( C ) ( C ) C ) c 1 N C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C n 1 n c c ( N C ( = O ) C N C ( = O ) O C ( C ) ( C ) C ) c 1 N C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C C c 1 c c c c c 1 ) C ( = O ) C n 1 c c ( C C C ( = O ) O ) c 2 c c ( O C c 3 c c c c c 3 ) c c c 2 1 _EOS
Predicted text: C N ( C C c 1 c c c c c 1 ) C ( = O ) C n 1 c c ( C C C ( = O ) O ) c 2 c c ( O C c 3 c c c c c 3 ) c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: Cl [SiH] ( Cl ) C c 1 c c c c c 1 _EOS
Predicted text: Cl [Si] ( Cl ) ( Cl ) C c 1 c c c c c 1 _EOS
acc_token: 0.4666666666666667, acc_seq: False

Target text: O = C ( N c 1 c c c c ( - n 2 c ( = O ) c ( C c 3 c c c n c 3 ) n c 3 c c c n c 3 2 ) c 1 ) c 1 c c ( Cl ) c c ( Cl ) c 1 _EOS
Predicted text: O = C ( N c 1 c c c c ( - n 2 c ( = O ) c ( C c 3 c c c n c 3 ) n c 3 c c c n c 3 2 ) c 1 ) c 1 c c ( Cl ) c c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 290000, eval acc (token): 0.9316219259513578, eval acc (sequence): 0.8759124087591241
Saving at step 290000
Step 290100, loss: 0.03435495451558381, acc: 99.64644274115562, p_norm: 2211.707570761955, g_norm: 0.6154895409272408, lr:  0.000464, elapsed time:  267154
Step 290200, loss: 0.033418409922160205, acc: 99.66604919731617, p_norm: 2211.7873168635565, g_norm: 0.5339010173994402, lr:  0.000464, elapsed time:  267244
Step 290300, loss: 0.033715083771385254, acc: 99.64567685127258, p_norm: 2211.886307544, g_norm: 1.0511123189252218, lr:  0.000464, elapsed time:  267334
Step 290400, loss: 0.03381643391214311, acc: 99.6548762023449, p_norm: 2211.9928955034293, g_norm: 0.7462519772030166, lr:  0.000464, elapsed time:  267427
Step 290500, loss: 0.03372366453055292, acc: 99.6504737585783, p_norm: 2212.1033813351773, g_norm: 0.6273236686050523, lr:  0.000464, elapsed time:  267514
Step 290600, loss: 0.03364364213310182, acc: 99.64388957619667, p_norm: 2212.2096269053723, g_norm: 0.5178007217086976, lr:  0.000464, elapsed time:  267608
Step 290700, loss: 0.033219019761309025, acc: 99.66475488245487, p_norm: 2212.3117366836796, g_norm: 0.5244634652037209, lr:  0.000464, elapsed time:  267696
Step 290800, loss: 0.03340637735556811, acc: 99.6607196778059, p_norm: 2212.4206874516403, g_norm: 0.7051852397100872, lr:  0.000463, elapsed time:  267787
Step 290900, loss: 0.03327645921614021, acc: 99.6592763364315, p_norm: 2212.5208880306136, g_norm: 0.6612529510213938, lr:  0.000463, elapsed time:  267873
Step 291000, loss: 0.033828982966952026, acc: 99.64582267403603, p_norm: 2212.6300473634797, g_norm: 0.6806613863135492, lr:  0.000463, elapsed time:  267963
Step 291100, loss: 0.03325987933203578, acc: 99.66202606260777, p_norm: 2212.7445733726977, g_norm: 0.5613998455102737, lr:  0.000463, elapsed time:  268054
Step 291200, loss: 0.03405088046565652, acc: 99.63102841377258, p_norm: 2212.854183712711, g_norm: 0.5094503581027487, lr:  0.000463, elapsed time:  268146
Step 291300, loss: 0.033730736738070845, acc: 99.64521983265877, p_norm: 2212.960318019297, g_norm: 0.6289987550895341, lr:  0.000463, elapsed time:  268233
Step 291400, loss: 0.034230656051076946, acc: 99.63041737675667, p_norm: 2213.0747315489907, g_norm: 0.5098957683448384, lr:  0.000463, elapsed time:  268321
Step 291500, loss: 0.03388820996042341, acc: 99.63876770436764, p_norm: 2213.1807032715765, g_norm: 0.7139325488671749, lr:  0.000463, elapsed time:  268410
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 291600, loss: 0.03323128538913378, acc: 99.65611687369146, p_norm: 2213.279569175429, g_norm: 0.579909431161434, lr:  0.000463, elapsed time:  268500
Step 291700, loss: 0.033584677670151, acc: 99.65241511166096, p_norm: 2213.387718136359, g_norm: 0.5730679570216745, lr:  0.000463, elapsed time:  268588
Step 291800, loss: 0.034265610976144674, acc: 99.63869009912014, p_norm: 2213.4907703585613, g_norm: 0.5990761004644933, lr:  0.000463, elapsed time:  268678
Step 291900, loss: 0.03399129971861839, acc: 99.65934808552265, p_norm: 2213.588699502457, g_norm: 0.5580044990191207, lr:  0.000463, elapsed time:  268769
Step 292000, loss: 0.03430914086289704, acc: 99.64256556332111, p_norm: 2213.6997225184787, g_norm: 0.624257672131452, lr:  0.000463, elapsed time:  268859
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 292000, eval loss: 0.04267188817262651, eval acc: 99.56779479980469
Step 292100, loss: 0.03472567206248641, acc: 99.63683271408081, p_norm: 2213.8132251070524, g_norm: 0.5924363323787801, lr:  0.000462, elapsed time:  268963
Step 292200, loss: 0.03382351783569902, acc: 99.65480926632881, p_norm: 2213.925728725756, g_norm: 0.5646740514511187, lr:  0.000462, elapsed time:  269051
Step 292300, loss: 0.03370900090783834, acc: 99.64950881898403, p_norm: 2214.0422845080625, g_norm: 0.5370734903379639, lr:  0.000462, elapsed time:  269142
Step 292400, loss: 0.033352663298137485, acc: 99.65509335696697, p_norm: 2214.145403356022, g_norm: 0.5211608869952781, lr:  0.000462, elapsed time:  269230
Step 292500, loss: 0.03389918878674507, acc: 99.63976821303368, p_norm: 2214.2683973888484, g_norm: 0.6528045978882966, lr:  0.000462, elapsed time:  269322
Step 292600, loss: 0.03377212337683886, acc: 99.64373007416725, p_norm: 2214.3823231887063, g_norm: 0.5174378512972122, lr:  0.000462, elapsed time:  269410
Step 292700, loss: 0.03369929528329521, acc: 99.6515051573515, p_norm: 2214.483513444129, g_norm: 0.5637072827214779, lr:  0.000462, elapsed time:  269498
Step 292800, loss: 0.03458988524973392, acc: 99.62836340069771, p_norm: 2214.6127162712082, g_norm: 0.6581318067998864, lr:  0.000462, elapsed time:  269586
Step 292900, loss: 0.03404487606137991, acc: 99.64543282985687, p_norm: 2214.7280517317226, g_norm: 0.4194425095937605, lr:  0.000462, elapsed time:  269677
Step 293000, loss: 0.03399735108949244, acc: 99.63495936989784, p_norm: 2214.8282899633527, g_norm: 0.675680039012109, lr:  0.000462, elapsed time:  269766
Step 293100, loss: 0.03364509456325322, acc: 99.65605127811432, p_norm: 2214.9285742754973, g_norm: 0.7290137144107347, lr:  0.000462, elapsed time:  269859
Step 293200, loss: 0.034119622283615175, acc: 99.63726179301739, p_norm: 2215.0369972954854, g_norm: 0.5947082253135321, lr:  0.000462, elapsed time:  269948
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 293300, loss: 0.034126855936779575, acc: 99.63743325794306, p_norm: 2215.1449248886925, g_norm: 0.6295820796365275, lr:  0.000461, elapsed time:  270037
Step 293400, loss: 0.03353426450863481, acc: 99.64623387157917, p_norm: 2215.2447311247265, g_norm: 0.5046721490966898, lr:  0.000461, elapsed time:  270123
Step 293500, loss: 0.033439084072597325, acc: 99.65494684875011, p_norm: 2215.350760580729, g_norm: 0.5940459611325593, lr:  0.000461, elapsed time:  270217
Step 293600, loss: 0.033213432440534235, acc: 99.6622721850872, p_norm: 2215.4563433053863, g_norm: 0.7913828854835682, lr:  0.000461, elapsed time:  270311
Step 293700, loss: 0.03354875591117889, acc: 99.64819099009037, p_norm: 2215.554189949976, g_norm: 0.6025881746886086, lr:  0.000461, elapsed time:  270399
Step 293800, loss: 0.03335807190742344, acc: 99.65675316751003, p_norm: 2215.6535188347666, g_norm: 0.5279694052755953, lr:  0.000461, elapsed time:  270490
Step 293900, loss: 0.033271450703032314, acc: 99.65671533346176, p_norm: 2215.7634206836024, g_norm: 0.5971870467093586, lr:  0.000461, elapsed time:  270581
Step 294000, loss: 0.03278445539064705, acc: 99.67442314326763, p_norm: 2215.8547447285596, g_norm: 0.6939612614191658, lr:  0.000461, elapsed time:  270670
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 294000, eval loss: 0.04361712103709579, eval acc: 99.547607421875
Step 294100, loss: 0.03335291894152761, acc: 99.65578700602055, p_norm: 2215.954336364167, g_norm: 0.6695841112034993, lr:  0.000461, elapsed time:  270779
Step 294200, loss: 0.03486780785024166, acc: 99.6323798596859, p_norm: 2216.049258914178, g_norm: 0.5483505786826688, lr:  0.000461, elapsed time:  270866
Step 294300, loss: 0.03391548925079405, acc: 99.65195553004742, p_norm: 2216.143657327489, g_norm: 0.539059366501985, lr:  0.000461, elapsed time:  270956
Step 294400, loss: 0.0347985049104318, acc: 99.61542628705502, p_norm: 2216.2503655294768, g_norm: 0.6559755913064479, lr:  0.000461, elapsed time:  271045
Step 294500, loss: 0.03338806836400181, acc: 99.66229049861431, p_norm: 2216.3526890394764, g_norm: 0.6917101412147032, lr:  0.000461, elapsed time:  271135
Step 294600, loss: 0.034544838820584116, acc: 99.6342461258173, p_norm: 2216.4724536322474, g_norm: 0.5930841324095004, lr:  0.000460, elapsed time:  271226
Step 294700, loss: 0.03360067845322192, acc: 99.66209761798382, p_norm: 2216.569988720618, g_norm: 0.6956954466943347, lr:  0.000460, elapsed time:  271316
Step 294800, loss: 0.03578180109616369, acc: 99.59891456365585, p_norm: 2216.6918808235037, g_norm: 0.6268981824448886, lr:  0.000460, elapsed time:  271410
Step 294900, loss: 0.03414200687315315, acc: 99.63255086541176, p_norm: 2216.785763694918, g_norm: 0.6670408663910947, lr:  0.000460, elapsed time:  271497
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 295000, loss: 0.033835716439277005, acc: 99.63749398664564, p_norm: 2216.8949964682256, g_norm: 0.5040973858209414, lr:  0.000460, elapsed time:  271588
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c ( O C c 2 c ( - c 3 c c c c c 3 O C ( F ) ( F ) F ) n o c 2 C 2 C C 2 ) c c c 1 - c 1 c c c 2 c ( C ( = O ) O ) c ( C ) s c 2 c 1 _EOS
Predicted text: C c 1 c c ( O C c 2 c ( - c 3 c c c c c 3 O C ( F ) ( F ) F ) n o c 2 C 2 C C 2 ) c c c 1 - c 1 c c c 2 c ( C ( = O ) O ) c ( C ) s c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = S 1 C C n 2 c 1 n c ( - c 1 c c c ( F ) c c 1 ) c 2 - c 1 c c n c c 1 _EOS
Predicted text: O = S 1 C C n 2 c 1 n c ( - c 1 c c c ( F ) c c 1 ) c 2 - c 1 c c n c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c n c ( - c 2 c c c c c 2 ) n c 1 Cl _EOS
Predicted text: C C O C ( = O ) c 1 c n c ( - c 2 c c c c c 2 ) n c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C C C ( C ( N ) = O ) N 1 C c 2 c ( O C c 3 c c c 4 c c c c c 4 n 3 ) c c c c 2 C 1 = O _EOS
Predicted text: C O C ( = O ) C C C ( C ( N ) = O ) N 1 C c 2 c ( O C c 3 c c c 4 c c c c c 4 n 3 ) c c c c 2 C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C c 1 c c ( - c 2 n o c ( C ) n 2 ) c c c 1 O S ( = O ) ( = O ) C ( F ) ( F ) F _EOS
Predicted text: C = C C c 1 c c ( - c 2 n o c ( C ) n 2 ) c c c 1 O S ( = O ) ( = O ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 295000, eval acc (token): 0.9399351068999217, eval acc (sequence): 0.8891040309804612
Saving at step 295000
Step 295100, loss: 0.0326309467246756, acc: 99.67801386117935, p_norm: 2216.9993258300183, g_norm: 0.5811787218466139, lr:  0.000460, elapsed time:  271759
Step 295200, loss: 0.03297355280723423, acc: 99.66267651319504, p_norm: 2217.098651879713, g_norm: 0.5477035279514874, lr:  0.000460, elapsed time:  271849
Step 295300, loss: 0.032941443156450985, acc: 99.6630547940731, p_norm: 2217.1879056128882, g_norm: 0.5747383943485092, lr:  0.000460, elapsed time:  271938
Step 295400, loss: 0.03283823407255113, acc: 99.66486638784409, p_norm: 2217.3014789131444, g_norm: 0.5544952092181108, lr:  0.000460, elapsed time:  272031
Step 295500, loss: 0.03340813490562141, acc: 99.65895649790764, p_norm: 2217.396938601307, g_norm: 0.4980858659117436, lr:  0.000460, elapsed time:  272122
Step 295600, loss: 0.03325562238227576, acc: 99.6570658236742, p_norm: 2217.5011900351215, g_norm: 0.5714654569018185, lr:  0.000460, elapsed time:  272211
Step 295700, loss: 0.033594453553669155, acc: 99.637257412076, p_norm: 2217.606990763421, g_norm: 0.5182810655099388, lr:  0.000460, elapsed time:  272300
Step 295800, loss: 0.033191452324390414, acc: 99.66304603219032, p_norm: 2217.7099773320365, g_norm: 0.5796615407588244, lr:  0.000460, elapsed time:  272393
Step 295900, loss: 0.033901918032206595, acc: 99.64044250547886, p_norm: 2217.812950351385, g_norm: 0.82433234315776, lr:  0.000459, elapsed time:  272483
Step 296000, loss: 0.03356221770402044, acc: 99.64928112924099, p_norm: 2217.9213502425737, g_norm: 0.5809528307743758, lr:  0.000459, elapsed time:  272575
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 296000, eval loss: 0.04804268568754198, eval acc: 99.46802520751953
Step 296100, loss: 0.03382507698610425, acc: 99.63839693367481, p_norm: 2218.0199813638033, g_norm: 0.403088273287408, lr:  0.000459, elapsed time:  272680
Step 296200, loss: 0.03396589244250208, acc: 99.64107573032379, p_norm: 2218.136675817185, g_norm: 0.49091277611956785, lr:  0.000459, elapsed time:  272767
Step 296300, loss: 0.03361027492210269, acc: 99.64538098871708, p_norm: 2218.2421259821886, g_norm: 0.5944995890712069, lr:  0.000459, elapsed time:  272855
Step 296400, loss: 0.034017592230811716, acc: 99.63425570726395, p_norm: 2218.351807128747, g_norm: 0.5813003393855999, lr:  0.000459, elapsed time:  272945
Step 296500, loss: 0.034067511977627876, acc: 99.638910099864, p_norm: 2218.4525345774177, g_norm: 0.6135108134815024, lr:  0.000459, elapsed time:  273043
Step 296600, loss: 0.03356770030688495, acc: 99.64259380102158, p_norm: 2218.5531777530496, g_norm: 0.5507295083389852, lr:  0.000459, elapsed time:  273138
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 296700, loss: 0.03364321303833507, acc: 99.64307977011423, p_norm: 2218.663130336227, g_norm: 0.5440462317828282, lr:  0.000459, elapsed time:  273229
Step 296800, loss: 0.0335716886119917, acc: 99.64625264704227, p_norm: 2218.756338815332, g_norm: 0.5678229846050976, lr:  0.000459, elapsed time:  273318
Step 296900, loss: 0.032235580994747576, acc: 99.69307950139046, p_norm: 2218.8581947836915, g_norm: 0.5247965366109552, lr:  0.000459, elapsed time:  273411
Step 297000, loss: 0.03290312275290489, acc: 99.66966065764427, p_norm: 2218.942540372377, g_norm: 0.5507551477614039, lr:  0.000459, elapsed time:  273502
Step 297100, loss: 0.03314872412476689, acc: 99.65558145940304, p_norm: 2219.056187413303, g_norm: 0.572625632335137, lr:  0.000459, elapsed time:  273597
Step 297200, loss: 0.03330155202187598, acc: 99.65536153316498, p_norm: 2219.172535238936, g_norm: 0.6913400179569433, lr:  0.000458, elapsed time:  273688
Step 297300, loss: 0.033146633324213325, acc: 99.66624520719051, p_norm: 2219.273075437766, g_norm: 0.5235708370031632, lr:  0.000458, elapsed time:  273778
Step 297400, loss: 0.03329684246331453, acc: 99.65245166420937, p_norm: 2219.3694397751933, g_norm: 0.826991609949575, lr:  0.000458, elapsed time:  273873
Step 297500, loss: 0.033591753821820024, acc: 99.64565351605415, p_norm: 2219.484971441931, g_norm: 0.4256553983580955, lr:  0.000458, elapsed time:  273961
Step 297600, loss: 0.033930542673915626, acc: 99.64215932786465, p_norm: 2219.595758441886, g_norm: 0.6665836892020919, lr:  0.000458, elapsed time:  274051
Step 297700, loss: 0.03455337624531239, acc: 99.64211337268353, p_norm: 2219.7192885832437, g_norm: 0.7498103311787763, lr:  0.000458, elapsed time:  274149
Step 297800, loss: 0.033770867944695054, acc: 99.65398620069027, p_norm: 2219.8244868674137, g_norm: 0.5914328162963486, lr:  0.000458, elapsed time:  274237
Step 297900, loss: 0.03390507441014051, acc: 99.63492549955845, p_norm: 2219.9190493073747, g_norm: 0.4723923367622424, lr:  0.000458, elapsed time:  274329
Step 298000, loss: 0.034209686471149324, acc: 99.62931883335114, p_norm: 2220.0175504372537, g_norm: 0.565423516494663, lr:  0.000458, elapsed time:  274420
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 298000, eval loss: 0.044131399299949414, eval acc: 99.52383422851562
Step 298100, loss: 0.03397008722648025, acc: 99.63786743581295, p_norm: 2220.1125813941635, g_norm: 0.4744952935903758, lr:  0.000458, elapsed time:  274521
Step 298200, loss: 0.03349746928550303, acc: 99.65605460107327, p_norm: 2220.2022243537563, g_norm: 0.5415313791559474, lr:  0.000458, elapsed time:  274611
Step 298300, loss: 0.03370821044314653, acc: 99.64789429306984, p_norm: 2220.3112034258497, g_norm: 0.6611446492515742, lr:  0.000458, elapsed time:  274700
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 298400, loss: 0.03315386164554443, acc: 99.66473490665332, p_norm: 2220.4094076017586, g_norm: 0.5054000957986637, lr:  0.000458, elapsed time:  274792
Step 298500, loss: 0.03291815932374448, acc: 99.67343842983246, p_norm: 2220.506016752688, g_norm: 0.6393368128334463, lr:  0.000457, elapsed time:  274883
Step 298600, loss: 0.033308954895474016, acc: 99.66140380501747, p_norm: 2220.6178467761633, g_norm: 0.47538771669555285, lr:  0.000457, elapsed time:  274975
Step 298700, loss: 0.0328419084707275, acc: 99.67380814254284, p_norm: 2220.7084880435627, g_norm: 0.5686440340623157, lr:  0.000457, elapsed time:  275067
Step 298800, loss: 0.033219841518439354, acc: 99.65662832558155, p_norm: 2220.802392227093, g_norm: 0.5418880967135521, lr:  0.000457, elapsed time:  275156
Step 298900, loss: 0.03310188309289515, acc: 99.65882731974125, p_norm: 2220.905169745902, g_norm: 0.7042378795271851, lr:  0.000457, elapsed time:  275247
Step 299000, loss: 0.033537394194863734, acc: 99.64632008969784, p_norm: 2221.001382255701, g_norm: 0.6261703842201736, lr:  0.000457, elapsed time:  275337
Step 299100, loss: 0.03442588175181299, acc: 99.64640094339848, p_norm: 2221.1074516067515, g_norm: 0.619359588454419, lr:  0.000457, elapsed time:  275427
Step 299200, loss: 0.03463279640767723, acc: 99.6381015330553, p_norm: 2221.1997534879692, g_norm: 0.49551169936392514, lr:  0.000457, elapsed time:  275517
Step 299300, loss: 0.03325347537640482, acc: 99.67137813568115, p_norm: 2221.305974444007, g_norm: 0.5291927750494303, lr:  0.000457, elapsed time:  275614
Step 299400, loss: 0.03433175936341286, acc: 99.63745264708996, p_norm: 2221.4168251121746, g_norm: 0.4603613254782485, lr:  0.000457, elapsed time:  275695
Step 299500, loss: 0.03333839581348002, acc: 99.6576739102602, p_norm: 2221.5046666974154, g_norm: 0.762643556423512, lr:  0.000457, elapsed time:  275764
Step 299600, loss: 0.03415346083696932, acc: 99.63132531940937, p_norm: 2221.6115767475185, g_norm: 0.5666212208089191, lr:  0.000457, elapsed time:  275837
Step 299700, loss: 0.03442126035690308, acc: 99.62603367865086, p_norm: 2221.726322787561, g_norm: 0.6485702192116747, lr:  0.000457, elapsed time:  275926
Step 299800, loss: 0.03334909524768591, acc: 99.65508687496185, p_norm: 2221.8324457181925, g_norm: 0.7695518718202308, lr:  0.000456, elapsed time:  276017
Step 299900, loss: 0.03320605772547424, acc: 99.66110751032829, p_norm: 2221.936786569337, g_norm: 0.45370550429014184, lr:  0.000456, elapsed time:  276106
Step 300000, loss: 0.03369717950001359, acc: 99.6440497636795, p_norm: 2222.041737601173, g_norm: 0.8657853787313401, lr:  0.000456, elapsed time:  276197
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 300000, eval loss: 0.04493283767253161, eval acc: 99.5057601928711
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( C ) O C ( = O ) N C 1 ( c 2 c c c ( - c 3 c ( - c 4 c c c c c 4 ) o c 4 c c c c c 4 c 3 = O ) c c 2 ) C C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C 1 ( c 2 c c c ( - c 3 c ( - c 4 c c c c c 4 ) o c 4 c c c c c 4 c 3 = O ) c c 2 ) C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 s c ( S C ) c 2 c 1 C C C ( C = O ) = C 2 Cl _EOS
Predicted text: C C O C ( = O ) c 1 s c ( Cl ) c 2 c 1 C C C C 2 = O _EOS _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.48484848484848486, acc_seq: False

Target text: O = C C C O C C C C c 1 c c c c c 1 _EOS
Predicted text: O = C C C O C C C C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C # C c 1 c n c c ( C 2 C C C ( = O ) N 2 C ) c 1 _EOS
Predicted text: C # C C ( C ) ( C c 1 c n c c ( C 2 C C C ( = O ) N 2 C ) c 1 ) O C _EOS
acc_token: 0.15384615384615385, acc_seq: False

Target text: C C C C N 1 C C N ( S ( C ) ( = O ) = O ) c 2 c c c ( C ( = O ) N C ( C c 3 c c ( F ) c c ( F ) c 3 ) C ( O ) C N C c 3 c c c c ( C C ) c 3 ) c c 2 1 _EOS
Predicted text: C C C C N 1 C C N ( S ( C ) ( = O ) = O ) c 2 c c c ( C ( = O ) N C ( C c 3 c c ( F ) c c ( F ) c 3 ) C ( O ) C N C c 3 c c c c ( C C ) c 3 ) c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 300000, eval acc (token): 0.93125868496257, eval acc (sequence): 0.8782216494845361
Saving at step 300000
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 300100, loss: 0.03391730242793388, acc: 99.63931740812994, p_norm: 2222.1551189221464, g_norm: 0.6459593600546509, lr:  0.000456, elapsed time:  276385
Step 300200, loss: 0.03312241139821708, acc: 99.67822408676147, p_norm: 2222.250235785121, g_norm: 0.5440542662490576, lr:  0.000456, elapsed time:  276480
Step 300300, loss: 0.034063255582004785, acc: 99.65066935122013, p_norm: 2222.3514245907745, g_norm: 0.6014941638123787, lr:  0.000456, elapsed time:  276573
Step 300400, loss: 0.033666278808377685, acc: 99.66348388791084, p_norm: 2222.4546173656545, g_norm: 0.6496742872029239, lr:  0.000456, elapsed time:  276663
Step 300500, loss: 0.03387698492500931, acc: 99.63907180726528, p_norm: 2222.563930865738, g_norm: 0.6420277805985513, lr:  0.000456, elapsed time:  276752
Step 300600, loss: 0.03382222185377032, acc: 99.64493276178837, p_norm: 2222.6711294634774, g_norm: 0.5412934386588937, lr:  0.000456, elapsed time:  276841
Step 300700, loss: 0.03331530722323805, acc: 99.65844249725342, p_norm: 2222.776368285108, g_norm: 0.5746826566252446, lr:  0.000456, elapsed time:  276932
Step 300800, loss: 0.033102867747657, acc: 99.6683275103569, p_norm: 2222.880591454542, g_norm: 0.40287386894692306, lr:  0.000456, elapsed time:  277025
Step 300900, loss: 0.033439348358660935, acc: 99.65062296390533, p_norm: 2222.9886447213876, g_norm: 0.618115214203091, lr:  0.000456, elapsed time:  277118
Step 301000, loss: 0.03357844692189246, acc: 99.64812014997005, p_norm: 2223.097149579393, g_norm: 0.5801990944807606, lr:  0.000456, elapsed time:  277207
Step 301100, loss: 0.03335868287831545, acc: 99.64827805757523, p_norm: 2223.203522694596, g_norm: 0.5882163577672674, lr:  0.000455, elapsed time:  277299
Step 301200, loss: 0.033824400808662176, acc: 99.63996441662312, p_norm: 2223.3060825493017, g_norm: 0.5581932713162473, lr:  0.000455, elapsed time:  277391
Step 301300, loss: 0.033399492860771714, acc: 99.65264715254307, p_norm: 2223.404251664986, g_norm: 0.7214062374211277, lr:  0.000455, elapsed time:  277481
Step 301400, loss: 0.034026185106486084, acc: 99.63477939367294, p_norm: 2223.511039201309, g_norm: 0.6193316446414189, lr:  0.000455, elapsed time:  277572
Step 301500, loss: 0.033237421959638594, acc: 99.65935523808002, p_norm: 2223.611186847108, g_norm: 0.6912897454197429, lr:  0.000455, elapsed time:  277664
Step 301600, loss: 0.033769213217310606, acc: 99.64436835050583, p_norm: 2223.72302001219, g_norm: 0.4252630676907945, lr:  0.000455, elapsed time:  277753
Step 301700, loss: 0.03277933746576309, acc: 99.6761199682951, p_norm: 2223.8147763757615, g_norm: 0.6003612859283838, lr:  0.000455, elapsed time:  277847
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 301800, loss: 0.033556214603247925, acc: 99.65747935854974, p_norm: 2223.9241034733172, g_norm: 0.4678856993542537, lr:  0.000455, elapsed time:  277936
Step 301900, loss: 0.0333550062822178, acc: 99.65244787931442, p_norm: 2224.0233795974536, g_norm: 0.5623440370588765, lr:  0.000455, elapsed time:  278028
Step 302000, loss: 0.0328344718972221, acc: 99.66639086604118, p_norm: 2224.1215753666283, g_norm: 0.4340324349696321, lr:  0.000455, elapsed time:  278120
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 302000, eval loss: 0.041916114874184146, eval acc: 99.56720733642578
Step 302100, loss: 0.03288125235587359, acc: 99.67125533521175, p_norm: 2224.221333219697, g_norm: 0.8262709260062712, lr:  0.000455, elapsed time:  278225
Step 302200, loss: 0.033149354471825064, acc: 99.66477866470814, p_norm: 2224.327111769126, g_norm: 0.5457718271879828, lr:  0.000455, elapsed time:  278314
Step 302300, loss: 0.032941056229174134, acc: 99.66873620450497, p_norm: 2224.4095569624487, g_norm: 0.43631138080930953, lr:  0.000455, elapsed time:  278402
Step 302400, loss: 0.03316089410334826, acc: 99.66081514954567, p_norm: 2224.4995122124474, g_norm: 0.5565777820613187, lr:  0.000454, elapsed time:  278494
Step 302500, loss: 0.03317593184299767, acc: 99.66111598908901, p_norm: 2224.60309417491, g_norm: 0.6461873859709031, lr:  0.000454, elapsed time:  278584
Step 302600, loss: 0.033311428632587195, acc: 99.65310935676098, p_norm: 2224.7083327834816, g_norm: 0.419476465713129, lr:  0.000454, elapsed time:  278679
Step 302700, loss: 0.033486716444604096, acc: 99.65290054678917, p_norm: 2224.8096401653384, g_norm: 0.4513431290011217, lr:  0.000454, elapsed time:  278771
Step 302800, loss: 0.03344022213015705, acc: 99.6519402563572, p_norm: 2224.9080417423525, g_norm: 0.7178134766596669, lr:  0.000454, elapsed time:  278862
Step 302900, loss: 0.03352282064966858, acc: 99.6548760086298, p_norm: 2225.0072478745706, g_norm: 0.5880812854077611, lr:  0.000454, elapsed time:  278951
Step 303000, loss: 0.03303573756013065, acc: 99.66950069367886, p_norm: 2225.1100036586054, g_norm: 0.6215993101166071, lr:  0.000454, elapsed time:  279043
Step 303100, loss: 0.034269053461030125, acc: 99.63888536393642, p_norm: 2225.206089840661, g_norm: 0.5109370610396193, lr:  0.000454, elapsed time:  279135
Step 303200, loss: 0.034783640187233685, acc: 99.64505071938038, p_norm: 2225.299692715923, g_norm: 0.49833630025655457, lr:  0.000454, elapsed time:  279233
Step 303300, loss: 0.034071274464949966, acc: 99.64387729763985, p_norm: 2225.3968440874664, g_norm: 0.4581720464982949, lr:  0.000454, elapsed time:  279320
Step 303400, loss: 0.03377895781770349, acc: 99.64411264657974, p_norm: 2225.4954971899465, g_norm: 0.5507287791080292, lr:  0.000454, elapsed time:  279408
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 303500, loss: 0.03356773747366948, acc: 99.65510616823107, p_norm: 2225.6070738990766, g_norm: 0.6109119522241048, lr:  0.000454, elapsed time:  279500
Step 303600, loss: 0.03264243985991925, acc: 99.68569521605968, p_norm: 2225.708130015078, g_norm: 0.4653723750141283, lr:  0.000454, elapsed time:  279592
Step 303700, loss: 0.033283550753258166, acc: 99.66464623808861, p_norm: 2225.801146757737, g_norm: 0.5474780302205651, lr:  0.000454, elapsed time:  279680
Step 303800, loss: 0.03333906692452729, acc: 99.65058368444443, p_norm: 2225.90352313343, g_norm: 0.6498441522350603, lr:  0.000453, elapsed time:  279768
Step 303900, loss: 0.0328480032319203, acc: 99.66913376748562, p_norm: 2226.0114758288005, g_norm: 0.5300006521502892, lr:  0.000453, elapsed time:  279859
Step 304000, loss: 0.03371040470898151, acc: 99.63985146582127, p_norm: 2226.113810944806, g_norm: 0.5443243347295088, lr:  0.000453, elapsed time:  279948
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 304000, eval loss: 0.04551630198955534, eval acc: 99.51681518554688
Step 304100, loss: 0.033764585671015084, acc: 99.6445237249136, p_norm: 2226.2067602795173, g_norm: 0.6317450660417614, lr:  0.000453, elapsed time:  280050
Step 304200, loss: 0.03288254783954472, acc: 99.66533379256725, p_norm: 2226.3029559019583, g_norm: 0.8822834360426346, lr:  0.000453, elapsed time:  280142
Step 304300, loss: 0.03372939168475568, acc: 99.64816631376743, p_norm: 2226.4045924916904, g_norm: 0.5154297968746415, lr:  0.000453, elapsed time:  280231
Step 304400, loss: 0.03321491749957204, acc: 99.66754326224327, p_norm: 2226.5064489509546, g_norm: 0.6112370731388657, lr:  0.000453, elapsed time:  280321
Step 304500, loss: 0.033376790350303054, acc: 99.64651353657246, p_norm: 2226.6083711363945, g_norm: 0.4872528037101616, lr:  0.000453, elapsed time:  280413
Step 304600, loss: 0.0338554132077843, acc: 99.64875046908855, p_norm: 2226.705818312942, g_norm: 0.6253255012331526, lr:  0.000453, elapsed time:  280499
Step 304700, loss: 0.033374658478423955, acc: 99.66387788951397, p_norm: 2226.807982622679, g_norm: 0.540488776717185, lr:  0.000453, elapsed time:  280588
Step 304800, loss: 0.03358257134445011, acc: 99.66282024979591, p_norm: 2226.897955286484, g_norm: 0.5867385924051495, lr:  0.000453, elapsed time:  280677
Step 304900, loss: 0.03382991953752935, acc: 99.65013222396374, p_norm: 2227.0056069093716, g_norm: 0.4192281340240458, lr:  0.000453, elapsed time:  280769
Step 305000, loss: 0.033713428424671295, acc: 99.64391821622849, p_norm: 2227.12261671617, g_norm: 0.9243311891277154, lr:  0.000453, elapsed time:  280859
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Target text: C O C ( = O ) c 1 c n c ( N 2 C C C ( O c 3 c c ( F ) c c c 3 Br ) C C 2 ) c n 1 _EOS
Predicted text: C O C ( = O ) c 1 c n c ( N 2 C C C ( O c 3 c c ( F ) c c c 3 Br ) C C 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C ( F ) ( F ) c 1 c ( C ( = O ) O ) n o c 1 - c 1 c c c c c 1 _EOS
Predicted text: C C C ( F ) ( F ) c 1 c ( C ( = O ) O ) n o c 1 - c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N 1 C ( = O ) N c 2 c c c ( Br ) c c 2 C 1 ( C N C ( = O ) c 1 c c c ( F ) c c 1 ) C ( F ) ( F ) F _EOS
Predicted text: C N 1 C ( = O ) N c 2 c c c ( Br ) c c 2 C 1 ( C N C ( = O ) c 1 c c c ( F ) c c 1 ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C ) O c 1 c c c ( O c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 Cl ) c c 1 _EOS
Predicted text: C O C ( = O ) C ( C ) O c 1 c c c ( O c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C 1 C c 2 c c ( F ) c ( F ) c c 2 C 1 = O ) O C c 1 c c c c c 1 _EOS
Predicted text: O = C ( N C 1 C c 2 c c ( F ) c ( F ) c c 2 C 1 = O ) O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 305000, eval acc (token): 0.9378876449880907, eval acc (sequence): 0.8879176379176379
Saving at step 305000
Step 305100, loss: 0.033618957633152605, acc: 99.6466654241085, p_norm: 2227.2156475132406, g_norm: 0.950216453046653, lr:  0.000452, elapsed time:  281035
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 305200, loss: 0.03349422113438398, acc: 99.65390428420037, p_norm: 2227.32937387078, g_norm: 0.41302545931422435, lr:  0.000452, elapsed time:  281125
Step 305300, loss: 0.03277270876336843, acc: 99.66618458926678, p_norm: 2227.4303878563014, g_norm: 0.6071830056581061, lr:  0.000452, elapsed time:  281216
Step 305400, loss: 0.03264423739630729, acc: 99.67608830332756, p_norm: 2227.5199630734055, g_norm: 0.5163160128887659, lr:  0.000452, elapsed time:  281304
Step 305500, loss: 0.032558444156311456, acc: 99.67695485055447, p_norm: 2227.6304176117314, g_norm: 0.48412528123207804, lr:  0.000452, elapsed time:  281394
Step 305600, loss: 0.03283667931333184, acc: 99.66628661751747, p_norm: 2227.7282001760914, g_norm: 0.7173377870736757, lr:  0.000452, elapsed time:  281486
Step 305700, loss: 0.033366053034551445, acc: 99.6540697067976, p_norm: 2227.8167747753555, g_norm: 0.5513400306459265, lr:  0.000452, elapsed time:  281575
Step 305800, loss: 0.03338754691649228, acc: 99.65568788349628, p_norm: 2227.924013058627, g_norm: 0.6544946269296122, lr:  0.000452, elapsed time:  281666
Step 305900, loss: 0.033051866940222684, acc: 99.66313077509403, p_norm: 2228.039821991343, g_norm: 0.5892635940539417, lr:  0.000452, elapsed time:  281761
Step 306000, loss: 0.03336180895101279, acc: 99.65649780631065, p_norm: 2228.1283225246084, g_norm: 0.6199859405680858, lr:  0.000452, elapsed time:  281849
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 306000, eval loss: 0.04533816210925581, eval acc: 99.50137329101562
Step 306100, loss: 0.03223738509230316, acc: 99.68730947375298, p_norm: 2228.22114906338, g_norm: 0.7130023343117631, lr:  0.000452, elapsed time:  281961
Step 306200, loss: 0.03325073542073369, acc: 99.65813359618187, p_norm: 2228.3185575701764, g_norm: 0.43249453500397567, lr:  0.000452, elapsed time:  282045
Step 306300, loss: 0.032739757392555476, acc: 99.67507329583168, p_norm: 2228.426534365779, g_norm: 0.45969036408454067, lr:  0.000452, elapsed time:  282117
Step 306400, loss: 0.032568193594925104, acc: 99.67163196206093, p_norm: 2228.5365694205916, g_norm: 0.6145062318329392, lr:  0.000452, elapsed time:  282214
Step 306500, loss: 0.0334038319112733, acc: 99.65161015093327, p_norm: 2228.6456071997936, g_norm: 0.610055181579517, lr:  0.000451, elapsed time:  282302
Step 306600, loss: 0.033703520661219954, acc: 99.6462948769331, p_norm: 2228.740038070984, g_norm: 0.6035564233568981, lr:  0.000451, elapsed time:  282390
Step 306700, loss: 0.03396235796157271, acc: 99.63988293707371, p_norm: 2228.845364927843, g_norm: 0.5589380881169878, lr:  0.000451, elapsed time:  282478
Step 306800, loss: 0.033683651932515206, acc: 99.64967846870422, p_norm: 2228.9481334666307, g_norm: 0.565426826318234, lr:  0.000451, elapsed time:  282568
Step 306900, loss: 0.03346543967258185, acc: 99.6537658572197, p_norm: 2229.058545601992, g_norm: 0.7523065613789726, lr:  0.000451, elapsed time:  282658
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 307000, loss: 0.03244251388566518, acc: 99.68310315023285, p_norm: 2229.1656997121245, g_norm: 0.5478561796617681, lr:  0.000451, elapsed time:  282748
Step 307100, loss: 0.033471337151713666, acc: 99.65326699614525, p_norm: 2229.2688359119734, g_norm: 1.8759496818865204, lr:  0.000451, elapsed time:  282838
Step 307200, loss: 0.03380904089193791, acc: 99.64717236161232, p_norm: 2229.359575895333, g_norm: 0.6053481677909001, lr:  0.000451, elapsed time:  282927
Step 307300, loss: 0.03312472921330482, acc: 99.66344237327576, p_norm: 2229.453297809861, g_norm: 0.7104846376971382, lr:  0.000451, elapsed time:  283017
Step 307400, loss: 0.032951502227224407, acc: 99.67207272350788, p_norm: 2229.5428692705245, g_norm: 0.6299194081979922, lr:  0.000451, elapsed time:  283107
Step 307500, loss: 0.033094768752343955, acc: 99.65549001097679, p_norm: 2229.634959966018, g_norm: 0.566604286420705, lr:  0.000451, elapsed time:  283196
Step 307600, loss: 0.033264699992723766, acc: 99.66212897002697, p_norm: 2229.7370474567515, g_norm: 0.9151291488295428, lr:  0.000451, elapsed time:  283285
Step 307700, loss: 0.03307847589254379, acc: 99.66738249361515, p_norm: 2229.838175721235, g_norm: 0.532841630454731, lr:  0.000451, elapsed time:  283378
Step 307800, loss: 0.03308746667113155, acc: 99.66391789913177, p_norm: 2229.9429397907793, g_norm: 0.7786625006469808, lr:  0.000450, elapsed time:  283467
Step 307900, loss: 0.033163246205076574, acc: 99.65631844103336, p_norm: 2230.044770812882, g_norm: 0.5406016263691228, lr:  0.000450, elapsed time:  283556
Step 308000, loss: 0.03387933948077262, acc: 99.64256729185581, p_norm: 2230.1409671029437, g_norm: 0.5805674333062613, lr:  0.000450, elapsed time:  283647
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 308000, eval loss: 0.04453729389235378, eval acc: 99.52560424804688
Step 308100, loss: 0.03338977677747607, acc: 99.65637627243996, p_norm: 2230.2570046863534, g_norm: 0.5070976297457633, lr:  0.000450, elapsed time:  283755
Step 308200, loss: 0.0339476920152083, acc: 99.63551588356495, p_norm: 2230.36921123439, g_norm: 0.5767952016437262, lr:  0.000450, elapsed time:  283844
Step 308300, loss: 0.03361038306262344, acc: 99.64651818573475, p_norm: 2230.4828727749928, g_norm: 0.749956515259997, lr:  0.000450, elapsed time:  283929
Step 308400, loss: 0.032845774330198765, acc: 99.67079888284206, p_norm: 2230.583532209963, g_norm: 0.5734609802314792, lr:  0.000450, elapsed time:  284018
Step 308500, loss: 0.033126082252711055, acc: 99.66644102334976, p_norm: 2230.684648614936, g_norm: 0.5451209342649993, lr:  0.000450, elapsed time:  284109
Step 308600, loss: 0.03317911521997303, acc: 99.65657183527946, p_norm: 2230.7892745916743, g_norm: 0.630332806232503, lr:  0.000450, elapsed time:  284196
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 308700, loss: 0.03281150315483806, acc: 99.66891686023021, p_norm: 2230.8978140019112, g_norm: 0.5325018033264742, lr:  0.000450, elapsed time:  284288
Step 308800, loss: 0.03323804804123938, acc: 99.65749989449978, p_norm: 2230.995165660706, g_norm: 0.615009610726062, lr:  0.000450, elapsed time:  284376
Step 308900, loss: 0.032514208904467524, acc: 99.67836906015873, p_norm: 2231.099280218317, g_norm: 0.47446611450920173, lr:  0.000450, elapsed time:  284467
Step 309000, loss: 0.032803761740215126, acc: 99.66784200072289, p_norm: 2231.203393255815, g_norm: 0.5851810604658682, lr:  0.000450, elapsed time:  284555
Step 309100, loss: 0.03339485626202077, acc: 99.6519714742899, p_norm: 2231.3010322387768, g_norm: 0.5706079657706907, lr:  0.000450, elapsed time:  284644
Step 309200, loss: 0.03345075550954789, acc: 99.6573279350996, p_norm: 2231.3964170620893, g_norm: 0.5210978343781193, lr:  0.000449, elapsed time:  284733
Step 309300, loss: 0.03325516942422837, acc: 99.65511466562748, p_norm: 2231.498469918637, g_norm: 0.8014905431687038, lr:  0.000449, elapsed time:  284821
Step 309400, loss: 0.033196980813518163, acc: 99.66432663798332, p_norm: 2231.586836467233, g_norm: 1.979367012972985, lr:  0.000449, elapsed time:  284912
Step 309500, loss: 0.03413650221657008, acc: 99.62916740775108, p_norm: 2231.6940777098057, g_norm: 0.47197147958364416, lr:  0.000449, elapsed time:  284997
Step 309600, loss: 0.032984927920624615, acc: 99.66786029934883, p_norm: 2231.7892030293665, g_norm: 0.45101211414652204, lr:  0.000449, elapsed time:  285087
Step 309700, loss: 0.03358345058746636, acc: 99.65500645339489, p_norm: 2231.886223113723, g_norm: 0.5052240884142872, lr:  0.000449, elapsed time:  285174
Step 309800, loss: 0.033407328072935345, acc: 99.66100363433361, p_norm: 2231.9928839533036, g_norm: 0.5481945002501976, lr:  0.000449, elapsed time:  285264
Step 309900, loss: 0.03299791553989053, acc: 99.66345457732677, p_norm: 2232.0976478636144, g_norm: 0.7125703049620403, lr:  0.000449, elapsed time:  285357
Step 310000, loss: 0.033002785411663356, acc: 99.66907751560211, p_norm: 2232.1902022615227, g_norm: 0.5379098204876339, lr:  0.000449, elapsed time:  285448
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 310000, eval loss: 0.04390893118456006, eval acc: 99.51962280273438
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C 1 ( C N c 2 n c ( O ) c c c 2 F ) C C O C C 1 _EOS
Predicted text: C C 1 ( C N c 2 n c ( O ) c c c 2 F ) C C O C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C ( C c 1 c c c c c 1 ) C C ( O ) C ( N ) C c 1 c c c c c 1 _EOS
Predicted text: N C ( C c 1 c c c c c 1 ) C C ( O ) C ( N ) C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C # N ) c ( O N = C ( C ) C ) c 1 _EOS
Predicted text: C O c 1 c c c ( C # N ) c ( O N = C ( C ) C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C 2 C ( C C C ( O ) c 3 c c c ( O C c 4 c c c ( C Br ) c c 4 ) c c 3 ) C ( = O ) N 2 c 2 c c c ( F ) c c 2 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C 2 C ( C C C ( O ) c 3 c c c ( O C c 4 c c c ( C Br ) c c 4 ) c c 3 ) C ( = O ) N 2 c 2 c c c ( F ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O C 1 ( c 2 c c c ( Cl ) c c 2 ) C C C ( C N 2 C C C C ( C O c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) C 2 ) C C 1 _EOS
Predicted text: O C 1 ( c 2 c c c ( Cl ) c c 2 ) C C C ( C N 2 C C C C ( C O c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 310000, eval acc (token): 0.9400873269488089, eval acc (sequence): 0.8888693201831631
Saving at step 310000
Step 310100, loss: 0.03332975903525948, acc: 99.65604914724827, p_norm: 2232.284803055512, g_norm: 0.5883241901272406, lr:  0.000449, elapsed time:  285636
Step 310200, loss: 0.033871308718807995, acc: 99.64574407041073, p_norm: 2232.3825446790715, g_norm: 0.5854432613969198, lr:  0.000449, elapsed time:  285725
Step 310300, loss: 0.033506510979495946, acc: 99.65967099368572, p_norm: 2232.4866649447445, g_norm: 0.43312557632620946, lr:  0.000449, elapsed time:  285816
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 310400, loss: 0.033162842123369424, acc: 99.6619919097749, p_norm: 2232.5835467082998, g_norm: 0.5189053673781008, lr:  0.000449, elapsed time:  285909
Step 310500, loss: 0.032526111691258845, acc: 99.67742788791656, p_norm: 2232.674543663262, g_norm: 1.0567262733414233, lr:  0.000449, elapsed time:  285999
Step 310600, loss: 0.034157864688895645, acc: 99.65065014362335, p_norm: 2232.7779088180255, g_norm: 0.7657607562399087, lr:  0.000448, elapsed time:  286089
Step 310700, loss: 0.033432183722034096, acc: 99.66206154227257, p_norm: 2232.8667258550527, g_norm: 0.7418603985714967, lr:  0.000448, elapsed time:  286184
Step 310800, loss: 0.03254887264221907, acc: 99.68222966790199, p_norm: 2232.958762246756, g_norm: 0.5190210190181535, lr:  0.000448, elapsed time:  286273
Step 310900, loss: 0.033507481487467884, acc: 99.65544526278973, p_norm: 2233.061812851304, g_norm: 0.5804570094181586, lr:  0.000448, elapsed time:  286362
Step 311000, loss: 0.03279748655389994, acc: 99.67856192588806, p_norm: 2233.156902093964, g_norm: 0.6216307665942281, lr:  0.000448, elapsed time:  286448
Step 311100, loss: 0.03296957947779447, acc: 99.6692753136158, p_norm: 2233.243791344375, g_norm: 0.5742877636246573, lr:  0.000448, elapsed time:  286534
Step 311200, loss: 0.032915196153335276, acc: 99.66731978952885, p_norm: 2233.338714931409, g_norm: 0.5741214239260305, lr:  0.000448, elapsed time:  286625
Step 311300, loss: 0.033471502149477604, acc: 99.64642563462257, p_norm: 2233.453885432829, g_norm: 0.7451284085221432, lr:  0.000448, elapsed time:  286715
Step 311400, loss: 0.03345189154613763, acc: 99.65806196630001, p_norm: 2233.5622189474366, g_norm: 0.6345735649001115, lr:  0.000448, elapsed time:  286811
Step 311500, loss: 0.033588175042532385, acc: 99.65147332847118, p_norm: 2233.647512464581, g_norm: 0.43082716794272347, lr:  0.000448, elapsed time:  286904
Step 311600, loss: 0.03342878311406821, acc: 99.65119574964046, p_norm: 2233.741012684562, g_norm: 0.6572638184832683, lr:  0.000448, elapsed time:  286993
Step 311700, loss: 0.03394133179448545, acc: 99.64530065655708, p_norm: 2233.836717185602, g_norm: 0.6671179328764154, lr:  0.000448, elapsed time:  287084
Step 311800, loss: 0.03282476028893143, acc: 99.66552320122719, p_norm: 2233.924117478461, g_norm: 0.5490423785732482, lr:  0.000448, elapsed time:  287178
Step 311900, loss: 0.03365183737594634, acc: 99.64434392750263, p_norm: 2234.026611132916, g_norm: 0.5908043800591184, lr:  0.000448, elapsed time:  287278
Step 312000, loss: 0.033884308319538835, acc: 99.64046411216259, p_norm: 2234.1313426445595, g_norm: 0.551216227381578, lr:  0.000447, elapsed time:  287369
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 312000, eval loss: 0.043222037665545956, eval acc: 99.53894805908203
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 312100, loss: 0.032901807539906375, acc: 99.66249891478031, p_norm: 2234.2248591119287, g_norm: 0.5371007816385684, lr:  0.000447, elapsed time:  287478
Step 312200, loss: 0.032993174851872024, acc: 99.66709558665752, p_norm: 2234.3331398811547, g_norm: 0.7597332437728814, lr:  0.000447, elapsed time:  287571
Step 312300, loss: 0.03345948263071477, acc: 99.66063760221004, p_norm: 2234.427633351812, g_norm: 0.5341479651777488, lr:  0.000447, elapsed time:  287665
Step 312400, loss: 0.03299835681449622, acc: 99.67219178378582, p_norm: 2234.5210147268144, g_norm: 0.7773024818953653, lr:  0.000447, elapsed time:  287761
Step 312500, loss: 0.032906027999706565, acc: 99.66535578668118, p_norm: 2234.627592671273, g_norm: 0.6577962169754947, lr:  0.000447, elapsed time:  287855
Step 312600, loss: 0.03307698618620634, acc: 99.66196531057358, p_norm: 2234.72391153567, g_norm: 0.6031873898984486, lr:  0.000447, elapsed time:  287939
Step 312700, loss: 0.03326037283986807, acc: 99.66293178498745, p_norm: 2234.8165619157207, g_norm: 0.477169660595848, lr:  0.000447, elapsed time:  288027
Step 312800, loss: 0.0330071724858135, acc: 99.66713298857212, p_norm: 2234.9084686518167, g_norm: 0.6169734240420212, lr:  0.000447, elapsed time:  288117
Step 312900, loss: 0.0335081590898335, acc: 99.65241675078869, p_norm: 2235.007274204961, g_norm: 0.566522982837471, lr:  0.000447, elapsed time:  288210
Step 313000, loss: 0.03341465109027922, acc: 99.661799877882, p_norm: 2235.1068024211254, g_norm: 0.621041252433132, lr:  0.000447, elapsed time:  288301
Step 313100, loss: 0.03296291613485664, acc: 99.66232323646545, p_norm: 2235.209528342524, g_norm: 1.0730080829465942, lr:  0.000447, elapsed time:  288394
Step 313200, loss: 0.033839817233383654, acc: 99.64539733529091, p_norm: 2235.3075879181165, g_norm: 0.5708920283667878, lr:  0.000447, elapsed time:  288486
Step 313300, loss: 0.03366641189903021, acc: 99.64730454981327, p_norm: 2235.4130013658187, g_norm: 0.633088928495913, lr:  0.000447, elapsed time:  288581
Step 313400, loss: 0.03361886970233172, acc: 99.6534189581871, p_norm: 2235.516168135263, g_norm: 0.6731423427970541, lr:  0.000446, elapsed time:  288674
Step 313500, loss: 0.03327272854745388, acc: 99.66280670464039, p_norm: 2235.6175250812107, g_norm: 0.5308414149055009, lr:  0.000446, elapsed time:  288768
Step 313600, loss: 0.03324468699749559, acc: 99.65421003103256, p_norm: 2235.7100155313783, g_norm: 0.5984182896968214, lr:  0.000446, elapsed time:  288857
Step 313700, loss: 0.03221679026260972, acc: 99.68708510696888, p_norm: 2235.8059163812295, g_norm: 0.5168178303648265, lr:  0.000446, elapsed time:  288949
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 313800, loss: 0.032169957804694664, acc: 99.6808634798225, p_norm: 2235.890056123024, g_norm: 0.5708824785038401, lr:  0.000446, elapsed time:  289041
Step 313900, loss: 0.0326139048114419, acc: 99.68126960098743, p_norm: 2235.989796315287, g_norm: 0.5015299561391894, lr:  0.000446, elapsed time:  289132
Step 314000, loss: 0.03297461263369769, acc: 99.65980340540409, p_norm: 2236.084007863763, g_norm: 0.8575973702165655, lr:  0.000446, elapsed time:  289224
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 527
Evaluation (with teacher) at step 314000, eval loss: 0.0453826104477048, eval acc: 99.50227355957031
Step 314100, loss: 0.03267006197944283, acc: 99.66929823160172, p_norm: 2236.1819869724886, g_norm: 0.6881347798664056, lr:  0.000446, elapsed time:  289336
Step 314200, loss: 0.032123560765758154, acc: 99.69266639649868, p_norm: 2236.2905073183424, g_norm: 1.1083046133410421, lr:  0.000446, elapsed time:  289430
Step 314300, loss: 0.03305784506723285, acc: 99.66550596058369, p_norm: 2236.3824764144283, g_norm: 0.7100766414426501, lr:  0.000446, elapsed time:  289524
Step 314400, loss: 0.03317556744907051, acc: 99.65653194487095, p_norm: 2236.4940006634906, g_norm: 0.5602663639763905, lr:  0.000446, elapsed time:  289615
Step 314500, loss: 0.033375842631794515, acc: 99.66215269267559, p_norm: 2236.596165364345, g_norm: 0.6527678356526144, lr:  0.000446, elapsed time:  289703
Step 314600, loss: 0.033845477057620886, acc: 99.6569926738739, p_norm: 2236.7002302067795, g_norm: 0.4244082328355092, lr:  0.000446, elapsed time:  289796
Step 314700, loss: 0.03413454552646726, acc: 99.63725166022778, p_norm: 2236.801098985715, g_norm: 0.5934908803318839, lr:  0.000446, elapsed time:  289885
Step 314800, loss: 0.03430741337593645, acc: 99.6393817961216, p_norm: 2236.9150744572976, g_norm: 0.629153366103432, lr:  0.000445, elapsed time:  289977
Step 314900, loss: 0.0328328423993662, acc: 99.6766149699688, p_norm: 2237.0022842764956, g_norm: 0.38616968857253525, lr:  0.000445, elapsed time:  290069
Step 315000, loss: 0.0336233222251758, acc: 99.66021317243576, p_norm: 2237.0990922006736, g_norm: 0.5859443116510039, lr:  0.000445, elapsed time:  290161
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C N ( C C ) C ( = O ) N C 1 C C 2 c 3 c c c c 4 [nH] c ( C ) c ( c 3 4 ) C C 2 N ( C ) C 1 _EOS
Predicted text: C C N ( C C ) C ( = O ) N C 1 C C 2 c 3 c c c c 4 [nH] c ( C ( = O ) O C ) c ( c 3 4 ) C C 2 N ( C ) C 1 _EOS
acc_token: 0.6739130434782609, acc_seq: False

Target text: C O c 1 c c c c ( C ( = O ) c 2 n c c ( C ( = O ) O ) c 3 c c ( O C c 4 c c c c c 4 ) c ( O C ) c c 2 3 ) c 1 _EOS
Predicted text: C O c 1 c c c c ( C ( = O ) c 2 n c c ( C ( = O ) O ) c 3 c c ( O C c 4 c c c c c 4 ) c ( O C ) c c 2 3 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C 1 ( C C C n 2 c ( = O ) c c c 3 c c c n c 3 2 ) C C N ( C C S c 2 c c c s 2 ) C C 1 _EOS
Predicted text: O = C ( O ) C 1 ( C C C n 2 c ( = O ) c c c 3 c c c n c 3 2 ) C C N ( C C S c 2 c c c s 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( N c 2 c c c c c 2 ) c ( C ( = O ) O C ) c c 1 F _EOS
Predicted text: C O C ( = O ) c 1 c c ( N c 2 c c c c c 2 ) c ( C ( = O ) O C ) c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N 1 C C N ( C ( = O ) c 2 c ( C ) n o c 2 C C ( = O ) c 2 c c c c c 2 ) C C 1 _EOS
Predicted text: C C ( = O ) N 1 C C N ( C ( = O ) c 2 c ( C ) n o c 2 C C ( = O ) c 2 c c c c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 315000, eval acc (token): 0.9394234191151297, eval acc (sequence): 0.8896739130434783
Saving at step 315000
Step 315100, loss: 0.03362798170186579, acc: 99.6458824723959, p_norm: 2237.186777162095, g_norm: 0.8194554759338593, lr:  0.000445, elapsed time:  290344
Step 315200, loss: 0.03249035894870758, acc: 99.68298850953579, p_norm: 2237.279351739416, g_norm: 0.43397810010846144, lr:  0.000445, elapsed time:  290435
Step 315300, loss: 0.03300810152664781, acc: 99.66276302933693, p_norm: 2237.3786865644174, g_norm: 0.6630817649566952, lr:  0.000445, elapsed time:  290534
Step 315400, loss: 0.03337139773182571, acc: 99.65225666761398, p_norm: 2237.48687252458, g_norm: 0.5789828525729218, lr:  0.000445, elapsed time:  290622
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 315500, loss: 0.03268561680932938, acc: 99.67087483583549, p_norm: 2237.585152841424, g_norm: 0.4814434009787522, lr:  0.000445, elapsed time:  290709
Step 315600, loss: 0.03288791346363723, acc: 99.67184630036354, p_norm: 2237.6909175193327, g_norm: 0.5728330982293462, lr:  0.000445, elapsed time:  290800
Step 315700, loss: 0.03235879509244114, acc: 99.68577696383, p_norm: 2237.776736632784, g_norm: 0.5850381765721475, lr:  0.000445, elapsed time:  290896
Step 315800, loss: 0.0334384299442172, acc: 99.64927293360233, p_norm: 2237.8762414667835, g_norm: 0.6522998383243068, lr:  0.000445, elapsed time:  290984
Step 315900, loss: 0.03216433783993125, acc: 99.6896997243166, p_norm: 2237.970944643215, g_norm: 0.5664141494309197, lr:  0.000445, elapsed time:  291074
Step 316000, loss: 0.03302581164054572, acc: 99.66658322513103, p_norm: 2238.085018770776, g_norm: 0.6471494767561627, lr:  0.000445, elapsed time:  291167
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 316000, eval loss: 0.048441485073417404, eval acc: 99.51300811767578
Step 316100, loss: 0.035055633946321905, acc: 99.66155268251896, p_norm: 2238.170908605029, g_norm: 0.8652257225455433, lr:  0.000445, elapsed time:  291274
Step 316200, loss: 0.03401210959535092, acc: 99.66682662069798, p_norm: 2238.2649366911082, g_norm: 0.5423890915693926, lr:  0.000444, elapsed time:  291362
Step 316300, loss: 0.03392611552961171, acc: 99.65422074496746, p_norm: 2238.376808058089, g_norm: 0.4274095367159359, lr:  0.000444, elapsed time:  291449
Step 316400, loss: 0.03349229797720909, acc: 99.65929344296455, p_norm: 2238.4706665912076, g_norm: 0.6709362700838244, lr:  0.000444, elapsed time:  291538
Step 316500, loss: 0.03350616980809718, acc: 99.65813972055912, p_norm: 2238.565278053009, g_norm: 0.5624452573195579, lr:  0.000444, elapsed time:  291626
Step 316600, loss: 0.03327577214688063, acc: 99.65863344073296, p_norm: 2238.6605933205633, g_norm: 0.5934973014022155, lr:  0.000444, elapsed time:  291713
Step 316700, loss: 0.032766777416691185, acc: 99.67910693585873, p_norm: 2238.7552275155513, g_norm: 0.6940009196981497, lr:  0.000444, elapsed time:  291803
Step 316800, loss: 0.03296453135553747, acc: 99.67223612964153, p_norm: 2238.83771751263, g_norm: 0.5831636939781263, lr:  0.000444, elapsed time:  291891
Step 316900, loss: 0.033088433095254006, acc: 99.66475234925747, p_norm: 2238.9406692252205, g_norm: 0.571929463674349, lr:  0.000444, elapsed time:  291983
Step 317000, loss: 0.033226138674654064, acc: 99.66093368828297, p_norm: 2239.0488605244095, g_norm: 0.7037820177015882, lr:  0.000444, elapsed time:  292074
Step 317100, loss: 0.03355356933083385, acc: 99.65456733107567, p_norm: 2239.1406935187815, g_norm: 0.6591952119410773, lr:  0.000444, elapsed time:  292163
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 317200, loss: 0.03345580002011052, acc: 99.65279489829582, p_norm: 2239.254697155604, g_norm: 0.5101126460596025, lr:  0.000444, elapsed time:  292254
Step 317300, loss: 0.0332564911339432, acc: 99.65428946912289, p_norm: 2239.355457712561, g_norm: 0.5289696766271537, lr:  0.000444, elapsed time:  292344
Step 317400, loss: 0.03262557899579406, acc: 99.6777253895998, p_norm: 2239.4463128592574, g_norm: 0.5786286564237401, lr:  0.000444, elapsed time:  292433
Step 317500, loss: 0.031887355037033556, acc: 99.69698421657085, p_norm: 2239.542664295356, g_norm: 0.5630058849750671, lr:  0.000444, elapsed time:  292525
Step 317600, loss: 0.03292415736243129, acc: 99.66378745436668, p_norm: 2239.6571636965264, g_norm: 0.4165549700896128, lr:  0.000443, elapsed time:  292614
Step 317700, loss: 0.034650151534005996, acc: 99.65065623819828, p_norm: 2239.7736904682683, g_norm: 0.48683766183573823, lr:  0.000443, elapsed time:  292705
Step 317800, loss: 0.03325170088093728, acc: 99.66880667209625, p_norm: 2239.8613625656967, g_norm: 0.47066895057213626, lr:  0.000443, elapsed time:  292794
Step 317900, loss: 0.03362664700020104, acc: 99.64926308393478, p_norm: 2239.9506070137795, g_norm: 0.6096409220440603, lr:  0.000443, elapsed time:  292878
Step 318000, loss: 0.03263561692088843, acc: 99.6678601950407, p_norm: 2240.0369027205807, g_norm: 0.6534621727841016, lr:  0.000443, elapsed time:  292970
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 318000, eval loss: 0.04398353025317192, eval acc: 99.54694366455078
Step 318100, loss: 0.03289908556267619, acc: 99.66449013352394, p_norm: 2240.126420148259, g_norm: 0.4678454739598142, lr:  0.000443, elapsed time:  293072
Step 318200, loss: 0.03210818586871028, acc: 99.68841192126274, p_norm: 2240.224270665328, g_norm: 0.47646000915741804, lr:  0.000443, elapsed time:  293165
Step 318300, loss: 0.03331241896376014, acc: 99.66004846990108, p_norm: 2240.315502431017, g_norm: 0.6371702064051852, lr:  0.000443, elapsed time:  293253
Step 318400, loss: 0.03371847032103688, acc: 99.65962636470795, p_norm: 2240.4081146536323, g_norm: 0.7156398656519345, lr:  0.000443, elapsed time:  293343
Step 318500, loss: 0.033493737787939605, acc: 99.6690014153719, p_norm: 2240.5082810595854, g_norm: 0.4742032679091744, lr:  0.000443, elapsed time:  293432
Step 318600, loss: 0.03424053309950978, acc: 99.63896475732327, p_norm: 2240.6059563750737, g_norm: 0.5876582399371374, lr:  0.000443, elapsed time:  293522
Step 318700, loss: 0.033243991648778316, acc: 99.66942204535007, p_norm: 2240.6809894447674, g_norm: 0.46834530740813163, lr:  0.000443, elapsed time:  293612
Step 318800, loss: 0.03310427898541093, acc: 99.66573823988438, p_norm: 2240.7735052604853, g_norm: 0.5388594613665177, lr:  0.000443, elapsed time:  293702
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 318900, loss: 0.03273970772865836, acc: 99.67512347857947, p_norm: 2240.8799427089375, g_norm: 0.6570466026395069, lr:  0.000443, elapsed time:  293792
Step 319000, loss: 0.03372476826421916, acc: 99.64627178013325, p_norm: 2240.992982239723, g_norm: 0.6199240594028285, lr:  0.000443, elapsed time:  293881
Step 319100, loss: 0.0328245109366253, acc: 99.67335499823093, p_norm: 2241.108379619799, g_norm: 0.48736725131037445, lr:  0.000442, elapsed time:  293972
Step 319200, loss: 0.032505536708049475, acc: 99.68170091509819, p_norm: 2241.1938481017146, g_norm: 0.5963443997954374, lr:  0.000442, elapsed time:  294064
Step 319300, loss: 0.03261023646686226, acc: 99.67254854738712, p_norm: 2241.2827339715896, g_norm: 0.9298196471096084, lr:  0.000442, elapsed time:  294151
Step 319400, loss: 0.03296692817471922, acc: 99.66438269615173, p_norm: 2241.3730323704967, g_norm: 0.6221521784442207, lr:  0.000442, elapsed time:  294238
Step 319500, loss: 0.03270381911657751, acc: 99.67706516385078, p_norm: 2241.4757661840194, g_norm: 0.5313543474817906, lr:  0.000442, elapsed time:  294328
Step 319600, loss: 0.033547374694608154, acc: 99.64587427675724, p_norm: 2241.5848596817086, g_norm: 0.4620714380800925, lr:  0.000442, elapsed time:  294420
Step 319700, loss: 0.03331883770413697, acc: 99.66116110980511, p_norm: 2241.700271182982, g_norm: 0.6405248368799569, lr:  0.000442, elapsed time:  294509
Step 319800, loss: 0.03258003747090697, acc: 99.67930786311626, p_norm: 2241.788570549096, g_norm: 0.5226097557235873, lr:  0.000442, elapsed time:  294603
Step 319900, loss: 0.03361065780278295, acc: 99.64061196148396, p_norm: 2241.887821235493, g_norm: 0.5669480569744406, lr:  0.000442, elapsed time:  294690
Step 320000, loss: 0.032400888740085065, acc: 99.68356913328171, p_norm: 2241.9816036218676, g_norm: 0.8450381242632198, lr:  0.000442, elapsed time:  294779
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 320000, eval loss: 0.043337341882288445, eval acc: 99.56775665283203
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( c 1 c c c c c 1 ) N ( C C N 1 C C C ( N c 2 n c 3 c c c c c 3 n 2 C c 2 c c c ( F ) c c 2 ) C C 1 ) c 1 n c c s 1 _EOS
Predicted text: O = C ( c 1 c c c c c 1 ) N ( C C N 1 C C C ( N c 2 n c 3 c c c c c 3 n 2 C c 2 c c c ( F ) c c 2 ) C C 1 ) c 1 n c c s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( C c 2 c ( C ) c ( O C ) c ( O C ) c ( O C ) c 2 O C ) c c c 1 O C c 1 c c c n c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c ( C c 2 c ( C ) c ( O C ) c ( O C ) c ( O C ) c 2 O C ) c c c 1 O C c 1 c c c n c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C ) c ( Cl ) c ( C ) c 1 _EOS
Predicted text: C O c 1 c c ( C ) c ( Cl ) c ( C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N c 1 n c c c ( N c 2 c c ( - c 3 c c ( Cl ) c c c 3 F ) n c 3 n c c c c 2 3 ) n 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N c 1 n c c c ( N c 2 c c ( - c 3 c c ( Cl ) c c c 3 F ) n c 3 n c c c c 2 3 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( c 1 c c c ( C ( F ) ( F ) F ) n c 1 ) S ( C ) = N C # N _EOS
Predicted text: C C ( c 1 c c c ( C ( F ) ( F ) F ) n c 1 ) S ( C ) = N C # N _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 320000, eval acc (token): 0.9368381166703327, eval acc (sequence): 0.8896551724137931
Saving at step 320000
Step 320100, loss: 0.034313740744255486, acc: 99.6290433704853, p_norm: 2242.0834662081247, g_norm: 0.46282087553600815, lr:  0.000442, elapsed time:  294964
Step 320200, loss: 0.03277084404136985, acc: 99.67129707336426, p_norm: 2242.170346589227, g_norm: 0.5331064425604894, lr:  0.000442, elapsed time:  295054
Step 320300, loss: 0.03327471277210861, acc: 99.66334037482738, p_norm: 2242.267763899289, g_norm: 0.515787640402615, lr:  0.000442, elapsed time:  295145
Step 320400, loss: 0.03266477257944644, acc: 99.6717129200697, p_norm: 2242.3566867129384, g_norm: 0.49559477192845175, lr:  0.000442, elapsed time:  295236
Step 320500, loss: 0.03299863986670971, acc: 99.66615891456604, p_norm: 2242.443593038108, g_norm: 0.5017056005598324, lr:  0.000441, elapsed time:  295324
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 320600, loss: 0.03278373770656124, acc: 99.67445963369705, p_norm: 2242.5355151522685, g_norm: 0.5410259018034973, lr:  0.000441, elapsed time:  295412
Step 320700, loss: 0.03273577465675771, acc: 99.67408457398415, p_norm: 2242.635774986765, g_norm: 0.6319728854913366, lr:  0.000441, elapsed time:  295505
Step 320800, loss: 0.03431420513894409, acc: 99.66266344487667, p_norm: 2242.7237678221704, g_norm: 0.6787374630258142, lr:  0.000441, elapsed time:  295592
Step 320900, loss: 0.03431699392851442, acc: 99.65889701247215, p_norm: 2242.808386925987, g_norm: 0.5600456721730568, lr:  0.000441, elapsed time:  295680
Step 321000, loss: 0.03339098074007779, acc: 99.67815512418747, p_norm: 2242.910189056471, g_norm: 0.8306262809395082, lr:  0.000441, elapsed time:  295771
Step 321100, loss: 0.03405198907479644, acc: 99.65733966231346, p_norm: 2243.0073064189846, g_norm: 1.977277770990866, lr:  0.000441, elapsed time:  295859
Step 321200, loss: 0.03366018677130342, acc: 99.6585423052311, p_norm: 2243.115070630701, g_norm: 0.5422776054849467, lr:  0.000441, elapsed time:  295949
Step 321300, loss: 0.03274993799161166, acc: 99.67192880809307, p_norm: 2243.2067038611135, g_norm: 0.5177486883342018, lr:  0.000441, elapsed time:  296037
Step 321400, loss: 0.032459421972744165, acc: 99.67750079929829, p_norm: 2243.2973103190056, g_norm: 0.5601658124219544, lr:  0.000441, elapsed time:  296128
Step 321500, loss: 0.03340032390318811, acc: 99.6448966562748, p_norm: 2243.3904460858384, g_norm: 0.6026251114394499, lr:  0.000441, elapsed time:  296216
Step 321600, loss: 0.03258784628007561, acc: 99.67593239247799, p_norm: 2243.487416760407, g_norm: 0.5736969241206628, lr:  0.000441, elapsed time:  296306
Step 321700, loss: 0.03327786483801901, acc: 99.65135636925697, p_norm: 2243.5921602333456, g_norm: 0.6151147961260744, lr:  0.000441, elapsed time:  296393
Step 321800, loss: 0.03317645997274667, acc: 99.66015534102917, p_norm: 2243.711672921311, g_norm: 0.5180309612517379, lr:  0.000441, elapsed time:  296485
Step 321900, loss: 0.033447194979526106, acc: 99.64936527609825, p_norm: 2243.808198632268, g_norm: 0.53736485379412, lr:  0.000441, elapsed time:  296575
Step 322000, loss: 0.032451877896673975, acc: 99.68160678446293, p_norm: 2243.9031217903, g_norm: 0.4972874499400375, lr:  0.000440, elapsed time:  296666
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 322000, eval loss: 0.04918102759867907, eval acc: 99.41323852539062
Step 322100, loss: 0.03321837713941932, acc: 99.65710000693798, p_norm: 2244.007253221729, g_norm: 0.5033905755109492, lr:  0.000440, elapsed time:  296772
Step 322200, loss: 0.033227209080941976, acc: 99.65692539513111, p_norm: 2244.1024982325757, g_norm: 0.5596575696553746, lr:  0.000440, elapsed time:  296863
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 322300, loss: 0.032896549443231324, acc: 99.6658900979139, p_norm: 2244.2026631348926, g_norm: 0.6142222676316728, lr:  0.000440, elapsed time:  296954
Step 322400, loss: 0.03267814541235566, acc: 99.66489413380623, p_norm: 2244.284437449177, g_norm: 0.681623357599975, lr:  0.000440, elapsed time:  297045
Step 322500, loss: 0.03250668397638947, acc: 99.68313762545586, p_norm: 2244.3774570417536, g_norm: 0.6114797199127858, lr:  0.000440, elapsed time:  297133
Step 322600, loss: 0.033259227382950486, acc: 99.65471686422825, p_norm: 2244.478546698912, g_norm: 0.6601541361177181, lr:  0.000440, elapsed time:  297223
Step 322700, loss: 0.03296146566048264, acc: 99.67214894294739, p_norm: 2244.567562496818, g_norm: 0.8800967391321057, lr:  0.000440, elapsed time:  297312
Step 322800, loss: 0.03395361487753689, acc: 99.63890820741653, p_norm: 2244.6672679357366, g_norm: 0.7998691375174399, lr:  0.000440, elapsed time:  297400
Step 322900, loss: 0.032716768537648024, acc: 99.67795005440712, p_norm: 2244.7772477957565, g_norm: 0.7660257510248782, lr:  0.000440, elapsed time:  297490
Step 323000, loss: 0.032373560727573934, acc: 99.68506532907486, p_norm: 2244.8726154535966, g_norm: 0.4474068528341032, lr:  0.000440, elapsed time:  297578
Step 323100, loss: 0.03186752884183079, acc: 99.69853736460209, p_norm: 2244.959823009264, g_norm: 0.5493371503102564, lr:  0.000440, elapsed time:  297668
Step 323200, loss: 0.03269804993644357, acc: 99.6724656522274, p_norm: 2245.0487064178274, g_norm: 0.6992757280128264, lr:  0.000440, elapsed time:  297757
Step 323300, loss: 0.032889098981395366, acc: 99.67005862295628, p_norm: 2245.1388366289484, g_norm: 0.5689413209084082, lr:  0.000440, elapsed time:  297845
Step 323400, loss: 0.033029126315377653, acc: 99.66430658102036, p_norm: 2245.232561921622, g_norm: 0.6324735589426005, lr:  0.000439, elapsed time:  297935
Step 323500, loss: 0.03363797101657837, acc: 99.64877726137638, p_norm: 2245.3395243638856, g_norm: 0.4825656409126606, lr:  0.000439, elapsed time:  298024
Step 323600, loss: 0.032326423679478467, acc: 99.6864562034607, p_norm: 2245.4366078110356, g_norm: 0.5364064620113285, lr:  0.000439, elapsed time:  298119
Step 323700, loss: 0.03286786252632737, acc: 99.66650277376175, p_norm: 2245.5413699630835, g_norm: 0.5372949063157423, lr:  0.000439, elapsed time:  298208
Step 323800, loss: 0.032832438894547525, acc: 99.6718829125166, p_norm: 2245.641956616266, g_norm: 0.6728790079780824, lr:  0.000439, elapsed time:  298297
Step 323900, loss: 0.033422393556684256, acc: 99.65634369850159, p_norm: 2245.744952059141, g_norm: 0.5133313812570847, lr:  0.000439, elapsed time:  298387
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 324000, loss: 0.03283113382515771, acc: 99.67413560964575, p_norm: 2245.844326116517, g_norm: 0.5867349430070179, lr:  0.000439, elapsed time:  298478
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 324000, eval loss: 0.048333300948143, eval acc: 99.46212768554688
Step 324100, loss: 0.03287181391380727, acc: 99.6714026927948, p_norm: 2245.9405304554166, g_norm: 0.4897798689723103, lr:  0.000439, elapsed time:  298580
Step 324200, loss: 0.03266682466957718, acc: 99.6769851744175, p_norm: 2246.0306056765817, g_norm: 0.6403433348339412, lr:  0.000439, elapsed time:  298668
Step 324300, loss: 0.03279347916133702, acc: 99.6674802750349, p_norm: 2246.117096971588, g_norm: 0.46673135108561997, lr:  0.000439, elapsed time:  298758
Step 324400, loss: 0.03232247201725841, acc: 99.68354012072086, p_norm: 2246.207139012614, g_norm: 0.6495674011792435, lr:  0.000439, elapsed time:  298849
Step 324500, loss: 0.03275500744581222, acc: 99.67095538973808, p_norm: 2246.311203197961, g_norm: 0.6060216955746712, lr:  0.000439, elapsed time:  298942
Step 324600, loss: 0.032519907723180946, acc: 99.67129051685333, p_norm: 2246.4023721713834, g_norm: 0.9209973401951469, lr:  0.000439, elapsed time:  299030
Step 324700, loss: 0.0330791517207399, acc: 99.6718003153801, p_norm: 2246.5054881779456, g_norm: 0.5399540945813651, lr:  0.000439, elapsed time:  299119
Step 324800, loss: 0.03244235150981695, acc: 99.6829779446125, p_norm: 2246.5815400677957, g_norm: 0.5525152608349846, lr:  0.000439, elapsed time:  299210
Step 324900, loss: 0.032709771608933805, acc: 99.67952804267406, p_norm: 2246.6771358262426, g_norm: 0.6738606059153683, lr:  0.000438, elapsed time:  299300
Step 325000, loss: 0.033560381084680554, acc: 99.64862009882927, p_norm: 2246.7813677339414, g_norm: 0.7445325077551467, lr:  0.000438, elapsed time:  299390
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O C ( = O ) C 1 C C C ( C N = [N+] = [N-] ) C 1 _EOS
Predicted text: C O C ( = O ) C 1 C C C ( C N = [N+] = [N-] ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( [O-] ) c 1 c c n c ( - c 2 c c c c c 2 ) c 1 _EOS
Predicted text: O = C ( O ) c 1 c c n c ( - c 2 c c c c c 2 ) c 1 _EOS
acc_token: 0.9615384615384616, acc_seq: False

Target text: C c 1 n c ( C ) c ( C ( = O ) N 2 C C C C 2 ) c ( - c 2 c c c c ( Cl ) c 2 ) c 1 C ( = O ) O C C C ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C c 1 n c ( C ) c ( C ( = O ) O C C C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c ( - c 2 c c c c ( Cl ) c 2 ) c 1 C ( = O ) N 1 C C C C 1 _EOS
acc_token: 0.45588235294117646, acc_seq: False

Target text: C c 1 c n ( C 2 ( F ) O C ( C ( O ) C ( = O ) C ( C ) ( C ) C ) C ( O ) ( C ( = O ) c 3 c c c n c 3 ) C 2 ( F ) F ) c ( = O ) [nH] c 1 = O _EOS
Predicted text: C c 1 c n ( C 2 ( F ) O C ( C ( O ) C ( = O ) C ( C ) ( C ) C ) C ( O ) C 2 ( F ) F ) c ( = O ) [nH] c 1 = O _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.5362318840579711, acc_seq: False

Target text: C O C ( = O ) C ( O c 1 c c c c 2 c 1 C C C 2 ) c 1 c c c ( O c 2 c c c ( Cl ) c c 2 ) c c 1 _EOS
Predicted text: C O C ( = O ) C ( O c 1 c c c c 2 c 1 C C C 2 ) c 1 c c c ( O c 2 c c c ( Cl ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 325000, eval acc (token): 0.9356519875747408, eval acc (sequence): 0.882549774134181
Saving at step 325000
Step 325100, loss: 0.033581844461150465, acc: 99.6545008122921, p_norm: 2246.883772478342, g_norm: 0.6523205536525489, lr:  0.000438, elapsed time:  299558
Step 325200, loss: 0.03334616564679891, acc: 99.65220659971237, p_norm: 2246.989302297023, g_norm: 0.5811149647616966, lr:  0.000438, elapsed time:  299644
Step 325300, loss: 0.03275382578838617, acc: 99.67302085459232, p_norm: 2247.0859390188407, g_norm: 0.4817830060853101, lr:  0.000438, elapsed time:  299734
Step 325400, loss: 0.03304124251473695, acc: 99.66426940262318, p_norm: 2247.1853659721355, g_norm: 0.7099419632729705, lr:  0.000438, elapsed time:  299825
Step 325500, loss: 0.032231486923992636, acc: 99.68478260934353, p_norm: 2247.2840652040754, g_norm: 0.5589545366957724, lr:  0.000438, elapsed time:  299917
Step 325600, loss: 0.03353576458524912, acc: 99.65432427823544, p_norm: 2247.36689694714, g_norm: 0.6798753897749189, lr:  0.000438, elapsed time:  300007
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 325700, loss: 0.03320465204548599, acc: 99.66037771837883, p_norm: 2247.4610840581104, g_norm: 0.47727699652758326, lr:  0.000438, elapsed time:  300093
Step 325800, loss: 0.032327696392312644, acc: 99.68506552278996, p_norm: 2247.556172442191, g_norm: 0.8729610444175773, lr:  0.000438, elapsed time:  300190
Step 325900, loss: 0.03241611268371344, acc: 99.69573433697224, p_norm: 2247.638763208268, g_norm: 0.6871961772382552, lr:  0.000438, elapsed time:  300281
Step 326000, loss: 0.032632352970540526, acc: 99.6693819463253, p_norm: 2247.730174198489, g_norm: 0.8119529245505368, lr:  0.000438, elapsed time:  300371
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 326000, eval loss: 0.04627647921442983, eval acc: 99.47978210449219
Step 326100, loss: 0.03314935193862766, acc: 99.66256968677044, p_norm: 2247.845956185243, g_norm: 0.6018935952727464, lr:  0.000438, elapsed time:  300473
Step 326200, loss: 0.03290687064640224, acc: 99.67580036818981, p_norm: 2247.9449706087066, g_norm: 0.5427221222598146, lr:  0.000438, elapsed time:  300563
Step 326300, loss: 0.03258532291743904, acc: 99.67911857366562, p_norm: 2248.03213083949, g_norm: 0.5842771880829677, lr:  0.000438, elapsed time:  300650
Step 326400, loss: 0.03320785264018923, acc: 99.66013810038567, p_norm: 2248.1306556664513, g_norm: 0.6897136110535376, lr:  0.000437, elapsed time:  300737
Step 326500, loss: 0.033280265163630245, acc: 99.65462158620358, p_norm: 2248.2198957685655, g_norm: 0.5553930683247437, lr:  0.000437, elapsed time:  300828
Step 326600, loss: 0.0328451689472422, acc: 99.67745323479176, p_norm: 2248.319429461578, g_norm: 0.49776601571705353, lr:  0.000437, elapsed time:  300916
Step 326700, loss: 0.03368061433080584, acc: 99.67461235821247, p_norm: 2248.397973588573, g_norm: 0.5886887364870392, lr:  0.000437, elapsed time:  301006
Step 326800, loss: 0.034097468722611664, acc: 99.65381470322609, p_norm: 2248.485495804528, g_norm: 0.571433181761977, lr:  0.000437, elapsed time:  301092
Step 326900, loss: 0.03366851717233658, acc: 99.65378561615944, p_norm: 2248.5696451660756, g_norm: 0.48864530894492986, lr:  0.000437, elapsed time:  301181
Step 327000, loss: 0.03231520111206919, acc: 99.68809834122658, p_norm: 2248.6591702932624, g_norm: 0.5821282919501758, lr:  0.000437, elapsed time:  301273
Step 327100, loss: 0.03286619910039008, acc: 99.67083339393139, p_norm: 2248.758385075237, g_norm: 0.4486120278294884, lr:  0.000437, elapsed time:  301364
Step 327200, loss: 0.03327595005743206, acc: 99.65602523088455, p_norm: 2248.859299972638, g_norm: 0.5905997509395748, lr:  0.000437, elapsed time:  301453
Step 327300, loss: 0.03364385060034692, acc: 99.65038366615772, p_norm: 2248.96591830128, g_norm: 0.7643040293637635, lr:  0.000437, elapsed time:  301543
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 327400, loss: 0.03271988948469718, acc: 99.66994031487269, p_norm: 2249.073950267518, g_norm: 0.5275650163863547, lr:  0.000437, elapsed time:  301632
Step 327500, loss: 0.03273818818852305, acc: 99.67049314081669, p_norm: 2249.1544122492446, g_norm: 0.6469670038446248, lr:  0.000437, elapsed time:  301723
Step 327600, loss: 0.03233504684176296, acc: 99.68319708108902, p_norm: 2249.245162522247, g_norm: 0.4415873924768963, lr:  0.000437, elapsed time:  301812
Step 327700, loss: 0.03223624893464148, acc: 99.68838053941727, p_norm: 2249.3137081304053, g_norm: 0.42085294944827994, lr:  0.000437, elapsed time:  301899
Step 327800, loss: 0.03341291174292564, acc: 99.65908919274807, p_norm: 2249.4199174145488, g_norm: 0.6015937528888414, lr:  0.000437, elapsed time:  301989
Step 327900, loss: 0.03278890718705952, acc: 99.69518421590328, p_norm: 2249.5206091411665, g_norm: 0.5620905145724779, lr:  0.000436, elapsed time:  302078
Step 328000, loss: 0.03366907356772572, acc: 99.66010604798794, p_norm: 2249.616736724717, g_norm: 0.6060763453353992, lr:  0.000436, elapsed time:  302165
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 328000, eval loss: 0.04390287343412637, eval acc: 99.52163696289062
Step 328100, loss: 0.03264704323373735, acc: 99.69134759902954, p_norm: 2249.7048131255456, g_norm: 0.4840811692816156, lr:  0.000436, elapsed time:  302270
Step 328200, loss: 0.033765947283245626, acc: 99.6417434066534, p_norm: 2249.800618580358, g_norm: 0.5794111020270567, lr:  0.000436, elapsed time:  302360
Step 328300, loss: 0.032644409509375694, acc: 99.67305018007755, p_norm: 2249.888486692982, g_norm: 0.504220323445648, lr:  0.000436, elapsed time:  302449
Step 328400, loss: 0.03273485864046961, acc: 99.67264296114445, p_norm: 2249.9746885744908, g_norm: 0.5177682636257602, lr:  0.000436, elapsed time:  302540
Step 328500, loss: 0.03342908460181206, acc: 99.65005005896091, p_norm: 2250.0811018664303, g_norm: 0.6420478256230104, lr:  0.000436, elapsed time:  302632
Step 328600, loss: 0.0328781981067732, acc: 99.66969579458237, p_norm: 2250.1768952827765, g_norm: 0.7697653552730926, lr:  0.000436, elapsed time:  302722
Step 328700, loss: 0.0322548385290429, acc: 99.69090111553669, p_norm: 2250.2750522087667, g_norm: 0.6014524287504979, lr:  0.000436, elapsed time:  302816
Step 328800, loss: 0.03288267870433628, acc: 99.67075411975384, p_norm: 2250.3622258328824, g_norm: 0.466489042517896, lr:  0.000436, elapsed time:  302903
Step 328900, loss: 0.03313428827095777, acc: 99.6633539646864, p_norm: 2250.460721842409, g_norm: 0.6013351011042652, lr:  0.000436, elapsed time:  302992
Step 329000, loss: 0.0325343266222626, acc: 99.67477875947952, p_norm: 2250.55394762298, g_norm: 0.54654898481041, lr:  0.000436, elapsed time:  303081
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 329100, loss: 0.03214146799544247, acc: 99.69210745974746, p_norm: 2250.6392355319394, g_norm: 0.7223615152083633, lr:  0.000436, elapsed time:  303172
Step 329200, loss: 0.032469035796821116, acc: 99.6799534112215, p_norm: 2250.7307299725767, g_norm: 0.573891244576965, lr:  0.000436, elapsed time:  303260
Step 329300, loss: 0.03350040519144386, acc: 99.65049459040165, p_norm: 2250.8287001488543, g_norm: 0.6224883880883574, lr:  0.000436, elapsed time:  303346
Step 329400, loss: 0.03273476250469685, acc: 99.67132949829102, p_norm: 2250.9345604128152, g_norm: 0.5197516943904736, lr:  0.000435, elapsed time:  303434
Step 329500, loss: 0.03244873811956495, acc: 99.67623849213123, p_norm: 2251.0190929927594, g_norm: 0.5799859456914316, lr:  0.000435, elapsed time:  303524
Step 329600, loss: 0.03212543057277799, acc: 99.6914819329977, p_norm: 2251.1106967815035, g_norm: 0.8585239552273584, lr:  0.000435, elapsed time:  303616
Step 329700, loss: 0.03284754168707878, acc: 99.67129111289978, p_norm: 2251.226478998976, g_norm: 0.6598642107600288, lr:  0.000435, elapsed time:  303706
Step 329800, loss: 0.032985962037928404, acc: 99.66718766093254, p_norm: 2251.321689309611, g_norm: 0.4356066974980861, lr:  0.000435, elapsed time:  303793
Step 329900, loss: 0.03272690045647323, acc: 99.66782054305077, p_norm: 2251.4135093207396, g_norm: 0.5308757427712588, lr:  0.000435, elapsed time:  303885
Step 330000, loss: 0.03240265724249184, acc: 99.68783947825432, p_norm: 2251.517866940741, g_norm: 0.5344273205568069, lr:  0.000435, elapsed time:  303974
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 330000, eval loss: 0.04466274209320546, eval acc: 99.52198028564453
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C C C O C ( = O ) N c 1 c c c c 2 c c 3 c c c c 4 c 3 c ( c 1 2 ) C ( = O ) N ( C C N ( C ) C ) C 4 = O _EOS
Predicted text: C C C C O C ( = O ) N c 1 c c c c 2 c c 3 c c c c 4 c 3 c ( c 1 2 ) C ( = O ) N ( C C N ( C ) C ) C 4 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 s c 2 c ( c 1 C ) C ( c 1 c c c ( Cl ) c c 1 ) = N C ( C C ( = O ) N C c 1 c c c n c 1 ) c 1 n n c ( C ) n 1 - 2 _EOS
Predicted text: C c 1 s c 2 c ( c 1 C ) C ( c 1 c c c ( Cl ) c c 1 ) = N C ( C C ( = O ) N C c 1 c c c n c 1 ) c 1 n n c ( C ) n 1 - 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( C C 2 ( O ) C C N ( C C C O c 3 c c c c ( O C c 4 c c c c c 4 ) c 3 ) C C 2 ) c c 1 _EOS
Predicted text: C c 1 c c c ( C C 2 ( O ) C C N ( C C C O c 3 c c c c ( O C c 4 c c c c c 4 ) c 3 ) C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O C C N 1 C C C ( = C ( c 2 c c c ( F ) c c 2 ) c 2 c c c ( F ) c c 2 ) C C 1 ) C 1 2 C C 3 C C ( C C ( C 3 ) C 1 ) C 2 _EOS
Predicted text: O = C ( O C C N 1 C C C ( = C ( c 2 c c c ( F ) c c 2 ) c 2 c c c ( F ) c c 2 ) C C 1 ) C 1 2 C C 3 C C ( C C ( C 3 ) C 1 ) C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C C N ( C c 2 c c c ( C ( O ) ( C ( F ) ( F ) F ) C ( F ) ( F ) F ) c c 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C C N ( C c 2 c c c ( C ( O ) ( C ( F ) ( F ) F ) C ( F ) ( F ) F ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 330000, eval acc (token): 0.9393454898750984, eval acc (sequence): 0.8897142857142857
Saving at step 330000
Step 330100, loss: 0.03284596363082528, acc: 99.66717924177647, p_norm: 2251.606382360465, g_norm: 0.5227432718962813, lr:  0.000435, elapsed time:  304166
Step 330200, loss: 0.03260381085332483, acc: 99.67427964508533, p_norm: 2251.6983176426616, g_norm: 0.7103253224232337, lr:  0.000435, elapsed time:  304259
Step 330300, loss: 0.0330870726518333, acc: 99.66329212486744, p_norm: 2251.789907444058, g_norm: 0.8235157769705367, lr:  0.000435, elapsed time:  304346
Step 330400, loss: 0.03340602671727538, acc: 99.65276952087879, p_norm: 2251.8946147482657, g_norm: 0.4689774915242099, lr:  0.000435, elapsed time:  304438
Step 330500, loss: 0.033104469967074696, acc: 99.66473123431206, p_norm: 2252.0015294883588, g_norm: 0.6991507509124767, lr:  0.000435, elapsed time:  304530
Step 330600, loss: 0.033229173142462966, acc: 99.68586149811745, p_norm: 2252.0855225278638, g_norm: 0.7642581737131493, lr:  0.000435, elapsed time:  304621
Step 330700, loss: 0.03332083187997341, acc: 99.6723817139864, p_norm: 2252.165388747359, g_norm: 0.6057399759574638, lr:  0.000435, elapsed time:  304708
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 330800, loss: 0.03300092854160381, acc: 99.68273082087117, p_norm: 2252.25486619647, g_norm: 0.6084721353118088, lr:  0.000435, elapsed time:  304797
Step 330900, loss: 0.03233239045832306, acc: 99.69290597736835, p_norm: 2252.3502443147404, g_norm: 0.6907344818718746, lr:  0.000434, elapsed time:  304886
Step 331000, loss: 0.03284685846418142, acc: 99.66543421149254, p_norm: 2252.442980658649, g_norm: 0.6466836202828814, lr:  0.000434, elapsed time:  304973
Step 331100, loss: 0.03264770623296499, acc: 99.67914877831936, p_norm: 2252.544059936533, g_norm: 0.5516897737752667, lr:  0.000434, elapsed time:  305063
Step 331200, loss: 0.03272277659270913, acc: 99.68368563055992, p_norm: 2252.6427353957756, g_norm: 0.47555036616171065, lr:  0.000434, elapsed time:  305153
Step 331300, loss: 0.03272660128772259, acc: 99.6787506788969, p_norm: 2252.738940376726, g_norm: 0.4324172644164752, lr:  0.000434, elapsed time:  305244
Step 331400, loss: 0.032485031806863844, acc: 99.68473471701145, p_norm: 2252.8306912463368, g_norm: 0.6211405981482154, lr:  0.000434, elapsed time:  305334
Step 331500, loss: 0.033256788719445464, acc: 99.65599605441093, p_norm: 2252.9358267732105, g_norm: 0.43849811336743955, lr:  0.000434, elapsed time:  305421
Step 331600, loss: 0.03242265459150076, acc: 99.67908263206482, p_norm: 2253.0318852967425, g_norm: 0.7918939712348455, lr:  0.000434, elapsed time:  305512
Step 331700, loss: 0.032075783158652484, acc: 99.69644472002983, p_norm: 2253.1230184141095, g_norm: 0.5847135563661392, lr:  0.000434, elapsed time:  305605
Step 331800, loss: 0.03248077957425267, acc: 99.68195500969887, p_norm: 2253.218551786297, g_norm: 0.5584966515690863, lr:  0.000434, elapsed time:  305694
Step 331900, loss: 0.032249261080287396, acc: 99.68339693546295, p_norm: 2253.306811914378, g_norm: 0.4771231712534885, lr:  0.000434, elapsed time:  305783
Step 332000, loss: 0.03286600336432457, acc: 99.67003671824932, p_norm: 2253.4032639441907, g_norm: 0.6077486201414609, lr:  0.000434, elapsed time:  305874
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 332000, eval loss: 0.04824268706142905, eval acc: 99.48036193847656
Step 332100, loss: 0.03276704694144428, acc: 99.67140728235245, p_norm: 2253.50502680121, g_norm: 0.6657857172308176, lr:  0.000434, elapsed time:  305979
Step 332200, loss: 0.03253350520506501, acc: 99.67903251945972, p_norm: 2253.592323587291, g_norm: 0.642664160408782, lr:  0.000434, elapsed time:  306069
Step 332300, loss: 0.033614500416442754, acc: 99.65516881644726, p_norm: 2253.6931093702256, g_norm: 0.6565384921874464, lr:  0.000434, elapsed time:  306158
Step 332400, loss: 0.033212110381573436, acc: 99.65833030641079, p_norm: 2253.798030192747, g_norm: 0.7339020473950869, lr:  0.000433, elapsed time:  306247
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 332500, loss: 0.03359166334011123, acc: 99.63836505750272, p_norm: 2253.8919987537847, g_norm: 0.5321832595246667, lr:  0.000433, elapsed time:  306335
Step 332600, loss: 0.031676866351626816, acc: 99.70442448556423, p_norm: 2253.969763086272, g_norm: 0.5392355991729096, lr:  0.000433, elapsed time:  306425
Step 332700, loss: 0.03288900603074581, acc: 99.66427367925644, p_norm: 2254.0712178750555, g_norm: 0.4977863899904298, lr:  0.000433, elapsed time:  306517
Step 332800, loss: 0.03261192088015377, acc: 99.66797250509262, p_norm: 2254.156827359564, g_norm: 0.5708990752215933, lr:  0.000433, elapsed time:  306607
Step 332900, loss: 0.0323912330949679, acc: 99.68200793862343, p_norm: 2254.2435388925055, g_norm: 0.461825498191038, lr:  0.000433, elapsed time:  306699
Step 333000, loss: 0.03270486116874963, acc: 99.67102661728859, p_norm: 2254.3262216760954, g_norm: 0.562524736394343, lr:  0.000433, elapsed time:  306786
Step 333100, loss: 0.03295131613034755, acc: 99.66389845311642, p_norm: 2254.422973349178, g_norm: 0.4279726341256201, lr:  0.000433, elapsed time:  306873
Step 333200, loss: 0.0333643585909158, acc: 99.65726053714752, p_norm: 2254.5177766448332, g_norm: 0.4967265060018657, lr:  0.000433, elapsed time:  306963
Step 333300, loss: 0.032771991286426785, acc: 99.67080608010292, p_norm: 2254.6131080894484, g_norm: 0.7341483793303799, lr:  0.000433, elapsed time:  307047
Step 333400, loss: 0.03259595610201359, acc: 99.67079535126686, p_norm: 2254.7055790930235, g_norm: 0.46828591699352873, lr:  0.000433, elapsed time:  307139
Step 333500, loss: 0.032195307961665094, acc: 99.68422628939152, p_norm: 2254.7945380825618, g_norm: 0.5748205018706568, lr:  0.000433, elapsed time:  307229
Step 333600, loss: 0.03230132980272174, acc: 99.67756731808186, p_norm: 2254.877609599553, g_norm: 0.6545643221965994, lr:  0.000433, elapsed time:  307319
Step 333700, loss: 0.032260580966249106, acc: 99.68756559491158, p_norm: 2254.981997151192, g_norm: 0.6814789853089106, lr:  0.000433, elapsed time:  307407
Step 333800, loss: 0.03225037682335824, acc: 99.68271298706532, p_norm: 2255.0811415020385, g_norm: 0.518421213819714, lr:  0.000433, elapsed time:  307501
Step 333900, loss: 0.033008014415390786, acc: 99.66926634311676, p_norm: 2255.1726215914955, g_norm: 0.7641391545408496, lr:  0.000433, elapsed time:  307602
Step 334000, loss: 0.03292217536829412, acc: 99.67638140916824, p_norm: 2255.2755773654485, g_norm: 0.5997943030560313, lr:  0.000432, elapsed time:  307695
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 334000, eval loss: 0.04436965225264431, eval acc: 99.51007080078125
Step 334100, loss: 0.03299892119597644, acc: 99.67776961624622, p_norm: 2255.367812450668, g_norm: 1.2833649159115141, lr:  0.000432, elapsed time:  307803
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 334200, loss: 0.03319169724573247, acc: 99.66764842989433, p_norm: 2255.46610676933, g_norm: 0.7258737908181498, lr:  0.000432, elapsed time:  307901
Step 334300, loss: 0.032309399964287874, acc: 99.68811838328838, p_norm: 2255.542748182995, g_norm: 0.6539895830050223, lr:  0.000432, elapsed time:  307991
Step 334400, loss: 0.03287306279875338, acc: 99.67084366083145, p_norm: 2255.6307683283417, g_norm: 0.8760100225669358, lr:  0.000432, elapsed time:  308082
Step 334500, loss: 0.03256270045414567, acc: 99.67224943637848, p_norm: 2255.7286771035374, g_norm: 0.5105949852737652, lr:  0.000432, elapsed time:  308172
Step 334600, loss: 0.03240726968739182, acc: 99.68081346154213, p_norm: 2255.8139116895495, g_norm: 0.47341703895020815, lr:  0.000432, elapsed time:  308264
Step 334700, loss: 0.032516369847580794, acc: 99.6764831840992, p_norm: 2255.9133374775497, g_norm: 0.5356210332037107, lr:  0.000432, elapsed time:  308353
Step 334800, loss: 0.03257155709434301, acc: 99.67564907670021, p_norm: 2255.991021517179, g_norm: 0.6346202018351879, lr:  0.000432, elapsed time:  308442
Step 334900, loss: 0.03281174461822957, acc: 99.66567251086235, p_norm: 2256.092524406656, g_norm: 1.0816609342749515, lr:  0.000432, elapsed time:  308532
Step 335000, loss: 0.032431505606509745, acc: 99.68785226345062, p_norm: 2256.2045366139473, g_norm: 0.6957658810415117, lr:  0.000432, elapsed time:  308628
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O P ( = O ) ( O C C ) O c 1 c c c ( C ( = O ) c 2 c c c ( C S c 3 n c 4 c c c c ( C ) c 4 c ( = O ) n 3 C ) c c 2 ) c c 1 _EOS
Predicted text: C C O P ( = O ) ( O C C ) O c 1 c c c ( C ( = O ) c 2 c c c ( C S c 3 n c 4 c c c c ( C ) c 4 c ( = O ) n 3 C ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C 4 C C 3 C N 4 S ( C ) ( = O ) = O ) n ( C ) c 2 n 1 _EOS
Predicted text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C 4 C C 3 C N 4 S ( C ) ( = O ) = O ) n ( C ) c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( C # N ) c ( F ) c 1 _EOS
Predicted text: C c 1 c c c ( C # N ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( C ) c ( - n 2 n c ( C ) c 3 c ( O C 4 C C O C 4 ) c c ( C ) n c 3 2 ) c ( C ) c 1 _EOS
Predicted text: C c 1 c c ( C ) c ( - n 2 n c ( C ) c 3 c ( O C 4 C C O C 4 ) c c ( C ) n c 3 2 ) c ( C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) c 1 c c ( N C ( = O ) N c 2 c c c ( O c 3 c c n c 4 [nH] c ( = O ) c n c 3 4 ) c c 2 F ) n ( - c 2 c c c c c 2 ) n 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c ( N C ( = O ) N c 2 c c c ( O c 3 c c n c 4 [nH] c ( = O ) c n c 3 4 ) c c 2 F ) n ( - c 2 c c c c c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 335000, eval acc (token): 0.9435489079357992, eval acc (sequence): 0.8947943210775391
Saving at step 335000
Step 335100, loss: 0.0325162398442626, acc: 99.67807832360268, p_norm: 2256.289268420276, g_norm: 0.7309423645690533, lr:  0.000432, elapsed time:  308806
Step 335200, loss: 0.03308069676626474, acc: 99.65142205357552, p_norm: 2256.3785320322413, g_norm: 0.8074708646690061, lr:  0.000432, elapsed time:  308896
Step 335300, loss: 0.03217003964819014, acc: 99.68268920481205, p_norm: 2256.4737859164943, g_norm: 0.6877835316275319, lr:  0.000432, elapsed time:  308994
Step 335400, loss: 0.032920654928311706, acc: 99.66802109777927, p_norm: 2256.567130563594, g_norm: 1.0771282699592846, lr:  0.000432, elapsed time:  309082
Step 335500, loss: 0.03263502208981663, acc: 99.67242096364498, p_norm: 2256.6714855744162, g_norm: 0.5878521277192442, lr:  0.000431, elapsed time:  309174
Step 335600, loss: 0.03254720367025584, acc: 99.67897681891918, p_norm: 2256.7549083657827, g_norm: 0.6235925095398557, lr:  0.000431, elapsed time:  309265
Step 335700, loss: 0.03330768575426191, acc: 99.65966321527958, p_norm: 2256.839467896374, g_norm: 0.7636235421376723, lr:  0.000431, elapsed time:  309354
Step 335800, loss: 0.03235261127818376, acc: 99.68606805801392, p_norm: 2256.9223141568477, g_norm: 0.7281088412705315, lr:  0.000431, elapsed time:  309443
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 335900, loss: 0.03273796677016295, acc: 99.67787653281731, p_norm: 2257.023129028787, g_norm: 0.531054418463416, lr:  0.000431, elapsed time:  309535
Step 336000, loss: 0.032316786418668926, acc: 99.68095974624157, p_norm: 2257.098277910248, g_norm: 0.6848276690427343, lr:  0.000431, elapsed time:  309631
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 336000, eval loss: 0.04517805954441428, eval acc: 99.5069351196289
Step 336100, loss: 0.03225261576939374, acc: 99.68114374577999, p_norm: 2257.186830548204, g_norm: 0.5326043994135276, lr:  0.000431, elapsed time:  309737
Step 336200, loss: 0.032099883179180326, acc: 99.68675863742828, p_norm: 2257.279839330341, g_norm: 0.6239220976395056, lr:  0.000431, elapsed time:  309828
Step 336300, loss: 0.03244293888565153, acc: 99.68526627123356, p_norm: 2257.3794552875006, g_norm: 0.6697421474021404, lr:  0.000431, elapsed time:  309919
Step 336400, loss: 0.03254405370913446, acc: 99.68340304493904, p_norm: 2257.473656653352, g_norm: 0.5618344139870001, lr:  0.000431, elapsed time:  310009
Step 336500, loss: 0.032196576367132364, acc: 99.6802679002285, p_norm: 2257.5586129753747, g_norm: 0.505756372144284, lr:  0.000431, elapsed time:  310103
Step 336600, loss: 0.0326631566695869, acc: 99.68035317957401, p_norm: 2257.6551375755594, g_norm: 0.6766345779728767, lr:  0.000431, elapsed time:  310193
Step 336700, loss: 0.03232114965096116, acc: 99.69246785342693, p_norm: 2257.7680468139615, g_norm: 0.6685889230249144, lr:  0.000431, elapsed time:  310291
Step 336800, loss: 0.03314154606312513, acc: 99.6708068549633, p_norm: 2257.863543175005, g_norm: 0.4326747353801816, lr:  0.000431, elapsed time:  310380
Step 336900, loss: 0.032430117782205344, acc: 99.68873499333858, p_norm: 2257.9394467129064, g_norm: 0.5700046226743429, lr:  0.000431, elapsed time:  310471
Step 337000, loss: 0.03321697391103953, acc: 99.66778489947319, p_norm: 2258.029662904364, g_norm: 0.5643581632034966, lr:  0.000431, elapsed time:  310564
Step 337100, loss: 0.03222811774350703, acc: 99.69150795042515, p_norm: 2258.1210518877465, g_norm: 0.6077966084071393, lr:  0.000430, elapsed time:  310652
Step 337200, loss: 0.03255240639671683, acc: 99.68105667829514, p_norm: 2258.214724319799, g_norm: 0.6836824178178039, lr:  0.000430, elapsed time:  310739
Step 337300, loss: 0.03280767210759222, acc: 99.66798724234104, p_norm: 2258.309000503397, g_norm: 0.5229175635402312, lr:  0.000430, elapsed time:  310831
Step 337400, loss: 0.032376099382527175, acc: 99.67970782518387, p_norm: 2258.395348697516, g_norm: 0.8748222765561562, lr:  0.000430, elapsed time:  310919
Step 337500, loss: 0.03336592725478113, acc: 99.65256454050541, p_norm: 2258.4808902139102, g_norm: 0.570441365407124, lr:  0.000430, elapsed time:  311005
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 337600, loss: 0.03296457767190768, acc: 99.66182510551093, p_norm: 2258.571645858464, g_norm: 0.5209377519008516, lr:  0.000430, elapsed time:  311097
Step 337700, loss: 0.03258438345976174, acc: 99.67219866812229, p_norm: 2258.6665185184643, g_norm: 0.7642075368093256, lr:  0.000430, elapsed time:  311186
Step 337800, loss: 0.032498840200714765, acc: 99.68490454554558, p_norm: 2258.766638084163, g_norm: 0.5735270147464697, lr:  0.000430, elapsed time:  311274
Step 337900, loss: 0.03240108360070735, acc: 99.68016070127487, p_norm: 2258.843121173545, g_norm: 0.541483818998985, lr:  0.000430, elapsed time:  311362
Step 338000, loss: 0.03254061894956976, acc: 99.67670023441315, p_norm: 2258.9283735498216, g_norm: 0.6371801617378192, lr:  0.000430, elapsed time:  311451
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 338000, eval loss: 0.046757169645279636, eval acc: 99.4857177734375
Step 338100, loss: 0.032369365906342866, acc: 99.6801359206438, p_norm: 2259.0123652433563, g_norm: 0.5452095466696902, lr:  0.000430, elapsed time:  311555
Step 338200, loss: 0.03293361933901906, acc: 99.67094905674458, p_norm: 2259.103654317194, g_norm: 0.45765800409337076, lr:  0.000430, elapsed time:  311649
Step 338300, loss: 0.0320421509584412, acc: 99.69664339721203, p_norm: 2259.193448926513, g_norm: 0.5321481558742007, lr:  0.000430, elapsed time:  311742
Step 338400, loss: 0.032968322155065836, acc: 99.66591866314411, p_norm: 2259.2875575423222, g_norm: 0.5023648861062245, lr:  0.000430, elapsed time:  311830
Step 338500, loss: 0.03252915218938142, acc: 99.68192964792252, p_norm: 2259.381827976462, g_norm: 0.6796039376240506, lr:  0.000430, elapsed time:  311922
Step 338600, loss: 0.03243470499757677, acc: 99.68137781322002, p_norm: 2259.4743994710057, g_norm: 0.8242509307956439, lr:  0.000430, elapsed time:  312013
Step 338700, loss: 0.03311816920991987, acc: 99.65851406753063, p_norm: 2259.570564188591, g_norm: 0.5360834114224344, lr:  0.000429, elapsed time:  312103
Step 338800, loss: 0.03248754059430212, acc: 99.67766018211842, p_norm: 2259.6569451934965, g_norm: 0.6452668927033198, lr:  0.000429, elapsed time:  312193
Step 338900, loss: 0.032333558262325826, acc: 99.68533769249916, p_norm: 2259.755865512957, g_norm: 0.7620785823007287, lr:  0.000429, elapsed time:  312291
Step 339000, loss: 0.03218774465378374, acc: 99.68613684177399, p_norm: 2259.839862238101, g_norm: 0.622952377299664, lr:  0.000429, elapsed time:  312383
Step 339100, loss: 0.03244420802220702, acc: 99.67939291894436, p_norm: 2259.933016533112, g_norm: 0.574889632024186, lr:  0.000429, elapsed time:  312472
Step 339200, loss: 0.03259109748993069, acc: 99.67326848208904, p_norm: 2260.02509807931, g_norm: 0.6105006095181447, lr:  0.000429, elapsed time:  312564
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 339300, loss: 0.032732762225323515, acc: 99.67386008196374, p_norm: 2260.1143028371002, g_norm: 0.6028024717280505, lr:  0.000429, elapsed time:  312655
Step 339400, loss: 0.032557568731717765, acc: 99.67271521687508, p_norm: 2260.2157188660235, g_norm: 0.6065952892329267, lr:  0.000429, elapsed time:  312744
Step 339500, loss: 0.032063860539346935, acc: 99.69701194763184, p_norm: 2260.3028270068394, g_norm: 0.6220232624103379, lr:  0.000429, elapsed time:  312836
Step 339600, loss: 0.0325509936735034, acc: 99.68594026565552, p_norm: 2260.384224134557, g_norm: 0.745985654317862, lr:  0.000429, elapsed time:  312924
Step 339700, loss: 0.03276071450673044, acc: 99.67298993468285, p_norm: 2260.4707008857954, g_norm: 0.45442713652700345, lr:  0.000429, elapsed time:  313014
Step 339800, loss: 0.03225803763139993, acc: 99.68445599079132, p_norm: 2260.563491768166, g_norm: 0.4889504511204227, lr:  0.000429, elapsed time:  313104
Step 339900, loss: 0.03292862062808126, acc: 99.6628223657608, p_norm: 2260.6562955475906, g_norm: 0.5738545959437279, lr:  0.000429, elapsed time:  313193
Step 340000, loss: 0.03269835563376546, acc: 99.66923461854458, p_norm: 2260.740842782723, g_norm: 0.6212947633598418, lr:  0.000429, elapsed time:  313282
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 340000, eval loss: 0.04517106046900153, eval acc: 99.500732421875
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) ( C ) O C ( = O ) C ( C ) ( C ) S c 1 n c ( C N C ( = O ) c 2 c c c ( - c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) c c 2 ) c s 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) C ( C ) ( C ) S c 1 n c ( C N C ( = O ) c 2 c c c ( - c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) c c 2 ) c s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c ( N C ( = O ) N C 2 N = C ( c 3 c c c c c 3 ) c 3 c c c c c 3 N ( C C ( = O ) c 3 c c c c c 3 ) C 2 = O ) c 1 _EOS
Predicted text: C c 1 c c c c ( N C ( = O ) N C 2 N = C ( c 3 c c c c c 3 ) c 3 c c c c c 3 N ( C C ( = O ) c 3 c c c c c 3 ) C 2 = O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C C ( = O ) C C N C C O c 2 c c c ( C ( = O ) O ) c c 2 O C ) c c c 1 N C ( = O ) N c 1 c c c c c 1 F _EOS
Predicted text: C O c 1 c c ( C C ( = O ) C C N C C O c 2 c c c ( C ( = O ) O ) c c 2 O C ) c c c 1 N C ( = O ) N c 1 c c c c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c ( O C C C N 2 C C ( C ) O C ( C ) C 2 ) c c c 2 c 1 N = C ( N C ( = O ) c 1 s c ( C ) n c 1 C ) N 1 C C N = C 2 1 _EOS
Predicted text: C O c 1 c ( O C C C N 2 C C ( C ) O C ( C ) C 2 ) c c c 2 c 1 N = C ( N C ( = O ) c 1 s c ( C ) n c 1 C ) N 1 C C N = C 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C c 1 c c c ( - c 2 n c 3 c c c ( C 4 ( c 5 c c c c n 5 ) C C 4 ) c c 3 s 2 ) c ( F ) c 1 _EOS
Predicted text: O = C c 1 c c c ( - c 2 n c 3 c c c ( C 4 ( c 5 c c c c n 5 ) C C 4 ) c c 3 s 2 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 340000, eval acc (token): 0.9378654700992907, eval acc (sequence): 0.8870677233429395
Saving at step 340000
Step 340100, loss: 0.032186199841089544, acc: 99.68602739274502, p_norm: 2260.834126205049, g_norm: 0.5556000278500469, lr:  0.000429, elapsed time:  313477
Step 340200, loss: 0.031637562806718054, acc: 99.69716702401638, p_norm: 2260.924237607215, g_norm: 0.5858462942170923, lr:  0.000428, elapsed time:  313570
Step 340300, loss: 0.032911464511416855, acc: 99.6694683432579, p_norm: 2261.027551101905, g_norm: 0.6148706066623836, lr:  0.000428, elapsed time:  313661
Step 340400, loss: 0.032446378525346514, acc: 99.67788028717041, p_norm: 2261.116760065962, g_norm: 0.6033328172445744, lr:  0.000428, elapsed time:  313751
Step 340500, loss: 0.03174484767019749, acc: 99.70241226255894, p_norm: 2261.2029116197123, g_norm: 0.8324023099300428, lr:  0.000428, elapsed time:  313842
Step 340600, loss: 0.03301564652472735, acc: 99.66333301365376, p_norm: 2261.3065348580462, g_norm: 0.5791133649871164, lr:  0.000428, elapsed time:  313919
Step 340700, loss: 0.03305684252642095, acc: 99.65626810491085, p_norm: 2261.3988375144213, g_norm: 0.7115484804666347, lr:  0.000428, elapsed time:  313995
Step 340800, loss: 0.032689177403226494, acc: 99.67086610198021, p_norm: 2261.5036539731545, g_norm: 0.8934155964092266, lr:  0.000428, elapsed time:  314086
Step 340900, loss: 0.03247893135994673, acc: 99.68414433300495, p_norm: 2261.609475422563, g_norm: 0.8753153339222355, lr:  0.000428, elapsed time:  314171
Step 341000, loss: 0.032797740492969754, acc: 99.67495860159397, p_norm: 2261.702827543982, g_norm: 0.6665961014848536, lr:  0.000428, elapsed time:  314266
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 341100, loss: 0.032616782226315505, acc: 99.67256422078343, p_norm: 2261.7839767071746, g_norm: 0.5801082056900185, lr:  0.000428, elapsed time:  314355
Step 341200, loss: 0.03255672660190612, acc: 99.67941799759865, p_norm: 2261.8774252645835, g_norm: 0.75209202766382, lr:  0.000428, elapsed time:  314449
Step 341300, loss: 0.03206271189730615, acc: 99.69025504589081, p_norm: 2261.9585296782716, g_norm: 0.6614589832500273, lr:  0.000428, elapsed time:  314541
Step 341400, loss: 0.03200055736582726, acc: 99.69219414889812, p_norm: 2262.0407776435463, g_norm: 0.9706974068795186, lr:  0.000428, elapsed time:  314630
Step 341500, loss: 0.03166452228091657, acc: 99.7054131180048, p_norm: 2262.137026165094, g_norm: 0.41464799966927635, lr:  0.000428, elapsed time:  314725
Step 341600, loss: 0.03190788733772933, acc: 99.69755049049854, p_norm: 2262.20993414811, g_norm: 0.5092008524895228, lr:  0.000428, elapsed time:  314815
Step 341700, loss: 0.03219475824851543, acc: 99.68976128101349, p_norm: 2262.294096832406, g_norm: 0.5591290294116479, lr:  0.000428, elapsed time:  314904
Step 341800, loss: 0.03197516235522926, acc: 99.69385014474392, p_norm: 2262.372227835429, g_norm: 0.699895586419431, lr:  0.000427, elapsed time:  314995
Step 341900, loss: 0.031884730719029905, acc: 99.69346845149994, p_norm: 2262.4552801092395, g_norm: 0.5381021399802164, lr:  0.000427, elapsed time:  315088
Step 342000, loss: 0.03280606954824179, acc: 99.66952234506607, p_norm: 2262.5538615865403, g_norm: 0.5256295536978423, lr:  0.000427, elapsed time:  315176
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 342000, eval loss: 0.04599824532866477, eval acc: 99.51753234863281
Step 342100, loss: 0.03257210809737444, acc: 99.67504653334618, p_norm: 2262.6541754952327, g_norm: 0.6218984567162212, lr:  0.000427, elapsed time:  315288
Step 342200, loss: 0.03385392179246992, acc: 99.6458083242178, p_norm: 2262.7635055428586, g_norm: 0.6694752040568933, lr:  0.000427, elapsed time:  315376
Step 342300, loss: 0.03219444181770086, acc: 99.69931431114674, p_norm: 2262.8534281953307, g_norm: 0.5374855317239651, lr:  0.000427, elapsed time:  315467
Step 342400, loss: 0.03181613391730934, acc: 99.69998110830784, p_norm: 2262.941017195896, g_norm: 0.5971639049991642, lr:  0.000427, elapsed time:  315556
Step 342500, loss: 0.0323570057656616, acc: 99.68168179690838, p_norm: 2263.0287052887556, g_norm: 0.593530056507608, lr:  0.000427, elapsed time:  315649
Step 342600, loss: 0.03287949311546981, acc: 99.67541429400444, p_norm: 2263.1317286146723, g_norm: 0.6010219970839165, lr:  0.000427, elapsed time:  315741
Step 342700, loss: 0.03352604999672622, acc: 99.64048287272453, p_norm: 2263.2311291824026, g_norm: 0.47325068051639474, lr:  0.000427, elapsed time:  315830
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 342800, loss: 0.03224172528406874, acc: 99.68172248026625, p_norm: 2263.325034350728, g_norm: 0.4654549097745091, lr:  0.000427, elapsed time:  315924
Step 342900, loss: 0.03236862434539944, acc: 99.6891780346632, p_norm: 2263.4047867414765, g_norm: 0.529623712850338, lr:  0.000427, elapsed time:  316016
Step 343000, loss: 0.03332962889224291, acc: 99.68427674472332, p_norm: 2263.48362857412, g_norm: 2.3653697562226914, lr:  0.000427, elapsed time:  316105
Step 343100, loss: 0.03488199983723462, acc: 99.6715544462204, p_norm: 2263.5654398402567, g_norm: 0.7255527174475009, lr:  0.000427, elapsed time:  316193
Step 343200, loss: 0.03367960970848799, acc: 99.6832429766655, p_norm: 2263.642483364759, g_norm: 0.4065902883568271, lr:  0.000427, elapsed time:  316283
Step 343300, loss: 0.03385400309693068, acc: 99.6880344003439, p_norm: 2263.7142349266514, g_norm: 0.9657307082196982, lr:  0.000427, elapsed time:  316374
Step 343400, loss: 0.034363504657521846, acc: 99.67146691679955, p_norm: 2263.797950093593, g_norm: 0.5939575585160976, lr:  0.000426, elapsed time:  316468
Step 343500, loss: 0.03248673680238426, acc: 99.70471894741058, p_norm: 2263.8907288081687, g_norm: 0.7022820479821982, lr:  0.000426, elapsed time:  316564
Step 343600, loss: 0.033175030071288344, acc: 99.69412752985954, p_norm: 2263.9683889818566, g_norm: 0.5559657695831665, lr:  0.000426, elapsed time:  316664
Step 343700, loss: 0.03379700965248048, acc: 99.67794400453568, p_norm: 2264.062389337166, g_norm: 0.4714802596146256, lr:  0.000426, elapsed time:  316753
Step 343800, loss: 0.03500986751168966, acc: 99.65208107233047, p_norm: 2264.142693146286, g_norm: 0.5150313829367544, lr:  0.000426, elapsed time:  316839
Step 343900, loss: 0.03397094783838838, acc: 99.66497020423412, p_norm: 2264.2334025900414, g_norm: 0.7679572020306868, lr:  0.000426, elapsed time:  316927
Step 344000, loss: 0.0336383268982172, acc: 99.6658232063055, p_norm: 2264.3154657787722, g_norm: 0.8018011206891862, lr:  0.000426, elapsed time:  317017
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 344000, eval loss: 0.046888001151382926, eval acc: 99.49929809570312
Step 344100, loss: 0.033174785627052186, acc: 99.67756333947182, p_norm: 2264.412353462746, g_norm: 0.42773711315495805, lr:  0.000426, elapsed time:  317117
Step 344200, loss: 0.03334910488687456, acc: 99.66861249506474, p_norm: 2264.500906057615, g_norm: 0.46336741061687564, lr:  0.000426, elapsed time:  317206
Step 344300, loss: 0.033295642673037945, acc: 99.6703760176897, p_norm: 2264.5952181503176, g_norm: 0.37842569347813143, lr:  0.000426, elapsed time:  317297
Step 344400, loss: 0.033491496029309925, acc: 99.67376704514027, p_norm: 2264.6879991993083, g_norm: 0.5374399213428491, lr:  0.000426, elapsed time:  317388
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 344500, loss: 0.032662768732404236, acc: 99.68164115402828, p_norm: 2264.764313829935, g_norm: 0.5538635132062466, lr:  0.000426, elapsed time:  317478
Step 344600, loss: 0.03268619681708515, acc: 99.68726453185081, p_norm: 2264.8531619240894, g_norm: 0.5977595384370727, lr:  0.000426, elapsed time:  317566
Step 344700, loss: 0.032508735372684894, acc: 99.68921016156673, p_norm: 2264.950840543581, g_norm: 0.6167212168220733, lr:  0.000426, elapsed time:  317659
Step 344800, loss: 0.03229923886246979, acc: 99.68125735223293, p_norm: 2265.0352600351966, g_norm: 0.5821484818263057, lr:  0.000426, elapsed time:  317749
Step 344900, loss: 0.032240423383191226, acc: 99.69330839812756, p_norm: 2265.123218119472, g_norm: 0.5959650864240785, lr:  0.000426, elapsed time:  317842
Step 345000, loss: 0.03222036470659077, acc: 99.69118618965149, p_norm: 2265.2230146736297, g_norm: 0.594395301760882, lr:  0.000426, elapsed time:  317933
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C C ( C ( = O ) O ) C 1 C C N ( C ( = O ) O C c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 ) C C 1 _EOS
Predicted text: C C C ( C ( = O ) O ) C 1 C C N ( C ( = O ) O C c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C O c 1 c c c ( C C ( N C ( = O ) O C ( C ) ( C ) C ) C ( = O ) O ) c c 1 C ( = O ) O C _EOS
Predicted text: C O C ( = O ) C O c 1 c c c ( C C ( N C ( = O ) O C ( C ) ( C ) C ) C ( = O ) O ) c c 1 C ( = O ) O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( [SH] ( C c 2 c [nH] n c 2 C ) c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c c c 1 O C C ( = O ) O _EOS
Predicted text: C c 1 c c ( [SH] ( C c 2 c [nH] n c 2 C ) c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c c c 1 O C C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: N C ( = O ) C C N 1 C C C ( C 2 c 3 c c c c c 3 C = C c 3 c c c c c 3 2 ) C C 1 _EOS
Predicted text: N C ( = O ) C C N 1 C C C ( C 2 c 3 c c c c c 3 C = C c 3 c c c c c 3 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) [Si] ( S c 1 c c c c c 1 C c 1 n c 2 c ( N c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) n c n c 2 s 1 ) ( C ( C ) C ) C ( C ) C _EOS
Predicted text: C C ( C ) [Si] ( S c 1 c c c c c 1 C c 1 n c 2 c ( N c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) n c n c 2 s 1 ) ( C ( C ) C ) C ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 345000, eval acc (token): 0.9415424342317117, eval acc (sequence): 0.891185076810534
Saving at step 345000
Step 345100, loss: 0.032137452019378544, acc: 99.69242739677429, p_norm: 2265.3094018137094, g_norm: 0.592507505786776, lr:  0.000425, elapsed time:  318107
Step 345200, loss: 0.032177401958033446, acc: 99.68859878182411, p_norm: 2265.390400529522, g_norm: 0.5408277010429536, lr:  0.000425, elapsed time:  318198
Step 345300, loss: 0.03270139292348176, acc: 99.68271164596081, p_norm: 2265.4861269858184, g_norm: 0.7985268104454031, lr:  0.000425, elapsed time:  318291
Step 345400, loss: 0.03223231484182179, acc: 99.68522584438324, p_norm: 2265.5728181726695, g_norm: 0.7394480809946085, lr:  0.000425, elapsed time:  318384
Step 345500, loss: 0.03242907259613276, acc: 99.67556972801685, p_norm: 2265.6682369212085, g_norm: 0.548721507081489, lr:  0.000425, elapsed time:  318477
Step 345600, loss: 0.03295095223467797, acc: 99.66586683690548, p_norm: 2265.75448732825, g_norm: 0.5667855902884906, lr:  0.000425, elapsed time:  318565
Step 345700, loss: 0.03281209738459438, acc: 99.66552111506462, p_norm: 2265.8491966295387, g_norm: 0.5620274279329276, lr:  0.000425, elapsed time:  318658
Step 345800, loss: 0.032553400476463136, acc: 99.67081496119499, p_norm: 2265.9326030053894, g_norm: 0.5523109805597975, lr:  0.000425, elapsed time:  318747
Step 345900, loss: 0.03261991359293461, acc: 99.67723248898983, p_norm: 2266.0246634469554, g_norm: 0.5613432555875558, lr:  0.000425, elapsed time:  318836
Step 346000, loss: 0.03276516219135374, acc: 99.67005474865437, p_norm: 2266.115376139053, g_norm: 0.5937145820640873, lr:  0.000425, elapsed time:  318906
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Evaluation (with teacher) at step 346000, eval loss: 0.04640553101897239, eval acc: 99.49188232421875
Step 346100, loss: 0.03230660459492356, acc: 99.68425081670284, p_norm: 2266.1996378290423, g_norm: 0.7515368385931368, lr:  0.000425, elapsed time:  318986
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6822
Step 346200, loss: 0.0314797902012951, acc: 99.70951642351174, p_norm: 2266.2938534066748, g_norm: 0.4323274498727316, lr:  0.000425, elapsed time:  319056
Step 346300, loss: 0.031337687759660185, acc: 99.70609728991985, p_norm: 2266.37853379348, g_norm: 0.7259272417574235, lr:  0.000425, elapsed time:  319148
Step 346400, loss: 0.03203958697151393, acc: 99.68958070874214, p_norm: 2266.4756961296966, g_norm: 0.5216978589419576, lr:  0.000425, elapsed time:  319242
Step 346500, loss: 0.03228664833121002, acc: 99.68546211719513, p_norm: 2266.5589397081176, g_norm: 0.45658964273177044, lr:  0.000425, elapsed time:  319337
Step 346600, loss: 0.03212868657894433, acc: 99.6864607334137, p_norm: 2266.6461713189856, g_norm: 0.6475882285275838, lr:  0.000425, elapsed time:  319426
Step 346700, loss: 0.03217113709077239, acc: 99.6878038495779, p_norm: 2266.732614090887, g_norm: 0.9939423271554316, lr:  0.000424, elapsed time:  319517
Step 346800, loss: 0.032273031333461405, acc: 99.68623095750809, p_norm: 2266.8324160009684, g_norm: 1.5480411981407969, lr:  0.000424, elapsed time:  319605
Step 346900, loss: 0.03214028899092227, acc: 99.69537925720215, p_norm: 2266.908735660353, g_norm: 0.5164613998844629, lr:  0.000424, elapsed time:  319701
Step 347000, loss: 0.03194128251168877, acc: 99.69800269603729, p_norm: 2266.9987817222095, g_norm: 0.7446501464412723, lr:  0.000424, elapsed time:  319796
Step 347100, loss: 0.031951346071437, acc: 99.69487833976746, p_norm: 2267.0874536913775, g_norm: 0.523178302561129, lr:  0.000424, elapsed time:  319887
Step 347200, loss: 0.03267277433536947, acc: 99.67356795072556, p_norm: 2267.189901356533, g_norm: 0.5589662492144141, lr:  0.000424, elapsed time:  319976
Step 347300, loss: 0.03243843132629991, acc: 99.68441399931908, p_norm: 2267.276097634828, g_norm: 0.5197241385168044, lr:  0.000424, elapsed time:  320065
Step 347400, loss: 0.032589272088371216, acc: 99.67542205750942, p_norm: 2267.3630091195646, g_norm: 0.5988719160633681, lr:  0.000424, elapsed time:  320154
Step 347500, loss: 0.03290390106383711, acc: 99.66531935334206, p_norm: 2267.4607435967037, g_norm: 0.6849029121715764, lr:  0.000424, elapsed time:  320244
Step 347600, loss: 0.032742577879689636, acc: 99.67047882080078, p_norm: 2267.5422306199393, g_norm: 0.5998194615146062, lr:  0.000424, elapsed time:  320334
Step 347700, loss: 0.03294928238261491, acc: 99.66795742511749, p_norm: 2267.6378321762104, g_norm: 0.6616368132192634, lr:  0.000424, elapsed time:  320408
Step 347800, loss: 0.05474190111272037, acc: 99.66435185074806, p_norm: 2267.7264557153576, g_norm: 0.42634175515796985, lr:  0.000424, elapsed time:  320477
Calling G2SDataset.batch()
Done, time:  0.59 s, total batches: 6823
Step 347900, loss: 0.03308938859744155, acc: 99.6790426287485, p_norm: 2267.810435166859, g_norm: 0.45442605210275594, lr:  0.000424, elapsed time:  320561
Step 348000, loss: 0.03223330846056342, acc: 99.70214201509953, p_norm: 2267.892187159186, g_norm: 0.5923074525903445, lr:  0.000424, elapsed time:  320652
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 348000, eval loss: 0.04425386877730489, eval acc: 99.52316284179688
Step 348100, loss: 0.03224970511160791, acc: 99.69936263561249, p_norm: 2267.975351102303, g_norm: 0.5924052736826769, lr:  0.000424, elapsed time:  320758
Step 348200, loss: 0.0328841799357906, acc: 99.67468173801899, p_norm: 2268.054137605378, g_norm: 0.6309089592302232, lr:  0.000424, elapsed time:  320834
Step 348300, loss: 0.032389782429672775, acc: 99.67681597173214, p_norm: 2268.1373763322977, g_norm: 0.6552519421982668, lr:  0.000423, elapsed time:  320902
Step 348400, loss: 0.032897548470646146, acc: 99.66381458938122, p_norm: 2268.223761794296, g_norm: 0.6188499634465512, lr:  0.000423, elapsed time:  320971
Step 348500, loss: 0.03249199371319264, acc: 99.68228259682655, p_norm: 2268.3071888014147, g_norm: 0.5344175840967547, lr:  0.000423, elapsed time:  321041
Step 348600, loss: 0.032912066159769895, acc: 99.66871525347233, p_norm: 2268.4013530067014, g_norm: 0.41787828533936233, lr:  0.000423, elapsed time:  321120
Step 348700, loss: 0.0321579430764541, acc: 99.69393472373486, p_norm: 2268.484379188323, g_norm: 0.4522817760865619, lr:  0.000423, elapsed time:  321210
Step 348800, loss: 0.03169224048964679, acc: 99.69622559845448, p_norm: 2268.5605222658874, g_norm: 0.6647091237382861, lr:  0.000423, elapsed time:  321304
Step 348900, loss: 0.0327348227892071, acc: 99.67013284564018, p_norm: 2268.6556552201528, g_norm: 0.6103207331359068, lr:  0.000423, elapsed time:  321394
Step 349000, loss: 0.03233732960186899, acc: 99.68626627326012, p_norm: 2268.743998742896, g_norm: 0.5618274855695108, lr:  0.000423, elapsed time:  321483
Step 349100, loss: 0.03244446793105453, acc: 99.67757084965706, p_norm: 2268.8285504589467, g_norm: 0.7071764734161348, lr:  0.000423, elapsed time:  321574
Step 349200, loss: 0.03245666593313217, acc: 99.68045882880688, p_norm: 2268.919774633668, g_norm: 0.7122437392263288, lr:  0.000423, elapsed time:  321664
Step 349300, loss: 0.03172246998175979, acc: 99.70128577947617, p_norm: 2268.9954402756457, g_norm: 0.4691715925160214, lr:  0.000423, elapsed time:  321756
Step 349400, loss: 0.032898358455859124, acc: 99.67389361560345, p_norm: 2269.1020929232577, g_norm: 0.7300245334004615, lr:  0.000423, elapsed time:  321845
Step 349500, loss: 0.03361784951761365, acc: 99.65945626795292, p_norm: 2269.20156737439, g_norm: 0.48386577467374975, lr:  0.000423, elapsed time:  321935
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 349600, loss: 0.032249914921320996, acc: 99.69574125765571, p_norm: 2269.277362368775, g_norm: 0.6353250701975347, lr:  0.000423, elapsed time:  322026
Step 349700, loss: 0.03258354258723557, acc: 99.67751161754131, p_norm: 2269.3670818673463, g_norm: 0.9073405716712424, lr:  0.000423, elapsed time:  322115
Step 349800, loss: 0.03215886302292347, acc: 99.68738132715225, p_norm: 2269.4586727104397, g_norm: 0.45761337824635634, lr:  0.000423, elapsed time:  322204
Step 349900, loss: 0.03179072281811386, acc: 99.69829161465168, p_norm: 2269.540434438366, g_norm: 0.6870184570273608, lr:  0.000423, elapsed time:  322294
Step 350000, loss: 0.032305668611079454, acc: 99.68105165660381, p_norm: 2269.6299260944197, g_norm: 0.503742419701863, lr:  0.000422, elapsed time:  322384
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 350000, eval loss: 0.04500051550567152, eval acc: 99.53303527832031
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) c 1 c c ( Cl ) c c c 1 N C ( = O ) C O C C ( = O ) N c 1 c c ( - c 2 c c o c 2 ) c c c 1 C _EOS
Predicted text: C O C ( = O ) c 1 c c ( Cl ) c c c 1 N C ( = O ) C O C C ( = O ) N c 1 c c ( - c 2 c c o c 2 ) c c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C 1 C C C ( O c 2 c c c 3 c ( c 2 ) C C N ( C 2 C C C 2 ) C C 3 ) C C 1 ) N 1 C C O C C 1 _EOS
Predicted text: c 1 c c 2 c ( c c 1 O C 1 C C N C C 1 ) C C N ( C 1 C C C C 1 ) C C 2 _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.1, acc_seq: False

Target text: O = C ( C C O ) C 1 C C C N 1 C ( = O ) C 1 C C C N 1 C ( = O ) N C c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) ( C ) [Si] ( C ) ( C ) O C C C ( O ) C 1 C C C N 1 C ( = O ) C 1 C C C N 1 C ( = O ) N C c 1 c c c c c 1 _EOS
acc_token: 0.11627906976744186, acc_seq: False

Target text: C n 1 n c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c c 1 C O c 1 c c c 2 c c n ( C C ( = O ) O ) c 2 c 1 _EOS
Predicted text: C n 1 n c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c c 1 C O c 1 c c c 2 c c n ( C C ( = O ) O ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( C ) c c ( N ( C C N ) C c 2 c c c 3 n c ( N C C C N 4 C C O C C 4 ) n ( C c 4 n c ( C ) c c c 4 O ) c 3 c 2 ) c 1 _EOS
Predicted text: C c 1 c c ( C ) c c ( N ( C C N ) C c 2 c c c 3 n c ( N C C C N 4 C C O C C 4 ) n ( C c 4 n c ( C ) c c c 4 O ) c 3 c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 350000, eval acc (token): 0.9385708800736854, eval acc (sequence): 0.8842814105972001
Saving at step 350000
Step 350100, loss: 0.032586484821513294, acc: 99.68501280248165, p_norm: 2269.721013340796, g_norm: 0.5694517280921515, lr:  0.000422, elapsed time:  322570
Step 350200, loss: 0.0325476981094107, acc: 99.67091789841652, p_norm: 2269.815109699712, g_norm: 0.3986154701974335, lr:  0.000422, elapsed time:  322658
Step 350300, loss: 0.03272306602448225, acc: 99.69182802736759, p_norm: 2269.9029779519674, g_norm: 0.7314479155178739, lr:  0.000422, elapsed time:  322747
Step 350400, loss: 0.03235389599576592, acc: 99.69036349654198, p_norm: 2269.985333861794, g_norm: 0.7758697550109886, lr:  0.000422, elapsed time:  322837
Step 350500, loss: 0.03207225109916181, acc: 99.68520548939705, p_norm: 2270.0862142945316, g_norm: 0.6480393955468692, lr:  0.000422, elapsed time:  322930
Step 350600, loss: 0.03215139681939036, acc: 99.68986992537975, p_norm: 2270.1678495827687, g_norm: 0.617849096385102, lr:  0.000422, elapsed time:  323018
Step 350700, loss: 0.032086118184961376, acc: 99.68759170174599, p_norm: 2270.254323213254, g_norm: 0.5077612456999999, lr:  0.000422, elapsed time:  323111
Step 350800, loss: 0.032702352986671034, acc: 99.6818712502718, p_norm: 2270.346380704834, g_norm: 0.6977451846754659, lr:  0.000422, elapsed time:  323203
Step 350900, loss: 0.03254357340279967, acc: 99.680144906044, p_norm: 2270.4393516869586, g_norm: 0.5031289446131373, lr:  0.000422, elapsed time:  323297
Step 351000, loss: 0.03260985616128892, acc: 99.67599657177925, p_norm: 2270.529197760064, g_norm: 0.5435143069343669, lr:  0.000422, elapsed time:  323388
Step 351100, loss: 0.03290212713647634, acc: 99.66342729330063, p_norm: 2270.617693461657, g_norm: 0.5187556189164838, lr:  0.000422, elapsed time:  323477
Step 351200, loss: 0.032415508781559764, acc: 99.67904822528362, p_norm: 2270.707864782633, g_norm: 0.6796766272615535, lr:  0.000422, elapsed time:  323569
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 351300, loss: 0.03268742502641589, acc: 99.67430541592259, p_norm: 2270.8069131850616, g_norm: 0.49081864484119025, lr:  0.000422, elapsed time:  323659
Step 351400, loss: 0.03191057670861483, acc: 99.6916825324297, p_norm: 2270.900266988095, g_norm: 0.560421697422576, lr:  0.000422, elapsed time:  323753
Step 351500, loss: 0.032246047984808686, acc: 99.68286453187466, p_norm: 2270.998457036072, g_norm: 0.5274637277895449, lr:  0.000422, elapsed time:  323841
Step 351600, loss: 0.03243552628904581, acc: 99.67553310096264, p_norm: 2271.0811423277673, g_norm: 0.6932280384263375, lr:  0.000421, elapsed time:  323926
Step 351700, loss: 0.032296446715481576, acc: 99.68778851628304, p_norm: 2271.1634510429317, g_norm: 0.5940212066526718, lr:  0.000421, elapsed time:  324016
Step 351800, loss: 0.03174736766610295, acc: 99.70075553655624, p_norm: 2271.2530941120444, g_norm: 0.4559608908912308, lr:  0.000421, elapsed time:  324110
Step 351900, loss: 0.03176535069476813, acc: 99.70684732496738, p_norm: 2271.3387113165722, g_norm: 0.517830273181933, lr:  0.000421, elapsed time:  324198
Step 352000, loss: 0.032576070544309915, acc: 99.68264478445053, p_norm: 2271.4414624771916, g_norm: 1.1399992022417869, lr:  0.000421, elapsed time:  324288
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 352000, eval loss: 0.04611294977366925, eval acc: 99.51774597167969
Step 352100, loss: 0.03229615441057831, acc: 99.68730469048023, p_norm: 2271.521443941895, g_norm: 0.5130787437180158, lr:  0.000421, elapsed time:  324394
Step 352200, loss: 0.03201943972613663, acc: 99.68726749718189, p_norm: 2271.6086867724857, g_norm: 0.5544012661593019, lr:  0.000421, elapsed time:  324486
Step 352300, loss: 0.03227137913461774, acc: 99.68136435747147, p_norm: 2271.6961669950374, g_norm: 0.5864911848789354, lr:  0.000421, elapsed time:  324578
Step 352400, loss: 0.032368776551447806, acc: 99.67611116170883, p_norm: 2271.783442225628, g_norm: 0.6052543493160667, lr:  0.000421, elapsed time:  324668
Step 352500, loss: 0.03272354215849191, acc: 99.67289027571678, p_norm: 2271.8697773682993, g_norm: 0.47650737753081535, lr:  0.000421, elapsed time:  324754
Step 352600, loss: 0.03284623215906322, acc: 99.66441683471203, p_norm: 2271.9558420061185, g_norm: 0.6289953352361122, lr:  0.000421, elapsed time:  324843
Step 352700, loss: 0.032263523172587155, acc: 99.6856248229742, p_norm: 2272.039809126289, g_norm: 0.6900489675511675, lr:  0.000421, elapsed time:  324931
Step 352800, loss: 0.03190004687290639, acc: 99.69733928143978, p_norm: 2272.12697055468, g_norm: 0.5304757317734576, lr:  0.000421, elapsed time:  325021
Step 352900, loss: 0.03214350941590965, acc: 99.69494818150997, p_norm: 2272.2114946235165, g_norm: 0.6253059904714522, lr:  0.000421, elapsed time:  325111
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 353000, loss: 0.031626069895107654, acc: 99.69784529944558, p_norm: 2272.304101667402, g_norm: 0.5734232753092346, lr:  0.000421, elapsed time:  325204
Step 353100, loss: 0.03231158750131726, acc: 99.68677151203156, p_norm: 2272.3824998605555, g_norm: 1.1089325285116978, lr:  0.000421, elapsed time:  325292
Step 353200, loss: 0.03197490402963012, acc: 99.69470338523388, p_norm: 2272.4688370689537, g_norm: 0.6307377930442756, lr:  0.000421, elapsed time:  325383
Step 353300, loss: 0.03256487668957561, acc: 99.67139299213886, p_norm: 2272.5545297475655, g_norm: 0.5763194322855457, lr:  0.000420, elapsed time:  325475
Step 353400, loss: 0.03250886502675712, acc: 99.67946815490723, p_norm: 2272.6461611725126, g_norm: 0.4756411341709712, lr:  0.000420, elapsed time:  325564
Step 353500, loss: 0.03224046074319631, acc: 99.68501730263233, p_norm: 2272.731573920453, g_norm: 0.5420765088899344, lr:  0.000420, elapsed time:  325656
Step 353600, loss: 0.03177816420327872, acc: 99.69752931594849, p_norm: 2272.818891486606, g_norm: 0.5074848152129373, lr:  0.000420, elapsed time:  325745
Step 353700, loss: 0.0321953959017992, acc: 99.68806491792202, p_norm: 2272.897602966072, g_norm: 0.605719267384777, lr:  0.000420, elapsed time:  325836
Step 353800, loss: 0.03209599936380982, acc: 99.69108344614506, p_norm: 2272.9801680110268, g_norm: 0.6346376839419737, lr:  0.000420, elapsed time:  325927
Step 353900, loss: 0.03249105871655047, acc: 99.6685339808464, p_norm: 2273.075797137152, g_norm: 0.7672770552557235, lr:  0.000420, elapsed time:  326016
Step 354000, loss: 0.03140153122600168, acc: 99.70926941931248, p_norm: 2273.1611581687216, g_norm: 0.652070439699352, lr:  0.000420, elapsed time:  326110
Calling G2SDataset.batch()
Done, time:  0.06 s, total batches: 526
Evaluation (with teacher) at step 354000, eval loss: 0.045228286348283284, eval acc: 99.52330780029297
Step 354100, loss: 0.032424001521430906, acc: 99.6709002405405, p_norm: 2273.2482390072905, g_norm: 0.47264653353692054, lr:  0.000420, elapsed time:  326212
Step 354200, loss: 0.03162533017806709, acc: 99.70493549108505, p_norm: 2273.336057729364, g_norm: 0.7324404786164493, lr:  0.000420, elapsed time:  326300
Step 354300, loss: 0.032349151303060354, acc: 99.68532221019268, p_norm: 2273.422167407378, g_norm: 0.48767204118636076, lr:  0.000420, elapsed time:  326388
Step 354400, loss: 0.03266919636633247, acc: 99.6748469620943, p_norm: 2273.5122164644836, g_norm: 0.5430595168586158, lr:  0.000420, elapsed time:  326475
Step 354500, loss: 0.03255098302848637, acc: 99.67934888601303, p_norm: 2273.6077267886913, g_norm: 0.5647232485078538, lr:  0.000420, elapsed time:  326565
Step 354600, loss: 0.032456184807233515, acc: 99.67628069221973, p_norm: 2273.6885426551826, g_norm: 0.5990781413829865, lr:  0.000420, elapsed time:  326654
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 354700, loss: 0.032811210220379215, acc: 99.66858035281633, p_norm: 2273.774222284427, g_norm: 0.610551728337692, lr:  0.000420, elapsed time:  326744
Step 354800, loss: 0.03210156604647636, acc: 99.69424995779991, p_norm: 2273.857691840917, g_norm: 0.4877951918993801, lr:  0.000420, elapsed time:  326835
Step 354900, loss: 0.032274657539092005, acc: 99.68254160881042, p_norm: 2273.9500565187805, g_norm: 0.6272538898557652, lr:  0.000420, elapsed time:  326923
Step 355000, loss: 0.03215210506226868, acc: 99.68884362280369, p_norm: 2274.036469097712, g_norm: 0.9749114965042357, lr:  0.000419, elapsed time:  327010
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) c 1 c c c c ( - c 2 c c c c c 2 C N C ( = O ) O C ( C ) ( C ) C ) n 1 _EOS
Predicted text: C C O C ( = O ) c 1 c c c c ( - c 2 c c c c c 2 C N C ( = O ) O C ( C ) ( C ) C ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N c 1 n c c ( C 2 = C ( N C ( = O ) C C ( = O ) O ) N 3 C ( = O ) C ( c 4 c c c s 4 ) C 3 O C 2 ) s 1 _EOS
Predicted text: C C ( = O ) N c 1 n c c ( C 2 = C ( N C ( = O ) C C ( = O ) O ) N 3 C ( = O ) C ( c 4 c c c s 4 ) C 3 O C 2 ) s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C C C ( C ) = C C c 1 c ( O S ( = O ) ( = O ) C ( F ) ( F ) F ) c ( C ) c 2 c ( c 1 O S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 ) C ( = O ) O C 2 _EOS
Predicted text: C O C ( = O ) C C C ( C ) = C C c 1 c ( O S ( = O ) ( = O ) C ( F ) ( F ) F ) c ( C ) c 2 c ( c 1 O S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 ) C ( = O ) O C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c c ( O C ) c 1 - c 1 c c c ( C O ) c ( O C c 2 c c c c c 2 ) c 1 _EOS
Predicted text: C O c 1 c c c c ( O C ) c 1 - c 1 c c c ( C O ) c ( O C c 2 c c c c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 = C c 2 c c ( C ) c ( O ) c c 2 O C 1 C ( F ) ( F ) F _EOS
Predicted text: C C O C ( = O ) C 1 = C c 2 c c ( C ) c ( O ) c c 2 O C 1 C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 355000, eval acc (token): 0.9394247069240885, eval acc (sequence): 0.8882408278457197
Saving at step 355000
Step 355100, loss: 0.03178173129446805, acc: 99.70413680374622, p_norm: 2274.121410601483, g_norm: 0.5655223389303156, lr:  0.000419, elapsed time:  327184
Step 355200, loss: 0.03156256825663149, acc: 99.70432198047638, p_norm: 2274.2132933834628, g_norm: 0.7267816204520576, lr:  0.000419, elapsed time:  327279
Step 355300, loss: 0.032336473977193234, acc: 99.67985017597675, p_norm: 2274.299366304213, g_norm: 0.4817569741803181, lr:  0.000419, elapsed time:  327367
Step 355400, loss: 0.03230435591656715, acc: 99.67891457676888, p_norm: 2274.3812861356037, g_norm: 0.569558771368883, lr:  0.000419, elapsed time:  327451
Step 355500, loss: 0.03185647818259895, acc: 99.68999586999416, p_norm: 2274.4663203386926, g_norm: 0.7979012233204859, lr:  0.000419, elapsed time:  327541
Step 355600, loss: 0.03231470935046673, acc: 99.6831768155098, p_norm: 2274.550772685169, g_norm: 0.7171940575495328, lr:  0.000419, elapsed time:  327631
Step 355700, loss: 0.03199118432588875, acc: 99.69973869621754, p_norm: 2274.641425018117, g_norm: 0.5161447919958199, lr:  0.000419, elapsed time:  327723
Step 355800, loss: 0.03219552374444902, acc: 99.69037947058678, p_norm: 2274.7453011668636, g_norm: 0.4311106070923223, lr:  0.000419, elapsed time:  327814
Step 355900, loss: 0.03299188055563718, acc: 99.66578359901905, p_norm: 2274.826231735694, g_norm: 0.6256955330704056, lr:  0.000419, elapsed time:  327906
Step 356000, loss: 0.031934386896900833, acc: 99.69645689427853, p_norm: 2274.913213823819, g_norm: 0.6869348963880911, lr:  0.000419, elapsed time:  327998
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 356000, eval loss: 0.04430621081963182, eval acc: 99.52960968017578
Step 356100, loss: 0.032159135504625735, acc: 99.69335460662842, p_norm: 2274.995590300693, g_norm: 0.5457203204634391, lr:  0.000419, elapsed time:  328102
Step 356200, loss: 0.032339028804562985, acc: 99.68212133646011, p_norm: 2275.093236716014, g_norm: 0.6878102679711824, lr:  0.000419, elapsed time:  328191
Step 356300, loss: 0.03257822988089174, acc: 99.67767202854156, p_norm: 2275.180793335772, g_norm: 0.6104680159451473, lr:  0.000419, elapsed time:  328280
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 356400, loss: 0.03248361694550248, acc: 99.68265805291774, p_norm: 2275.2755087700293, g_norm: 0.8934373202241604, lr:  0.000419, elapsed time:  328369
Step 356500, loss: 0.03209972001146525, acc: 99.6929130256176, p_norm: 2275.3700441056035, g_norm: 0.5768489337929597, lr:  0.000419, elapsed time:  328461
Step 356600, loss: 0.032150829904712734, acc: 99.68990743160248, p_norm: 2275.460964210205, g_norm: 0.4873302965281485, lr:  0.000419, elapsed time:  328552
Step 356700, loss: 0.031966994199901816, acc: 99.69469214975834, p_norm: 2275.536661409582, g_norm: 0.4826868898724478, lr:  0.000418, elapsed time:  328642
Step 356800, loss: 0.03207165801431984, acc: 99.68716578185558, p_norm: 2275.604917379078, g_norm: 0.5624634911018811, lr:  0.000418, elapsed time:  328732
Step 356900, loss: 0.032153382459655405, acc: 99.68314026296139, p_norm: 2275.7013804326057, g_norm: 0.5355299338748538, lr:  0.000418, elapsed time:  328820
Step 357000, loss: 0.03215124448295683, acc: 99.69760060310364, p_norm: 2275.7813902508833, g_norm: 0.5269730532681558, lr:  0.000418, elapsed time:  328913
Step 357100, loss: 0.032997382478788494, acc: 99.6558602899313, p_norm: 2275.873446874278, g_norm: 0.6744560208612432, lr:  0.000418, elapsed time:  329001
Step 357200, loss: 0.03168513341806829, acc: 99.69639655947685, p_norm: 2275.9811374555798, g_norm: 0.6177160736516653, lr:  0.000418, elapsed time:  329091
Step 357300, loss: 0.031973866517655554, acc: 99.69814658164978, p_norm: 2276.0556324971944, g_norm: 0.6691477610747553, lr:  0.000418, elapsed time:  329180
Step 357400, loss: 0.03197397857904434, acc: 99.69229358434677, p_norm: 2276.1366350695807, g_norm: 0.6215803071481542, lr:  0.000418, elapsed time:  329268
Step 357500, loss: 0.03219736831728369, acc: 99.68563811480999, p_norm: 2276.217214676064, g_norm: 0.5114415484437971, lr:  0.000418, elapsed time:  329359
Step 357600, loss: 0.03192122376989573, acc: 99.688741594553, p_norm: 2276.295632576754, g_norm: 0.5791863663703872, lr:  0.000418, elapsed time:  329451
Step 357700, loss: 0.03243457382079214, acc: 99.6798006594181, p_norm: 2276.382395995005, g_norm: 0.5331511238731672, lr:  0.000418, elapsed time:  329542
Step 357800, loss: 0.03266941833309829, acc: 99.67311242222786, p_norm: 2276.4682194801876, g_norm: 0.5505906963421663, lr:  0.000418, elapsed time:  329629
Step 357900, loss: 0.032050714739598335, acc: 99.69310316443443, p_norm: 2276.5479912643104, g_norm: 0.4923092744470112, lr:  0.000418, elapsed time:  329720
Step 358000, loss: 0.03235188040416688, acc: 99.67837388813496, p_norm: 2276.6484803525495, g_norm: 0.6452033412554765, lr:  0.000418, elapsed time:  329806
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 358000, eval loss: 0.046489110253751284, eval acc: 99.529052734375
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 358100, loss: 0.032373527956955486, acc: 99.68442079742849, p_norm: 2276.7302393295317, g_norm: 0.5293719684793349, lr:  0.000418, elapsed time:  329913
Step 358200, loss: 0.031997515577822926, acc: 99.69520765542984, p_norm: 2276.815553802712, g_norm: 0.6486609852358111, lr:  0.000418, elapsed time:  330005
Step 358300, loss: 0.03226576129440218, acc: 99.68934860825539, p_norm: 2276.8973652320647, g_norm: 0.6642686658709573, lr:  0.000418, elapsed time:  330092
Step 358400, loss: 0.03184734670445323, acc: 99.69919177889824, p_norm: 2276.9846768591733, g_norm: 0.6648207648960945, lr:  0.000417, elapsed time:  330184
Step 358500, loss: 0.033267062827944754, acc: 99.65668527781963, p_norm: 2277.073079846476, g_norm: 0.562893963029299, lr:  0.000417, elapsed time:  330271
Step 358600, loss: 0.03185932526364923, acc: 99.6982693374157, p_norm: 2277.1529658675913, g_norm: 0.758846680005352, lr:  0.000417, elapsed time:  330361
Step 358700, loss: 0.03250864701345563, acc: 99.67855162918568, p_norm: 2277.2362145169373, g_norm: 0.6418011174903544, lr:  0.000417, elapsed time:  330449
Step 358800, loss: 0.031370115410536525, acc: 99.70858898758888, p_norm: 2277.3217892620214, g_norm: 0.6270888057975343, lr:  0.000417, elapsed time:  330540
Step 358900, loss: 0.03194420308806002, acc: 99.68335057795048, p_norm: 2277.4177453446787, g_norm: 0.5430862938466532, lr:  0.000417, elapsed time:  330629
Step 359000, loss: 0.031725494144484404, acc: 99.70579619705677, p_norm: 2277.4974639495545, g_norm: 0.6356478917034551, lr:  0.000417, elapsed time:  330722
Step 359100, loss: 0.0323699562670663, acc: 99.6845772266388, p_norm: 2277.580061507515, g_norm: 0.4781940135577504, lr:  0.000417, elapsed time:  330814
Step 359200, loss: 0.03190913372207433, acc: 99.69159579277039, p_norm: 2277.666167848499, g_norm: 0.5897206973609285, lr:  0.000417, elapsed time:  330902
Step 359300, loss: 0.03192679084837437, acc: 99.68913905322552, p_norm: 2277.7581770537545, g_norm: 0.5171172737648919, lr:  0.000417, elapsed time:  330992
Step 359400, loss: 0.03250376518350095, acc: 99.67551697790623, p_norm: 2277.8464828028505, g_norm: 0.48349527378355583, lr:  0.000417, elapsed time:  331079
Step 359500, loss: 0.03276618059258908, acc: 99.66765722632408, p_norm: 2277.9350069697043, g_norm: 0.6613393751978709, lr:  0.000417, elapsed time:  331167
Step 359600, loss: 0.031729936730116606, acc: 99.69825880229473, p_norm: 2278.013786404108, g_norm: 0.5343398240733016, lr:  0.000417, elapsed time:  331259
Step 359700, loss: 0.03222520458977669, acc: 99.68647518754005, p_norm: 2278.096969451981, g_norm: 0.6261931532086161, lr:  0.000417, elapsed time:  331350
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 359800, loss: 0.031588181529757994, acc: 99.70268389723141, p_norm: 2278.18497521015, g_norm: 0.9841044578559037, lr:  0.000417, elapsed time:  331442
Step 359900, loss: 0.031472762413322926, acc: 99.70427475869656, p_norm: 2278.262825785716, g_norm: 0.9494579123940029, lr:  0.000417, elapsed time:  331528
Step 360000, loss: 0.03196420337539166, acc: 99.69089102745056, p_norm: 2278.356423580486, g_norm: 0.6170965552236034, lr:  0.000417, elapsed time:  331621
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 360000, eval loss: 0.04526337450370192, eval acc: 99.52272033691406
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: O = C 1 C C c 2 c c ( N C ( = O ) c 3 n c 4 c c c ( Cl ) c c 4 n 3 C c 3 c c c c c 3 ) c c c 2 N 1 _EOS
Predicted text: N c 1 c c c 2 c ( c 1 ) C C C N 2 C c 1 n c 2 c c c ( Cl ) c c 2 n 1 C c 1 c c c c c 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.18, acc_seq: False

Target text: C c 1 n o c ( C ) c 1 - c 1 n c ( C n 2 c c c 3 c ( C ( F ) ( F ) F ) c ( C # N ) c c c 3 2 ) n o 1 _EOS
Predicted text: C c 1 n o c ( C ) c 1 - c 1 n c ( C n 2 c c c 3 c ( C ( F ) ( F ) F ) c ( C # N ) c c c 3 2 ) n o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 s c ( C = C 3 C N ( C ( = O ) O C ( C ) ( C ) C ) C 3 ) c c 2 n 1 _EOS
Predicted text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 s c ( C = C 3 C N ( C ( = O ) O C ( C ) ( C ) C ) C 3 ) c c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n n c ( - c 2 c c ( Cl ) c c c 2 N S ( = O ) ( = O ) c 2 c c c ( N 3 C C O C C 3 ) c ( F ) c 2 ) n 1 C _EOS
Predicted text: C c 1 n n c ( - c 2 c c ( Cl ) c c c 2 N S ( = O ) ( = O ) c 2 c c c ( N 3 C C O C C 3 ) c ( F ) c 2 ) n 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C c 1 c c c ( - c 2 c n c 3 c c ( - c 4 c c c c n 4 ) c c n 2 3 ) c c 1 F ) N c 1 c c ( C ( = O ) N 2 C C N C C 2 ) c c ( C ( F ) ( F ) F ) c 1 _EOS
Predicted text: O = C ( C c 1 c c c ( - c 2 c n c 3 c c ( - c 4 c c c c n 4 ) c c n 2 3 ) c c 1 F ) N c 1 c c ( C ( = O ) N 2 C C N C C 2 ) c c ( C ( F ) ( F ) F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 360000, eval acc (token): 0.9367879280794955, eval acc (sequence): 0.884866163349348
Saving at step 360000
Step 360100, loss: 0.032099247574806214, acc: 99.70060569047928, p_norm: 2278.4439141230882, g_norm: 0.6267805616076957, lr:  0.000416, elapsed time:  331814
Step 360200, loss: 0.03237503875046968, acc: 99.68783162534237, p_norm: 2278.5344520032154, g_norm: 0.45142345682555896, lr:  0.000416, elapsed time:  331906
Step 360300, loss: 0.03178027921356261, acc: 99.6976625174284, p_norm: 2278.619727418722, g_norm: 0.602387233707576, lr:  0.000416, elapsed time:  331993
Step 360400, loss: 0.031664728871546685, acc: 99.69765400886536, p_norm: 2278.703536383918, g_norm: 0.49673256396596094, lr:  0.000416, elapsed time:  332083
Step 360500, loss: 0.03227359051350504, acc: 99.68868164718151, p_norm: 2278.7990101783225, g_norm: 0.5915080243664632, lr:  0.000416, elapsed time:  332174
Step 360600, loss: 0.03227057980373502, acc: 99.68551416695118, p_norm: 2278.8765649724546, g_norm: 0.38407615331414136, lr:  0.000416, elapsed time:  332262
Step 360700, loss: 0.03248708250466734, acc: 99.67372255027294, p_norm: 2278.9684354543215, g_norm: 0.6987271243972406, lr:  0.000416, elapsed time:  332352
Step 360800, loss: 0.03201460941229015, acc: 99.69294238090515, p_norm: 2279.0694997357486, g_norm: 0.846091684656403, lr:  0.000416, elapsed time:  332443
Step 360900, loss: 0.031971173267811535, acc: 99.69082532823086, p_norm: 2279.14596553411, g_norm: 0.5165266495317998, lr:  0.000416, elapsed time:  332533
Step 361000, loss: 0.03229363387916237, acc: 99.68141800165176, p_norm: 2279.2307039325083, g_norm: 0.5148429604724629, lr:  0.000416, elapsed time:  332622
Step 361100, loss: 0.032719608512707055, acc: 99.66282659769058, p_norm: 2279.3077148328352, g_norm: 0.6784818555249559, lr:  0.000416, elapsed time:  332709
Step 361200, loss: 0.03192094421479851, acc: 99.69417095184326, p_norm: 2279.3904909588905, g_norm: 0.42938836645944806, lr:  0.000416, elapsed time:  332797
Step 361300, loss: 0.03281952159013599, acc: 99.6702691167593, p_norm: 2279.484174217608, g_norm: 0.6640116571952813, lr:  0.000416, elapsed time:  332884
Step 361400, loss: 0.03174310671631247, acc: 99.69938363134861, p_norm: 2279.5723716711605, g_norm: 0.5732268373309021, lr:  0.000416, elapsed time:  332975
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 361500, loss: 0.031916526171653796, acc: 99.6930311246782, p_norm: 2279.6727553609426, g_norm: 0.6151109286281596, lr:  0.000416, elapsed time:  333068
Step 361600, loss: 0.03201214271597564, acc: 99.69812375307083, p_norm: 2279.7523202117764, g_norm: 0.7018154549377948, lr:  0.000416, elapsed time:  333155
Step 361700, loss: 0.031529640667140486, acc: 99.70498467981815, p_norm: 2279.8348037597025, g_norm: 0.9581766678627729, lr:  0.000416, elapsed time:  333244
Step 361800, loss: 0.03206435259897262, acc: 99.68875050544739, p_norm: 2279.917586741947, g_norm: 0.5490754136280749, lr:  0.000416, elapsed time:  333333
Step 361900, loss: 0.03133324125315994, acc: 99.70921878516674, p_norm: 2280.0024941680394, g_norm: 0.608770622761097, lr:  0.000415, elapsed time:  333422
Step 362000, loss: 0.03191316814161837, acc: 99.69964781403542, p_norm: 2280.0909851961974, g_norm: 0.6396150490768101, lr:  0.000415, elapsed time:  333515
Calling G2SDataset.batch()
Done, time:  0.05 s, total batches: 527
Evaluation (with teacher) at step 362000, eval loss: 0.044643056206405164, eval acc: 99.52764129638672
Step 362100, loss: 0.031644704574719074, acc: 99.70436109602451, p_norm: 2280.1714703226585, g_norm: 0.6063573438820477, lr:  0.000415, elapsed time:  333619
Step 362200, loss: 0.032365525206550956, acc: 99.68266813457012, p_norm: 2280.2647520429136, g_norm: 0.45570021646517006, lr:  0.000415, elapsed time:  333708
Step 362300, loss: 0.03212832428514958, acc: 99.69415992498398, p_norm: 2280.3615939111746, g_norm: 0.5852864196745564, lr:  0.000415, elapsed time:  333797
Step 362400, loss: 0.03313517494592816, acc: 99.6631156951189, p_norm: 2280.4506852558334, g_norm: 0.4625254695363913, lr:  0.000415, elapsed time:  333885
Step 362500, loss: 0.03217231262475252, acc: 99.68347695469856, p_norm: 2280.5417492540428, g_norm: 0.6794546759640936, lr:  0.000415, elapsed time:  333978
Step 362600, loss: 0.032378749656490985, acc: 99.68473790585995, p_norm: 2280.625356250068, g_norm: 0.5072921410090259, lr:  0.000415, elapsed time:  334069
Step 362700, loss: 0.03167860397137701, acc: 99.70629538595676, p_norm: 2280.705617302686, g_norm: 0.6442934118429723, lr:  0.000415, elapsed time:  334156
Step 362800, loss: 0.03196737983264029, acc: 99.69406789541245, p_norm: 2280.796109294656, g_norm: 0.49684631969992515, lr:  0.000415, elapsed time:  334247
Step 362900, loss: 0.0321627997700125, acc: 99.6887736916542, p_norm: 2280.872391621393, g_norm: 0.4653623702709027, lr:  0.000415, elapsed time:  334333
Step 363000, loss: 0.031868207091465595, acc: 99.69170591235161, p_norm: 2280.952173890317, g_norm: 0.6439528735064568, lr:  0.000415, elapsed time:  334419
Step 363100, loss: 0.032176339514553544, acc: 99.68526335060596, p_norm: 2281.031824755729, g_norm: 0.5514199251969597, lr:  0.000415, elapsed time:  334510
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 363200, loss: 0.031970676952111185, acc: 99.68834411149001, p_norm: 2281.1073641942544, g_norm: 0.5971247684911983, lr:  0.000415, elapsed time:  334603
Step 363300, loss: 0.03196094272192568, acc: 99.69700464606285, p_norm: 2281.194536439159, g_norm: 0.5849633405366306, lr:  0.000415, elapsed time:  334693
Step 363400, loss: 0.031064383988268673, acc: 99.7241528481245, p_norm: 2281.2821554929087, g_norm: 0.648434750951757, lr:  0.000415, elapsed time:  334783
Step 363500, loss: 0.031509899171069264, acc: 99.70950151979923, p_norm: 2281.363225418504, g_norm: 0.5664917140152488, lr:  0.000415, elapsed time:  334874
Step 363600, loss: 0.03234523166902363, acc: 99.68503685295582, p_norm: 2281.4494603358007, g_norm: 0.570061731324004, lr:  0.000414, elapsed time:  334961
Step 363700, loss: 0.03141947430092842, acc: 99.70934830605984, p_norm: 2281.5461618949807, g_norm: 0.5029206608787394, lr:  0.000414, elapsed time:  335053
Step 363800, loss: 0.0323258957779035, acc: 99.67718786001205, p_norm: 2281.6327238218023, g_norm: 0.732236009907636, lr:  0.000414, elapsed time:  335141
Step 363900, loss: 0.03179686821531504, acc: 99.70261399447918, p_norm: 2281.7079566150064, g_norm: 0.6212352595636834, lr:  0.000414, elapsed time:  335230
Step 364000, loss: 0.031775452666915956, acc: 99.69784343242645, p_norm: 2281.7909759618474, g_norm: 0.6363671091552643, lr:  0.000414, elapsed time:  335319
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 364000, eval loss: 0.04476550161838532, eval acc: 99.54766082763672
Step 364100, loss: 0.03220376910176128, acc: 99.69055028259754, p_norm: 2281.8870981978566, g_norm: 0.5693577025914964, lr:  0.000414, elapsed time:  335422
Step 364200, loss: 0.032711417553946374, acc: 99.67131085693836, p_norm: 2281.9728876450363, g_norm: 1.1110220375765205, lr:  0.000414, elapsed time:  335507
Step 364300, loss: 0.03196304867509753, acc: 99.69675332307816, p_norm: 2282.0475292580127, g_norm: 0.4585997286401809, lr:  0.000414, elapsed time:  335597
Step 364400, loss: 0.0324908237112686, acc: 99.6814644485712, p_norm: 2282.1335136620987, g_norm: 0.5823278837812428, lr:  0.000414, elapsed time:  335684
Step 364500, loss: 0.03208478558342904, acc: 99.68339817225933, p_norm: 2282.21132030736, g_norm: 0.6278558316189513, lr:  0.000414, elapsed time:  335774
Step 364600, loss: 0.03193331972230226, acc: 99.69086331129074, p_norm: 2282.3045282722833, g_norm: 0.42792454878202424, lr:  0.000414, elapsed time:  335866
Step 364700, loss: 0.0327432519197464, acc: 99.67075403034687, p_norm: 2282.402897597145, g_norm: 0.47810721145443635, lr:  0.000414, elapsed time:  335956
Step 364800, loss: 0.032270111571997405, acc: 99.68136142194271, p_norm: 2282.506939135547, g_norm: 0.4947716196472959, lr:  0.000414, elapsed time:  336048
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 364900, loss: 0.032728003819857666, acc: 99.67568510800452, p_norm: 2282.589958452144, g_norm: 0.39346257149483965, lr:  0.000414, elapsed time:  336138
Step 365000, loss: 0.03214339911006391, acc: 99.69125391542912, p_norm: 2282.6851773641456, g_norm: 0.6110580467907296, lr:  0.000414, elapsed time:  336227
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O C C O C C N c 1 c c c c c 1 O C C O _EOS
Predicted text: O C C O C C N c 1 c c c c c 1 O C C O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C C ( C ) ( C ( = O ) O ) C C 1 _EOS
Predicted text: C C 1 ( C ( = O ) O ) C C N ( C ( = O ) O C ( C ) ( C ) C ) C C 1 _EOS
acc_token: 0.3235294117647059, acc_seq: False

Target text: C C C C C C C C C C C C ( = O ) O C C 1 O C ( S C ( C ) = O ) C ( O C ( = O ) C C C C C C C C C C C ) C ( O C ( = O ) C C C C C C C C C C C ) C 1 O C ( = O ) C C C C C C C C C C C _EOS
Predicted text: C C C C C C C C C C C C ( = O ) O C C 1 O C ( S C ( C ) = O ) C ( O C ( = O ) C C C C C C C C C C C ) C ( O C ( = O ) C C C C C C C C C C C ) C 1 O C ( = O ) C C C C C C C C C C C _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c c c c ( C C ( = O ) N 2 C C c 3 c c ( - c 4 c s c 5 c c n c ( N ) c 4 5 ) c c c 3 2 ) c 1 _EOS
Predicted text: N # C c 1 c c c c ( C C ( = O ) N 2 C C c 3 c c ( - c 4 c s c 5 c c n c ( N ) c 4 5 ) c c c 3 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( N ( N ) C C C 2 C C C C C 2 ) c c 1 _EOS
Predicted text: C c 1 c c c ( N ( N ) C C C 2 C C C C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 365000, eval acc (token): 0.938832052622933, eval acc (sequence): 0.8881691101261507
Saving at step 365000
Step 365100, loss: 0.03248109663370997, acc: 99.67666654288769, p_norm: 2282.7597657943375, g_norm: 0.4832269173631718, lr:  0.000414, elapsed time:  336394
Step 365200, loss: 0.0319785029720515, acc: 99.69152821600437, p_norm: 2282.8460924557744, g_norm: 0.5755197617710208, lr:  0.000414, elapsed time:  336481
Step 365300, loss: 0.03169880707748234, acc: 99.70704232156277, p_norm: 2282.9335394270515, g_norm: 0.895669780678382, lr:  0.000414, elapsed time:  336571
Step 365400, loss: 0.03137637102045119, acc: 99.71368406713009, p_norm: 2283.0178487593926, g_norm: 0.5410600477323484, lr:  0.000413, elapsed time:  336666
Step 365500, loss: 0.03194296012632549, acc: 99.69154368340969, p_norm: 2283.1076175407857, g_norm: 0.6534439367567869, lr:  0.000413, elapsed time:  336756
Step 365600, loss: 0.03209141426254064, acc: 99.68954163789749, p_norm: 2283.1948125160025, g_norm: 0.4349375182553584, lr:  0.000413, elapsed time:  336843
Step 365700, loss: 0.0324476503347978, acc: 99.67871567606926, p_norm: 2283.2707801663614, g_norm: 0.6314909040847327, lr:  0.000413, elapsed time:  336929
Step 365800, loss: 0.03205996840726584, acc: 99.69285421073437, p_norm: 2283.3498559776353, g_norm: 0.6166299279759365, lr:  0.000413, elapsed time:  337020
Step 365900, loss: 0.03215298300608992, acc: 99.68395760655403, p_norm: 2283.441043886102, g_norm: 0.6461058091189391, lr:  0.000413, elapsed time:  337110
Step 366000, loss: 0.031585510424338284, acc: 99.70649924874306, p_norm: 2283.541684218528, g_norm: 0.5165377812526715, lr:  0.000413, elapsed time:  337201
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 366000, eval loss: 0.04220284178853035, eval acc: 99.57768249511719
Step 366100, loss: 0.03197364811785519, acc: 99.69385351240635, p_norm: 2283.6266830123423, g_norm: 0.45322413137302137, lr:  0.000413, elapsed time:  337304
Step 366200, loss: 0.032015643906779585, acc: 99.68963578343391, p_norm: 2283.7100291473316, g_norm: 0.516536926105871, lr:  0.000413, elapsed time:  337393
Step 366300, loss: 0.03247891314793378, acc: 99.67548024654388, p_norm: 2283.7964389160593, g_norm: 0.6773977375052429, lr:  0.000413, elapsed time:  337481
Step 366400, loss: 0.032135838842950765, acc: 99.68914552032948, p_norm: 2283.882457194101, g_norm: 0.5476721819230636, lr:  0.000413, elapsed time:  337570
Step 366500, loss: 0.031851299153640864, acc: 99.69952051341534, p_norm: 2283.9616714254425, g_norm: 0.7720034495393104, lr:  0.000413, elapsed time:  337659
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 366600, loss: 0.031758823036851715, acc: 99.69397858709614, p_norm: 2284.053082215133, g_norm: 0.47024131015962806, lr:  0.000413, elapsed time:  337751
Step 366700, loss: 0.03179742900654674, acc: 99.69709435105324, p_norm: 2284.1185469729976, g_norm: 0.6851775245713578, lr:  0.000413, elapsed time:  337840
Step 366800, loss: 0.032274441444315016, acc: 99.69110974669456, p_norm: 2284.203701303883, g_norm: 0.5492475554316381, lr:  0.000413, elapsed time:  337925
Step 366900, loss: 0.03403519804123789, acc: 99.68733176589012, p_norm: 2284.3050911843984, g_norm: 0.7137277539426521, lr:  0.000413, elapsed time:  338019
Step 367000, loss: 0.03280157880857587, acc: 99.69315584003925, p_norm: 2284.371539168342, g_norm: 0.45565629671089464, lr:  0.000413, elapsed time:  338109
Step 367100, loss: 0.03297551543917507, acc: 99.6803837120533, p_norm: 2284.453981560115, g_norm: 0.519747656215791, lr:  0.000412, elapsed time:  338194
Step 367200, loss: 0.03194796472322196, acc: 99.69686849415302, p_norm: 2284.5388779757095, g_norm: 1.1646033797645947, lr:  0.000412, elapsed time:  338284
Step 367300, loss: 0.03188681724481285, acc: 99.69510543346405, p_norm: 2284.6186406527722, g_norm: 0.6486228880787568, lr:  0.000412, elapsed time:  338371
Step 367400, loss: 0.03184302534442395, acc: 99.70008765161037, p_norm: 2284.698923022511, g_norm: 0.5455434437298158, lr:  0.000412, elapsed time:  338459
Step 367500, loss: 0.031642441912554206, acc: 99.69254809617996, p_norm: 2284.7750562682845, g_norm: 0.5755558299568264, lr:  0.000412, elapsed time:  338549
Step 367600, loss: 0.03175226574297994, acc: 99.69310884177685, p_norm: 2284.867229050002, g_norm: 0.5274942968183804, lr:  0.000412, elapsed time:  338639
Step 367700, loss: 0.032143657309934494, acc: 99.68646778166294, p_norm: 2284.9486150234575, g_norm: 0.657042759928629, lr:  0.000412, elapsed time:  338735
Step 367800, loss: 0.03177891187835485, acc: 99.6953653395176, p_norm: 2285.0306096904505, g_norm: 0.6806451248632673, lr:  0.000412, elapsed time:  338830
Step 367900, loss: 0.03208561039995402, acc: 99.69416382908821, p_norm: 2285.113134114556, g_norm: 0.6338398058248336, lr:  0.000412, elapsed time:  338923
Step 368000, loss: 0.032893572887405756, acc: 99.66112643480301, p_norm: 2285.2072497744048, g_norm: 0.6044109412875842, lr:  0.000412, elapsed time:  338997
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Evaluation (with teacher) at step 368000, eval loss: 0.04591299472376704, eval acc: 99.51396179199219
Step 368100, loss: 0.032031838078983126, acc: 99.69017440080643, p_norm: 2285.294147297938, g_norm: 0.4716190369262256, lr:  0.000412, elapsed time:  339082
Step 368200, loss: 0.03162253810092807, acc: 99.70696614682674, p_norm: 2285.371580284346, g_norm: 0.6269139012879144, lr:  0.000412, elapsed time:  339158
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 368300, loss: 0.03154886737188541, acc: 99.70397663767226, p_norm: 2285.4500125704385, g_norm: 0.5491036842411687, lr:  0.000412, elapsed time:  339255
Step 368400, loss: 0.03151750419754535, acc: 99.70011660456657, p_norm: 2285.5232184004276, g_norm: 0.6228138229427129, lr:  0.000412, elapsed time:  339352
Step 368500, loss: 0.03129500183742493, acc: 99.70565964281559, p_norm: 2285.6106621700255, g_norm: 0.5569204350146553, lr:  0.000412, elapsed time:  339445
Step 368600, loss: 0.03204761565197259, acc: 99.68858209252357, p_norm: 2285.698435583856, g_norm: 0.6596930538054875, lr:  0.000412, elapsed time:  339537
Step 368700, loss: 0.032498412262648345, acc: 99.67831958830357, p_norm: 2285.772725007904, g_norm: 0.4761895969739712, lr:  0.000412, elapsed time:  339631
Step 368800, loss: 0.03148327443748713, acc: 99.70469063520432, p_norm: 2285.845665210317, g_norm: 0.4515841751210486, lr:  0.000412, elapsed time:  339722
Step 368900, loss: 0.032650214019231495, acc: 99.67503862082958, p_norm: 2285.9271510098856, g_norm: 0.44952872024178825, lr:  0.000411, elapsed time:  339813
Step 369000, loss: 0.032099705468863246, acc: 99.68928010761738, p_norm: 2286.009163982649, g_norm: 0.6444999279458707, lr:  0.000411, elapsed time:  339903
Step 369100, loss: 0.03189076608978212, acc: 99.69228683412075, p_norm: 2286.0820983610624, g_norm: 0.6764215453873342, lr:  0.000411, elapsed time:  339993
Step 369200, loss: 0.031474865567870436, acc: 99.70450142025948, p_norm: 2286.1725258292186, g_norm: 0.4095623901080511, lr:  0.000411, elapsed time:  340088
Step 369300, loss: 0.03222739330958575, acc: 99.68958522379398, p_norm: 2286.2709676962136, g_norm: 0.43373831562152576, lr:  0.000411, elapsed time:  340180
Step 369400, loss: 0.031905757933855056, acc: 99.68580181896687, p_norm: 2286.3486072272876, g_norm: 0.6063129742414368, lr:  0.000411, elapsed time:  340288
Step 369500, loss: 0.03159231274854392, acc: 99.70275929570198, p_norm: 2286.425734701004, g_norm: 0.8083399788798162, lr:  0.000411, elapsed time:  340378
Step 369600, loss: 0.03192511206492782, acc: 99.68909068405628, p_norm: 2286.511660226548, g_norm: 0.6120218854632089, lr:  0.000411, elapsed time:  340471
Step 369700, loss: 0.03159610486123711, acc: 99.70023100078106, p_norm: 2286.5938001505924, g_norm: 0.9492993809584015, lr:  0.000411, elapsed time:  340564
Step 369800, loss: 0.03174202054738998, acc: 99.70120412111282, p_norm: 2286.6877367442034, g_norm: 0.6334605037468489, lr:  0.000411, elapsed time:  340639
Step 369900, loss: 0.03286559381522238, acc: 99.69543746113777, p_norm: 2286.767632130618, g_norm: 0.6765111161713744, lr:  0.000411, elapsed time:  340713
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 370000, loss: 0.03274486434011169, acc: 99.68824772099357, p_norm: 2286.852535879756, g_norm: 0.5173179931095735, lr:  0.000411, elapsed time:  340785
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 370000, eval loss: 0.048001562301069486, eval acc: 99.46862030029297
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Target text: C c 1 c c c c 2 n c ( S C c 3 c c c ( C ( = O ) c 4 c c c ( O C ( = O ) N ( C ) C ) c c 4 ) c c 3 ) n ( C ) c ( = O ) c 1 2 _EOS
Predicted text: C c 1 c c c c 2 n c ( S C c 3 c c c ( C ( = O ) c 4 c c c ( O C ( = O ) N ( C ) C ) c c 4 ) c c 3 ) n ( C ) c ( = O ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) C = C C C ( C ) C C C = C ( C ) C _EOS
Predicted text: C C ( C ) = C C C C ( C ) C C ( = O ) O _EOS _PAD _PAD _PAD
acc_token: 0.2916666666666667, acc_seq: False

Target text: C C ( = O ) N c 1 c c c c 2 c ( S ( = O ) ( = O ) Cl ) c c c c 1 2 _EOS
Predicted text: C C ( = O ) N c 1 c c c c 2 c ( S ( = O ) ( = O ) Cl ) c c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c 2 n c n c ( N c 3 c c c c ( Cl ) c 3 F ) c 2 c c 1 O C 1 C C C N ( C ( = O ) C Cl ) C 1 _EOS
Predicted text: C O c 1 c c 2 n c n c ( N c 3 c c c c ( Cl ) c 3 F ) c 2 c c 1 O C 1 C C C N ( C ( = O ) C Cl ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) C 1 = C C C 2 C 3 = C C = C 4 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C 4 ( C ) C 3 C C C 1 2 C _EOS
Predicted text: C C 1 = C C C 2 C 3 = C C = C 4 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C 4 ( C ) C 3 C C C 1 2 C _EOS _PAD _PAD _PAD _PAD _PAD
acc_token: 0.30666666666666664, acc_seq: False

Evaluation (without teacher) at step 370000, eval acc (token): 0.9405680396048955, eval acc (sequence): 0.889554794520548
Saving at step 370000
Step 370100, loss: 0.03244942687917501, acc: 99.69539856910706, p_norm: 2286.9443845244336, g_norm: 0.6704297248198047, lr:  0.000411, elapsed time:  340967
Step 370200, loss: 0.0320788382133469, acc: 99.69811123609543, p_norm: 2287.017700760763, g_norm: 0.5654695923012352, lr:  0.000411, elapsed time:  341061
Step 370300, loss: 0.03243126826826483, acc: 99.68970811367035, p_norm: 2287.099841413073, g_norm: 0.6837927259042483, lr:  0.000411, elapsed time:  341153
Step 370400, loss: 0.031184912468306722, acc: 99.7265881896019, p_norm: 2287.171751156732, g_norm: 0.4877662256195772, lr:  0.000411, elapsed time:  341248
Step 370500, loss: 0.03235753718297928, acc: 99.68247549235821, p_norm: 2287.254171053641, g_norm: 0.5424511899583168, lr:  0.000411, elapsed time:  341323
slurmstepd-gpu-3: error: *** JOB 732849 ON gpu-3 CANCELLED AT 2025-07-26T18:47:04 ***
