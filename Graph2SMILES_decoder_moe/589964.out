Logging arguments
**** model = *g2s_series_rel*
**** data_name = *USPTO_480k*
**** task = *retrosynthesis*
**** representation_end = *smiles*
**** seed = *42*
**** max_src_len = *512*
**** max_tgt_len = *512*
**** num_workers = *16*
**** verbose = *False*
**** log_file = *USPTO_480k_g2s_series_rel_smiles_smiles.train.1.log*
**** vocab_file = *./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt*
**** preprocess_output_path = **
**** save_dir = *./checkpoints/USPTO_480k_g2s_series_rel_smiles_smiles.1*
**** train_bin = *./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/train_0.npz*
**** valid_bin = *./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/val_0.npz*
**** load_from = **
**** embed_size = *256*
**** share_embeddings = *False*
**** mpn_type = *dgat*
**** encoder_num_layers = *4*
**** encoder_hidden_size = *256*
**** encoder_attn_heads = *8*
**** encoder_filter_size = *2048*
**** encoder_norm = **
**** encoder_skip_connection = **
**** encoder_positional_encoding = *none*
**** encoder_emb_scale = *sqrt*
**** compute_graph_distance = *True*
**** attn_enc_num_layers = *6*
**** attn_enc_hidden_size = *256*
**** attn_enc_heads = *8*
**** attn_enc_filter_size = *2048*
**** rel_pos = *emb_only*
**** rel_pos_buckets = *11*
**** decoder_num_layers = *6*
**** decoder_hidden_size = *256*
**** decoder_attn_heads = *8*
**** decoder_filter_size = *2048*
**** dropout = *0.3*
**** attn_dropout = *0.3*
**** max_relative_positions = *4*
**** enable_amp = *False*
**** epoch = *2000*
**** max_steps = *500000*
**** warmup_steps = *8000*
**** lr = *4.0*
**** beta1 = *0.9*
**** beta2 = *0.998*
**** eps = *1e-09*
**** weight_decay = *0.0*
**** clip_norm = *20.0*
**** batch_type = *tokens*
**** train_batch_size = *4096*
**** valid_batch_size = *4096*
**** accumulation_count = *4*
**** log_iter = *100*
**** eval_iter = *2000*
**** save_iter = *5000*
**** do_profile = *False*
**** record_shapes = *False*
**** do_predict = *False*
**** do_score = *False*
**** checkpoint_step_start = *None*
**** checkpoint_step_end = *None*
**** predict_batch_size = *4096*
**** test_bin = **
**** result_file = **
**** beam_size = *5*
**** n_best = *10*
**** temperature = *1.0*
**** predict_min_len = *1*
**** predict_max_len = *512*
**** gpu = *0*
Loading vocab from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt
Graph2SeqSeriesRel(
  (encoder): GraphFeatEncoder(
    (mpn): DGATEncoder(
      (leaky_relu): LeakyReLU(negative_slope=0.01)
      (W_o): Sequential(
        (0): Linear(in_features=361, out_features=256, bias=True)
        (1): GELU(approximate='none')
      )
      (rnn): DGATGRU(
        (W_z): Linear(in_features=370, out_features=256, bias=True)
        (W_r): Linear(in_features=114, out_features=256, bias=False)
        (U_r): Linear(in_features=256, out_features=256, bias=True)
        (W_h): Linear(in_features=370, out_features=256, bias=True)
        (leaky_relu): LeakyReLU(negative_slope=0.01)
        (attn_W_q): Linear(in_features=114, out_features=256, bias=True)
        (attn_W_k): Linear(in_features=256, out_features=256, bias=True)
        (attn_W_v): Linear(in_features=256, out_features=256, bias=True)
        (softmax): Softmax(dim=1)
        (dropout): Dropout(p=0.3, inplace=False)
        (attn_dropout): Dropout(p=0.3, inplace=False)
      )
      (attn_W_q): Linear(in_features=105, out_features=256, bias=True)
      (attn_W_k): Linear(in_features=256, out_features=256, bias=True)
      (attn_W_v): Linear(in_features=256, out_features=256, bias=True)
      (softmax): Softmax(dim=1)
      (dropout): Dropout(p=0.3, inplace=False)
      (attn_dropout): Dropout(p=0.3, inplace=False)
    )
  )
  (attention_encoder): AttnEncoderXL(
    (dropout): Dropout(p=0.3, inplace=False)
    (attention_layers): ModuleList(
      (0-5): 6 x SALayerXL(
        (self_attn): MultiHeadedRelAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
          (relative_pe): Embedding(12, 256, padding_idx=11)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.3, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.3, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder_embeddings): Embeddings(
    (make_embedding): Sequential(
      (emb_luts): Elementwise(
        (0): Embedding(299, 256, padding_idx=0)
      )
      (pe): PositionalEncoding(
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(299, 256, padding_idx=0)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
          (relative_positions_embeddings): Embedding(9, 32)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.3, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.3, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.3, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (output_layer): Linear(in_features=256, out_features=299, bias=True)
  (criterion): CrossEntropyLoss()
)
Number of parameters = 18236411
Loading vocab from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt
Loading preprocessed features from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/train_0.npz
Loaded and initialized G2SDataset, size: 409035
Loading vocab from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/vocab_smiles.txt
Loading preprocessed features from ./preprocessed/USPTO_480k_g2s_series_rel_smiles_smiles/val_0.npz
Loaded and initialized G2SDataset, size: 30000
Start training
Calling G2SDataset.batch()
Done, time:  0.60 s, total batches: 6823
Step 100, loss: 3.53690285384655, acc: 24.841539426066447, p_norm: 203.9387821472325, g_norm: 4.089829376155499, lr:  0.000035, elapsed time:  55
Step 200, loss: 2.0009521731734274, acc: 42.006213568151, p_norm: 203.97649980711617, g_norm: 2.9063457448101113, lr:  0.000070, elapsed time:  101
Step 300, loss: 1.6890471121668815, acc: 46.527842685580254, p_norm: 204.03145072411942, g_norm: 2.9493059577419336, lr:  0.000105, elapsed time:  148
Step 400, loss: 1.5164393875002862, acc: 50.63439132273197, p_norm: 204.1246443290548, g_norm: 2.822967483660976, lr:  0.000140, elapsed time:  194
Step 500, loss: 1.365534409582615, acc: 54.60937825590372, p_norm: 204.27012074633194, g_norm: 3.7472662470588096, lr:  0.000175, elapsed time:  241
Step 600, loss: 1.2340878376364708, acc: 58.65302950143814, p_norm: 204.48782987559807, g_norm: 1.8422213005553787, lr:  0.000210, elapsed time:  287
Step 700, loss: 1.1284978905320167, acc: 61.88193006813526, p_norm: 204.7708199685161, g_norm: 2.05367535948718, lr:  0.000245, elapsed time:  334
Step 800, loss: 1.0402453415095807, acc: 64.62125678360462, p_norm: 205.11699756332027, g_norm: 3.670544398182033, lr:  0.000280, elapsed time:  382
Step 900, loss: 0.9546530430018901, acc: 67.35329069197178, p_norm: 205.55165745736218, g_norm: 2.0047281323192574, lr:  0.000315, elapsed time:  429
Step 1000, loss: 0.8732367360591888, acc: 70.02218325436115, p_norm: 206.0719531342656, g_norm: 2.8100956141674667, lr:  0.000350, elapsed time:  475
Step 1100, loss: 0.7940202806890011, acc: 72.58446262776852, p_norm: 206.60542695557837, g_norm: 2.072154533175655, lr:  0.000385, elapsed time:  521
Step 1200, loss: 0.7284417220950127, acc: 74.77254229784012, p_norm: 207.20330596549968, g_norm: 3.0836556372058337, lr:  0.000420, elapsed time:  567
Step 1300, loss: 0.6706281466782094, acc: 76.70126655697823, p_norm: 207.83438273197933, g_norm: 3.3459803611371264, lr:  0.000455, elapsed time:  614
Step 1400, loss: 0.6244149434566498, acc: 78.21004974842072, p_norm: 208.5419446425215, g_norm: 2.8956424450449534, lr:  0.000489, elapsed time:  661
Step 1500, loss: 0.5738528967648745, acc: 80.0049999654293, p_norm: 209.29010235649034, g_norm: 2.5198552714812363, lr:  0.000524, elapsed time:  708
Step 1600, loss: 0.5272069311887025, acc: 81.72580727934837, p_norm: 210.07874228597856, g_norm: 2.5804436757462246, lr:  0.000559, elapsed time:  754
Step 1700, loss: 0.4859948045015335, acc: 83.17607942223549, p_norm: 210.9564674275101, g_norm: 2.1593313377831627, lr:  0.000594, elapsed time:  801
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 1800, loss: 0.4488004031903099, acc: 84.53371938937356, p_norm: 211.8807399641657, g_norm: 1.8379632438277833, lr:  0.000630, elapsed time:  848
Step 1900, loss: 0.4189699490368366, acc: 85.60266563296318, p_norm: 212.92739914148677, g_norm: 1.9825329450074098, lr:  0.000665, elapsed time:  895
Step 2000, loss: 0.38722957149147985, acc: 86.74363727867603, p_norm: 214.00886735486446, g_norm: 2.332647009310599, lr:  0.000699, elapsed time:  942
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 2000, eval loss: 0.24979913756251343, eval acc: 91.68933868408203
Step 2100, loss: 0.36370132960379126, acc: 87.60701605677605, p_norm: 215.19146776473306, g_norm: 1.745779866717376, lr:  0.000734, elapsed time:  996
Step 2200, loss: 0.3395374337211251, acc: 88.51309981942177, p_norm: 216.4536540458686, g_norm: 1.8915144628812524, lr:  0.000769, elapsed time:  1042
Step 2300, loss: 0.31272445771843194, acc: 89.46230259537697, p_norm: 217.78949670720348, g_norm: 1.7797171010012767, lr:  0.000804, elapsed time:  1088
Step 2400, loss: 0.2959973718971014, acc: 90.12027153372765, p_norm: 219.27473290797263, g_norm: 1.9169987079144029, lr:  0.000839, elapsed time:  1136
Step 2500, loss: 0.28298031639307736, acc: 90.61761875450611, p_norm: 220.88680931961957, g_norm: 1.4819133758159864, lr:  0.000874, elapsed time:  1182
Step 2600, loss: 0.26501947671175, acc: 91.26720221340656, p_norm: 222.59000451849758, g_norm: 1.515133209232018, lr:  0.000909, elapsed time:  1229
Step 2700, loss: 0.24692814867943524, acc: 91.89146317541599, p_norm: 224.36507823662552, g_norm: 1.2116394334987015, lr:  0.000944, elapsed time:  1275
Step 2800, loss: 0.2301429533213377, acc: 92.47518479824066, p_norm: 226.2051685823073, g_norm: 1.8493081748931846, lr:  0.000979, elapsed time:  1322
Step 2900, loss: 0.22884260024875402, acc: 92.58708786964417, p_norm: 228.27300739885592, g_norm: 1.6345488912942754, lr:  0.001014, elapsed time:  1369
Step 3000, loss: 0.21245495656505228, acc: 93.11043176054955, p_norm: 230.44770499233488, g_norm: 2.014872280756712, lr:  0.001049, elapsed time:  1416
Step 3100, loss: 0.20606209667399525, acc: 93.39793542027473, p_norm: 232.73518860191018, g_norm: 0.8714757996490288, lr:  0.001084, elapsed time:  1462
Step 3200, loss: 0.1964581967331469, acc: 93.707623898983, p_norm: 235.177686576415, g_norm: 0.8842825076497856, lr:  0.001119, elapsed time:  1509
Step 3300, loss: 0.18651756362989544, acc: 94.0239820331335, p_norm: 237.693088476855, g_norm: 1.5186829202426975, lr:  0.001154, elapsed time:  1555
Step 3400, loss: 0.17813737630844118, acc: 94.33432513475418, p_norm: 240.32000612827497, g_norm: 1.703773870035189, lr:  0.001189, elapsed time:  1602
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 3500, loss: 0.17370701355688625, acc: 94.49707284458813, p_norm: 243.19037442234284, g_norm: 1.1300309131158102, lr:  0.001224, elapsed time:  1649
Step 3600, loss: 0.16690198928117753, acc: 94.7317686676979, p_norm: 246.30830744073106, g_norm: 1.4387377771976972, lr:  0.001259, elapsed time:  1696
Step 3700, loss: 0.1628672319278121, acc: 94.9058786034584, p_norm: 249.5099688554776, g_norm: 0.9565873422491621, lr:  0.001294, elapsed time:  1742
Step 3800, loss: 0.15710757315158844, acc: 95.05388994514942, p_norm: 252.7988552642572, g_norm: 1.1324239744545157, lr:  0.001329, elapsed time:  1789
Step 3900, loss: 0.15564128467813135, acc: 95.12221258878708, p_norm: 256.3097412810856, g_norm: 1.2451057167283561, lr:  0.001364, elapsed time:  1835
Step 4000, loss: 0.14959720293059944, acc: 95.32105562090874, p_norm: 259.9788612372266, g_norm: 0.8317143272669075, lr:  0.001399, elapsed time:  1882
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 4000, eval loss: 0.08818832356482746, eval acc: 97.38848114013672
Step 4100, loss: 0.14159938767552377, acc: 95.58403418958187, p_norm: 263.575817286057, g_norm: 0.7210718346495076, lr:  0.001434, elapsed time:  1934
Step 4200, loss: 0.13975720010697842, acc: 95.63453094661236, p_norm: 267.5489659534566, g_norm: 0.7846739168272264, lr:  0.001468, elapsed time:  1981
Step 4300, loss: 0.1410829773824662, acc: 95.62796358764172, p_norm: 271.7776037415874, g_norm: 0.8776704696079132, lr:  0.001503, elapsed time:  2027
Step 4400, loss: 0.14116574225947262, acc: 95.6129013299942, p_norm: 276.307155112905, g_norm: 1.1000400079039805, lr:  0.001538, elapsed time:  2074
Step 4500, loss: 0.13985101530328392, acc: 95.67481553554535, p_norm: 281.1499575627218, g_norm: 1.0049772342002634, lr:  0.001573, elapsed time:  2121
Step 4600, loss: 0.13729875934310257, acc: 95.74019801616669, p_norm: 285.97826682865076, g_norm: 0.7134089004122622, lr:  0.001608, elapsed time:  2168
Step 4700, loss: 0.13267541655339302, acc: 95.89682495594025, p_norm: 290.9555691918839, g_norm: 0.5814893499758851, lr:  0.001643, elapsed time:  2215
Step 4800, loss: 0.12616741234436632, acc: 96.10750041902065, p_norm: 295.7876183638067, g_norm: 1.3882972403253402, lr:  0.001678, elapsed time:  2262
Step 4900, loss: 0.12719266696833073, acc: 96.06675736606121, p_norm: 301.0271812922449, g_norm: 0.9497506805823948, lr:  0.001713, elapsed time:  2309
Step 5000, loss: 0.12448945957235992, acc: 96.16121092438698, p_norm: 306.1670314954202, g_norm: 0.6491454577286263, lr:  0.001748, elapsed time:  2356
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( C c 1 c c c ( O C C c 2 c c c ( N S ( = O ) ( = O ) c 3 c c ( Cl ) c ( Cl ) c c 3 Cl ) c c 2 ) c c 1 ) C ( = O ) O _EOS
Predicted text: C C O C ( C c 1 c c c ( O C C c 2 c c c ( N S ( = O ) ( = O ) c 3 c c ( Cl ) c ( Cl ) c c 3 Cl ) c c 2 ) c c 1 ) C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N C C ( = O ) N C c 1 c c c ( - n 2 n c ( C ( C ) ( C ) C ) c c 2 N C ( = O ) N c 2 c c c ( O c 3 c c n c c 3 ) c c 2 ) c c 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C C ( = O ) N C c 1 c c c ( - n 2 n c ( C ( C ) ( C ) C ) c c 2 N C ( = O ) N c 2 c c c ( O c 3 c c n c c 3 ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C c 1 c c ( - c 2 n o c ( C ) n 2 ) c c c 1 O S ( = O ) ( = O ) C ( F ) ( F ) F _EOS
Predicted text: C = C C c 1 c c ( - c 2 n o c ( C ) n 2 ) c c c 1 O S ( = O ) ( = O ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) c 1 c c c ( N 2 C C C ( = N O C 3 C C N ( C # N ) C C 3 ) C C 2 ) c ( F ) c 1 _EOS
Predicted text: C S ( = O ) ( = O ) c 1 c c c ( N 2 C C C ( = N O C 3 C C N ( C # N ) C C 3 ) C C 2 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 c ( = O ) c ( - c 2 c ( Cl ) c c c c 2 Cl ) c c 2 c n c ( N c 3 c c c c ( C O ) c 3 ) n c 2 1 _EOS
Predicted text: C n 1 c ( = O ) c ( - c 2 c ( Cl ) c c c c 2 Cl ) c c 2 c n c ( N c 3 c c c c ( C O ) c 3 ) n c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 5000, eval acc (token): 0.7577266086141754, eval acc (sequence): 0.5681028492008339
Saving at step 5000
Step 5100, loss: 0.12081651378422975, acc: 96.29609654843807, p_norm: 311.4061273926521, g_norm: 0.7020065308738676, lr:  0.001783, elapsed time:  2455
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 5200, loss: 0.11940973350967722, acc: 96.3278281481627, p_norm: 317.17832263718475, g_norm: 0.5655073354641995, lr:  0.001818, elapsed time:  2503
Step 5300, loss: 0.11859566994942725, acc: 96.347556874156, p_norm: 322.99228201135173, g_norm: 0.5358363882651589, lr:  0.001853, elapsed time:  2550
Step 5400, loss: 0.11775188189931214, acc: 96.37801368534565, p_norm: 329.05121244582836, g_norm: 0.5318250230705093, lr:  0.001888, elapsed time:  2597
Step 5500, loss: 0.11340734435245395, acc: 96.52129523456097, p_norm: 334.6808845080443, g_norm: 0.5736102853039109, lr:  0.001923, elapsed time:  2643
Step 5600, loss: 0.11235080464743077, acc: 96.5713476985693, p_norm: 340.9196696840922, g_norm: 0.5311002310549555, lr:  0.001958, elapsed time:  2690
Step 5700, loss: 0.1101590256812051, acc: 96.62117660045624, p_norm: 346.96469986400825, g_norm: 0.4667333950554646, lr:  0.001993, elapsed time:  2737
Step 5800, loss: 0.11067405228503048, acc: 96.6180335432291, p_norm: 353.4998253631691, g_norm: 0.7663278743014605, lr:  0.002028, elapsed time:  2783
Step 5900, loss: 0.11029024529270828, acc: 96.64974768459797, p_norm: 360.01974651213266, g_norm: 0.5478292588106822, lr:  0.002063, elapsed time:  2830
Step 6000, loss: 0.1090304515324533, acc: 96.67982944846153, p_norm: 366.69934306758637, g_norm: 1.0655231006749892, lr:  0.002098, elapsed time:  2877
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 6000, eval loss: 0.0632131180819124, eval acc: 98.17472839355469
Step 6100, loss: 0.10867686169221998, acc: 96.67501582205296, p_norm: 373.68825107165503, g_norm: 0.6692393993870142, lr:  0.002133, elapsed time:  2930
Step 6200, loss: 0.10952629250939935, acc: 96.62910169363022, p_norm: 381.27997398789796, g_norm: 0.6476069833766199, lr:  0.002168, elapsed time:  2977
Step 6300, loss: 0.10830691333394497, acc: 96.71479965746403, p_norm: 388.70746757223344, g_norm: 0.8594996919837928, lr:  0.002203, elapsed time:  3024
Step 6400, loss: 0.10504612035118044, acc: 96.79226617515087, p_norm: 395.9945455005256, g_norm: 0.6019923568514318, lr:  0.002237, elapsed time:  3071
Step 6500, loss: 0.10551014395430684, acc: 96.8051575422287, p_norm: 403.2542225596606, g_norm: 0.5045665587430154, lr:  0.002272, elapsed time:  3117
Step 6600, loss: 0.10288116944022477, acc: 96.8836607336998, p_norm: 410.9841388775461, g_norm: 0.6143073183877169, lr:  0.002307, elapsed time:  3165
Step 6700, loss: 0.09850856885313988, acc: 97.01218950748444, p_norm: 418.09515760942276, g_norm: 0.586830690716868, lr:  0.002342, elapsed time:  3211
Step 6800, loss: 0.10238043866120279, acc: 96.90796732902527, p_norm: 425.81132453820186, g_norm: 0.5068570544252708, lr:  0.002377, elapsed time:  3258
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 6900, loss: 0.09680772730826444, acc: 97.06665395802955, p_norm: 433.3771327948386, g_norm: 0.49965915042128906, lr:  0.002413, elapsed time:  3305
Step 7000, loss: 0.09894256719388067, acc: 96.97236889600754, p_norm: 441.54710197347845, g_norm: 0.4756777676120393, lr:  0.002447, elapsed time:  3352
Step 7100, loss: 0.0954695528652519, acc: 97.09514629840851, p_norm: 449.55783138263405, g_norm: 0.5379378989642072, lr:  0.002482, elapsed time:  3399
Step 7200, loss: 0.09757602587342262, acc: 97.04874360561371, p_norm: 457.62595775339713, g_norm: 0.4193182175883723, lr:  0.002517, elapsed time:  3445
Step 7300, loss: 0.09838315427303314, acc: 97.016682356596, p_norm: 465.9089053396607, g_norm: 0.4015124146638278, lr:  0.002552, elapsed time:  3492
Step 7400, loss: 0.09597644561901689, acc: 97.09807907044888, p_norm: 474.45658578950275, g_norm: 0.5567052020790714, lr:  0.002587, elapsed time:  3538
Step 7500, loss: 0.09024516287725419, acc: 97.27415007352829, p_norm: 482.4728387220554, g_norm: 0.5103485412690335, lr:  0.002622, elapsed time:  3585
Step 7600, loss: 0.09476907829754054, acc: 97.12720531225204, p_norm: 491.15049608898136, g_norm: 0.4534261069200523, lr:  0.002657, elapsed time:  3632
Step 7700, loss: 0.09275045461952686, acc: 97.20255088806152, p_norm: 499.84600223532925, g_norm: 0.6548404470721628, lr:  0.002692, elapsed time:  3679
Step 7800, loss: 0.09585092559922487, acc: 97.11317375302315, p_norm: 509.16902946700014, g_norm: 0.40571048052861974, lr:  0.002727, elapsed time:  3726
Step 7900, loss: 0.08972678940743208, acc: 97.2904672473669, p_norm: 517.8611422947714, g_norm: 0.46626366412266423, lr:  0.002762, elapsed time:  3773
Step 8000, loss: 0.09188780456781387, acc: 97.22992931306362, p_norm: 527.2594877161013, g_norm: 0.4690402314654882, lr:  0.002794, elapsed time:  3820
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 8000, eval loss: 0.05772244109539313, eval acc: 98.36770629882812
Step 8100, loss: 0.09333357260562479, acc: 97.18527230620384, p_norm: 536.3931198389932, g_norm: 0.3876033346365306, lr:  0.002777, elapsed time:  3873
Step 8200, loss: 0.08962297721765936, acc: 97.28169138729572, p_norm: 545.0398922018817, g_norm: 0.5174906968075919, lr:  0.002760, elapsed time:  3920
Step 8300, loss: 0.0884386427514255, acc: 97.32890446484089, p_norm: 553.9129241829917, g_norm: 0.39876518796306104, lr:  0.002743, elapsed time:  3968
Step 8400, loss: 0.08439680361188948, acc: 97.4607956558466, p_norm: 561.388729456322, g_norm: 0.3476512484932505, lr:  0.002727, elapsed time:  4014
Step 8500, loss: 0.08518850112333894, acc: 97.43298135697842, p_norm: 569.5431334379164, g_norm: 0.39139273493826293, lr:  0.002711, elapsed time:  4061
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 8600, loss: 0.08006103939159, acc: 97.58965504999777, p_norm: 577.1223038955222, g_norm: 0.4692008014901319, lr:  0.002695, elapsed time:  4109
Step 8700, loss: 0.08063987989444285, acc: 97.55772340297699, p_norm: 584.899416861983, g_norm: 0.33374049365071634, lr:  0.002679, elapsed time:  4156
Step 8800, loss: 0.08190143000800162, acc: 97.5324644446373, p_norm: 592.5011944605021, g_norm: 0.41545464519391045, lr:  0.002664, elapsed time:  4203
Step 8900, loss: 0.07721276479773223, acc: 97.68931709229946, p_norm: 599.5031178076798, g_norm: 0.36897484915308276, lr:  0.002649, elapsed time:  4249
Step 9000, loss: 0.07649887401144952, acc: 97.71379612386227, p_norm: 606.5517297102992, g_norm: 0.3644003016567013, lr:  0.002634, elapsed time:  4296
Step 9100, loss: 0.07364330861717462, acc: 97.78241096436977, p_norm: 613.159187333981, g_norm: 0.43479871935486514, lr:  0.002620, elapsed time:  4342
Step 9200, loss: 0.07651802302338183, acc: 97.68179100751877, p_norm: 620.8202820702445, g_norm: 0.3334404950332085, lr:  0.002606, elapsed time:  4389
Step 9300, loss: 0.07641245499253273, acc: 97.6933177113533, p_norm: 627.8408221478312, g_norm: 0.35638979054597847, lr:  0.002592, elapsed time:  4435
Step 9400, loss: 0.07758891741745173, acc: 97.66889098286629, p_norm: 635.3567039441017, g_norm: 0.2992151352847169, lr:  0.002578, elapsed time:  4482
Step 9500, loss: 0.07553484713658691, acc: 97.71933844685555, p_norm: 642.6012331265325, g_norm: 0.3932906326914143, lr:  0.002564, elapsed time:  4530
Step 9600, loss: 0.07477128639817238, acc: 97.75107891857624, p_norm: 649.1580990520665, g_norm: 0.3313283063713808, lr:  0.002551, elapsed time:  4576
Step 9700, loss: 0.0733876643422991, acc: 97.77378909289837, p_norm: 655.8554628178571, g_norm: 0.3361825809150049, lr:  0.002538, elapsed time:  4623
Step 9800, loss: 0.07299499125219881, acc: 97.81135159730911, p_norm: 662.5791675099973, g_norm: 0.3124062378473955, lr:  0.002525, elapsed time:  4670
Step 9900, loss: 0.07007980443537236, acc: 97.89919646084309, p_norm: 668.8029376531309, g_norm: 0.49129864601016876, lr:  0.002512, elapsed time:  4717
Step 10000, loss: 0.07044040519278497, acc: 97.8927159756422, p_norm: 675.2297068236992, g_norm: 0.3719884154670538, lr:  0.002499, elapsed time:  4764
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 10000, eval loss: 0.04377901350148021, eval acc: 98.7417984008789
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c ( [N+] ( = O ) [O-] ) c c c 1 N C ( = O ) c 1 c c c c c 1 _EOS
Predicted text: C c 1 c c ( [N+] ( = O ) [O-] ) c c c 1 N C ( = O ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C ( C ) ( C ) C = C ( Br ) Br ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C ( C ) ( C ) C = C ( Br ) Br ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O c 1 n c c ( - c 2 c c c ( C ( C ) N 3 C C C ( C C ( C ) ( C ) O ) ( c 4 c c c c c 4 ) O C 3 = O ) c c 2 ) c c 1 C _EOS
Predicted text: C C O c 1 n c c ( - c 2 c c c ( C ( C ) N 3 C C C ( C C ( C ) ( C ) O ) ( c 4 c c c c c 4 ) O C 3 = O ) c c 2 ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: Cl . O = C ( C C C N 1 C C C ( C ( O ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) C C 1 ) c 1 c c c s 1 _EOS
Predicted text: O = C ( C C C N 1 C C C ( C ( O ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) C C 1 ) c 1 c c c s 1 _EOS _PAD _PAD
acc_token: 0.3, acc_seq: False

Target text: N c 1 c c c ( C ( = O ) N 2 C C N ( c 3 c c c c c 3 ) C C 2 ) c c 1 _EOS
Predicted text: N c 1 c c c ( C ( = O ) N 2 C C N ( c 3 c c c c c 3 ) C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 10000, eval acc (token): 0.8446742939641803, eval acc (sequence): 0.7191805656272662
Saving at step 10000
Step 10100, loss: 0.07063394384924322, acc: 97.89744172990322, p_norm: 681.3348075411964, g_norm: 0.37400394921995694, lr:  0.002487, elapsed time:  4878
Step 10200, loss: 0.06877417257521301, acc: 97.95157235860825, p_norm: 687.2762885603476, g_norm: 0.3163934158078727, lr:  0.002475, elapsed time:  4925
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 10300, loss: 0.06799843019480001, acc: 97.96750833911281, p_norm: 693.5018246931431, g_norm: 0.37306853179643185, lr:  0.002462, elapsed time:  4972
Step 10400, loss: 0.06693376537645236, acc: 97.99662758409977, p_norm: 699.3459829854612, g_norm: 0.35917249348707625, lr:  0.002451, elapsed time:  5019
Step 10500, loss: 0.06487700388301164, acc: 98.04897485673428, p_norm: 705.2880336735498, g_norm: 0.4706939962339836, lr:  0.002439, elapsed time:  5065
Step 10600, loss: 0.06524689900455996, acc: 98.04614175856113, p_norm: 711.0168203584393, g_norm: 0.29494207856763544, lr:  0.002427, elapsed time:  5112
Step 10700, loss: 0.06407089728629217, acc: 98.08416044712067, p_norm: 716.593762508402, g_norm: 0.34802099799808284, lr:  0.002416, elapsed time:  5158
Step 10800, loss: 0.06359572070883587, acc: 98.10878773033619, p_norm: 722.5213743910842, g_norm: 0.4006717457576955, lr:  0.002405, elapsed time:  5205
Step 10900, loss: 0.062235052387695756, acc: 98.13359741866589, p_norm: 728.322062037419, g_norm: 0.2635833669630508, lr:  0.002394, elapsed time:  5252
Step 11000, loss: 0.06315463515231386, acc: 98.11883296072483, p_norm: 734.0766498278045, g_norm: 0.32393085312882025, lr:  0.002383, elapsed time:  5300
Step 11100, loss: 0.06270722466288134, acc: 98.12916292250156, p_norm: 739.557497878564, g_norm: 0.3141145279191704, lr:  0.002372, elapsed time:  5346
Step 11200, loss: 0.06266705533955247, acc: 98.14948946237564, p_norm: 744.9778166404892, g_norm: 0.3388212523412638, lr:  0.002362, elapsed time:  5393
Step 11300, loss: 0.06236746232490987, acc: 98.14178709685802, p_norm: 750.5132589534364, g_norm: 0.33595597578192454, lr:  0.002351, elapsed time:  5439
Step 11400, loss: 0.06443199212895706, acc: 98.05766052007675, p_norm: 756.328773337011, g_norm: 0.345151075991174, lr:  0.002341, elapsed time:  5486
Step 11500, loss: 0.06411959882825613, acc: 98.07000800967216, p_norm: 762.2403838433911, g_norm: 0.3729032537877295, lr:  0.002331, elapsed time:  5533
Step 11600, loss: 0.06141990760806948, acc: 98.17037719488144, p_norm: 767.512384165307, g_norm: 0.4560077343616022, lr:  0.002320, elapsed time:  5580
Step 11700, loss: 0.06006222457624972, acc: 98.21093009412289, p_norm: 772.7660180413405, g_norm: 0.26074369640626205, lr:  0.002311, elapsed time:  5627
Step 11800, loss: 0.06116016177693382, acc: 98.180474370718, p_norm: 777.635362872519, g_norm: 0.29192957597295166, lr:  0.002301, elapsed time:  5674
Step 11900, loss: 0.05913688940927386, acc: 98.22671854496002, p_norm: 782.6853518521069, g_norm: 0.26149337920290117, lr:  0.002291, elapsed time:  5721
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 12000, loss: 0.05684696555960341, acc: 98.30888280501732, p_norm: 787.7007649510577, g_norm: 0.27305186819077265, lr:  0.002281, elapsed time:  5769
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 12000, eval loss: 0.039234241105150426, eval acc: 98.90141296386719
Step 12100, loss: 0.05730868433369324, acc: 98.28725770115852, p_norm: 792.558469729932, g_norm: 0.3418581547415144, lr:  0.002272, elapsed time:  5823
Step 12200, loss: 0.056807012714270966, acc: 98.30086842179298, p_norm: 797.3443727793486, g_norm: 0.33041182963999416, lr:  0.002263, elapsed time:  5869
Step 12300, loss: 0.057373269067611546, acc: 98.28977216780186, p_norm: 802.2605534600182, g_norm: 0.36983223519302366, lr:  0.002253, elapsed time:  5916
Step 12400, loss: 0.05590304542332888, acc: 98.34618435800076, p_norm: 807.0738236104539, g_norm: 0.3371843175346602, lr:  0.002244, elapsed time:  5964
Step 12500, loss: 0.05602622746489942, acc: 98.32610879838467, p_norm: 811.7618825527497, g_norm: 0.35476997900659335, lr:  0.002235, elapsed time:  6010
Step 12600, loss: 0.055740610614884646, acc: 98.33223314583302, p_norm: 816.4921070813551, g_norm: 0.27842509982463787, lr:  0.002226, elapsed time:  6057
Step 12700, loss: 0.054008459942415356, acc: 98.39854092895985, p_norm: 820.9327631630719, g_norm: 0.28300196065423877, lr:  0.002218, elapsed time:  6104
Step 12800, loss: 0.055950586984399704, acc: 98.32582920789719, p_norm: 825.6025572084557, g_norm: 0.22374720367903284, lr:  0.002209, elapsed time:  6150
Step 12900, loss: 0.05469165202579461, acc: 98.37080831825733, p_norm: 830.2041339204508, g_norm: 0.269374604367422, lr:  0.002200, elapsed time:  6197
Step 13000, loss: 0.055663622084539385, acc: 98.34765374660492, p_norm: 834.6895530846597, g_norm: 0.46315436920895486, lr:  0.002192, elapsed time:  6243
Step 13100, loss: 0.05468119815690443, acc: 98.38711194694042, p_norm: 839.2031816295565, g_norm: 0.23726945090759224, lr:  0.002184, elapsed time:  6289
Step 13200, loss: 0.05601410172181204, acc: 98.3502721786499, p_norm: 843.6119303700224, g_norm: 0.34262413050530977, lr:  0.002175, elapsed time:  6336
Step 13300, loss: 0.05456866931403056, acc: 98.38049195706844, p_norm: 848.0444256423646, g_norm: 0.31276491777229626, lr:  0.002167, elapsed time:  6383
Step 13400, loss: 0.05431840491830371, acc: 98.36838099360466, p_norm: 852.5294989649433, g_norm: 0.341538438124063, lr:  0.002159, elapsed time:  6430
Step 13500, loss: 0.05317548876511864, acc: 98.41069297492504, p_norm: 856.9503437947508, g_norm: 0.22694675824782934, lr:  0.002151, elapsed time:  6476
Step 13600, loss: 0.05378910986706614, acc: 98.40231351554394, p_norm: 861.1837841485117, g_norm: 0.24548085555552876, lr:  0.002143, elapsed time:  6523
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 13700, loss: 0.05206355467327771, acc: 98.4544218326029, p_norm: 865.376136645272, g_norm: 0.2956481029126622, lr:  0.002135, elapsed time:  6570
Step 13800, loss: 0.05152993897907436, acc: 98.46073161065578, p_norm: 869.2922924060318, g_norm: 0.30766350473369347, lr:  0.002127, elapsed time:  6617
Step 13900, loss: 0.051186750968918206, acc: 98.47859120368958, p_norm: 873.4163612709963, g_norm: 0.3035216185957063, lr:  0.002120, elapsed time:  6663
Step 14000, loss: 0.051039711257908495, acc: 98.47929063439369, p_norm: 877.7003073760083, g_norm: 0.2598599891788758, lr:  0.002112, elapsed time:  6710
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 14000, eval loss: 0.03597618747502565, eval acc: 99.00064086914062
Step 14100, loss: 0.05255523181403987, acc: 98.41549552977085, p_norm: 882.1502321306797, g_norm: 0.2775252479129458, lr:  0.002105, elapsed time:  6764
Step 14200, loss: 0.05105819957796484, acc: 98.46724316477776, p_norm: 886.2642945314321, g_norm: 0.22170522868994263, lr:  0.002097, elapsed time:  6811
Step 14300, loss: 0.051638848544098434, acc: 98.46467693150043, p_norm: 890.0094480965, g_norm: 0.29815074042562834, lr:  0.002090, elapsed time:  6857
Step 14400, loss: 0.049446489491965624, acc: 98.5253467708826, p_norm: 893.7456122688268, g_norm: 0.2525964297190047, lr:  0.002083, elapsed time:  6904
Step 14500, loss: 0.04994421472074464, acc: 98.52499231696129, p_norm: 897.622903020216, g_norm: 0.3109645300307042, lr:  0.002075, elapsed time:  6951
Step 14600, loss: 0.051129508512094614, acc: 98.47909732162952, p_norm: 901.651359511104, g_norm: 0.3891049476555955, lr:  0.002068, elapsed time:  6998
Step 14700, loss: 0.04822056974750012, acc: 98.57476937770844, p_norm: 905.3925360448372, g_norm: 0.20816310054165732, lr:  0.002061, elapsed time:  7045
Step 14800, loss: 0.048526708853896705, acc: 98.54101736843586, p_norm: 909.1642040686961, g_norm: 0.2963453420704722, lr:  0.002054, elapsed time:  7092
Step 14900, loss: 0.048746297997422514, acc: 98.55215778946877, p_norm: 912.8321473490012, g_norm: 0.28229944200018126, lr:  0.002047, elapsed time:  7138
Step 15000, loss: 0.049498481755144895, acc: 98.52754005789757, p_norm: 916.8847061987711, g_norm: 0.2877067257385973, lr:  0.002041, elapsed time:  7186
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C N ( N ) C ( = S ) N c 1 c c c ( C # N ) c c 1 _EOS
Predicted text: C N ( N ) C ( = S ) N c 1 c c c ( C # N ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) O C ( = O ) c 1 n [nH] c 2 c ( = O ) [nH] c 3 c c ( Cl ) c c c 3 c ( = O ) c 1 2 _EOS
Predicted text: C C ( C ) O C ( = O ) c 1 n [nH] c 2 c ( = O ) [nH] c 3 c c ( Cl ) c c c 3 c ( = O ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 n c c c c 1 - c 1 c c c c c 1 _EOS
Predicted text: C O C ( = O ) c 1 n c c c c 1 - c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O C C # C c 1 c c c ( C 2 C C 2 ) c c 1 _EOS
Predicted text: O C C # C c 1 c c c ( C 2 C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O c 1 c c c c c 1 ) N ( C ( = O ) O c 1 c c c c c 1 ) c 1 c c ( O c 2 c c c ( N C ( = O ) C 3 ( C ( = O ) N c 4 c c c c c 4 ) C C 3 ) c ( F ) c 2 ) c c n 1 _EOS
Predicted text: O = C ( N c 1 c c c ( O c 3 c c ( N C ( = O ) C 3 ( C ( = O ) N c 4 c c c c c 4 ) C C 3 ) c ( F ) c 2 ) c c 1 ) O c 1 c c c c c 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.21686746987951808, acc_seq: False

Evaluation (without teacher) at step 15000, eval acc (token): 0.8723374696473334, eval acc (sequence): 0.7674750356633381
Saving at step 15000
Step 15100, loss: 0.048437321026576684, acc: 98.5627513974905, p_norm: 920.3992767063738, g_norm: 0.3092798015001081, lr:  0.002034, elapsed time:  7290
Step 15200, loss: 0.04843948452384211, acc: 98.5532865524292, p_norm: 923.9436637699204, g_norm: 0.21477869069273767, lr:  0.002027, elapsed time:  7336
Step 15300, loss: 0.04721556291449815, acc: 98.60017497837543, p_norm: 927.3886647840325, g_norm: 0.30927195488031667, lr:  0.002021, elapsed time:  7383
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 15400, loss: 0.04599143468788756, acc: 98.63184903984639, p_norm: 930.7057780807438, g_norm: 0.40704571876681206, lr:  0.002014, elapsed time:  7431
Step 15500, loss: 0.04532308097113855, acc: 98.64915136992931, p_norm: 934.3076916651896, g_norm: 0.3184845600463882, lr:  0.002007, elapsed time:  7477
Step 15600, loss: 0.04689297064789571, acc: 98.61045642197132, p_norm: 937.9030990750202, g_norm: 0.45145864161374577, lr:  0.002001, elapsed time:  7525
Step 15700, loss: 0.046187079694354906, acc: 98.6192314773798, p_norm: 941.4205975341517, g_norm: 0.2263445101292552, lr:  0.001995, elapsed time:  7571
Step 15800, loss: 0.04521416783798486, acc: 98.6487514525652, p_norm: 944.901822617895, g_norm: 0.2754124534119543, lr:  0.001988, elapsed time:  7618
Step 15900, loss: 0.04608853389043361, acc: 98.62704928219318, p_norm: 948.3145776975418, g_norm: 0.22537565071599958, lr:  0.001982, elapsed time:  7665
Step 16000, loss: 0.04583185440278612, acc: 98.64228059351444, p_norm: 951.7734239781729, g_norm: 0.27421670217129085, lr:  0.001976, elapsed time:  7712
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 16000, eval loss: 0.028196232522605, eval acc: 99.1889419555664
Step 16100, loss: 0.0464982310065534, acc: 98.61716917157173, p_norm: 955.1427406790975, g_norm: 0.3011552575920889, lr:  0.001970, elapsed time:  7765
Step 16200, loss: 0.04442795015173033, acc: 98.67260190844536, p_norm: 958.5193787415551, g_norm: 0.2226859574098837, lr:  0.001964, elapsed time:  7812
Step 16300, loss: 0.04486011202679947, acc: 98.65241493284702, p_norm: 961.9752235001492, g_norm: 0.30976470740731255, lr:  0.001958, elapsed time:  7860
Step 16400, loss: 0.047263768560951575, acc: 98.59419064223766, p_norm: 965.3132204461465, g_norm: 0.31871372051076885, lr:  0.001952, elapsed time:  7906
Step 16500, loss: 0.04499223129125312, acc: 98.65634183585644, p_norm: 968.5325034010374, g_norm: 0.1886785728464463, lr:  0.001946, elapsed time:  7953
Step 16600, loss: 0.04531661774381064, acc: 98.64854606986046, p_norm: 971.736248201629, g_norm: 0.2639748690428346, lr:  0.001940, elapsed time:  8000
Step 16700, loss: 0.04479586706729606, acc: 98.67251358926296, p_norm: 974.8430774197997, g_norm: 0.3181206806103352, lr:  0.001934, elapsed time:  8046
Step 16800, loss: 0.04551630859961733, acc: 98.63275609910488, p_norm: 978.0269705002072, g_norm: 0.23935402871349823, lr:  0.001928, elapsed time:  8093
Step 16900, loss: 0.04405843799235299, acc: 98.69152566790581, p_norm: 981.1316679629746, g_norm: 0.27882807135771204, lr:  0.001923, elapsed time:  8139
Step 17000, loss: 0.04421575587475672, acc: 98.68620969355106, p_norm: 984.2682536548725, g_norm: 0.3650882395404309, lr:  0.001917, elapsed time:  8186
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 17100, loss: 0.04244443033219533, acc: 98.74276392791995, p_norm: 987.4120006322867, g_norm: 0.2422668647551086, lr:  0.001911, elapsed time:  8233
Step 17200, loss: 0.04313772438908927, acc: 98.71174746751785, p_norm: 990.6003673250997, g_norm: 0.25490512017882117, lr:  0.001906, elapsed time:  8280
Step 17300, loss: 0.0419273152470123, acc: 98.74954426288605, p_norm: 993.7167681818931, g_norm: 0.2684968279773213, lr:  0.001900, elapsed time:  8327
Step 17400, loss: 0.043062425064854325, acc: 98.71152776479721, p_norm: 996.8667890156368, g_norm: 0.3679702387041905, lr:  0.001895, elapsed time:  8374
Step 17500, loss: 0.043457201012643054, acc: 98.7025295495987, p_norm: 999.9389302004887, g_norm: 0.2788375662814212, lr:  0.001889, elapsed time:  8420
Step 17600, loss: 0.04249402021756396, acc: 98.72574533522129, p_norm: 1002.889024446984, g_norm: 0.255478599538738, lr:  0.001884, elapsed time:  8467
Step 17700, loss: 0.04448875049361959, acc: 98.67320376634598, p_norm: 1006.1054802516269, g_norm: 0.2701669720829683, lr:  0.001879, elapsed time:  8515
Step 17800, loss: 0.04323837983421981, acc: 98.72753727436066, p_norm: 1008.9867095045279, g_norm: 0.25729278483076756, lr:  0.001873, elapsed time:  8561
Step 17900, loss: 0.04245217626332305, acc: 98.73923152685165, p_norm: 1011.9778500631938, g_norm: 0.24375860105053143, lr:  0.001868, elapsed time:  8608
Step 18000, loss: 0.04166100804228336, acc: 98.75446958839893, p_norm: 1014.8441481081079, g_norm: 0.2229221455201653, lr:  0.001863, elapsed time:  8655
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 18000, eval loss: 0.03088465485256166, eval acc: 99.1222915649414
Step 18100, loss: 0.04204178997548297, acc: 98.74310973286629, p_norm: 1017.6249421295435, g_norm: 0.24127071877550743, lr:  0.001858, elapsed time:  8708
Step 18200, loss: 0.041105604437179866, acc: 98.7799940109253, p_norm: 1020.3559534884315, g_norm: 0.2061039122719507, lr:  0.001853, elapsed time:  8755
Step 18300, loss: 0.042603204157203436, acc: 98.73143863677979, p_norm: 1023.2478649919622, g_norm: 0.22176644556046282, lr:  0.001847, elapsed time:  8802
Step 18400, loss: 0.041068703461205586, acc: 98.78991335630417, p_norm: 1025.9643495149917, g_norm: 0.27455164487474676, lr:  0.001842, elapsed time:  8849
Step 18500, loss: 0.04274219519924372, acc: 98.7230200022459, p_norm: 1028.7497819708765, g_norm: 0.3100056880743664, lr:  0.001837, elapsed time:  8895
Step 18600, loss: 0.042438508577179165, acc: 98.73306415975094, p_norm: 1031.5608006631724, g_norm: 0.360330006796295, lr:  0.001833, elapsed time:  8942
Step 18700, loss: 0.041625939719378946, acc: 98.76486103236675, p_norm: 1034.3467622057, g_norm: 0.3140915680579621, lr:  0.001828, elapsed time:  8989
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 18800, loss: 0.04020192301067621, acc: 98.80686486834911, p_norm: 1037.031777620031, g_norm: 0.2615350134014066, lr:  0.001823, elapsed time:  9036
Step 18900, loss: 0.040255398881272414, acc: 98.80554495751858, p_norm: 1039.8510547002816, g_norm: 0.24660265202960777, lr:  0.001818, elapsed time:  9082
Step 19000, loss: 0.040085937230614946, acc: 98.79398068785667, p_norm: 1042.5416508455276, g_norm: 0.28835976257303725, lr:  0.001813, elapsed time:  9129
Step 19100, loss: 0.03920892044436187, acc: 98.82989384233952, p_norm: 1045.2576790257299, g_norm: 0.25479975596723625, lr:  0.001808, elapsed time:  9176
Step 19200, loss: 0.03925835703499615, acc: 98.82746769487858, p_norm: 1047.9273251389013, g_norm: 0.23882575795853517, lr:  0.001804, elapsed time:  9223
Step 19300, loss: 0.03861559921875596, acc: 98.84251023828983, p_norm: 1050.60021668535, g_norm: 0.3075289156104678, lr:  0.001799, elapsed time:  9270
Step 19400, loss: 0.040404778514057396, acc: 98.79117749631405, p_norm: 1053.2742794705418, g_norm: 0.26363143407273687, lr:  0.001794, elapsed time:  9317
Step 19500, loss: 0.03987162097124383, acc: 98.80836667120457, p_norm: 1055.870475599899, g_norm: 0.23968401422710373, lr:  0.001790, elapsed time:  9363
Step 19600, loss: 0.038892707695194983, acc: 98.82885530591011, p_norm: 1058.4359588215716, g_norm: 0.2114716586125277, lr:  0.001785, elapsed time:  9410
Step 19700, loss: 0.03877578853920568, acc: 98.83765408396721, p_norm: 1060.976265981379, g_norm: 0.3076635195998283, lr:  0.001781, elapsed time:  9457
Step 19800, loss: 0.039632748069707305, acc: 98.81671741604805, p_norm: 1063.4454168303223, g_norm: 0.2108538398035189, lr:  0.001776, elapsed time:  9504
Step 19900, loss: 0.03916883158206474, acc: 98.84469969570637, p_norm: 1065.9272716627436, g_norm: 0.2623626281381711, lr:  0.001772, elapsed time:  9550
Step 20000, loss: 0.04018031922867522, acc: 98.80738580226898, p_norm: 1068.4336370759945, g_norm: 0.20613396137345807, lr:  0.001767, elapsed time:  9597
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 20000, eval loss: 0.02478251026594079, eval acc: 99.2949447631836
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C n 1 c c 2 c ( - c 3 c c c n c 3 ) c ( - c 3 c c n c c 3 ) c ( - c 3 c c c ( F ) c c 3 ) n c 2 n 1 _EOS
Predicted text: C n 1 c c 2 c ( - c 3 c c c n c 3 ) c ( - c 3 c c c ( F ) c c 3 ) c ( - c 3 c c n c c 3 ) n c 2 n 1 _EOS
acc_token: 0.7450980392156863, acc_seq: False

Target text: C O C C 1 C ( = O ) N ( C c 2 c c c 3 c ( N ) n c n c 3 c 2 ) C C N 1 C ( = O ) c 1 n c 2 c c c ( Cl ) c c 2 [nH] 1 _EOS
Predicted text: C O C C 1 C ( = O ) N ( C c 2 c c c 3 c ( N C ( = O ) c 4 n c 5 c c c ( Cl ) c c 5 [nH] 4 ) n c n c 3 c 2 ) C C N 1 C ( = O ) O C c 1 c c c c c 1 _EOS
acc_token: 0.43859649122807015, acc_seq: False

Target text: C c 1 c c ( C ) n c ( N C ( = O ) N ( C ) C ) c 1 _EOS
Predicted text: C c 1 c c ( C ) n c ( N C ( = O ) N ( C ) C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C C C C C C C Br ) C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C O C ( = O ) C ( C C C C C C C Br ) C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N c 1 c c c ( N C ( = O ) c 2 c c c ( F ) c c 2 O ) c ( O C c 2 c c c c c 2 ) c 1 ) O C C 1 c 2 c c c c c 2 - c 2 c c c c c 2 1 _EOS
Predicted text: O = C ( N c 1 c c c ( N C ( = O ) c 2 c c c ( F ) c c 2 O ) c ( O C c 2 c c c c c 2 ) c 1 ) O C C 1 c 2 c c c c c 2 - c 2 c c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 20000, eval acc (token): 0.891304899065285, eval acc (sequence): 0.8039821489872984
Saving at step 20000
Step 20100, loss: 0.03961580070434138, acc: 98.83062316477299, p_norm: 1070.9408303718835, g_norm: 0.3270507227124648, lr:  0.001763, elapsed time:  9701
Step 20200, loss: 0.04085539683583193, acc: 98.77775339782238, p_norm: 1073.6515712007777, g_norm: 0.263811662050937, lr:  0.001758, elapsed time:  9748
Step 20300, loss: 0.04036304013687186, acc: 98.80018240213394, p_norm: 1076.1199442032437, g_norm: 0.31591162470862016, lr:  0.001754, elapsed time:  9795
Step 20400, loss: 0.03936760693788528, acc: 98.8218095600605, p_norm: 1078.584731568266, g_norm: 0.2532528553466608, lr:  0.001750, elapsed time:  9842
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 20500, loss: 0.038976415851969204, acc: 98.83967803666373, p_norm: 1081.107428195399, g_norm: 0.3617985207485318, lr:  0.001746, elapsed time:  9890
Step 20600, loss: 0.03703307315299753, acc: 98.8990827947855, p_norm: 1083.3526777508007, g_norm: 0.19368262436110553, lr:  0.001741, elapsed time:  9936
Step 20700, loss: 0.03610127636929974, acc: 98.9166644513607, p_norm: 1085.7315325267705, g_norm: 0.2185110309675615, lr:  0.001737, elapsed time:  9982
Step 20800, loss: 0.03740476417005993, acc: 98.88253970444202, p_norm: 1088.2086415946897, g_norm: 0.25146709071614065, lr:  0.001733, elapsed time:  10030
Step 20900, loss: 0.03813571923121344, acc: 98.85918310284615, p_norm: 1090.6169121539929, g_norm: 0.29087792050569905, lr:  0.001729, elapsed time:  10076
Step 21000, loss: 0.03802116058708634, acc: 98.86583392322063, p_norm: 1092.9945938040746, g_norm: 0.204279858666721, lr:  0.001725, elapsed time:  10123
Step 21100, loss: 0.03751337294146651, acc: 98.87926051020622, p_norm: 1095.3298085580686, g_norm: 0.20911122415114664, lr:  0.001721, elapsed time:  10169
Step 21200, loss: 0.037486173936631534, acc: 98.87778279185295, p_norm: 1097.6074997099438, g_norm: 0.21009294120203567, lr:  0.001716, elapsed time:  10216
Step 21300, loss: 0.03717616955866106, acc: 98.8923727273941, p_norm: 1099.9011531419083, g_norm: 0.20817435502555573, lr:  0.001712, elapsed time:  10262
Step 21400, loss: 0.03720060247927904, acc: 98.88943354785442, p_norm: 1102.4056088599068, g_norm: 0.23102636040718394, lr:  0.001708, elapsed time:  10310
Step 21500, loss: 0.03868585053074639, acc: 98.85051579773426, p_norm: 1104.7404614503275, g_norm: 0.26436632800649706, lr:  0.001704, elapsed time:  10356
Step 21600, loss: 0.03767275325371884, acc: 98.87180297076702, p_norm: 1107.0164141865835, g_norm: 0.1853558545591717, lr:  0.001701, elapsed time:  10403
Step 21700, loss: 0.03667183424026007, acc: 98.89709483087063, p_norm: 1109.3651143815346, g_norm: 0.2450832488837288, lr:  0.001697, elapsed time:  10450
Step 21800, loss: 0.03748584949440556, acc: 98.8824530094862, p_norm: 1111.735150037311, g_norm: 0.23266644826084848, lr:  0.001693, elapsed time:  10497
Step 21900, loss: 0.03693309120077174, acc: 98.89595921337605, p_norm: 1114.0606419777885, g_norm: 0.27668342029823195, lr:  0.001689, elapsed time:  10544
Step 22000, loss: 0.036959660777356476, acc: 98.9073970913887, p_norm: 1116.3669552378772, g_norm: 0.24790418370444967, lr:  0.001685, elapsed time:  10591
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 22000, eval loss: 0.02818147483543726, eval acc: 99.19999694824219
Step 22100, loss: 0.03733304756053258, acc: 98.89391838014126, p_norm: 1118.5297170711963, g_norm: 0.2275456698770661, lr:  0.001681, elapsed time:  10645
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 22200, loss: 0.035801380697092405, acc: 98.94458275870709, p_norm: 1120.6956596910652, g_norm: 0.2702989225132354, lr:  0.001677, elapsed time:  10693
Step 22300, loss: 0.03607569357962347, acc: 98.93305324018002, p_norm: 1122.857579380137, g_norm: 0.2521483738256146, lr:  0.001674, elapsed time:  10740
Step 22400, loss: 0.03452050335239619, acc: 98.96768534183502, p_norm: 1125.0143896117822, g_norm: 0.1921858154814883, lr:  0.001670, elapsed time:  10787
Step 22500, loss: 0.036704548353445714, acc: 98.91417586803436, p_norm: 1127.2754855049861, g_norm: 0.25409746449809467, lr:  0.001666, elapsed time:  10834
Step 22600, loss: 0.03741714988776948, acc: 98.89018160104752, p_norm: 1129.3693479971482, g_norm: 0.32232970641050124, lr:  0.001662, elapsed time:  10880
Step 22700, loss: 0.036449363956344315, acc: 98.90229238569736, p_norm: 1131.4475111153315, g_norm: 0.21554786240627455, lr:  0.001659, elapsed time:  10927
Step 22800, loss: 0.03464460296090692, acc: 98.95630750060081, p_norm: 1133.5789161853932, g_norm: 0.23086649401384796, lr:  0.001655, elapsed time:  10974
Step 22900, loss: 0.03564770103315823, acc: 98.93458716571331, p_norm: 1135.6261204121054, g_norm: 0.24355599341176729, lr:  0.001652, elapsed time:  11020
Step 23000, loss: 0.0334739668565453, acc: 98.99266190826893, p_norm: 1137.716851343407, g_norm: 0.35183116304733936, lr:  0.001648, elapsed time:  11067
Step 23100, loss: 0.0356244075554423, acc: 98.93406672775745, p_norm: 1139.8831796414477, g_norm: 0.19363680306540712, lr:  0.001644, elapsed time:  11114
Step 23200, loss: 0.035253143067238854, acc: 98.95105373859406, p_norm: 1141.9008082919156, g_norm: 0.19105562019733197, lr:  0.001641, elapsed time:  11160
Step 23300, loss: 0.03586843630590011, acc: 98.93853521347046, p_norm: 1144.0543794677767, g_norm: 0.1668303527313218, lr:  0.001637, elapsed time:  11207
Step 23400, loss: 0.034253659326350314, acc: 98.98179788887501, p_norm: 1146.0185999762386, g_norm: 0.2036403548089584, lr:  0.001634, elapsed time:  11254
Step 23500, loss: 0.034540206009987744, acc: 98.98127311468124, p_norm: 1148.1251275917512, g_norm: 0.2709690639029372, lr:  0.001630, elapsed time:  11301
Step 23600, loss: 0.03609753801545594, acc: 98.92892025411129, p_norm: 1150.1656059625657, g_norm: 0.21446584868038746, lr:  0.001627, elapsed time:  11347
Step 23700, loss: 0.03478811060253065, acc: 98.96588306128979, p_norm: 1152.0950201935627, g_norm: 0.23444537484789524, lr:  0.001623, elapsed time:  11394
Step 23800, loss: 0.03552709051931743, acc: 98.93687771260738, p_norm: 1154.1520317812701, g_norm: 0.27054294445549987, lr:  0.001620, elapsed time:  11441
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 23900, loss: 0.0360967140530111, acc: 98.93186999790704, p_norm: 1156.2689986471078, g_norm: 0.22930041661394443, lr:  0.001617, elapsed time:  11488
Step 24000, loss: 0.03370811034110375, acc: 98.99713635444641, p_norm: 1158.2687995942117, g_norm: 0.19766877084654777, lr:  0.001613, elapsed time:  11535
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 24000, eval loss: 0.026486698664957647, eval acc: 99.26822662353516
Step 24100, loss: 0.033610767598147503, acc: 98.99208809435368, p_norm: 1160.2971815691337, g_norm: 0.1785267400730433, lr:  0.001610, elapsed time:  11589
Step 24200, loss: 0.03569745543412864, acc: 98.92508262395859, p_norm: 1162.3063111280856, g_norm: 0.20159850427648984, lr:  0.001607, elapsed time:  11635
Step 24300, loss: 0.03351583528608899, acc: 98.99958334863186, p_norm: 1164.2265019478073, g_norm: 0.2732620393548151, lr:  0.001603, elapsed time:  11682
Step 24400, loss: 0.03318349842098542, acc: 99.00626353919506, p_norm: 1166.127604532981, g_norm: 0.29180572376890485, lr:  0.001600, elapsed time:  11728
Step 24500, loss: 0.03355579585477244, acc: 98.9982126057148, p_norm: 1168.068240895827, g_norm: 0.2440933616678657, lr:  0.001597, elapsed time:  11775
Step 24600, loss: 0.03346318308846094, acc: 99.0035896897316, p_norm: 1170.0941906437636, g_norm: 0.19112109392309296, lr:  0.001593, elapsed time:  11822
Step 24700, loss: 0.03389750695438124, acc: 98.98628088831902, p_norm: 1172.0015201782744, g_norm: 0.21531125411960916, lr:  0.001590, elapsed time:  11869
Step 24800, loss: 0.03367513207893353, acc: 98.98906660079956, p_norm: 1174.105724615468, g_norm: 0.3099295527437294, lr:  0.001587, elapsed time:  11916
Step 24900, loss: 0.033825227142660876, acc: 98.99747423827648, p_norm: 1176.0439869304669, g_norm: 0.2823910572749714, lr:  0.001584, elapsed time:  11963
Step 25000, loss: 0.033343133892049084, acc: 99.004649117589, p_norm: 1177.8732404135778, g_norm: 0.2666389199491091, lr:  0.001581, elapsed time:  12009
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C # C C ( C ) c 1 c c c c c 1 C ( = O ) c 1 o c n c 1 C _EOS
Predicted text: C # C C ( C ) c 1 c c c c c 1 C ( = O ) c 1 o c n c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C ( C C ( N ) C O ) c 1 c c c ( Cl ) c c 1 _EOS
Predicted text: C C C ( C C ( N ) C O ) c 1 c c c ( Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C O C ( C ) O N C ( = O ) c 1 c c 2 c c c ( C = O ) c c 2 s 1 _EOS
Predicted text: C C ( C ) C O C ( C ) O N C ( = O ) c 1 c c 2 c c c ( C = O ) c c 2 s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c n c ( - c 2 c c c ( C ) n c 2 ) c ( Cl ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c n c ( - c 2 c c c ( C ) n c 2 ) c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( C ) C N ( c 2 c c c ( C ( = O ) N 3 C C N ( c 4 n c c ( C 5 C C 5 ) c c 4 C 4 C C 4 ) C C 3 ) c c 2 ) C ( = O ) O 1 _EOS
Predicted text: C C 1 ( C ) C N ( c 2 c c c ( C ( = O ) N 3 C C N ( c 4 n c c ( C 5 C C 5 ) c c 4 C 4 C C 4 ) C C 3 ) c c 2 ) C ( = O ) O 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 25000, eval acc (token): 0.8956367303509151, eval acc (sequence): 0.809989521480964
Saving at step 25000
Step 25100, loss: 0.0336269924393855, acc: 99.0024119913578, p_norm: 1179.838017625747, g_norm: 0.322416544852212, lr:  0.001578, elapsed time:  12107
Step 25200, loss: 0.03351610952988267, acc: 98.9918750077486, p_norm: 1181.7285239539235, g_norm: 0.23571170670258598, lr:  0.001574, elapsed time:  12154
Step 25300, loss: 0.03312548937276006, acc: 99.0236865580082, p_norm: 1183.5714416731569, g_norm: 0.20044837963233061, lr:  0.001571, elapsed time:  12201
Step 25400, loss: 0.03408001814852469, acc: 98.99143545329571, p_norm: 1185.3698846776504, g_norm: 0.2947301969886561, lr:  0.001568, elapsed time:  12247
Step 25500, loss: 0.03386781124572735, acc: 98.98693081736565, p_norm: 1187.274534442429, g_norm: 0.1769714918016338, lr:  0.001565, elapsed time:  12294
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 25600, loss: 0.03474657049180189, acc: 98.97013932318237, p_norm: 1189.1116293779453, g_norm: 0.21187017556195076, lr:  0.001562, elapsed time:  12341
Step 25700, loss: 0.033129042412037964, acc: 98.99666176736355, p_norm: 1191.1550751957918, g_norm: 0.18471321325984189, lr:  0.001559, elapsed time:  12387
Step 25800, loss: 0.03289586292405147, acc: 99.0071271955967, p_norm: 1193.09321142234, g_norm: 0.2028317062604676, lr:  0.001556, elapsed time:  12434
Step 25900, loss: 0.032436640206724404, acc: 99.03346891701221, p_norm: 1194.884841187271, g_norm: 0.19484894020052093, lr:  0.001553, elapsed time:  12482
Step 26000, loss: 0.03256581434427062, acc: 99.01820732653141, p_norm: 1196.6701926413969, g_norm: 0.19942553570974195, lr:  0.001550, elapsed time:  12528
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 26000, eval loss: 0.02678547853050987, eval acc: 99.25214385986328
Step 26100, loss: 0.03314651317079551, acc: 99.00716185569763, p_norm: 1198.3970656686438, g_norm: 0.2631561486158338, lr:  0.001547, elapsed time:  12582
Step 26200, loss: 0.03162397962529212, acc: 99.0648348480463, p_norm: 1200.154765229796, g_norm: 0.21613921304822067, lr:  0.001544, elapsed time:  12629
Step 26300, loss: 0.03228253918554401, acc: 99.03762172162533, p_norm: 1201.9472066696385, g_norm: 0.2372975233721141, lr:  0.001541, elapsed time:  12676
Step 26400, loss: 0.03226357767824083, acc: 99.04763035476208, p_norm: 1203.6016718072162, g_norm: 0.5832734304565987, lr:  0.001538, elapsed time:  12722
Step 26500, loss: 0.03290186683414504, acc: 99.02243901789188, p_norm: 1205.4189988373435, g_norm: 0.2570536948167913, lr:  0.001535, elapsed time:  12768
Step 26600, loss: 0.03264004783646669, acc: 99.02460387349129, p_norm: 1207.1819128046816, g_norm: 0.1867402049803804, lr:  0.001532, elapsed time:  12815
Step 26700, loss: 0.03284442760923412, acc: 99.00733526051044, p_norm: 1209.0307477853619, g_norm: 0.1881410290558966, lr:  0.001530, elapsed time:  12862
Step 26800, loss: 0.03252120338845998, acc: 99.02637274563313, p_norm: 1210.7736058075348, g_norm: 0.1878811872958859, lr:  0.001527, elapsed time:  12909
Step 26900, loss: 0.032032701085554435, acc: 99.05270454287529, p_norm: 1212.401683396498, g_norm: 0.23873986753285184, lr:  0.001524, elapsed time:  12956
Step 27000, loss: 0.031192441085586324, acc: 99.0660803169012, p_norm: 1214.061635015227, g_norm: 0.18516279642473488, lr:  0.001521, elapsed time:  13003
Step 27100, loss: 0.03317519779870054, acc: 99.02313415706158, p_norm: 1215.8658236445706, g_norm: 0.22341955145576672, lr:  0.001518, elapsed time:  13049
Step 27200, loss: 0.03110046642133966, acc: 99.07289573550224, p_norm: 1217.504571118494, g_norm: 0.23568683048586975, lr:  0.001515, elapsed time:  13097
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 27300, loss: 0.03121843876169241, acc: 99.07203791455063, p_norm: 1219.2467499711838, g_norm: 0.21953072399356577, lr:  0.001513, elapsed time:  13145
Step 27400, loss: 0.02971892771718558, acc: 99.11346474289894, p_norm: 1220.8669990899023, g_norm: 0.3174921627386105, lr:  0.001510, elapsed time:  13192
Step 27500, loss: 0.03134087025129702, acc: 99.06896960735321, p_norm: 1222.5719134888125, g_norm: 0.27044429506844947, lr:  0.001507, elapsed time:  13238
Step 27600, loss: 0.03083677846210776, acc: 99.08039003610611, p_norm: 1224.179592556614, g_norm: 0.2358892161209422, lr:  0.001504, elapsed time:  13284
Step 27700, loss: 0.030898564467352115, acc: 99.08696207404137, p_norm: 1225.9170763431998, g_norm: 0.2272275680382909, lr:  0.001502, elapsed time:  13331
Step 27800, loss: 0.030859882216900586, acc: 99.08240760862827, p_norm: 1227.5897168716617, g_norm: 0.29780783220835144, lr:  0.001499, elapsed time:  13378
Step 27900, loss: 0.030165868861367927, acc: 99.09968021512032, p_norm: 1229.174302365969, g_norm: 0.18664435708893684, lr:  0.001496, elapsed time:  13424
Step 28000, loss: 0.030837645209103356, acc: 99.07809768617153, p_norm: 1230.8294304455592, g_norm: 0.254197807802821, lr:  0.001494, elapsed time:  13472
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 28000, eval loss: 0.026746706446283488, eval acc: 99.2860107421875
Step 28100, loss: 0.030886168311117217, acc: 99.06901967525482, p_norm: 1232.5526539783007, g_norm: 0.23855630487724122, lr:  0.001491, elapsed time:  13526
Step 28200, loss: 0.03217762038621004, acc: 99.04025480151176, p_norm: 1234.2174656864981, g_norm: 0.3808611738978088, lr:  0.001488, elapsed time:  13572
Step 28300, loss: 0.031076949147391134, acc: 99.06891542673111, p_norm: 1235.8324049206547, g_norm: 0.3206624031384183, lr:  0.001486, elapsed time:  13619
Step 28400, loss: 0.03152510181127582, acc: 99.06239205598831, p_norm: 1237.4348941506905, g_norm: 0.2874002037260455, lr:  0.001483, elapsed time:  13667
Step 28500, loss: 0.031542529760627075, acc: 99.06098462641239, p_norm: 1238.977608891501, g_norm: 0.24434530683506073, lr:  0.001480, elapsed time:  13714
Step 28600, loss: 0.030938323176233098, acc: 99.09146194159985, p_norm: 1240.5148780612315, g_norm: 0.2104372881096119, lr:  0.001478, elapsed time:  13760
Step 28700, loss: 0.03280471510253847, acc: 99.02578400075436, p_norm: 1242.125923738671, g_norm: 0.28882769504807254, lr:  0.001475, elapsed time:  13807
Step 28800, loss: 0.031239569313474932, acc: 99.06402206420898, p_norm: 1243.7794542846661, g_norm: 0.21694159549477246, lr:  0.001473, elapsed time:  13854
Step 28900, loss: 0.029678652193688322, acc: 99.1226489841938, p_norm: 1245.2865548651503, g_norm: 0.22981804547076634, lr:  0.001470, elapsed time:  13901
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 29000, loss: 0.03208572881194594, acc: 99.05490888555352, p_norm: 1246.9807092903902, g_norm: 0.2373831483544856, lr:  0.001468, elapsed time:  13948
Step 29100, loss: 0.028980590791616124, acc: 99.14447635412216, p_norm: 1248.448982455782, g_norm: 0.2984902757518465, lr:  0.001465, elapsed time:  13994
Step 29200, loss: 0.029794463588332293, acc: 99.11728623509407, p_norm: 1249.9548020157504, g_norm: 0.29387399696541705, lr:  0.001463, elapsed time:  14041
Step 29300, loss: 0.028985696299059782, acc: 99.131939843297, p_norm: 1251.4970764075463, g_norm: 0.2284697528296827, lr:  0.001460, elapsed time:  14088
Step 29400, loss: 0.03034722717158729, acc: 99.08408491313457, p_norm: 1253.1228777236981, g_norm: 0.27185722038420473, lr:  0.001458, elapsed time:  14135
Step 29500, loss: 0.030164954366046003, acc: 99.09601694345474, p_norm: 1254.6359273546318, g_norm: 0.22357088351869236, lr:  0.001455, elapsed time:  14181
Step 29600, loss: 0.030747937328414993, acc: 99.08561491966248, p_norm: 1256.1875860544135, g_norm: 0.20942222007817063, lr:  0.001453, elapsed time:  14228
Step 29700, loss: 0.029534474632819184, acc: 99.11569607257843, p_norm: 1257.7120069277676, g_norm: 0.22185000206117428, lr:  0.001450, elapsed time:  14275
Step 29800, loss: 0.03047055912320502, acc: 99.09079776704311, p_norm: 1259.3012451637642, g_norm: 0.20275200180515757, lr:  0.001448, elapsed time:  14321
Step 29900, loss: 0.02882110148377251, acc: 99.12782447040081, p_norm: 1260.7820840693878, g_norm: 0.20077148973303935, lr:  0.001445, elapsed time:  14369
Step 30000, loss: 0.030380851469235495, acc: 99.10526560246944, p_norm: 1262.2635757174498, g_norm: 0.23970521120845423, lr:  0.001443, elapsed time:  14415
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 30000, eval loss: 0.022758070118725302, eval acc: 99.3415298461914
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C O C ( = O ) N 1 c 2 c c c ( O C ) n c 2 C ( N c 2 n c c ( C C C ( = O ) O ) c ( C c 3 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 3 ) n 2 ) C C 1 C C _EOS
Predicted text: C C O C ( = O ) N 1 c 2 c c c ( O C ) n c 2 C ( N c 2 n c c ( C C C ( = O ) O ) c ( C c 3 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 3 ) n 2 ) C C 1 C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) N 1 O C ( C ) ( c 2 c c ( Cl ) c c ( Cl ) c 2 ) C = C 1 c 1 c c c ( C ( = O ) O C ( C ) ( C ) C ) c ( C ) c 1 _EOS
Predicted text: C O C ( = O ) C c 1 c c ( C 2 = N O C ( C ) ( c 3 c c ( Cl ) c c ( Cl ) c 3 ) C 2 ) c c c 1 C ( = O ) O C ( C ) ( C ) C _EOS _PAD _PAD
acc_token: 0.24193548387096775, acc_seq: False

Target text: C C N ( C C ) C C # C c 1 c c 2 n c c c ( O c 3 c c c ( N ) c ( C ) c 3 ) c 2 s 1 _EOS
Predicted text: C C N ( C C ) C C # C c 1 c c 2 n c c c ( O c 3 c c c ( N ) c ( C ) c 3 ) c 2 s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c ( C ( F ) ( F ) F ) c c c 1 C ( = O ) Cl _EOS
Predicted text: C c 1 n c ( C ( F ) ( F ) F ) c c c 1 C ( = O ) Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 C C C ( = O ) N 1 C c 1 c c ( O C ) c ( C ( C ) ( C ) C ) c c 1 - c 1 c c c n c 1 O C c 1 c c c c c 1 _EOS
Predicted text: C C O C ( = O ) C 1 C C C ( = O ) N 1 C c 1 c c ( O C ) c ( C ( C ) ( C ) C ) c c 1 - c 1 c c c n c 1 O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 30000, eval acc (token): 0.9103089232444799, eval acc (sequence): 0.8405868776788659
Saving at step 30000
Step 30100, loss: 0.029655514604819473, acc: 99.11555871367455, p_norm: 1263.7343734162318, g_norm: 0.21769661744541027, lr:  0.001441, elapsed time:  14518
Step 30200, loss: 0.02967119118780829, acc: 99.11665984988213, p_norm: 1265.2202330255086, g_norm: 0.2720587246960397, lr:  0.001438, elapsed time:  14565
Step 30300, loss: 0.030525079006911256, acc: 99.09219594299793, p_norm: 1266.7580052841804, g_norm: 0.24402072987072163, lr:  0.001436, elapsed time:  14612
Step 30400, loss: 0.029961978832725434, acc: 99.11373654007912, p_norm: 1268.2019567408615, g_norm: 0.2020278043058462, lr:  0.001433, elapsed time:  14658
Step 30500, loss: 0.02942138476821128, acc: 99.11977389454842, p_norm: 1269.7560184975594, g_norm: 0.19246006249220896, lr:  0.001431, elapsed time:  14705
Step 30600, loss: 0.031173292165331077, acc: 99.06664235889912, p_norm: 1271.292976047025, g_norm: 0.2826998770671696, lr:  0.001429, elapsed time:  14752
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 30700, loss: 0.02950585938449348, acc: 99.12190305683808, p_norm: 1272.8376794795672, g_norm: 0.2345822872714704, lr:  0.001426, elapsed time:  14799
Step 30800, loss: 0.029433809057809412, acc: 99.11593337357044, p_norm: 1274.3531283659247, g_norm: 0.23546793252803871, lr:  0.001424, elapsed time:  14846
Step 30900, loss: 0.027451629213173873, acc: 99.17816372215748, p_norm: 1275.723156258327, g_norm: 0.1994796263465764, lr:  0.001422, elapsed time:  14893
Step 31000, loss: 0.02896053011325421, acc: 99.13267010450363, p_norm: 1277.1003404684486, g_norm: 0.2421430049638493, lr:  0.001419, elapsed time:  14940
Step 31100, loss: 0.027457010375801474, acc: 99.18387915194035, p_norm: 1278.502691900403, g_norm: 0.20211960285707886, lr:  0.001417, elapsed time:  14987
Step 31200, loss: 0.029698045148397797, acc: 99.10421292483807, p_norm: 1280.0167085838043, g_norm: 0.2735107803587808, lr:  0.001415, elapsed time:  15033
Step 31300, loss: 0.028567524641402997, acc: 99.14821587502956, p_norm: 1281.4171150965997, g_norm: 0.20126385423619064, lr:  0.001413, elapsed time:  15080
Step 31400, loss: 0.028391343775438144, acc: 99.15724483132362, p_norm: 1282.8044692317058, g_norm: 0.24105008887277818, lr:  0.001410, elapsed time:  15127
Step 31500, loss: 0.02810045679449104, acc: 99.16946794092655, p_norm: 1284.2473402292499, g_norm: 0.2637985392716324, lr:  0.001408, elapsed time:  15173
Step 31600, loss: 0.030139298146386863, acc: 99.09782980382442, p_norm: 1285.7742979817426, g_norm: 0.20132226912917173, lr:  0.001406, elapsed time:  15220
Step 31700, loss: 0.028698933990090155, acc: 99.14064463973045, p_norm: 1287.1719915829708, g_norm: 0.1930455764374134, lr:  0.001404, elapsed time:  15267
Step 31800, loss: 0.028668032556015532, acc: 99.13915637135506, p_norm: 1288.5980410865652, g_norm: 0.20347262194852903, lr:  0.001402, elapsed time:  15313
Step 31900, loss: 0.029500995788403088, acc: 99.12641768157482, p_norm: 1289.9328227248755, g_norm: 0.20926804360581494, lr:  0.001399, elapsed time:  15360
Step 32000, loss: 0.030170862145605496, acc: 99.0966362208128, p_norm: 1291.322286549065, g_norm: 0.18155953592838514, lr:  0.001397, elapsed time:  15406
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 32000, eval loss: 0.020993255300272726, eval acc: 99.43023681640625
Step 32100, loss: 0.029821658897562883, acc: 99.11808663606644, p_norm: 1292.8030669719487, g_norm: 0.2574388632130054, lr:  0.001395, elapsed time:  15460
Step 32200, loss: 0.02943774410057813, acc: 99.1274846047163, p_norm: 1294.180050721411, g_norm: 0.23338636789315167, lr:  0.001393, elapsed time:  15506
Step 32300, loss: 0.029435372387815732, acc: 99.12040777504444, p_norm: 1295.6406485729121, g_norm: 0.20631334615716895, lr:  0.001391, elapsed time:  15553
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 32400, loss: 0.029990803611680876, acc: 99.10623756590907, p_norm: 1297.0083908773393, g_norm: 0.21107895104819183, lr:  0.001388, elapsed time:  15601
Step 32500, loss: 0.02761053135880502, acc: 99.17333571612835, p_norm: 1298.3253955485752, g_norm: 0.24805096812702498, lr:  0.001386, elapsed time:  15648
Step 32600, loss: 0.02821243401354877, acc: 99.15695950388908, p_norm: 1299.6603181001142, g_norm: 0.21096244748325485, lr:  0.001384, elapsed time:  15694
Step 32700, loss: 0.026556232098955662, acc: 99.20182679593563, p_norm: 1300.9839951231122, g_norm: 0.21087228911958825, lr:  0.001382, elapsed time:  15741
Step 32800, loss: 0.02722791461943416, acc: 99.20142669975758, p_norm: 1302.2744556163098, g_norm: 0.168914401162643, lr:  0.001380, elapsed time:  15787
Step 32900, loss: 0.029325612434186042, acc: 99.12709987163544, p_norm: 1303.7928107592918, g_norm: 0.18731170217679308, lr:  0.001378, elapsed time:  15834
Step 33000, loss: 0.0282197202462703, acc: 99.148113951087, p_norm: 1305.0853497082198, g_norm: 0.20014365237935008, lr:  0.001376, elapsed time:  15880
Step 33100, loss: 0.026938239516020986, acc: 99.19421242177486, p_norm: 1306.3150869080082, g_norm: 0.219077551041752, lr:  0.001374, elapsed time:  15927
Step 33200, loss: 0.0272388825181406, acc: 99.18921786546707, p_norm: 1307.6221077835824, g_norm: 0.20332413180228284, lr:  0.001372, elapsed time:  15974
Step 33300, loss: 0.02795685721153859, acc: 99.17435498535633, p_norm: 1308.944155518539, g_norm: 0.2963369348636192, lr:  0.001370, elapsed time:  16020
Step 33400, loss: 0.027557035575155167, acc: 99.17481948435307, p_norm: 1310.3236691457369, g_norm: 0.21194785448558603, lr:  0.001368, elapsed time:  16068
Step 33500, loss: 0.027384627443389035, acc: 99.17799632251263, p_norm: 1311.59752259316, g_norm: 0.2653763446026276, lr:  0.001365, elapsed time:  16114
Step 33600, loss: 0.02890334885378252, acc: 99.13666385412216, p_norm: 1312.9311558628124, g_norm: 0.17861006281394096, lr:  0.001363, elapsed time:  16161
Step 33700, loss: 0.028335268713417464, acc: 99.15330618619919, p_norm: 1314.323832668163, g_norm: 0.3021921828600622, lr:  0.001361, elapsed time:  16207
Step 33800, loss: 0.027794632973673288, acc: 99.16105502843857, p_norm: 1315.56961798763, g_norm: 0.20247917136891516, lr:  0.001359, elapsed time:  16254
Step 33900, loss: 0.028608995166723616, acc: 99.14183577895164, p_norm: 1316.8809517681118, g_norm: 0.2674380143452381, lr:  0.001357, elapsed time:  16301
Step 34000, loss: 0.02884867874032352, acc: 99.12710718810558, p_norm: 1318.2046450159764, g_norm: 0.18832377628227281, lr:  0.001355, elapsed time:  16348
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 34000, eval loss: 0.024526148082804868, eval acc: 99.34186553955078
Step 34100, loss: 0.028248154677567073, acc: 99.15218676626682, p_norm: 1319.5704590791622, g_norm: 0.22087158413931537, lr:  0.001353, elapsed time:  16401
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 34200, loss: 0.0274484170255001, acc: 99.17836806074304, p_norm: 1320.8489858945263, g_norm: 0.2465953660079243, lr:  0.001351, elapsed time:  16449
Step 34300, loss: 0.026151197026774754, acc: 99.20923382043839, p_norm: 1322.0728467652389, g_norm: 0.1728958699938215, lr:  0.001349, elapsed time:  16496
Step 34400, loss: 0.02776668722741306, acc: 99.17216205596924, p_norm: 1323.4485453890663, g_norm: 0.20494818716295335, lr:  0.001347, elapsed time:  16543
Step 34500, loss: 0.026709627982927486, acc: 99.19378519058228, p_norm: 1324.7588179494974, g_norm: 0.33973951414608694, lr:  0.001346, elapsed time:  16589
Step 34600, loss: 0.027700432360870764, acc: 99.1711840480566, p_norm: 1326.0143449047907, g_norm: 0.16995930525374608, lr:  0.001344, elapsed time:  16635
Step 34700, loss: 0.026996357653697487, acc: 99.18454405665398, p_norm: 1327.2444403373302, g_norm: 0.23416125855046624, lr:  0.001342, elapsed time:  16682
Step 34800, loss: 0.027452613292552996, acc: 99.17724426090717, p_norm: 1328.503101740105, g_norm: 0.21086063103092295, lr:  0.001340, elapsed time:  16728
Step 34900, loss: 0.026930812953796703, acc: 99.1979708224535, p_norm: 1329.732869869392, g_norm: 0.2528193226776524, lr:  0.001338, elapsed time:  16775
Step 35000, loss: 0.027578712274553253, acc: 99.17104250192642, p_norm: 1331.06433982451, g_norm: 0.21357747897628937, lr:  0.001336, elapsed time:  16822
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C O c 1 c ( O ) c c ( Br ) c c 1 C ( C ) ( C ) C _EOS
Predicted text: C O C O c 1 c ( O ) c c ( Br ) c c 1 C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C C = C C C C C C C C C O C C ( O ) C O C C C C C C C C C = C C C C C C C C C _EOS
Predicted text: C C C C C C C C C = C C C C C C C C C O C C ( O ) C O C C C C C C C C C = C C C C C C C C C _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c c c 2 [nH] c c ( C C N ) c 2 c 1 _EOS
Predicted text: N # C c 1 c c c 2 [nH] c c ( C C N ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( C ( N C ( = O ) C c 2 c c c ( C = O ) c c 2 ) c 2 c c c c c 2 N 2 C C C C C 2 ) c c 1 _EOS
Predicted text: C c 1 c c c ( C ( N C ( = O ) C c 2 c c c ( C = O ) c c 2 ) c 2 c c c c c 2 N 2 C C C C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N C ( = O ) N N ( C ) C C ( = O ) N C ( C ) C ( = O ) N ( C c 1 c s c 2 c c c c c 1 2 ) C ( C ) C ( O C C ) O C C _EOS
Predicted text: C C N C ( = O ) N N ( C ) C C ( = O ) N C ( C ) C ( = O ) N ( C c 1 c s c 2 c c c c c 1 2 ) C ( C ) C ( O C C ) O C C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 35000, eval acc (token): 0.9141518220965728, eval acc (sequence): 0.8466111771700356
Saving at step 35000
Step 35100, loss: 0.027465861607925034, acc: 99.17532512545586, p_norm: 1332.3047972395732, g_norm: 0.2080762941807134, lr:  0.001334, elapsed time:  16918
Step 35200, loss: 0.027171921892731918, acc: 99.18213857710361, p_norm: 1333.57817536343, g_norm: 0.251202624480238, lr:  0.001332, elapsed time:  16966
Step 35300, loss: 0.027845708850654773, acc: 99.16020546853542, p_norm: 1334.8032625015253, g_norm: 0.20416673191526566, lr:  0.001330, elapsed time:  17013
Step 35400, loss: 0.027471343902288937, acc: 99.17890991270542, p_norm: 1336.0198968026853, g_norm: 0.18098638562565578, lr:  0.001328, elapsed time:  17059
Step 35500, loss: 0.026875929569941944, acc: 99.19193370640278, p_norm: 1337.1785670784454, g_norm: 0.2176996688586244, lr:  0.001326, elapsed time:  17105
Step 35600, loss: 0.02650416113247047, acc: 99.2128354460001, p_norm: 1338.4312397775836, g_norm: 0.23230893561032367, lr:  0.001325, elapsed time:  17152
Step 35700, loss: 0.027157671137683793, acc: 99.19347067177296, p_norm: 1339.636959561051, g_norm: 0.20692187669176157, lr:  0.001323, elapsed time:  17198
Step 35800, loss: 0.027051501550886314, acc: 99.18022736907005, p_norm: 1340.834997961912, g_norm: 0.22689410768767948, lr:  0.001321, elapsed time:  17245
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 35900, loss: 0.025054323402712984, acc: 99.25375560029822, p_norm: 1342.0334797005296, g_norm: 0.18172741959460653, lr:  0.001319, elapsed time:  17293
Step 36000, loss: 0.025622309031896294, acc: 99.2332508713007, p_norm: 1343.202868354079, g_norm: 0.260467527115491, lr:  0.001317, elapsed time:  17340
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 36000, eval loss: 0.0229908584995428, eval acc: 99.382080078125
Step 36100, loss: 0.025218597366911125, acc: 99.24732153117657, p_norm: 1344.3442733347938, g_norm: 0.17108674591195777, lr:  0.001315, elapsed time:  17394
Step 36200, loss: 0.025582083892659285, acc: 99.2348595559597, p_norm: 1345.489145692856, g_norm: 0.1612152703106667, lr:  0.001314, elapsed time:  17440
Step 36300, loss: 0.025256904868147103, acc: 99.25486551225185, p_norm: 1346.6517695000823, g_norm: 0.18128900234706222, lr:  0.001312, elapsed time:  17487
Step 36400, loss: 0.0268264905383694, acc: 99.18556573987007, p_norm: 1347.8443245744704, g_norm: 0.18597779031513126, lr:  0.001310, elapsed time:  17533
Step 36500, loss: 0.026078766879945762, acc: 99.22377291321754, p_norm: 1348.999161176554, g_norm: 0.18620891054074948, lr:  0.001308, elapsed time:  17579
Step 36600, loss: 0.02615655795787461, acc: 99.21899232268333, p_norm: 1350.1895455068789, g_norm: 0.23969730733643904, lr:  0.001306, elapsed time:  17626
Step 36700, loss: 0.02650964869739255, acc: 99.19930157065392, p_norm: 1351.427360139997, g_norm: 0.29039640317328597, lr:  0.001305, elapsed time:  17673
Step 36800, loss: 0.026239878953201696, acc: 99.21713592112064, p_norm: 1352.62561440542, g_norm: 0.2103755804391526, lr:  0.001303, elapsed time:  17720
Step 36900, loss: 0.026567420556675644, acc: 99.20595513284206, p_norm: 1353.8261720461487, g_norm: 0.20584062661822966, lr:  0.001301, elapsed time:  17767
Step 37000, loss: 0.026779126486508174, acc: 99.20749622583389, p_norm: 1355.047042439395, g_norm: 0.22127971719367662, lr:  0.001299, elapsed time:  17813
Step 37100, loss: 0.02644733019726118, acc: 99.21197035908699, p_norm: 1356.210084485662, g_norm: 0.18824364288506656, lr:  0.001298, elapsed time:  17860
Step 37200, loss: 0.02708898246870376, acc: 99.19230434298515, p_norm: 1357.3501104118743, g_norm: 0.20888370520157967, lr:  0.001296, elapsed time:  17907
Step 37300, loss: 0.026946344989119096, acc: 99.2060019671917, p_norm: 1358.5510342226974, g_norm: 0.2355919523988779, lr:  0.001294, elapsed time:  17953
Step 37400, loss: 0.02659327476663748, acc: 99.2110897153616, p_norm: 1359.6194254528064, g_norm: 0.19329688362718384, lr:  0.001292, elapsed time:  17999
Step 37500, loss: 0.026537727529357652, acc: 99.20890668034554, p_norm: 1360.7116915126262, g_norm: 0.21333666732951362, lr:  0.001291, elapsed time:  18046
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 37600, loss: 0.025790166620927313, acc: 99.23128863768791, p_norm: 1361.8129739945705, g_norm: 0.20866801692606987, lr:  0.001289, elapsed time:  18093
Step 37700, loss: 0.025506834297702882, acc: 99.23335725069046, p_norm: 1363.024129424881, g_norm: 0.16720446628472196, lr:  0.001287, elapsed time:  18140
Step 37800, loss: 0.0253182952105999, acc: 99.23812998831272, p_norm: 1364.137502260561, g_norm: 0.2363379068607542, lr:  0.001285, elapsed time:  18186
Step 37900, loss: 0.025502893526572736, acc: 99.238215431571, p_norm: 1365.3070734652388, g_norm: 0.21171136089255327, lr:  0.001284, elapsed time:  18233
Step 38000, loss: 0.02595455000118818, acc: 99.2168149203062, p_norm: 1366.483254917653, g_norm: 0.1944189576116705, lr:  0.001282, elapsed time:  18279
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 38000, eval loss: 0.024306232276721858, eval acc: 99.37410736083984
Step 38100, loss: 0.025298129797301953, acc: 99.24336187541485, p_norm: 1367.57519572303, g_norm: 0.20696697127313982, lr:  0.001280, elapsed time:  18333
Step 38200, loss: 0.025519472284649965, acc: 99.23943223059177, p_norm: 1368.6607083057893, g_norm: 0.2647795775681863, lr:  0.001279, elapsed time:  18379
Step 38300, loss: 0.025283325011841953, acc: 99.24168227612972, p_norm: 1369.779124639539, g_norm: 0.27679641539317923, lr:  0.001277, elapsed time:  18426
Step 38400, loss: 0.02523753680521622, acc: 99.24809668958187, p_norm: 1370.8603155908936, g_norm: 0.2156646592306935, lr:  0.001275, elapsed time:  18472
Step 38500, loss: 0.025025467024097452, acc: 99.25185111165047, p_norm: 1372.0058252661179, g_norm: 0.19523530302740588, lr:  0.001274, elapsed time:  18519
Step 38600, loss: 0.02638882358383853, acc: 99.21613104641438, p_norm: 1373.194398969493, g_norm: 0.23639018550787352, lr:  0.001272, elapsed time:  18566
Step 38700, loss: 0.025767076322808863, acc: 99.22632649540901, p_norm: 1374.3762894236938, g_norm: 0.2063422352300363, lr:  0.001270, elapsed time:  18613
Step 38800, loss: 0.024402141094615217, acc: 99.26539200544357, p_norm: 1375.4969174627201, g_norm: 0.22399207015557976, lr:  0.001269, elapsed time:  18660
Step 38900, loss: 0.02677505273692077, acc: 99.20181028544903, p_norm: 1376.649938256421, g_norm: 0.23849949112102822, lr:  0.001267, elapsed time:  18707
Step 39000, loss: 0.02694578144350089, acc: 99.1902115792036, p_norm: 1377.7635474888964, g_norm: 0.26016086929192545, lr:  0.001266, elapsed time:  18753
Step 39100, loss: 0.025815014866529963, acc: 99.23340377211571, p_norm: 1378.835282519021, g_norm: 0.2698947057513492, lr:  0.001264, elapsed time:  18799
Step 39200, loss: 0.024524487254675476, acc: 99.2762481123209, p_norm: 1379.8745173247794, g_norm: 0.22002248668689678, lr:  0.001262, elapsed time:  18846
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 39300, loss: 0.023332463162425425, acc: 99.29804287240759, p_norm: 1380.95164277072, g_norm: 0.3591515354238455, lr:  0.001261, elapsed time:  18894
Step 39400, loss: 0.02510684525623219, acc: 99.24321357905865, p_norm: 1382.0029314206854, g_norm: 0.20870581206749345, lr:  0.001259, elapsed time:  18941
Step 39500, loss: 0.025277572183986196, acc: 99.24215193092823, p_norm: 1383.0953333021953, g_norm: 0.36517887082112443, lr:  0.001258, elapsed time:  18987
Step 39600, loss: 0.02410123924331856, acc: 99.27259081602097, p_norm: 1384.1997110331051, g_norm: 0.20539076909039972, lr:  0.001256, elapsed time:  19035
Step 39700, loss: 0.025154889031691708, acc: 99.24445268511772, p_norm: 1385.2976374067164, g_norm: 0.23063606192176775, lr:  0.001254, elapsed time:  19082
Step 39800, loss: 0.024284046544053126, acc: 99.27477076649666, p_norm: 1386.2774529000392, g_norm: 0.2005856225546417, lr:  0.001253, elapsed time:  19128
Step 39900, loss: 0.024699772777967154, acc: 99.25230471789837, p_norm: 1387.3576781051738, g_norm: 0.1925856634406718, lr:  0.001251, elapsed time:  19174
Step 40000, loss: 0.025731607246998463, acc: 99.23284582793713, p_norm: 1388.432933471307, g_norm: 0.23831198627592914, lr:  0.001250, elapsed time:  19221
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 40000, eval loss: 0.020898054370118185, eval acc: 99.4222183227539
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( = O ) N c 1 c c c c ( - c 2 c c c 3 c ( C ( F ) ( F ) F ) c ( C ( = O ) c 4 c c c ( Cl ) c c 4 Cl ) o c 3 c 2 ) c 1 _EOS
Predicted text: C C ( = O ) N c 1 c c c ( Cl ) c 1 - c 1 c c c 2 c ( C ( F ) ( F ) F ) c ( C ( = O ) c 3 c c c ( Cl ) c c 3 Cl ) o c 2 c 1 _EOS
acc_token: 0.36065573770491804, acc_seq: False

Target text: C C O C ( C ( = O ) N C c 1 c c c 2 c ( N ) n [nH] c 2 c 1 ) n 1 c c c c ( N c 2 c c c c c 2 ) c 1 = O _EOS
Predicted text: C C O C ( C ( = O ) N C c 1 c c c 2 c ( N ) n [nH] c 2 c 1 ) n 1 c c c c ( N c 2 c c c c c 2 ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C c 1 c c 2 c c c ( O C C N ) c c 2 n ( C c 2 c c c c c 2 ) c 1 = O _EOS
Predicted text: C O C ( = O ) C c 1 c c 2 c c c ( O C C N ) c c 2 n ( C c 2 c c c c c 2 ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N C ( C N c 1 c c c c ( C ( = O ) O ) c 1 ) C S C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C ( C N c 1 c c c c ( C ( = O ) O ) c 1 ) C S C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C ( Cl ) C 1 ( C ( = O ) O ) C C C C C 1 _EOS
Predicted text: C = C ( Cl ) C 1 ( C ( = O ) O ) C C C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 40000, eval acc (token): 0.9207002132481358, eval acc (sequence): 0.8525738077214232
Saving at step 40000
Step 40100, loss: 0.025985388087865432, acc: 99.22671653330326, p_norm: 1389.5110793688032, g_norm: 0.2118368908418676, lr:  0.001248, elapsed time:  19326
Step 40200, loss: 0.024411397291987668, acc: 99.26356430351734, p_norm: 1390.562768724798, g_norm: 0.19711692474798978, lr:  0.001247, elapsed time:  19373
Step 40300, loss: 0.024979356097610435, acc: 99.24925078451633, p_norm: 1391.594625698987, g_norm: 0.17383444205914197, lr:  0.001245, elapsed time:  19420
Step 40400, loss: 0.024847501103649847, acc: 99.25555919110775, p_norm: 1392.5905176977083, g_norm: 0.2074834698316788, lr:  0.001243, elapsed time:  19466
Step 40500, loss: 0.024331432443868834, acc: 99.27747195959091, p_norm: 1393.5545495892093, g_norm: 0.1764401835803545, lr:  0.001242, elapsed time:  19512
Step 40600, loss: 0.024289050960505848, acc: 99.26909109950066, p_norm: 1394.5890689768435, g_norm: 0.22994492314882464, lr:  0.001240, elapsed time:  19559
Step 40700, loss: 0.02594082971860189, acc: 99.22189089655876, p_norm: 1395.6846196261831, g_norm: 0.20688669334467416, lr:  0.001239, elapsed time:  19606
Step 40800, loss: 0.025700670491787606, acc: 99.23429855704308, p_norm: 1396.751283591744, g_norm: 0.21480599499281783, lr:  0.001237, elapsed time:  19652
Step 40900, loss: 0.024674510458135047, acc: 99.25621505081654, p_norm: 1397.802990388034, g_norm: 0.18045408159545828, lr:  0.001236, elapsed time:  19699
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 41000, loss: 0.02486676145584736, acc: 99.25156244569025, p_norm: 1398.862648837344, g_norm: 0.19519672936884194, lr:  0.001234, elapsed time:  19747
Step 41100, loss: 0.024006977221579292, acc: 99.28318643569946, p_norm: 1399.9013057297548, g_norm: 0.19923816797088492, lr:  0.001233, elapsed time:  19793
Step 41200, loss: 0.024370002169162033, acc: 99.26816882193089, p_norm: 1400.9170836340363, g_norm: 0.21659928908895235, lr:  0.001231, elapsed time:  19840
Step 41300, loss: 0.02386377058806829, acc: 99.28087303042412, p_norm: 1401.9570073567859, g_norm: 0.1968999990071485, lr:  0.001230, elapsed time:  19887
Step 41400, loss: 0.02408069430384785, acc: 99.27844440937042, p_norm: 1402.9781796517332, g_norm: 0.16178891796018333, lr:  0.001228, elapsed time:  19933
Step 41500, loss: 0.02423645092829247, acc: 99.26762862503529, p_norm: 1403.9150737466746, g_norm: 0.2907214533963551, lr:  0.001227, elapsed time:  19980
Step 41600, loss: 0.02348245144385146, acc: 99.29733806848526, p_norm: 1404.9020164642175, g_norm: 0.22007466798246275, lr:  0.001225, elapsed time:  20026
Step 41700, loss: 0.02461490882851649, acc: 99.26178988814354, p_norm: 1405.9592884799995, g_norm: 0.388610152789433, lr:  0.001224, elapsed time:  20073
Step 41800, loss: 0.024773682505474424, acc: 99.26219074428082, p_norm: 1406.9568297201529, g_norm: 0.20776784049294844, lr:  0.001222, elapsed time:  20120
Step 41900, loss: 0.024003843154350762, acc: 99.28156116604805, p_norm: 1408.014048941604, g_norm: 0.198055968471395, lr:  0.001221, elapsed time:  20166
Step 42000, loss: 0.02338812325237086, acc: 99.3053528368473, p_norm: 1408.944193214402, g_norm: 0.19533473089397788, lr:  0.001220, elapsed time:  20216
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 42000, eval loss: 0.022103182572755033, eval acc: 99.37848663330078
Step 42100, loss: 0.024553853034740315, acc: 99.2662837356329, p_norm: 1409.9606755730326, g_norm: 0.14111121721408873, lr:  0.001218, elapsed time:  20271
Step 42200, loss: 0.0246616642238223, acc: 99.25601926445961, p_norm: 1410.9709138212202, g_norm: 0.1994869755642379, lr:  0.001217, elapsed time:  20319
Step 42300, loss: 0.02551943328100606, acc: 99.2351588010788, p_norm: 1412.0291942930687, g_norm: 0.22279123996252703, lr:  0.001215, elapsed time:  20366
Step 42400, loss: 0.024009282085171436, acc: 99.28047761321068, p_norm: 1413.0629549340288, g_norm: 0.18180032557645084, lr:  0.001214, elapsed time:  20420
Step 42500, loss: 0.024534085059858626, acc: 99.26033638417721, p_norm: 1414.0513519663778, g_norm: 0.18619999631372552, lr:  0.001212, elapsed time:  20467
Step 42600, loss: 0.02373741163974046, acc: 99.3024181574583, p_norm: 1415.0404642224958, g_norm: 0.20701338463033742, lr:  0.001211, elapsed time:  20515
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 42700, loss: 0.022821093978771648, acc: 99.30238553667186, p_norm: 1415.9541824146002, g_norm: 0.24584943629320033, lr:  0.001209, elapsed time:  20563
Step 42800, loss: 0.02277852635132149, acc: 99.31510615348816, p_norm: 1416.8426529419346, g_norm: 0.1754999579037317, lr:  0.001208, elapsed time:  20611
Step 42900, loss: 0.023112800030212384, acc: 99.29544369876385, p_norm: 1417.7782987452135, g_norm: 0.20778848432905772, lr:  0.001207, elapsed time:  20659
Step 43000, loss: 0.024389061957772355, acc: 99.27518570423126, p_norm: 1418.80347092737, g_norm: 0.153721227593575, lr:  0.001205, elapsed time:  20706
Step 43100, loss: 0.023186636748869206, acc: 99.30742631852627, p_norm: 1419.7827482656355, g_norm: 0.22045178186556716, lr:  0.001204, elapsed time:  20754
Step 43200, loss: 0.02217327418089553, acc: 99.34322753548622, p_norm: 1420.7221596202328, g_norm: 0.1777121316779376, lr:  0.001202, elapsed time:  20802
Step 43300, loss: 0.023921094012330286, acc: 99.28023733198643, p_norm: 1421.6948983309303, g_norm: 0.24177008592096635, lr:  0.001201, elapsed time:  20849
Step 43400, loss: 0.023587651075067696, acc: 99.28447422385216, p_norm: 1422.7023133607106, g_norm: 0.22152567179270494, lr:  0.001200, elapsed time:  20897
Step 43500, loss: 0.023932938607467803, acc: 99.2826299071312, p_norm: 1423.6767388798094, g_norm: 0.18369208985030308, lr:  0.001198, elapsed time:  20944
Step 43600, loss: 0.02464101002726238, acc: 99.26301848888397, p_norm: 1424.6500446963164, g_norm: 0.17054707571174985, lr:  0.001197, elapsed time:  20992
Step 43700, loss: 0.024221223410277163, acc: 99.27822795510292, p_norm: 1425.6245798159387, g_norm: 0.27987914922994506, lr:  0.001196, elapsed time:  21039
Step 43800, loss: 0.024646390528505435, acc: 99.26540260016918, p_norm: 1426.7103105813935, g_norm: 0.22669740550038195, lr:  0.001194, elapsed time:  21087
Step 43900, loss: 0.0242435398681846, acc: 99.27224713563919, p_norm: 1427.709182975271, g_norm: 0.21184299854989497, lr:  0.001193, elapsed time:  21136
Step 44000, loss: 0.023096277901204304, acc: 99.31265914440155, p_norm: 1428.6154158304992, g_norm: 0.20475663960861704, lr:  0.001191, elapsed time:  21183
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 44000, eval loss: 0.021394152882276102, eval acc: 99.4214096069336
Step 44100, loss: 0.023871022934326903, acc: 99.27607487142086, p_norm: 1429.54607428435, g_norm: 0.2724084826083842, lr:  0.001190, elapsed time:  21237
Step 44200, loss: 0.023863239213824272, acc: 99.28882703185081, p_norm: 1430.4728111310772, g_norm: 0.18455665785931694, lr:  0.001189, elapsed time:  21285
Step 44300, loss: 0.02351703715743497, acc: 99.30337315797806, p_norm: 1431.3714334114152, g_norm: 0.2187945172141903, lr:  0.001187, elapsed time:  21332
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 44400, loss: 0.022278565151395077, acc: 99.34005212251365, p_norm: 1432.219222692439, g_norm: 0.19087353254728173, lr:  0.001186, elapsed time:  21380
Step 44500, loss: 0.02323038650130911, acc: 99.29502359032631, p_norm: 1433.1661642192228, g_norm: 0.22255007619534403, lr:  0.001185, elapsed time:  21428
Step 44600, loss: 0.02246098799689207, acc: 99.32292200624943, p_norm: 1434.084142609992, g_norm: 0.1988921596829898, lr:  0.001183, elapsed time:  21476
Step 44700, loss: 0.02373559389372531, acc: 99.27757565677166, p_norm: 1435.0233314286506, g_norm: 0.1828728009996507, lr:  0.001182, elapsed time:  21524
Step 44800, loss: 0.02282810913224239, acc: 99.3093241751194, p_norm: 1435.9736848016485, g_norm: 0.1904194927403775, lr:  0.001181, elapsed time:  21572
Step 44900, loss: 0.02185819150909083, acc: 99.3365688174963, p_norm: 1436.8756390174105, g_norm: 0.1688358275773962, lr:  0.001179, elapsed time:  21620
Step 45000, loss: 0.024211885443073698, acc: 99.27680841088295, p_norm: 1437.861964772537, g_norm: 0.17732992225706493, lr:  0.001178, elapsed time:  21667
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: N c 1 c c c ( N 2 C C C O C 2 = O ) c c 1 _EOS
Predicted text: N c 1 c c c ( N 2 C C C O C 2 = O ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( S ( C ) ( = O ) = O ) c ( O c 2 c c c c ( S ( F ) ( F ) ( F ) ( F ) F ) c 2 ) c c 1 C _EOS
Predicted text: C O C ( = O ) c 1 c c ( S ( C ) ( = O ) = O ) c ( O c 2 c c c c ( S ( F ) ( F ) ( F ) ( F ) F ) c 2 ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c ( Cl ) c ( C ) c ( C ( C ) = O ) c ( O C C N C 2 C C C C 2 ) c 1 O C C C ( C ) c 1 c c c ( F ) c c 1 _EOS
Predicted text: C O c 1 c ( Cl ) c ( C ) c ( C ( C ) = O ) c ( O C C N C 2 C C C C 2 ) c 1 O C C C ( C ) c 1 c c c ( F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 N c 2 c c c c c 2 C 1 2 C C 2 c 1 c c c 2 c ( C = C c 3 c c n c c 3 ) n [nH] c 2 c 1 _EOS
Predicted text: O = C 1 N c 2 c c c c c 2 C 1 2 C C 2 c 1 c c c 2 c ( C = C c 3 c c n c c 3 ) n [nH] c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C # C C O c 1 n c n c ( N 2 C C ( C ) C C ( C ) C 2 ) c 1 F _EOS
Predicted text: C C # C C O c 1 n c n c ( N 2 C C ( C ) C C ( C ) C 2 ) c 1 F _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 45000, eval acc (token): 0.9123172478003811, eval acc (sequence): 0.8409638554216867
Saving at step 45000
Step 45100, loss: 0.02329240390477935, acc: 99.29762150347233, p_norm: 1438.779942066256, g_norm: 0.24501480515587978, lr:  0.001177, elapsed time:  21767
Step 45200, loss: 0.022568364036851564, acc: 99.32629677653313, p_norm: 1439.6765561398913, g_norm: 0.23563873401635763, lr:  0.001176, elapsed time:  21815
Step 45300, loss: 0.023076027902425265, acc: 99.3136289268732, p_norm: 1440.5715423743522, g_norm: 0.19004973878462902, lr:  0.001174, elapsed time:  21862
Step 45400, loss: 0.023887172297254438, acc: 99.28916129469872, p_norm: 1441.5281837456089, g_norm: 0.22139180955997476, lr:  0.001173, elapsed time:  21910
Step 45500, loss: 0.02270415618797415, acc: 99.31315438449383, p_norm: 1442.372049363024, g_norm: 0.18455888633338435, lr:  0.001172, elapsed time:  21958
Step 45600, loss: 0.023139953157660785, acc: 99.31444075703621, p_norm: 1443.2577434771201, g_norm: 0.1766690520988946, lr:  0.001170, elapsed time:  22006
Step 45700, loss: 0.023374005349178332, acc: 99.30105182528496, p_norm: 1444.1170170557587, g_norm: 0.16723784899573715, lr:  0.001169, elapsed time:  22054
Step 45800, loss: 0.023620117291866336, acc: 99.2908253222704, p_norm: 1445.023283803124, g_norm: 0.17752290693897071, lr:  0.001168, elapsed time:  22101
Step 45900, loss: 0.02346047969709616, acc: 99.29651303589344, p_norm: 1445.963606697031, g_norm: 0.2558368739353501, lr:  0.001167, elapsed time:  22149
Step 46000, loss: 0.02325149736716412, acc: 99.3095361739397, p_norm: 1446.8337952547286, g_norm: 0.2705081788990755, lr:  0.001165, elapsed time:  22197
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 46000, eval loss: 0.020033613187260928, eval acc: 99.45467376708984
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 46100, loss: 0.023309405990679335, acc: 99.29463689896598, p_norm: 1447.73090987913, g_norm: 0.1977103572076263, lr:  0.001164, elapsed time:  22252
Step 46200, loss: 0.021544366403468303, acc: 99.34505401551723, p_norm: 1448.6027657957595, g_norm: 0.19830747639241258, lr:  0.001163, elapsed time:  22299
Step 46300, loss: 0.022150453450594795, acc: 99.33878523111343, p_norm: 1449.5631092974638, g_norm: 0.18912597814473706, lr:  0.001161, elapsed time:  22347
Step 46400, loss: 0.02184817004323122, acc: 99.34437917172909, p_norm: 1450.4360797144, g_norm: 0.2301621169416794, lr:  0.001160, elapsed time:  22395
Step 46500, loss: 0.02254690412839409, acc: 99.31058378517628, p_norm: 1451.3455899643873, g_norm: 0.256971559552432, lr:  0.001159, elapsed time:  22443
Step 46600, loss: 0.023291003249469214, acc: 99.3042242527008, p_norm: 1452.2765503513085, g_norm: 0.22532132439386487, lr:  0.001158, elapsed time:  22491
Step 46700, loss: 0.021826127701788208, acc: 99.33286647498608, p_norm: 1453.1319963890912, g_norm: 0.22314604268881008, lr:  0.001157, elapsed time:  22539
Step 46800, loss: 0.02147641778981779, acc: 99.36195112764835, p_norm: 1453.9543686324769, g_norm: 0.24631064175941308, lr:  0.001155, elapsed time:  22587
Step 46900, loss: 0.023491053639445453, acc: 99.28804434835911, p_norm: 1454.8594517688148, g_norm: 0.27625325908601384, lr:  0.001154, elapsed time:  22635
Step 47000, loss: 0.02257229859729705, acc: 99.32258096337318, p_norm: 1455.746215855273, g_norm: 0.18672714816036995, lr:  0.001153, elapsed time:  22682
Step 47100, loss: 0.021667247204313754, acc: 99.35940138995647, p_norm: 1456.6417937682158, g_norm: 0.21209022627622973, lr:  0.001152, elapsed time:  22731
Step 47200, loss: 0.022237001143366797, acc: 99.32738642394543, p_norm: 1457.510936163038, g_norm: 0.20959960272991188, lr:  0.001150, elapsed time:  22779
Step 47300, loss: 0.0236047444990254, acc: 99.28410790860653, p_norm: 1458.3715274838983, g_norm: 0.19811854803419993, lr:  0.001149, elapsed time:  22826
Step 47400, loss: 0.022225909613771366, acc: 99.33297155797482, p_norm: 1459.207220196762, g_norm: 0.18827655762046963, lr:  0.001148, elapsed time:  22873
Step 47500, loss: 0.022789636812813114, acc: 99.3309134542942, p_norm: 1460.0776206684188, g_norm: 0.21815596456728098, lr:  0.001147, elapsed time:  22921
Step 47600, loss: 0.023335282258922233, acc: 99.30167454481125, p_norm: 1460.9122214842594, g_norm: 0.23000054151363555, lr:  0.001146, elapsed time:  22968
Step 47700, loss: 0.02382815700941137, acc: 99.2807040065527, p_norm: 1461.8065784301657, g_norm: 0.19183627663926464, lr:  0.001144, elapsed time:  23015
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 47800, loss: 0.022135384496221683, acc: 99.3380632796891, p_norm: 1462.6603272582215, g_norm: 0.20981500622373878, lr:  0.001143, elapsed time:  23064
Step 47900, loss: 0.02141909871745156, acc: 99.35665918886662, p_norm: 1463.4456662722653, g_norm: 0.1516644883976287, lr:  0.001142, elapsed time:  23111
Step 48000, loss: 0.021996767152450046, acc: 99.34163019061089, p_norm: 1464.2876068635692, g_norm: 0.20288457706520616, lr:  0.001141, elapsed time:  23159
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 48000, eval loss: 0.020633711252594368, eval acc: 99.4300765991211
Step 48100, loss: 0.021816718416666846, acc: 99.3484607487917, p_norm: 1465.113977433013, g_norm: 0.23381240126664457, lr:  0.001140, elapsed time:  23213
Step 48200, loss: 0.020849103648506572, acc: 99.37803228199482, p_norm: 1466.0304377155685, g_norm: 0.17583209029828906, lr:  0.001138, elapsed time:  23262
Step 48300, loss: 0.02089208750941907, acc: 99.37422807514668, p_norm: 1466.8969627657837, g_norm: 0.23317426661102744, lr:  0.001137, elapsed time:  23310
Step 48400, loss: 0.02295311031746678, acc: 99.31269145011902, p_norm: 1467.74534741077, g_norm: 0.19697098065663537, lr:  0.001136, elapsed time:  23357
Step 48500, loss: 0.022409752470557577, acc: 99.32728128135204, p_norm: 1468.6130217504426, g_norm: 0.26954782663016197, lr:  0.001135, elapsed time:  23405
Step 48600, loss: 0.021826313262281474, acc: 99.35101123154163, p_norm: 1469.4772496051264, g_norm: 0.3086622235023756, lr:  0.001134, elapsed time:  23452
Step 48700, loss: 0.022562919519114075, acc: 99.31889620423317, p_norm: 1470.2849503918026, g_norm: 0.21217163044730553, lr:  0.001133, elapsed time:  23500
Step 48800, loss: 0.022416804249078267, acc: 99.3266616910696, p_norm: 1471.100430730208, g_norm: 0.2200120075978757, lr:  0.001131, elapsed time:  23548
Step 48900, loss: 0.02247863874770701, acc: 99.32315690815449, p_norm: 1471.9049440633921, g_norm: 0.23008630586836204, lr:  0.001130, elapsed time:  23596
Step 49000, loss: 0.022694452413343242, acc: 99.32367840409279, p_norm: 1472.7199676011055, g_norm: 0.22360533373595168, lr:  0.001129, elapsed time:  23643
Step 49100, loss: 0.021764684149529784, acc: 99.3440379947424, p_norm: 1473.547043772817, g_norm: 0.22803182716761522, lr:  0.001128, elapsed time:  23691
Step 49200, loss: 0.02189356371440226, acc: 99.33397732675076, p_norm: 1474.3800977790356, g_norm: 0.20891369828981607, lr:  0.001127, elapsed time:  23739
Step 49300, loss: 0.022584736055869144, acc: 99.31493739783764, p_norm: 1475.2627479058265, g_norm: 0.17283942420125073, lr:  0.001126, elapsed time:  23787
Step 49400, loss: 0.022147109328070656, acc: 99.33205427229404, p_norm: 1476.0315211928175, g_norm: 0.22406350417478962, lr:  0.001124, elapsed time:  23835
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 49500, loss: 0.020812017399420218, acc: 99.37112409778624, p_norm: 1476.7925971930922, g_norm: 0.19301125425522156, lr:  0.001123, elapsed time:  23884
Step 49600, loss: 0.021735859202308347, acc: 99.34637689590454, p_norm: 1477.6030570141263, g_norm: 0.23435110855958227, lr:  0.001122, elapsed time:  23931
Step 49700, loss: 0.021145872829365545, acc: 99.35699348151684, p_norm: 1478.4329685191096, g_norm: 0.20542688806290135, lr:  0.001121, elapsed time:  23979
Step 49800, loss: 0.02124542657380516, acc: 99.35246929526329, p_norm: 1479.272944210943, g_norm: 0.22283870254459184, lr:  0.001120, elapsed time:  24027
Step 49900, loss: 0.021473009763722076, acc: 99.35183230042458, p_norm: 1480.0905161305307, g_norm: 0.16930354797178257, lr:  0.001119, elapsed time:  24075
Step 50000, loss: 0.021757792388962117, acc: 99.35028570890427, p_norm: 1480.9159430593259, g_norm: 0.258865282952484, lr:  0.001118, elapsed time:  24122
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 50000, eval loss: 0.020255862238154804, eval acc: 99.46619415283203
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C N C ( = O ) N c 1 c c c c ( C ( = O ) N c 2 c c c c n 2 ) c 1 _EOS
Predicted text: C N C ( = O ) N c 1 c c c c ( C ( = O ) N c 2 c c c c n 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) N N = C ( c 1 c c c ( Cl ) c c 1 ) c 1 c c c ( C S C ) c c 1 _EOS
Predicted text: C C O C ( = O ) N N = C ( c 1 c c c ( Cl ) c c 1 ) c 1 c c c ( C S C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N C 1 C C C ( C C N 2 C C N ( c 3 c c c c 4 c 3 C C C 4 ) C C 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C 1 C C C ( C C N 2 C C N ( c 3 c c c c 4 c 3 C C C 4 ) C C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) [Si] ( O C c 1 c c ( Br ) c s 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) ( C ) [Si] ( O C c 1 c c ( Br ) c s 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( N C = O ) c 1 c c c 2 c ( c 1 ) n c n 2 - c 1 c c c c ( Br ) c 1 _EOS
Predicted text: C C ( N C = O ) c 1 c c c 2 c ( c 1 ) n c n 2 - c 1 c c c c ( Br ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 50000, eval acc (token): 0.9178060820228645, eval acc (sequence): 0.8509573917543557
Saving at step 50000
Step 50100, loss: 0.020826384852989578, acc: 99.37543034553528, p_norm: 1481.6804393336708, g_norm: 0.17700883922970126, lr:  0.001117, elapsed time:  24230
Step 50200, loss: 0.021435070385341533, acc: 99.348702698946, p_norm: 1482.5750015446342, g_norm: 0.18131446327589498, lr:  0.001115, elapsed time:  24278
Step 50300, loss: 0.021599826774036046, acc: 99.34420038759708, p_norm: 1483.4127826959466, g_norm: 0.26428463841569455, lr:  0.001114, elapsed time:  24326
Step 50400, loss: 0.023158069076016544, acc: 99.30146542191505, p_norm: 1484.2916388810324, g_norm: 0.31038599190577454, lr:  0.001113, elapsed time:  24373
Step 50500, loss: 0.02239425079082139, acc: 99.32329879701138, p_norm: 1485.135210166034, g_norm: 0.19303173962202236, lr:  0.001112, elapsed time:  24421
Step 50600, loss: 0.022021056595258416, acc: 99.33738239109516, p_norm: 1485.9314267833101, g_norm: 0.21414463361595576, lr:  0.001111, elapsed time:  24468
Step 50700, loss: 0.022444476474775002, acc: 99.32570123672485, p_norm: 1486.7275311897488, g_norm: 0.19020167051264483, lr:  0.001110, elapsed time:  24516
Step 50800, loss: 0.021998324123851488, acc: 99.34850598871708, p_norm: 1487.5402083883441, g_norm: 0.2761504000714648, lr:  0.001109, elapsed time:  24563
Step 50900, loss: 0.02131607174378587, acc: 99.36159656941891, p_norm: 1488.291703525022, g_norm: 0.24649453322037224, lr:  0.001108, elapsed time:  24611
Step 51000, loss: 0.021121339749370235, acc: 99.36707308888435, p_norm: 1489.0356348474966, g_norm: 0.15934536496946608, lr:  0.001107, elapsed time:  24659
Step 51100, loss: 0.021803175534078036, acc: 99.34815242886543, p_norm: 1489.8348272355993, g_norm: 0.2118548547176748, lr:  0.001106, elapsed time:  24707
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 51200, loss: 0.02108565880483705, acc: 99.35903067032693, p_norm: 1490.6422726303158, g_norm: 0.20727837789785528, lr:  0.001105, elapsed time:  24756
Step 51300, loss: 0.021127990265522385, acc: 99.36533889174461, p_norm: 1491.430581793995, g_norm: 0.23348215479410422, lr:  0.001103, elapsed time:  24802
Step 51400, loss: 0.019811293073289563, acc: 99.4012263417244, p_norm: 1492.1993666937462, g_norm: 0.1867179447155396, lr:  0.001102, elapsed time:  24850
Step 51500, loss: 0.020932676306401846, acc: 99.37214305996895, p_norm: 1492.9814558389814, g_norm: 0.20561443090738257, lr:  0.001101, elapsed time:  24898
Step 51600, loss: 0.021705614449456335, acc: 99.35051034390926, p_norm: 1493.7968867324073, g_norm: 0.1787934699747607, lr:  0.001100, elapsed time:  24945
Step 51700, loss: 0.021605270261352415, acc: 99.34417697787285, p_norm: 1494.575223247204, g_norm: 0.17556798963774986, lr:  0.001099, elapsed time:  24992
Step 51800, loss: 0.020208986989746335, acc: 99.3941076695919, p_norm: 1495.3668397538563, g_norm: 0.18695920333223878, lr:  0.001098, elapsed time:  25041
Step 51900, loss: 0.02148700391757302, acc: 99.34968857467175, p_norm: 1496.1917964341715, g_norm: 0.20788865835690987, lr:  0.001097, elapsed time:  25089
Step 52000, loss: 0.021678003353590613, acc: 99.34581817686558, p_norm: 1496.9562948220748, g_norm: 0.21797538768231992, lr:  0.001096, elapsed time:  25136
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 52000, eval loss: 0.020499507435597475, eval acc: 99.46060943603516
Step 52100, loss: 0.021034952469053677, acc: 99.3691653907299, p_norm: 1497.7436600273693, g_norm: 0.25503527692636935, lr:  0.001095, elapsed time:  25190
Step 52200, loss: 0.021765516464365645, acc: 99.35067524015903, p_norm: 1498.544695972133, g_norm: 0.19351635305602805, lr:  0.001094, elapsed time:  25237
Step 52300, loss: 0.02166162640307448, acc: 99.35488080978394, p_norm: 1499.3610407648862, g_norm: 0.16818850401880936, lr:  0.001093, elapsed time:  25285
Step 52400, loss: 0.02133964537817519, acc: 99.36706273257732, p_norm: 1500.132133676296, g_norm: 0.16248370288638775, lr:  0.001092, elapsed time:  25332
Step 52500, loss: 0.020993718560494017, acc: 99.3671478331089, p_norm: 1500.875809930489, g_norm: 0.2517337236324641, lr:  0.001091, elapsed time:  25380
Step 52600, loss: 0.02145987337549741, acc: 99.35926446318626, p_norm: 1501.6034081866821, g_norm: 0.2083331938635704, lr:  0.001090, elapsed time:  25428
Step 52700, loss: 0.02106763595918892, acc: 99.36588387191296, p_norm: 1502.4175195775988, g_norm: 0.1887330826825596, lr:  0.001089, elapsed time:  25476
Step 52800, loss: 0.02124675986065995, acc: 99.37377080321312, p_norm: 1503.1728261059036, g_norm: 0.21749671516045188, lr:  0.001088, elapsed time:  25524
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 52900, loss: 0.02130151395796015, acc: 99.3569968796488, p_norm: 1503.9353202045484, g_norm: 0.187463701438922, lr:  0.001087, elapsed time:  25573
Step 53000, loss: 0.02059417437252705, acc: 99.37321400642395, p_norm: 1504.7277047693008, g_norm: 0.19908616188278463, lr:  0.001086, elapsed time:  25620
Step 53100, loss: 0.020745749420602807, acc: 99.37180107831955, p_norm: 1505.461891254593, g_norm: 0.15436920813716157, lr:  0.001085, elapsed time:  25667
Step 53200, loss: 0.020185711186786647, acc: 99.39730483293533, p_norm: 1506.1929575479662, g_norm: 0.231072025286721, lr:  0.001084, elapsed time:  25714
Step 53300, loss: 0.020875198098510735, acc: 99.36010110378265, p_norm: 1506.915969592742, g_norm: 0.15373297030983746, lr:  0.001083, elapsed time:  25762
Step 53400, loss: 0.02093772516163881, acc: 99.36555077135563, p_norm: 1507.6307790995604, g_norm: 0.14029911570332848, lr:  0.001082, elapsed time:  25809
Step 53500, loss: 0.02125120436117868, acc: 99.34824182093143, p_norm: 1508.4278520759826, g_norm: 0.15384261794065157, lr:  0.001081, elapsed time:  25857
Step 53600, loss: 0.02095506364130415, acc: 99.3613819628954, p_norm: 1509.1634072213415, g_norm: 0.2452644056538637, lr:  0.001080, elapsed time:  25904
Step 53700, loss: 0.019636776326151448, acc: 99.40248475968838, p_norm: 1509.9341377001579, g_norm: 0.17403270723259068, lr:  0.001079, elapsed time:  25953
Step 53800, loss: 0.02131253330677282, acc: 99.35666047036648, p_norm: 1510.6736592896102, g_norm: 0.181041522343979, lr:  0.001078, elapsed time:  26000
Step 53900, loss: 0.019936151364818216, acc: 99.40105427801609, p_norm: 1511.406681544777, g_norm: 0.23657679769869008, lr:  0.001077, elapsed time:  26048
Step 54000, loss: 0.020655275161843747, acc: 99.38081282377243, p_norm: 1512.1313093680837, g_norm: 0.2762792037950371, lr:  0.001076, elapsed time:  26095
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 54000, eval loss: 0.019504622803360683, eval acc: 99.5015640258789
Step 54100, loss: 0.021430998651194386, acc: 99.35422237217426, p_norm: 1512.850699170675, g_norm: 0.19687734598712697, lr:  0.001075, elapsed time:  26150
Step 54200, loss: 0.02067150925693568, acc: 99.37858825922012, p_norm: 1513.5941173559297, g_norm: 0.21134772551700864, lr:  0.001074, elapsed time:  26198
Step 54300, loss: 0.02082626920659095, acc: 99.37328538298607, p_norm: 1514.3679763326288, g_norm: 0.26224966850994325, lr:  0.001073, elapsed time:  26246
Step 54400, loss: 0.022173556978814304, acc: 99.3332136720419, p_norm: 1515.129806732112, g_norm: 0.20007577030710633, lr:  0.001072, elapsed time:  26293
Step 54500, loss: 0.02008105635177344, acc: 99.39608359336853, p_norm: 1515.8489267525358, g_norm: 0.23644642182560704, lr:  0.001071, elapsed time:  26341
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 54600, loss: 0.02026218076746804, acc: 99.38353159237857, p_norm: 1516.51345588508, g_norm: 0.2972064950372651, lr:  0.001070, elapsed time:  26389
Step 54700, loss: 0.020117356593545993, acc: 99.38898114860058, p_norm: 1517.229562308984, g_norm: 0.2115324625295696, lr:  0.001069, elapsed time:  26437
Step 54800, loss: 0.020090818918251898, acc: 99.39878652989864, p_norm: 1517.9375102908537, g_norm: 0.18153917148322915, lr:  0.001068, elapsed time:  26484
Step 54900, loss: 0.019874553758345428, acc: 99.4007089883089, p_norm: 1518.722222684386, g_norm: 0.31988976961236115, lr:  0.001067, elapsed time:  26532
Step 55000, loss: 0.019674193278842723, acc: 99.39485251903534, p_norm: 1519.441247836071, g_norm: 0.2069015489993161, lr:  0.001066, elapsed time:  26579
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: O = C 1 c 2 c c c c c 2 C ( = O ) N 1 N C C c 1 c [nH] c 2 c c c c c 1 2 _EOS
Predicted text: O = C 1 c 2 c c c c c 2 C ( = O ) N 1 C C c 1 c [nH] c 2 c c c c c 1 2 _EOS _PAD
acc_token: 0.6666666666666666, acc_seq: False

Target text: C C C ( N c 1 c c ( C ) n c ( O c 2 c ( C ) c c ( Cl ) c c 2 C ) c 1 C ( = O ) O C ) C ( C ) O _EOS
Predicted text: C C C ( N c 1 c c ( C ) n c ( O c 2 c ( C ) c c ( Cl ) c c 2 C ) c 1 C ( = O ) O C ) C ( C ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C N 1 C C C ( N C ( = O ) c 2 c [nH] c 3 c ( - c 4 c ( O C C 5 C C 5 ) c c c 5 c 4 O C O 5 ) n c n c 2 3 ) C C 1 _EOS
Predicted text: O = C N 1 C C C ( N C ( = O ) c 2 c [nH] c 3 c ( - c 4 c ( O C C 5 C C 5 ) c c c 5 c 4 O C O 5 ) n c n c 2 3 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( N ( C ) C ( C ) = O ) c 2 s c ( N C ( = O ) c 3 c c c ( F ) c c 3 ) n c 1 2 _EOS
Predicted text: C O c 1 c c c ( N ( C ) C ( C ) = O ) c 2 s c ( N C ( = O ) c 3 c c c ( F ) c c 3 ) n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N C ( = O ) c 1 c c c ( - n 2 n n c ( C ( = O ) N C 3 C C 3 ) c 2 C = C c 2 c o c ( C ) n 2 ) c c 1 _EOS
Predicted text: C C N C ( = O ) c 1 c c c ( - n 2 n n c ( C ( = O ) N C 3 C C 3 ) c 2 C = C c 2 c o c ( C ) n 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 55000, eval acc (token): 0.9207153991194693, eval acc (sequence): 0.8549942782409677
Saving at step 55000
Step 55100, loss: 0.019979624615516514, acc: 99.40960748493671, p_norm: 1520.1856007498536, g_norm: 0.2536554496967594, lr:  0.001065, elapsed time:  26680
Step 55200, loss: 0.02030420753508224, acc: 99.38921229541302, p_norm: 1520.8993727435393, g_norm: 0.16431626291191792, lr:  0.001064, elapsed time:  26727
Step 55300, loss: 0.020747938372660427, acc: 99.37877108156681, p_norm: 1521.624822753528, g_norm: 0.208033764018982, lr:  0.001063, elapsed time:  26775
Step 55400, loss: 0.02029980169783812, acc: 99.398681640625, p_norm: 1522.3595469855939, g_norm: 0.2047824078072332, lr:  0.001062, elapsed time:  26822
Step 55500, loss: 0.02196466958928795, acc: 99.33701096475124, p_norm: 1523.1181631906925, g_norm: 0.205482667295468, lr:  0.001061, elapsed time:  26869
Step 55600, loss: 0.020368569212878357, acc: 99.38715572655201, p_norm: 1523.8635785352403, g_norm: 0.18718295258905715, lr:  0.001060, elapsed time:  26917
Step 55700, loss: 0.020282608577108476, acc: 99.394037976861, p_norm: 1524.548524550325, g_norm: 0.19754199582599088, lr:  0.001059, elapsed time:  26965
Step 55800, loss: 0.020119578857556917, acc: 99.39492286741734, p_norm: 1525.2187557660295, g_norm: 0.24699529955318913, lr:  0.001058, elapsed time:  27012
Step 55900, loss: 0.019326130684639793, acc: 99.41493947803974, p_norm: 1525.9245225870604, g_norm: 0.18453910088708753, lr:  0.001057, elapsed time:  27060
Step 56000, loss: 0.020933513196359853, acc: 99.36274187266827, p_norm: 1526.6692109547714, g_norm: 0.23629968052062078, lr:  0.001056, elapsed time:  27107
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 56000, eval loss: 0.01883894777914975, eval acc: 99.48361206054688
Step 56100, loss: 0.021339516566076782, acc: 99.35785694420338, p_norm: 1527.3911297086922, g_norm: 0.1631255018888441, lr:  0.001055, elapsed time:  27161
Step 56200, loss: 0.02117113322339719, acc: 99.36259232461452, p_norm: 1528.160005039867, g_norm: 0.23577237296284714, lr:  0.001054, elapsed time:  27209
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 56300, loss: 0.02029434303642151, acc: 99.3872698867883, p_norm: 1528.9191480732907, g_norm: 0.25393350970456247, lr:  0.001053, elapsed time:  27258
Step 56400, loss: 0.020813907105621185, acc: 99.36871886253357, p_norm: 1529.629536448808, g_norm: 0.2213110558586747, lr:  0.001052, elapsed time:  27305
Step 56500, loss: 0.019108467015757923, acc: 99.42704704403877, p_norm: 1530.3026775512008, g_norm: 0.20044360242904302, lr:  0.001051, elapsed time:  27351
Step 56600, loss: 0.020217599930183495, acc: 99.39255777001381, p_norm: 1530.9845264559963, g_norm: 0.21741663732315009, lr:  0.001051, elapsed time:  27397
Step 56700, loss: 0.018386737728942535, acc: 99.44776293635368, p_norm: 1531.6679345382154, g_norm: 0.17677148408489515, lr:  0.001050, elapsed time:  27445
Step 56800, loss: 0.020097412325267214, acc: 99.3950500190258, p_norm: 1532.3562096071053, g_norm: 0.2713393107306425, lr:  0.001049, elapsed time:  27491
Step 56900, loss: 0.019565840852155816, acc: 99.41177371144295, p_norm: 1532.9886441764716, g_norm: 0.1962049449498888, lr:  0.001048, elapsed time:  27537
Step 57000, loss: 0.020606983738689452, acc: 99.37285839021206, p_norm: 1533.7372803071457, g_norm: 0.18631936090778706, lr:  0.001047, elapsed time:  27584
Step 57100, loss: 0.02061756111012073, acc: 99.38109347224236, p_norm: 1534.4151230757939, g_norm: 0.25310047619652115, lr:  0.001046, elapsed time:  27630
Step 57200, loss: 0.01976060229846553, acc: 99.40383467078209, p_norm: 1535.1233447784743, g_norm: 0.2134055409986442, lr:  0.001045, elapsed time:  27677
Step 57300, loss: 0.02015794276012457, acc: 99.39250993728638, p_norm: 1535.813904892376, g_norm: 0.16186180521896787, lr:  0.001044, elapsed time:  27723
Step 57400, loss: 0.02100133186846506, acc: 99.35950891673565, p_norm: 1536.5338787248518, g_norm: 0.21659850187872867, lr:  0.001043, elapsed time:  27770
Step 57500, loss: 0.018579476402665024, acc: 99.4414871186018, p_norm: 1537.1888291784544, g_norm: 0.22721845422044404, lr:  0.001042, elapsed time:  27817
Step 57600, loss: 0.02049027225279133, acc: 99.38029362261295, p_norm: 1537.8621144958722, g_norm: 0.21194655791937722, lr:  0.001041, elapsed time:  27863
Step 57700, loss: 0.02043634825735353, acc: 99.3838108330965, p_norm: 1538.5630308186394, g_norm: 0.19817785669509866, lr:  0.001040, elapsed time:  27910
Step 57800, loss: 0.019817307192643057, acc: 99.40406209230423, p_norm: 1539.2395668365277, g_norm: 0.22627806450106683, lr:  0.001040, elapsed time:  27957
Step 57900, loss: 0.020750011263517082, acc: 99.37836599349976, p_norm: 1539.9611096802676, g_norm: 0.16585727159679453, lr:  0.001039, elapsed time:  28003
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 58000, loss: 0.019710740869490442, acc: 99.39322057492087, p_norm: 1540.6506527568486, g_norm: 0.19243851498271813, lr:  0.001038, elapsed time:  28050
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 58000, eval loss: 0.019703273522027307, eval acc: 99.4946517944336
Step 58100, loss: 0.019017027845548, acc: 99.43256022036076, p_norm: 1541.270491608506, g_norm: 0.1665090741929345, lr:  0.001037, elapsed time:  28103
Step 58200, loss: 0.018512112274765968, acc: 99.4404408633709, p_norm: 1541.8963743464508, g_norm: 0.20382359491197138, lr:  0.001036, elapsed time:  28150
Step 58300, loss: 0.018948077937966445, acc: 99.42551770806313, p_norm: 1542.5902754215472, g_norm: 0.22905798154134013, lr:  0.001035, elapsed time:  28197
Step 58400, loss: 0.020109005681588313, acc: 99.39524953067303, p_norm: 1543.3151690385282, g_norm: 0.22482581124161308, lr:  0.001034, elapsed time:  28243
Step 58500, loss: 0.019624519045464694, acc: 99.40407657623291, p_norm: 1543.993694903025, g_norm: 0.1854131840571749, lr:  0.001033, elapsed time:  28290
Step 58600, loss: 0.020385706914094043, acc: 99.3847384005785, p_norm: 1544.6683303570273, g_norm: 0.2188259032974849, lr:  0.001032, elapsed time:  28337
Step 58700, loss: 0.0194694783668092, acc: 99.41236254572868, p_norm: 1545.336962075864, g_norm: 0.19207931430698733, lr:  0.001032, elapsed time:  28383
Step 58800, loss: 0.019263007055560593, acc: 99.41704533994198, p_norm: 1545.9738643557068, g_norm: 0.16743439475760957, lr:  0.001031, elapsed time:  28430
Step 58900, loss: 0.019477140158487602, acc: 99.41701847314835, p_norm: 1546.6347014131738, g_norm: 0.21206916348951624, lr:  0.001030, elapsed time:  28477
Step 59000, loss: 0.019842241079895757, acc: 99.40442928671837, p_norm: 1547.3471954086874, g_norm: 0.20452711123571982, lr:  0.001029, elapsed time:  28524
Step 59100, loss: 0.020041488302813378, acc: 99.39367265999317, p_norm: 1548.0537948648748, g_norm: 0.22224245744055637, lr:  0.001028, elapsed time:  28570
Step 59200, loss: 0.020425975613470655, acc: 99.38123619556427, p_norm: 1548.799225659391, g_norm: 0.21776909856957297, lr:  0.001027, elapsed time:  28616
Step 59300, loss: 0.020028163997121737, acc: 99.39139235019684, p_norm: 1549.4545510613573, g_norm: 0.17268851567490598, lr:  0.001026, elapsed time:  28663
Step 59400, loss: 0.02062167726631742, acc: 99.37886409461498, p_norm: 1550.076780210158, g_norm: 0.18299836173457895, lr:  0.001025, elapsed time:  28709
Step 59500, loss: 0.019075045307690743, acc: 99.42049185931683, p_norm: 1550.748348837244, g_norm: 0.18686692498482518, lr:  0.001025, elapsed time:  28756
Step 59600, loss: 0.01987642032720032, acc: 99.39562977850437, p_norm: 1551.4379231599632, g_norm: 0.15798116984812385, lr:  0.001024, elapsed time:  28803
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 59700, loss: 0.019713969551958144, acc: 99.40706717760924, p_norm: 1552.0751834222688, g_norm: 0.1890046793908016, lr:  0.001023, elapsed time:  28850
Step 59800, loss: 0.018355592320731376, acc: 99.45038297772408, p_norm: 1552.6887113674125, g_norm: 0.16901840027474685, lr:  0.001022, elapsed time:  28897
Step 59900, loss: 0.01908109804659034, acc: 99.42422372102737, p_norm: 1553.3238820998524, g_norm: 0.17640193983533206, lr:  0.001021, elapsed time:  28943
Step 60000, loss: 0.019309927755675745, acc: 99.42218792438507, p_norm: 1553.9625045373014, g_norm: 0.2856665365992671, lr:  0.001020, elapsed time:  28989
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 60000, eval loss: 0.01678965794202668, eval acc: 99.56062316894531
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C N ( C ) C 1 C C N ( c 2 c c c ( [N+] ( = O ) [O-] ) c ( N ) n 2 ) C C 1 _EOS
Predicted text: C N ( C ) C 1 C C N ( c 2 c c c ( [N+] ( = O ) [O-] ) c ( N ) n 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C ( = O ) c 1 c ( - c 2 c c c ( F ) c c 2 ) o c 2 n c 3 c ( c c 1 2 ) C ( C ) C N ( S ( C ) ( = O ) = O ) C C N 3 S ( C ) ( = O ) = O _EOS
Predicted text: C N C ( = O ) c 1 c ( - c 2 c c c ( F ) c c 2 ) o c 2 n c 3 c ( c c 1 2 ) C ( C O ) C N ( S ( C ) ( = O ) = O ) C C N 3 S ( C ) ( = O ) = O _EOS
acc_token: 0.5857142857142857, acc_seq: False

Target text: O = C ( Cl ) c 1 c c c c c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1 _EOS
Predicted text: O = C ( Cl ) c 1 c c c c c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C 1 C C C ( c 2 c c c ( - c 3 c c ( F ) c ( [N+] ( = O ) [O-] ) c c 3 F ) c c 2 ) C C 1 _EOS
Predicted text: C C C C C C 1 C C C ( c 2 c c c ( - c 3 c c ( F ) c ( [N+] ( = O ) [O-] ) c c 3 F ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C 1 C C ( c 2 c c c ( O C ( F ) F ) c c 2 ) C N ( C ( = O ) N 2 C C S ( = O ) ( = O ) C C 2 ) C 1 _EOS
Predicted text: O = C ( O ) C 1 C C ( c 2 c c c ( O C ( F ) F ) c c 2 ) C N ( C ( = O ) N 2 C C S ( = O ) ( = O ) C C 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 60000, eval acc (token): 0.9240305246339114, eval acc (sequence): 0.8623371924746743
Saving at step 60000
Step 60100, loss: 0.01950170632029767, acc: 99.41983772814274, p_norm: 1554.5999462220093, g_norm: 0.17610371776723244, lr:  0.001019, elapsed time:  29095
Step 60200, loss: 0.02104710450468701, acc: 99.36704698204994, p_norm: 1555.2277674294785, g_norm: 0.2757863213316238, lr:  0.001019, elapsed time:  29141
Step 60300, loss: 0.018939631751563865, acc: 99.43071947991848, p_norm: 1555.8799306405363, g_norm: 0.23314794929597552, lr:  0.001018, elapsed time:  29188
Step 60400, loss: 0.019048987099013176, acc: 99.42207531630993, p_norm: 1556.5297701072088, g_norm: 0.23541675833545134, lr:  0.001017, elapsed time:  29234
Step 60500, loss: 0.019140237115934725, acc: 99.42057454586029, p_norm: 1557.1446741760876, g_norm: 0.17953686976626293, lr:  0.001016, elapsed time:  29281
Step 60600, loss: 0.019262429128721125, acc: 99.4180821031332, p_norm: 1557.8123371867835, g_norm: 0.18787733515654095, lr:  0.001015, elapsed time:  29327
Step 60700, loss: 0.01879614177189069, acc: 99.42253659665585, p_norm: 1558.4832039675885, g_norm: 0.20267576406225832, lr:  0.001014, elapsed time:  29374
Step 60800, loss: 0.019718560261826498, acc: 99.4046933799982, p_norm: 1559.160118010706, g_norm: 0.16355937003528287, lr:  0.001014, elapsed time:  29420
Step 60900, loss: 0.019854797902953577, acc: 99.39982143044472, p_norm: 1559.8316492181223, g_norm: 0.24346277469977068, lr:  0.001013, elapsed time:  29467
Step 61000, loss: 0.018926902672974394, acc: 99.43517357110977, p_norm: 1560.4420182394379, g_norm: 0.2472204844913502, lr:  0.001012, elapsed time:  29513
Step 61100, loss: 0.01940531722691958, acc: 99.41853377223015, p_norm: 1561.111816221445, g_norm: 0.33296973151868825, lr:  0.001011, elapsed time:  29560
Step 61200, loss: 0.019974069123272785, acc: 99.4003005772829, p_norm: 1561.7819787433789, g_norm: 0.15125796530207705, lr:  0.001010, elapsed time:  29607
Step 61300, loss: 0.018869746968266553, acc: 99.42781905829906, p_norm: 1562.40286874161, g_norm: 0.22665101846892474, lr:  0.001009, elapsed time:  29653
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 61400, loss: 0.019553268675532923, acc: 99.41807229524807, p_norm: 1563.0865835300433, g_norm: 0.21124900497879107, lr:  0.001009, elapsed time:  29701
Step 61500, loss: 0.019154627852112752, acc: 99.40622413158417, p_norm: 1563.6967427792354, g_norm: 0.20728526626157856, lr:  0.001008, elapsed time:  29747
Step 61600, loss: 0.01833493798330892, acc: 99.45057512819767, p_norm: 1564.3492838691961, g_norm: 0.2085825842884357, lr:  0.001007, elapsed time:  29795
Step 61700, loss: 0.017498839826439506, acc: 99.47018931806087, p_norm: 1564.9648624147044, g_norm: 0.17152659004792747, lr:  0.001006, elapsed time:  29842
Step 61800, loss: 0.0192192348134995, acc: 99.41706427931786, p_norm: 1565.5742620566457, g_norm: 0.14937872637199706, lr:  0.001005, elapsed time:  29889
Step 61900, loss: 0.019411567275819833, acc: 99.40711618959904, p_norm: 1566.1944632919601, g_norm: 0.15112235913331648, lr:  0.001005, elapsed time:  29934
Step 62000, loss: 0.019478769062116045, acc: 99.41583970189095, p_norm: 1566.8305532109691, g_norm: 0.21032695082095404, lr:  0.001004, elapsed time:  29981
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 62000, eval loss: 0.01967592338332906, eval acc: 99.49263763427734
Step 62100, loss: 0.018784799175991792, acc: 99.43290968239307, p_norm: 1567.4543618937266, g_norm: 0.20004563001876216, lr:  0.001003, elapsed time:  30035
Step 62200, loss: 0.019118343904046924, acc: 99.42229287326336, p_norm: 1568.0884042942914, g_norm: 0.1614540010084158, lr:  0.001002, elapsed time:  30081
Step 62300, loss: 0.019142684294347418, acc: 99.4267004430294, p_norm: 1568.6983473581138, g_norm: 0.21123180805224934, lr:  0.001001, elapsed time:  30127
Step 62400, loss: 0.019001036879126333, acc: 99.42960213124752, p_norm: 1569.3388825831762, g_norm: 0.14082531822133562, lr:  0.001001, elapsed time:  30174
Step 62500, loss: 0.018859973391590755, acc: 99.4330084323883, p_norm: 1569.9544983660687, g_norm: 0.1927481981167901, lr:  0.001000, elapsed time:  30220
Step 62600, loss: 0.018251367441989713, acc: 99.45237255096436, p_norm: 1570.5587451274366, g_norm: 0.2257571058413452, lr:  0.000999, elapsed time:  30267
Step 62700, loss: 0.019796935441845562, acc: 99.40592010319233, p_norm: 1571.2381896251084, g_norm: 0.21007462257474768, lr:  0.000998, elapsed time:  30313
Step 62800, loss: 0.019327722341477057, acc: 99.41483514010906, p_norm: 1571.8622999985455, g_norm: 0.15573406136361456, lr:  0.000997, elapsed time:  30360
Step 62900, loss: 0.019189440563059178, acc: 99.42608964443207, p_norm: 1572.4624456340207, g_norm: 0.17928806430570748, lr:  0.000997, elapsed time:  30407
Step 63000, loss: 0.01971933915221598, acc: 99.40585786104202, p_norm: 1573.067779439242, g_norm: 0.23987339300252186, lr:  0.000996, elapsed time:  30453
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 63100, loss: 0.018909778777439445, acc: 99.42597947996248, p_norm: 1573.7149013054739, g_norm: 0.17579247460394867, lr:  0.000995, elapsed time:  30501
Step 63200, loss: 0.018679838940297486, acc: 99.4353791475296, p_norm: 1574.3175898061636, g_norm: 0.1800832277282123, lr:  0.000994, elapsed time:  30547
Step 63300, loss: 0.018710588313115294, acc: 99.4254459887743, p_norm: 1574.9017688293352, g_norm: 0.23197026584490169, lr:  0.000993, elapsed time:  30593
Step 63400, loss: 0.017627642306324562, acc: 99.4670607894659, p_norm: 1575.4900785043503, g_norm: 0.1844947242701514, lr:  0.000993, elapsed time:  30640
Step 63500, loss: 0.01894646094064228, acc: 99.42795892059803, p_norm: 1576.1054128936662, g_norm: 0.2261188373926769, lr:  0.000992, elapsed time:  30686
Step 63600, loss: 0.018859033068583813, acc: 99.42699958384037, p_norm: 1576.7787039010711, g_norm: 0.18030474396325374, lr:  0.000991, elapsed time:  30734
Step 63700, loss: 0.018931887892977103, acc: 99.4272093474865, p_norm: 1577.3972972393176, g_norm: 0.24128619304769688, lr:  0.000990, elapsed time:  30780
Step 63800, loss: 0.018801202079557697, acc: 99.4316973388195, p_norm: 1577.9791763949024, g_norm: 0.1595436822605829, lr:  0.000989, elapsed time:  30827
Step 63900, loss: 0.019424617660406512, acc: 99.41092723608017, p_norm: 1578.611342628405, g_norm: 0.17496736352328432, lr:  0.000989, elapsed time:  30873
Step 64000, loss: 0.018519770974526183, acc: 99.44790486991405, p_norm: 1579.213667268828, g_norm: 0.146182937248638, lr:  0.000988, elapsed time:  30919
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 64000, eval loss: 0.019890973033325286, eval acc: 99.4691390991211
Step 64100, loss: 0.018847346814291087, acc: 99.42991833388805, p_norm: 1579.8351487902328, g_norm: 0.40371050244672557, lr:  0.000987, elapsed time:  30973
Step 64200, loss: 0.018998598842445064, acc: 99.42340397834778, p_norm: 1580.5096664401888, g_norm: 0.17335751849353218, lr:  0.000986, elapsed time:  31020
Step 64300, loss: 0.019383238283771788, acc: 99.42000222206116, p_norm: 1581.1141498891832, g_norm: 0.17449913657240135, lr:  0.000986, elapsed time:  31066
Step 64400, loss: 0.018221451103454456, acc: 99.44719484448433, p_norm: 1581.6996062013266, g_norm: 0.1865069394402223, lr:  0.000985, elapsed time:  31113
Step 64500, loss: 0.018835285936656874, acc: 99.43056313693523, p_norm: 1582.3068681863517, g_norm: 0.262656924460849, lr:  0.000984, elapsed time:  31160
Step 64600, loss: 0.01885968492279062, acc: 99.44320666790009, p_norm: 1582.9115290528048, g_norm: 0.1891500389286044, lr:  0.000983, elapsed time:  31206
Step 64700, loss: 0.01936659552564379, acc: 99.41860173642635, p_norm: 1583.5501932768448, g_norm: 0.1582138019786524, lr:  0.000983, elapsed time:  31252
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 64800, loss: 0.018352304818975294, acc: 99.4422072808145, p_norm: 1584.1578760207235, g_norm: 0.21510839094536838, lr:  0.000982, elapsed time:  31300
Step 64900, loss: 0.01843116384392488, acc: 99.4441123008728, p_norm: 1584.7045473765147, g_norm: 0.17531825702802334, lr:  0.000981, elapsed time:  31347
Step 65000, loss: 0.018545523781649535, acc: 99.44029904901981, p_norm: 1585.2813384382182, g_norm: 0.32121855524088244, lr:  0.000980, elapsed time:  31394
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C N C ( = S ) N c 1 c c c ( C C c 2 n c 3 c c ( C ) c c n 3 c 2 C ) c c 1 _EOS
Predicted text: C C N C ( = S ) N c 1 c c c ( C C c 2 n c 3 c c ( C ) c c n 3 c 2 C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 n c n c 2 c 1 c ( C ( = O ) c 1 c c c c ( N S ( = O ) ( = O ) c 3 c c ( Cl ) c c ( Cl ) c 3 ) c 1 ) c n 2 C 1 C C N C C 1 _EOS
Predicted text: N c 1 n c n c 2 c 1 c ( C ( = O ) c 1 c c c c ( N S ( = O ) ( = O ) c 3 c c ( Cl ) c c ( Cl ) c 3 ) c 1 ) c n 2 C 1 C C N C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C # N ) c 1 c c ( F ) c c c 1 [N+] ( = O ) [O-] _EOS
Predicted text: C O C ( = O ) C ( C # N ) c 1 c c ( F ) c c c 1 [N+] ( = O ) [O-] _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C N ( C c 2 c c c ( N ) c c 2 ) C C N 1 C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C C 1 C N ( C c 2 c c c ( N ) c c 2 ) C C N 1 C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c ( - c 2 c c c c c 2 C ) c ( C ( F ) ( F ) F ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c ( - c 2 c c c c c 2 C ) c ( C ( F ) ( F ) F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 65000, eval acc (token): 0.925236678748749, eval acc (sequence): 0.8614006216858658
Saving at step 65000
Step 65100, loss: 0.018762728419096673, acc: 99.42349016666412, p_norm: 1585.9199030431623, g_norm: 0.1811047242300043, lr:  0.000980, elapsed time:  31492
Step 65200, loss: 0.017497833412271575, acc: 99.46441148221493, p_norm: 1586.490348625667, g_norm: 0.2381011840649841, lr:  0.000979, elapsed time:  31538
Step 65300, loss: 0.01794477438525064, acc: 99.46129502356052, p_norm: 1587.0529721781268, g_norm: 0.1522306081277396, lr:  0.000978, elapsed time:  31585
Step 65400, loss: 0.018366573897801573, acc: 99.44096471369267, p_norm: 1587.6435269167207, g_norm: 0.28481429849525386, lr:  0.000977, elapsed time:  31632
Step 65500, loss: 0.018436092813280992, acc: 99.43565414845943, p_norm: 1588.254585875145, g_norm: 0.19527475248248696, lr:  0.000977, elapsed time:  31678
Step 65600, loss: 0.0182844876312447, acc: 99.44771192967892, p_norm: 1588.8795746017358, g_norm: 0.2537648860239614, lr:  0.000976, elapsed time:  31725
Step 65700, loss: 0.01852140660586883, acc: 99.43324306607246, p_norm: 1589.5135976185263, g_norm: 0.20070760910793575, lr:  0.000975, elapsed time:  31772
Step 65800, loss: 0.018755514995209523, acc: 99.4359320551157, p_norm: 1590.0920334470193, g_norm: 0.18774195543704503, lr:  0.000974, elapsed time:  31818
Step 65900, loss: 0.01839144848185242, acc: 99.44541451334953, p_norm: 1590.6536415304497, g_norm: 0.18071847627879983, lr:  0.000974, elapsed time:  31864
Step 66000, loss: 0.018430807198019466, acc: 99.44462265074253, p_norm: 1591.213633068734, g_norm: 0.18543564581792793, lr:  0.000973, elapsed time:  31911
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 66000, eval loss: 0.01758913752215449, eval acc: 99.51655578613281
Step 66100, loss: 0.018149278347264045, acc: 99.45173017680645, p_norm: 1591.8013710553382, g_norm: 0.31064930981608985, lr:  0.000972, elapsed time:  31965
Step 66200, loss: 0.01822311611205805, acc: 99.4519539475441, p_norm: 1592.376658328831, g_norm: 0.18399060420904673, lr:  0.000971, elapsed time:  32011
Step 66300, loss: 0.018379979614765035, acc: 99.44591808319092, p_norm: 1592.9538416600167, g_norm: 0.21619159191905502, lr:  0.000971, elapsed time:  32058
Step 66400, loss: 0.018685700541027472, acc: 99.43062448501587, p_norm: 1593.5258634101838, g_norm: 0.2457656474423626, lr:  0.000970, elapsed time:  32104
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 66500, loss: 0.019232016193990134, acc: 99.41337901368627, p_norm: 1594.1708546860261, g_norm: 0.29685108701787755, lr:  0.000969, elapsed time:  32152
Step 66600, loss: 0.018082410936331145, acc: 99.44979743659496, p_norm: 1594.7227341480054, g_norm: 0.2563785799897976, lr:  0.000968, elapsed time:  32198
Step 66700, loss: 0.017080572231207042, acc: 99.48085451126099, p_norm: 1595.2747538015885, g_norm: 0.16935827057953734, lr:  0.000968, elapsed time:  32245
Step 66800, loss: 0.01743120417551836, acc: 99.47163265943527, p_norm: 1595.8644069806014, g_norm: 0.21502483294888744, lr:  0.000967, elapsed time:  32291
Step 66900, loss: 0.018338469080918005, acc: 99.4436452537775, p_norm: 1596.4861538258017, g_norm: 0.19587496252586456, lr:  0.000966, elapsed time:  32338
Step 67000, loss: 0.017906935341015923, acc: 99.4567434489727, p_norm: 1597.0529684150667, g_norm: 0.1640348501941939, lr:  0.000966, elapsed time:  32384
Step 67100, loss: 0.017596210852498188, acc: 99.46416562795639, p_norm: 1597.581773724044, g_norm: 0.23910141753772396, lr:  0.000965, elapsed time:  32431
Step 67200, loss: 0.018717820319870952, acc: 99.44002440571785, p_norm: 1598.1821202292056, g_norm: 0.23141744898760971, lr:  0.000964, elapsed time:  32477
Step 67300, loss: 0.018720895214064514, acc: 99.43895056843758, p_norm: 1598.7561703755105, g_norm: 0.2545950584937956, lr:  0.000963, elapsed time:  32523
Step 67400, loss: 0.01757708521770837, acc: 99.4653535336256, p_norm: 1599.2949828615756, g_norm: 0.1815525612741116, lr:  0.000963, elapsed time:  32570
Step 67500, loss: 0.017774107167351758, acc: 99.46091096103191, p_norm: 1599.898657061562, g_norm: 0.20152597985364443, lr:  0.000962, elapsed time:  32617
Step 67600, loss: 0.01821609289137996, acc: 99.45337855815887, p_norm: 1600.4485606365927, g_norm: 0.18663122200124452, lr:  0.000961, elapsed time:  32664
Step 67700, loss: 0.018193621139071182, acc: 99.45223139226437, p_norm: 1601.0607448581202, g_norm: 0.1704220308433221, lr:  0.000961, elapsed time:  32711
Step 67800, loss: 0.01786764552605746, acc: 99.4612507224083, p_norm: 1601.6185745242685, g_norm: 0.16129436017282303, lr:  0.000960, elapsed time:  32757
Step 67900, loss: 0.01817902219147072, acc: 99.45780067145824, p_norm: 1602.1702032977153, g_norm: 0.22884122262178272, lr:  0.000959, elapsed time:  32804
Step 68000, loss: 0.018821520005731146, acc: 99.43583792448044, p_norm: 1602.7567781546413, g_norm: 0.19457950681469416, lr:  0.000958, elapsed time:  32850
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 68000, eval loss: 0.017643149451905628, eval acc: 99.53712463378906
Step 68100, loss: 0.018121049315086565, acc: 99.45122495293617, p_norm: 1603.3288468901594, g_norm: 0.2153474271854944, lr:  0.000958, elapsed time:  32904
Step 68200, loss: 0.01927987655450124, acc: 99.40865191817284, p_norm: 1603.9010438362454, g_norm: 0.27181424219700256, lr:  0.000957, elapsed time:  32950
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 68300, loss: 0.017107692881944882, acc: 99.47809579946266, p_norm: 1604.4247271360668, g_norm: 0.20869126981716787, lr:  0.000956, elapsed time:  32998
Step 68400, loss: 0.01691140829192591, acc: 99.49009312689304, p_norm: 1604.9451083811452, g_norm: 0.18083252131904806, lr:  0.000956, elapsed time:  33044
Step 68500, loss: 0.018478562271848204, acc: 99.43655589222908, p_norm: 1605.538176374373, g_norm: 0.22445288382959525, lr:  0.000955, elapsed time:  33091
Step 68600, loss: 0.017114173321169802, acc: 99.4777277559042, p_norm: 1606.0780527224176, g_norm: 0.17331954126103843, lr:  0.000954, elapsed time:  33137
Step 68700, loss: 0.016815797048766398, acc: 99.48468892276287, p_norm: 1606.609693118383, g_norm: 0.1904225705283159, lr:  0.000954, elapsed time:  33183
Step 68800, loss: 0.017558806799352168, acc: 99.47799895703793, p_norm: 1607.2040874877482, g_norm: 0.17407773923172185, lr:  0.000953, elapsed time:  33230
Step 68900, loss: 0.01792530969971267, acc: 99.45416522026062, p_norm: 1607.7365381112131, g_norm: 0.18420179116307506, lr:  0.000952, elapsed time:  33277
Step 69000, loss: 0.017551556947510108, acc: 99.47249542176723, p_norm: 1608.3209643575226, g_norm: 0.17527199270995283, lr:  0.000951, elapsed time:  33324
Step 69100, loss: 0.01751614189517568, acc: 99.46539643406868, p_norm: 1608.9017037904027, g_norm: 0.1824538873240558, lr:  0.000951, elapsed time:  33371
Step 69200, loss: 0.017538025909743737, acc: 99.47211942076683, p_norm: 1609.4508513387211, g_norm: 0.18923847989183412, lr:  0.000950, elapsed time:  33418
Step 69300, loss: 0.01766578813898377, acc: 99.46219938993454, p_norm: 1609.9969822420383, g_norm: 0.2414134628639927, lr:  0.000949, elapsed time:  33465
Step 69400, loss: 0.01826053856340877, acc: 99.45212522149086, p_norm: 1610.5737778158268, g_norm: 0.2193032606392603, lr:  0.000949, elapsed time:  33511
Step 69500, loss: 0.017933022945944687, acc: 99.46021097898483, p_norm: 1611.0987628958933, g_norm: 0.3214816122859001, lr:  0.000948, elapsed time:  33557
Step 69600, loss: 0.018380928463011516, acc: 99.44812321662903, p_norm: 1611.6397549142282, g_norm: 0.19197613435171756, lr:  0.000947, elapsed time:  33604
Step 69700, loss: 0.018304717443097616, acc: 99.44700010120869, p_norm: 1612.1974830725528, g_norm: 0.2501179028603235, lr:  0.000947, elapsed time:  33651
Step 69800, loss: 0.020006298670195974, acc: 99.401148930192, p_norm: 1612.77015246947, g_norm: 0.21763890572867362, lr:  0.000946, elapsed time:  33703
Step 69900, loss: 0.018563437670673012, acc: 99.43761029839516, p_norm: 1613.3307483773835, g_norm: 0.2619875137884176, lr:  0.000945, elapsed time:  33755
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 70000, loss: 0.018029486587901242, acc: 99.45341944694519, p_norm: 1613.9076573449693, g_norm: 0.17473843894524674, lr:  0.000945, elapsed time:  33802
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 70000, eval loss: 0.01909195097628981, eval acc: 99.50311279296875
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N C C O C C N ) C ( c 2 c c c c ( Cl ) c 2 ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 _EOS
Predicted text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N C C O C C N ) C ( c 2 c c c c ( Cl ) c 2 ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) c 1 c c c ( N 2 C C c 3 c c c c ( N ) c 3 C 2 = O ) c c 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c c ( N 2 C C c 3 c c c c ( N ) c 3 C 2 = O ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) c 1 c c c ( C C ( = O ) N C ( C ) c 2 c c c ( N C C ( F ) ( F ) F ) c n 2 ) c c 1 _EOS
Predicted text: C C ( C ) c 1 c c c ( C C ( = O ) N C ( C ) c 2 c c c ( N C C ( F ) ( F ) F ) c n 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C ( C N ( C ) C ) c 1 c c c ( N C ( = O ) N C ) c c 1 _EOS
Predicted text: C = C ( C N ( C ) C ) c 1 c c c ( N C ( = O ) N C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C c 1 c c ( N c 2 c c c ( C ( F ) ( F ) F ) c n 2 ) c 2 c c c ( - c 3 n c c c c 3 C ( F ) ( F ) F ) n c 2 n 1 _EOS
Predicted text: C O C c 1 c c ( N c 2 c c c ( C ( F ) ( F ) F ) c n 2 ) c 2 c c c ( - c 3 n c c c c 3 C ( F ) ( F ) F ) n c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 70000, eval acc (token): 0.9334159980857839, eval acc (sequence): 0.8756667279749862
Saving at step 70000
Step 70100, loss: 0.017782720980394514, acc: 99.45855854451656, p_norm: 1614.4589599997637, g_norm: 0.25631893611345763, lr:  0.000944, elapsed time:  33907
Step 70200, loss: 0.01807885020010872, acc: 99.44451707601547, p_norm: 1615.033754433901, g_norm: 0.17659469818963228, lr:  0.000943, elapsed time:  33952
Step 70300, loss: 0.017364447200961877, acc: 99.47548028826714, p_norm: 1615.5343915878382, g_norm: 0.21297424303352083, lr:  0.000943, elapsed time:  33998
Step 70400, loss: 0.017786596313890186, acc: 99.46279162168503, p_norm: 1616.073740770837, g_norm: 0.195163554823217, lr:  0.000942, elapsed time:  34044
Step 70500, loss: 0.017084529553249014, acc: 99.48508717119694, p_norm: 1616.6324450628258, g_norm: 0.20326751789008535, lr:  0.000941, elapsed time:  34090
Step 70600, loss: 0.017013391423970462, acc: 99.48497033119202, p_norm: 1617.2051796808273, g_norm: 0.22139693957855966, lr:  0.000941, elapsed time:  34137
Step 70700, loss: 0.01741000582471315, acc: 99.466526851058, p_norm: 1617.7449839116357, g_norm: 0.3127216498173862, lr:  0.000940, elapsed time:  34183
Step 70800, loss: 0.017082474254784756, acc: 99.47681286931038, p_norm: 1618.3255414783873, g_norm: 0.16560666112096367, lr:  0.000939, elapsed time:  34230
Step 70900, loss: 0.01816312670445768, acc: 99.45568756759167, p_norm: 1618.8786523239849, g_norm: 0.13623226298930055, lr:  0.000939, elapsed time:  34276
Step 71000, loss: 0.01703553570638178, acc: 99.48874041438103, p_norm: 1619.4289224927418, g_norm: 0.2034260163881156, lr:  0.000938, elapsed time:  34323
Step 71100, loss: 0.01754332672149758, acc: 99.4708354473114, p_norm: 1619.9762323973969, g_norm: 0.15463154132627863, lr:  0.000937, elapsed time:  34370
Step 71200, loss: 0.01790316671860637, acc: 99.46937337517738, p_norm: 1620.522998396974, g_norm: 0.20010990603945963, lr:  0.000937, elapsed time:  34416
Step 71300, loss: 0.018371996388523257, acc: 99.44265705347061, p_norm: 1621.0721656307583, g_norm: 0.23602529825903126, lr:  0.000936, elapsed time:  34463
Step 71400, loss: 0.01788415838316723, acc: 99.45541767776012, p_norm: 1621.5649636674596, g_norm: 0.23688700879350177, lr:  0.000935, elapsed time:  34509
Step 71500, loss: 0.0178750714501075, acc: 99.46318565309048, p_norm: 1622.089811468075, g_norm: 0.20342335102268433, lr:  0.000935, elapsed time:  34555
Step 71600, loss: 0.01710213869850122, acc: 99.47983160614967, p_norm: 1622.6181122261573, g_norm: 0.22694842040181265, lr:  0.000934, elapsed time:  34602
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 71700, loss: 0.0168546701990306, acc: 99.48860544424791, p_norm: 1623.151852278327, g_norm: 0.20193389011519494, lr:  0.000933, elapsed time:  34649
Step 71800, loss: 0.01683003631806059, acc: 99.48401935398579, p_norm: 1623.659778758141, g_norm: 0.19624338705224978, lr:  0.000933, elapsed time:  34696
Step 71900, loss: 0.0167003674726584, acc: 99.48916660249233, p_norm: 1624.1894679533907, g_norm: 0.20067070314108681, lr:  0.000932, elapsed time:  34742
Step 72000, loss: 0.018026107040350327, acc: 99.45947816967964, p_norm: 1624.78604412147, g_norm: 0.2968201993196886, lr:  0.000931, elapsed time:  34789
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 72000, eval loss: 0.018549216173705647, eval acc: 99.51950073242188
Step 72100, loss: 0.017264699343068058, acc: 99.47901445627213, p_norm: 1625.3474202809375, g_norm: 0.26806192769278103, lr:  0.000931, elapsed time:  34843
Step 72200, loss: 0.017156394263147377, acc: 99.4714183062315, p_norm: 1625.8424296519531, g_norm: 0.1760217689140677, lr:  0.000930, elapsed time:  34889
Step 72300, loss: 0.017108924559142907, acc: 99.477563560009, p_norm: 1626.3473732733426, g_norm: 0.23581579046358422, lr:  0.000929, elapsed time:  34935
Step 72400, loss: 0.016915821147267706, acc: 99.48376342654228, p_norm: 1626.8825333359155, g_norm: 0.24258851669314155, lr:  0.000929, elapsed time:  34981
Step 72500, loss: 0.017855675048922423, acc: 99.45406366884708, p_norm: 1627.4248118633727, g_norm: 0.20352709233504349, lr:  0.000928, elapsed time:  35027
Step 72600, loss: 0.01715809695830103, acc: 99.47593656182289, p_norm: 1627.9539035048665, g_norm: 0.2759187872295402, lr:  0.000928, elapsed time:  35074
Step 72700, loss: 0.016833618539822057, acc: 99.48466211557388, p_norm: 1628.4824233496972, g_norm: 0.17766836873359276, lr:  0.000927, elapsed time:  35120
Step 72800, loss: 0.018238953051404678, acc: 99.44152890145779, p_norm: 1629.0279936562863, g_norm: 0.16517137385938788, lr:  0.000926, elapsed time:  35166
Step 72900, loss: 0.016753463651693893, acc: 99.49085295200348, p_norm: 1629.6124769360365, g_norm: 0.18981880299570641, lr:  0.000926, elapsed time:  35213
Step 73000, loss: 0.018114435238821898, acc: 99.45745134353638, p_norm: 1630.1395309737102, g_norm: 0.19365885207914255, lr:  0.000925, elapsed time:  35259
Step 73100, loss: 0.018572116893774363, acc: 99.43718881905079, p_norm: 1630.6519455657478, g_norm: 0.15547168729484911, lr:  0.000924, elapsed time:  35305
Step 73200, loss: 0.017677883480646413, acc: 99.45958109200001, p_norm: 1631.1606270619159, g_norm: 0.20685393009419423, lr:  0.000924, elapsed time:  35352
Step 73300, loss: 0.018181628364836798, acc: 99.45365743339062, p_norm: 1631.6962637955298, g_norm: 0.19112208783084297, lr:  0.000923, elapsed time:  35398
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 73400, loss: 0.017163939279487943, acc: 99.4818465437546, p_norm: 1632.178217239563, g_norm: 0.1761749790051841, lr:  0.000922, elapsed time:  35445
Step 73500, loss: 0.016632256385637447, acc: 99.49523141980171, p_norm: 1632.6963662942342, g_norm: 0.15533466204585863, lr:  0.000922, elapsed time:  35492
Step 73600, loss: 0.016028532706332043, acc: 99.51242160797119, p_norm: 1633.1958329790982, g_norm: 0.3152651125684212, lr:  0.000921, elapsed time:  35542
Step 73700, loss: 0.017168442411348225, acc: 99.47485326230526, p_norm: 1633.7158749345524, g_norm: 0.15187204746964555, lr:  0.000921, elapsed time:  35590
Step 73800, loss: 0.016487380635371664, acc: 99.49642656743526, p_norm: 1634.2182647990467, g_norm: 0.24927112638497984, lr:  0.000920, elapsed time:  35638
Step 73900, loss: 0.01708001797873294, acc: 99.48125943541527, p_norm: 1634.6846251478, g_norm: 0.18631759828943886, lr:  0.000919, elapsed time:  35685
Step 74000, loss: 0.01745659894091659, acc: 99.46710196137428, p_norm: 1635.1797579846323, g_norm: 0.18156140987795047, lr:  0.000919, elapsed time:  35733
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 74000, eval loss: 0.018995299836678893, eval acc: 99.49555969238281
Step 74100, loss: 0.01715449908646406, acc: 99.4842687100172, p_norm: 1635.6639659397154, g_norm: 0.22218928002645108, lr:  0.000918, elapsed time:  35789
Step 74200, loss: 0.01683932099935191, acc: 99.48663590848446, p_norm: 1636.1841451925893, g_norm: 0.2451469254498695, lr:  0.000918, elapsed time:  35837
Step 74300, loss: 0.01788368533656467, acc: 99.46082617342472, p_norm: 1636.7534346406185, g_norm: 0.17453814634144227, lr:  0.000917, elapsed time:  35886
Step 74400, loss: 0.01776313708680391, acc: 99.46198603510857, p_norm: 1637.2985385508464, g_norm: 0.18741614672348425, lr:  0.000916, elapsed time:  35934
Step 74500, loss: 0.017686632071490748, acc: 99.46830309927464, p_norm: 1637.8472382650295, g_norm: 0.23041850988031168, lr:  0.000916, elapsed time:  35982
Step 74600, loss: 0.0175092832602968, acc: 99.47412398457527, p_norm: 1638.3659428552999, g_norm: 0.3112502018735414, lr:  0.000915, elapsed time:  36030
Step 74700, loss: 0.016819401518841915, acc: 99.49470943212509, p_norm: 1638.847248632073, g_norm: 0.27058713002116114, lr:  0.000914, elapsed time:  36078
Step 74800, loss: 0.01729620770565816, acc: 99.47215203940868, p_norm: 1639.3132081657966, g_norm: 0.2404992429060612, lr:  0.000914, elapsed time:  36127
Step 74900, loss: 0.017522910294210305, acc: 99.4738153219223, p_norm: 1639.810194588199, g_norm: 0.1843982348110679, lr:  0.000913, elapsed time:  36175
Step 75000, loss: 0.016880681234251824, acc: 99.48436503112316, p_norm: 1640.2998179773917, g_norm: 0.1626210237121268, lr:  0.000913, elapsed time:  36223
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c c ( C 2 ( C ) C S c 3 c c ( O C ) c c c 3 C 2 C C C C C C C C O ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C 2 ( C ) C S c 3 c c ( O C ) c c c 3 C 2 C C C C C C C C O ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C 1 C C 1 ) C 1 C C C 2 = C ( C = C C 3 = C C C c 4 c 3 n 2 c 2 c c n c c 4 2 ) C 1 _EOS
Predicted text: O = C ( C 1 C C 1 ) C 1 C C C 2 = C ( C = C C 3 = C C C c 4 c 3 n 2 c 2 c c n c c 4 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C # C C N c 1 c c c ( C # N ) c c 1 _EOS
Predicted text: C # C C N c 1 c c c ( C # N ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N C C ( C ) ( C ) c 1 c c c ( N ) c c 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C C ( C ) ( C ) c 1 c c c ( N ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( - c 2 c c c ( O c 3 c c ( C ) c ( N ) c c 3 C ) c c 2 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( - c 2 c c c ( O c 3 c c ( C ) c ( N ) c c 3 C ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 75000, eval acc (token): 0.9309146038646566, eval acc (sequence): 0.8727552591072345
Saving at step 75000
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 75100, loss: 0.01591658609765859, acc: 99.51198152809522, p_norm: 1640.7915093494805, g_norm: 0.16895311611062114, lr:  0.000912, elapsed time:  36340
Step 75200, loss: 0.01683386714292283, acc: 99.4885867536068, p_norm: 1641.3007897169966, g_norm: 0.2216875484226916, lr:  0.000911, elapsed time:  36391
Step 75300, loss: 0.016202514705219072, acc: 99.50610265135765, p_norm: 1641.791144575567, g_norm: 0.1802203565728276, lr:  0.000911, elapsed time:  36438
Step 75400, loss: 0.01643054696985928, acc: 99.50389465689659, p_norm: 1642.2991995076854, g_norm: 0.17218985601850578, lr:  0.000910, elapsed time:  36485
Step 75500, loss: 0.017361343619559193, acc: 99.4640427082777, p_norm: 1642.7991202508258, g_norm: 0.19598363985908124, lr:  0.000910, elapsed time:  36532
Step 75600, loss: 0.016924925289567908, acc: 99.49057425558567, p_norm: 1643.2873218877257, g_norm: 0.15798309564883345, lr:  0.000909, elapsed time:  36580
Step 75700, loss: 0.016282435376706417, acc: 99.50685833394527, p_norm: 1643.776267227329, g_norm: 0.1844261759095115, lr:  0.000908, elapsed time:  36628
Step 75800, loss: 0.01601606815616833, acc: 99.518724411726, p_norm: 1644.2708328272115, g_norm: 0.20108248590072927, lr:  0.000908, elapsed time:  36675
Step 75900, loss: 0.017160780034391792, acc: 99.47660531103611, p_norm: 1644.7677058955737, g_norm: 0.21232455136396955, lr:  0.000907, elapsed time:  36722
Step 76000, loss: 0.0173084751823626, acc: 99.47834499180317, p_norm: 1645.3238462304012, g_norm: 0.22713993930435417, lr:  0.000907, elapsed time:  36770
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 76000, eval loss: 0.01682103377650492, eval acc: 99.5616683959961
Step 76100, loss: 0.016673663616165867, acc: 99.49763090908527, p_norm: 1645.826612818112, g_norm: 0.23577875634301312, lr:  0.000906, elapsed time:  36825
Step 76200, loss: 0.01741416734359518, acc: 99.46799446642399, p_norm: 1646.3432890913266, g_norm: 0.1743165318791952, lr:  0.000905, elapsed time:  36872
Step 76300, loss: 0.01615928292623721, acc: 99.50746402144432, p_norm: 1646.8311475496673, g_norm: 0.24845833524164776, lr:  0.000905, elapsed time:  36920
Step 76400, loss: 0.017552931249374525, acc: 99.46296133100986, p_norm: 1647.332438369974, g_norm: 0.17212795292426483, lr:  0.000904, elapsed time:  36967
Step 76500, loss: 0.017154743301216514, acc: 99.47715026140213, p_norm: 1647.8213722250525, g_norm: 0.14981629942554323, lr:  0.000904, elapsed time:  37014
Step 76600, loss: 0.01696345658536302, acc: 99.49026697874069, p_norm: 1648.2930491829804, g_norm: 0.2135911120121755, lr:  0.000903, elapsed time:  37061
Step 76700, loss: 0.016417044373811224, acc: 99.50513052940369, p_norm: 1648.7744085721731, g_norm: 0.16241943834714379, lr:  0.000902, elapsed time:  37110
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 76800, loss: 0.015810226973502976, acc: 99.51697012678308, p_norm: 1649.2861318808216, g_norm: 0.22384805845316316, lr:  0.000902, elapsed time:  37158
Step 76900, loss: 0.017298072359844808, acc: 99.47078168392181, p_norm: 1649.795757699078, g_norm: 0.2466928742041482, lr:  0.000901, elapsed time:  37206
Step 77000, loss: 0.01699872252123896, acc: 99.47959487140179, p_norm: 1650.2942487160076, g_norm: 0.21843443666169934, lr:  0.000901, elapsed time:  37253
Step 77100, loss: 0.016075829939945833, acc: 99.51491475105286, p_norm: 1650.7417311303334, g_norm: 0.20721866840316186, lr:  0.000900, elapsed time:  37300
Step 77200, loss: 0.016346462953079025, acc: 99.51154062151909, p_norm: 1651.2379412801097, g_norm: 0.15691421046693418, lr:  0.000900, elapsed time:  37347
Step 77300, loss: 0.017094396268803394, acc: 99.48426292836666, p_norm: 1651.7641493004041, g_norm: 0.26448437888210163, lr:  0.000899, elapsed time:  37395
Step 77400, loss: 0.016725919651944424, acc: 99.50319597125053, p_norm: 1652.260775615523, g_norm: 0.20801876471022038, lr:  0.000898, elapsed time:  37442
Step 77500, loss: 0.015943377316798433, acc: 99.51714184880257, p_norm: 1652.7187761792304, g_norm: 0.20632083618458752, lr:  0.000898, elapsed time:  37489
Step 77600, loss: 0.016437291662805366, acc: 99.50362180173397, p_norm: 1653.2017551517804, g_norm: 0.13457615734422504, lr:  0.000897, elapsed time:  37537
Step 77700, loss: 0.015895061334376806, acc: 99.5149749815464, p_norm: 1653.6533458618012, g_norm: 0.19965253956287296, lr:  0.000897, elapsed time:  37585
Step 77800, loss: 0.016372012221545447, acc: 99.50488704442978, p_norm: 1654.121630973371, g_norm: 0.1633448500251999, lr:  0.000896, elapsed time:  37633
Step 77900, loss: 0.017036218095672667, acc: 99.4771317243576, p_norm: 1654.6287765046743, g_norm: 0.39313838687428637, lr:  0.000895, elapsed time:  37680
Step 78000, loss: 0.016626765078799507, acc: 99.48975118994713, p_norm: 1655.0962858255323, g_norm: 0.18472686825663223, lr:  0.000895, elapsed time:  37728
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 78000, eval loss: 0.01897295738155663, eval acc: 99.53166198730469
Step 78100, loss: 0.016422836629863012, acc: 99.50130635499954, p_norm: 1655.573883079725, g_norm: 0.23866783538128492, lr:  0.000894, elapsed time:  37783
Step 78200, loss: 0.016795518378567065, acc: 99.50115329027176, p_norm: 1656.0759929169506, g_norm: 0.15969707723909868, lr:  0.000894, elapsed time:  37830
Step 78300, loss: 0.017207549971717525, acc: 99.47752563655376, p_norm: 1656.5811934525195, g_norm: 0.1875965507625404, lr:  0.000893, elapsed time:  37877
Step 78400, loss: 0.01708015410018561, acc: 99.48098269104958, p_norm: 1657.1010099858347, g_norm: 0.19095518955946664, lr:  0.000893, elapsed time:  37925
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 78500, loss: 0.016653570730733702, acc: 99.48845740879145, p_norm: 1657.5528150261196, g_norm: 0.22139602771241237, lr:  0.000892, elapsed time:  37973
Step 78600, loss: 0.016484130452518002, acc: 99.50245483219624, p_norm: 1658.0423630546577, g_norm: 0.17182452697378792, lr:  0.000891, elapsed time:  38021
Step 78700, loss: 0.016553180268747383, acc: 99.48940029740334, p_norm: 1658.5151180201844, g_norm: 0.2378067983928389, lr:  0.000891, elapsed time:  38068
Step 78800, loss: 0.0168075001795296, acc: 99.48944030702114, p_norm: 1659.0370155070166, g_norm: 0.2188229380982067, lr:  0.000890, elapsed time:  38115
Step 78900, loss: 0.016080748316744574, acc: 99.5172668248415, p_norm: 1659.491012564148, g_norm: 0.1401953619495977, lr:  0.000890, elapsed time:  38162
Step 79000, loss: 0.016653663922916166, acc: 99.50152885913849, p_norm: 1659.972455736814, g_norm: 0.1751905197529956, lr:  0.000889, elapsed time:  38215
Step 79100, loss: 0.016409340315149165, acc: 99.5048620402813, p_norm: 1660.4390058045824, g_norm: 0.16602881055581414, lr:  0.000889, elapsed time:  38270
Step 79200, loss: 0.016574746326441528, acc: 99.49579958617687, p_norm: 1660.9358488865134, g_norm: 0.18666735800845213, lr:  0.000888, elapsed time:  38319
Step 79300, loss: 0.015618074405720108, acc: 99.53130967915058, p_norm: 1661.4027153039647, g_norm: 0.23197056704657953, lr:  0.000888, elapsed time:  38367
Step 79400, loss: 0.01697040281185764, acc: 99.4783930182457, p_norm: 1661.880157844659, g_norm: 0.1924289433485514, lr:  0.000887, elapsed time:  38415
Step 79500, loss: 0.016202316059752774, acc: 99.5159743130207, p_norm: 1662.3406480483866, g_norm: 0.3213813794721956, lr:  0.000886, elapsed time:  38463
Step 79600, loss: 0.015701363542102626, acc: 99.52042196691036, p_norm: 1662.8028387806366, g_norm: 0.17111993080971452, lr:  0.000886, elapsed time:  38511
Step 79700, loss: 0.01684557413624134, acc: 99.48561944067478, p_norm: 1663.2878485963706, g_norm: 0.22002517204262104, lr:  0.000885, elapsed time:  38558
Step 79800, loss: 0.01625556150916964, acc: 99.50527949631214, p_norm: 1663.7796915637737, g_norm: 0.19039007752658416, lr:  0.000885, elapsed time:  38606
Step 79900, loss: 0.01576530243153684, acc: 99.52083940804005, p_norm: 1664.247904569784, g_norm: 0.21657930254143465, lr:  0.000884, elapsed time:  38653
Step 80000, loss: 0.01632039208750939, acc: 99.5060056746006, p_norm: 1664.7230039375645, g_norm: 0.18197480175672612, lr:  0.000884, elapsed time:  38701
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 80000, eval loss: 0.01944173533818684, eval acc: 99.49322509765625
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) ( C ) O C ( = O ) N C ( C c 1 c c c c c 1 ) C ( = O ) N C ( C c 1 c c c ( C 2 = C C ( = O ) N S 2 ( = O ) = O ) c c 1 ) C ( = O ) N c 1 c c c c c 1 N _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C ( C c 1 c c c c c 1 ) C ( = O ) N C ( C c 1 c c c ( C 2 = C C ( = O ) N S 2 ( = O ) = O ) c c 1 ) C ( = O ) N c 1 c c c c c 1 N _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N ( C c 1 c c c ( Cl ) c ( O c 2 c c ( Cl ) c c ( C # N ) c 2 ) c 1 F ) C ( = O ) c 1 c c c [nH] 1 _EOS
Predicted text: C C N ( C c 1 c c c ( Cl ) c ( O c 2 c c ( Cl ) c c ( C # N ) c 2 ) c 1 F ) C ( = O ) c 1 c c c [nH] 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C C c 1 c c c ( O ) c ( C ( C ) ( C ) C ) c 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c ( C C C O ) c c ( C ( C ) ( C ) C ) c 1 O _EOS
acc_token: 0.1935483870967742, acc_seq: False

Target text: C c 1 c c c c c 1 C ( = C C Br ) c 1 c c c c c 1 _EOS
Predicted text: C C = C ( c 1 c c c c c 1 ) c 1 c c c c c 1 C Br _EOS
acc_token: 0.32, acc_seq: False

Target text: C S c 1 c c c c c 1 C ( = O ) N c 1 c c c ( C ( = O ) N 2 C c 3 c c c c c 3 C c 3 c c c c c 3 2 ) c c 1 _EOS
Predicted text: C S c 1 c c c c c 1 C ( = O ) N c 1 c c c ( C ( = O ) N 2 C c 3 c c c c c 3 C c 3 c c c c c 3 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 80000, eval acc (token): 0.9280483949938035, eval acc (sequence): 0.8687069902209344
Saving at step 80000
Step 80100, loss: 0.016874549084313913, acc: 99.4864443987608, p_norm: 1665.2452699060184, g_norm: 0.18807761197851797, lr:  0.000883, elapsed time:  38809
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 80200, loss: 0.015810051737003672, acc: 99.5142377931486, p_norm: 1665.7122163104361, g_norm: 0.18285133425153002, lr:  0.000883, elapsed time:  38858
Step 80300, loss: 0.016452444298265617, acc: 99.49529294669628, p_norm: 1666.183640612069, g_norm: 0.2232753041577736, lr:  0.000882, elapsed time:  38906
Step 80400, loss: 0.015736019868127185, acc: 99.51678681373596, p_norm: 1666.6234834541062, g_norm: 0.17307591036891048, lr:  0.000881, elapsed time:  38954
Step 80500, loss: 0.016559143108170245, acc: 99.49787974357605, p_norm: 1667.080429861306, g_norm: 0.16873943309951006, lr:  0.000881, elapsed time:  39001
Step 80600, loss: 0.016342772770440207, acc: 99.50493101775646, p_norm: 1667.587410601259, g_norm: 0.2789601526296062, lr:  0.000880, elapsed time:  39048
Step 80700, loss: 0.015930242036192796, acc: 99.51682192087173, p_norm: 1668.0218434948333, g_norm: 0.2283325932291458, lr:  0.000880, elapsed time:  39096
Step 80800, loss: 0.016342294357018547, acc: 99.50132009387016, p_norm: 1668.4509930711324, g_norm: 0.20842958226621877, lr:  0.000879, elapsed time:  39143
Step 80900, loss: 0.016723471953300758, acc: 99.49135632812977, p_norm: 1668.9403860820362, g_norm: 0.23092246851967627, lr:  0.000879, elapsed time:  39191
Step 81000, loss: 0.016123138410184767, acc: 99.50258928537369, p_norm: 1669.3723875488433, g_norm: 0.21059159385842038, lr:  0.000878, elapsed time:  39238
Step 81100, loss: 0.01591070835122082, acc: 99.51431411504745, p_norm: 1669.8205649190752, g_norm: 0.21999514480961868, lr:  0.000878, elapsed time:  39286
Step 81200, loss: 0.01634587393811671, acc: 99.51018144190311, p_norm: 1670.304639428165, g_norm: 0.19177703628593948, lr:  0.000877, elapsed time:  39333
Step 81300, loss: 0.015923734446405432, acc: 99.52079333364964, p_norm: 1670.7519844974006, g_norm: 0.16620797328338155, lr:  0.000877, elapsed time:  39381
Step 81400, loss: 0.015983653184957803, acc: 99.51994965970516, p_norm: 1671.2409007705721, g_norm: 0.19044651561605536, lr:  0.000876, elapsed time:  39428
Step 81500, loss: 0.016615578259661562, acc: 99.50084927678108, p_norm: 1671.707370595648, g_norm: 0.1252190757465406, lr:  0.000875, elapsed time:  39475
Step 81600, loss: 0.01691591674891242, acc: 99.48749305307865, p_norm: 1672.1833035573306, g_norm: 0.23791696343070642, lr:  0.000875, elapsed time:  39523
Step 81700, loss: 0.01613276682313881, acc: 99.50894393026829, p_norm: 1672.663453070389, g_norm: 0.20948879613812715, lr:  0.000874, elapsed time:  39571
Step 81800, loss: 0.017137134464574048, acc: 99.47711044549942, p_norm: 1673.1441169814207, g_norm: 0.48431123410937604, lr:  0.000874, elapsed time:  39619
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 81900, loss: 0.016197010117543112, acc: 99.50369322861987, p_norm: 1673.6123263550758, g_norm: 0.2155841948351891, lr:  0.000873, elapsed time:  39667
Step 82000, loss: 0.015924297479359667, acc: 99.51020888984203, p_norm: 1674.0327570063464, g_norm: 0.17775119656194843, lr:  0.000873, elapsed time:  39714
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 82000, eval loss: 0.017926161544783086, eval acc: 99.549560546875
Step 82100, loss: 0.015571258142808802, acc: 99.52197888493538, p_norm: 1674.5438869022867, g_norm: 0.2098470776436594, lr:  0.000872, elapsed time:  39769
Step 82200, loss: 0.01574119636505202, acc: 99.5179386138916, p_norm: 1675.0049533297401, g_norm: 0.1754284839803005, lr:  0.000872, elapsed time:  39816
Step 82300, loss: 0.016072314833472774, acc: 99.51416559517384, p_norm: 1675.4774647176062, g_norm: 0.255740866122288, lr:  0.000871, elapsed time:  39864
Step 82400, loss: 0.01576740925294871, acc: 99.52005335688591, p_norm: 1675.917593525716, g_norm: 0.1910002452029719, lr:  0.000871, elapsed time:  39912
Step 82500, loss: 0.016482619967573556, acc: 99.49840332567692, p_norm: 1676.3963990764287, g_norm: 0.15194781583167297, lr:  0.000870, elapsed time:  39960
Step 82600, loss: 0.016462917108510736, acc: 99.50061857700348, p_norm: 1676.8353497739442, g_norm: 0.20062068354726517, lr:  0.000870, elapsed time:  40007
Step 82700, loss: 0.015902094390075946, acc: 99.51611031591892, p_norm: 1677.268126199289, g_norm: 0.1438741869444676, lr:  0.000869, elapsed time:  40055
Step 82800, loss: 0.015730578950897325, acc: 99.52261510491371, p_norm: 1677.7156738885517, g_norm: 0.2556962984562851, lr:  0.000869, elapsed time:  40103
Step 82900, loss: 0.01615489303607319, acc: 99.49667003750801, p_norm: 1678.1399884710154, g_norm: 0.16462160321153674, lr:  0.000868, elapsed time:  40156
Step 83000, loss: 0.016270696798164862, acc: 99.50684824585915, p_norm: 1678.5971048163167, g_norm: 0.1512348132555107, lr:  0.000868, elapsed time:  40206
Step 83100, loss: 0.015461368844553363, acc: 99.52919329702854, p_norm: 1679.0199733463992, g_norm: 0.1638468829399485, lr:  0.000867, elapsed time:  40254
Step 83200, loss: 0.015678598037411576, acc: 99.5309578627348, p_norm: 1679.4223340186384, g_norm: 0.15532544999420678, lr:  0.000866, elapsed time:  40302
Step 83300, loss: 0.016291062951640924, acc: 99.50178901851177, p_norm: 1679.8620526334273, g_norm: 0.20763907367312845, lr:  0.000866, elapsed time:  40350
Step 83400, loss: 0.016766225907122134, acc: 99.4889048486948, p_norm: 1680.3557901587478, g_norm: 0.23150472038978168, lr:  0.000865, elapsed time:  40398
Step 83500, loss: 0.015738895844624495, acc: 99.52480521798134, p_norm: 1680.7757195806723, g_norm: 0.17294749345644111, lr:  0.000865, elapsed time:  40445
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 83600, loss: 0.01578708448382419, acc: 99.50880942059986, p_norm: 1681.2130629856047, g_norm: 0.2041165976471429, lr:  0.000864, elapsed time:  40498
Step 83700, loss: 0.015501871884553112, acc: 99.52184224128723, p_norm: 1681.7014097844606, g_norm: 0.14046149383199347, lr:  0.000864, elapsed time:  40554
Step 83800, loss: 0.016291860518758767, acc: 99.50474832952023, p_norm: 1682.1424377593441, g_norm: 0.19695224605640227, lr:  0.000863, elapsed time:  40607
Step 83900, loss: 0.015474215489666676, acc: 99.52287730574608, p_norm: 1682.592185886163, g_norm: 0.16200886037826692, lr:  0.000863, elapsed time:  40654
Step 84000, loss: 0.01565754406648921, acc: 99.53392054140568, p_norm: 1683.0594355168937, g_norm: 0.1696460376277442, lr:  0.000862, elapsed time:  40702
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 84000, eval loss: 0.01663197581074201, eval acc: 99.58898162841797
Step 84100, loss: 0.015114006617077394, acc: 99.54042537510395, p_norm: 1683.4782467403202, g_norm: 0.17675729802683193, lr:  0.000862, elapsed time:  40757
Step 84200, loss: 0.015297783842906938, acc: 99.53131730854511, p_norm: 1683.9027678165849, g_norm: 0.15966996777447764, lr:  0.000861, elapsed time:  40804
Step 84300, loss: 0.015889811119795923, acc: 99.51505395770073, p_norm: 1684.3494978546448, g_norm: 0.20115390726905424, lr:  0.000861, elapsed time:  40852
Step 84400, loss: 0.015528839872858953, acc: 99.53248353302479, p_norm: 1684.789232526484, g_norm: 0.18178880275341996, lr:  0.000860, elapsed time:  40900
Step 84500, loss: 0.016405029893066966, acc: 99.50032657384872, p_norm: 1685.2833000315425, g_norm: 0.20462548943197426, lr:  0.000860, elapsed time:  40947
Step 84600, loss: 0.015679069890502433, acc: 99.51993794739246, p_norm: 1685.7421093276316, g_norm: 0.1323517321886087, lr:  0.000859, elapsed time:  40995
Step 84700, loss: 0.014462175595981534, acc: 99.5593945235014, p_norm: 1686.1541512592796, g_norm: 0.177847003136996, lr:  0.000859, elapsed time:  41043
Step 84800, loss: 0.016512561670751894, acc: 99.49930237233639, p_norm: 1686.5961777488785, g_norm: 0.14619632722443854, lr:  0.000858, elapsed time:  41090
Step 84900, loss: 0.015947860373707955, acc: 99.51632197201252, p_norm: 1687.0699912921011, g_norm: 0.14793657945867045, lr:  0.000858, elapsed time:  41138
Step 85000, loss: 0.015957065661859816, acc: 99.51233164966106, p_norm: 1687.5241137824382, g_norm: 0.22141134468883594, lr:  0.000857, elapsed time:  41186
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c c ( C ( N C ( = O ) C C ( N C ( = O ) O C c 2 c c c c c 2 ) C ( = O ) N C ( C ( = O ) O ) C ( C ) N C C c 2 c [nH] c n 2 ) c 2 c c c ( O C ) c c 2 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C ( N C ( = O ) C C ( N C ( = O ) O C c 2 c c c c c 2 ) C ( = O ) N C ( C ( = O ) O ) C ( C ) N C C c 2 c [nH] c n 2 ) c 2 c c c ( O C ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c c ( C # C c 2 c n c c ( Cl ) c 2 ) c c c 1 F _EOS
Predicted text: N c 1 c c ( C # C c 2 c n c c ( Cl ) c 2 ) c c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C O c 1 c c c c 2 c 1 C C C C 2 N ( C ) C ( C ) c 1 n c ( - c 2 c c c c c 2 ) c ( - c 2 c c c c c 2 ) o 1 _EOS
Predicted text: C C O C ( = O ) C O c 1 c c c c 2 c 1 C C C C 2 N ( C ) C ( C ) c 1 n c ( - c 2 c c c c c 2 ) c ( - c 2 c c c c c 2 ) o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O C C O C C N 1 C C N ( C ( = O ) N c 2 c c c c c 2 S c 2 c c c c c 2 ) C C 1 ) c 1 c c c c c 1 _EOS
Predicted text: O = C ( O C C O C C N 1 C C N ( C ( = O ) N c 2 c c c c c 2 S c 2 c c c c c 2 ) C C 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C ( = O ) N C C O c 1 c c c ( C C ( O C C ) C ( = O ) O C C ) c c 1 _EOS
Predicted text: C C C C C C C ( = O ) N C C O c 1 c c c ( C C ( O C C ) C ( = O ) O C C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 85000, eval acc (token): 0.9327955760831829, eval acc (sequence): 0.8791284800276673
Saving at step 85000
Step 85100, loss: 0.01665976250747917, acc: 99.49791333079338, p_norm: 1687.983190870304, g_norm: 0.14906787115314007, lr:  0.000857, elapsed time:  41291
Step 85200, loss: 0.016492113860149402, acc: 99.49835507571697, p_norm: 1688.4198439576749, g_norm: 0.17107380610777365, lr:  0.000856, elapsed time:  41339
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 85300, loss: 0.016200992315967073, acc: 99.50428980203411, p_norm: 1688.83919930791, g_norm: 0.20962821350329292, lr:  0.000856, elapsed time:  41387
Step 85400, loss: 0.015295988605357707, acc: 99.52890425920486, p_norm: 1689.276453069547, g_norm: 0.23047360126655672, lr:  0.000855, elapsed time:  41435
Step 85500, loss: 0.015304806389976874, acc: 99.5329615175724, p_norm: 1689.730719944197, g_norm: 0.20527860410437812, lr:  0.000855, elapsed time:  41483
Step 85600, loss: 0.0149948299004609, acc: 99.54261864721775, p_norm: 1690.1666734320856, g_norm: 0.17651790404519063, lr:  0.000854, elapsed time:  41531
Step 85700, loss: 0.015748289638431744, acc: 99.51984575390816, p_norm: 1690.6105068923098, g_norm: 0.27495784424945324, lr:  0.000854, elapsed time:  41578
Step 85800, loss: 0.015548060583678308, acc: 99.52257990837097, p_norm: 1691.0300849990408, g_norm: 0.25122141601126236, lr:  0.000853, elapsed time:  41626
Step 85900, loss: 0.015961994149911334, acc: 99.51909202337265, p_norm: 1691.4575897574346, g_norm: 0.12185266206711072, lr:  0.000853, elapsed time:  41672
Step 86000, loss: 0.015287439317180542, acc: 99.52694742381573, p_norm: 1691.888992939617, g_norm: 0.27125751643944446, lr:  0.000852, elapsed time:  41720
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 86000, eval loss: 0.017744860623788553, eval acc: 99.5365219116211
Step 86100, loss: 0.015232168065049337, acc: 99.53563739359379, p_norm: 1692.3248137662026, g_norm: 0.2058144198415616, lr:  0.000852, elapsed time:  41775
Step 86200, loss: 0.015370074418242438, acc: 99.53399500250816, p_norm: 1692.7584828006604, g_norm: 0.16046551172707738, lr:  0.000851, elapsed time:  41823
Step 86300, loss: 0.016108202220784733, acc: 99.51670655608177, p_norm: 1693.2015773624757, g_norm: 0.1702557394850927, lr:  0.000851, elapsed time:  41871
Step 86400, loss: 0.015935278270408162, acc: 99.51522342860699, p_norm: 1693.6347748997573, g_norm: 0.14297745019378844, lr:  0.000850, elapsed time:  41919
Step 86500, loss: 0.015152281742120976, acc: 99.54274174571037, p_norm: 1694.083218673811, g_norm: 0.20780222209678326, lr:  0.000850, elapsed time:  41966
Step 86600, loss: 0.015822083858365657, acc: 99.5189217031002, p_norm: 1694.4911369509932, g_norm: 0.22389841284181994, lr:  0.000849, elapsed time:  42030
Step 86700, loss: 0.016216443850280485, acc: 99.501869186759, p_norm: 1695.0164371862727, g_norm: 0.20478494613968062, lr:  0.000849, elapsed time:  42080
Step 86800, loss: 0.01644829402976029, acc: 99.50302223861217, p_norm: 1695.4347156751899, g_norm: 0.24460272802679894, lr:  0.000848, elapsed time:  42128
Step 86900, loss: 0.016471400048976646, acc: 99.49618588387966, p_norm: 1695.8563954746285, g_norm: 0.19482315146847606, lr:  0.000848, elapsed time:  42175
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 87000, loss: 0.015397610588664496, acc: 99.52766833175205, p_norm: 1696.2606006980866, g_norm: 0.2212096016079164, lr:  0.000847, elapsed time:  42224
Step 87100, loss: 0.014590050757969947, acc: 99.55296874046326, p_norm: 1696.6674422610374, g_norm: 0.23274233093905575, lr:  0.000847, elapsed time:  42272
Step 87200, loss: 0.015564516452359385, acc: 99.52776530385017, p_norm: 1697.0736340948138, g_norm: 0.18239778037055232, lr:  0.000846, elapsed time:  42332
Step 87300, loss: 0.015147483749351522, acc: 99.53463540971279, p_norm: 1697.513802591296, g_norm: 0.1547102301656216, lr:  0.000846, elapsed time:  42381
Step 87400, loss: 0.01503002580080647, acc: 99.54404145479202, p_norm: 1697.8976084267085, g_norm: 0.2287450380733934, lr:  0.000845, elapsed time:  42430
Step 87500, loss: 0.015285161453066394, acc: 99.53167940676212, p_norm: 1698.3138494777177, g_norm: 0.3071632914038697, lr:  0.000845, elapsed time:  42477
Step 87600, loss: 0.015547330660483567, acc: 99.52581222355366, p_norm: 1698.7491924974959, g_norm: 0.2706386910289535, lr:  0.000844, elapsed time:  42525
Step 87700, loss: 0.015074113612063228, acc: 99.53729943931103, p_norm: 1699.1836563242712, g_norm: 0.27635958855765513, lr:  0.000844, elapsed time:  42573
Step 87800, loss: 0.015252356225100811, acc: 99.53406475484371, p_norm: 1699.604708578815, g_norm: 0.21829881149610897, lr:  0.000843, elapsed time:  42620
Step 87900, loss: 0.015575654208951163, acc: 99.52902600169182, p_norm: 1700.0203339700893, g_norm: 0.16622336547042857, lr:  0.000843, elapsed time:  42669
Step 88000, loss: 0.015026951116524287, acc: 99.54267664253712, p_norm: 1700.4506450872627, g_norm: 0.21417573557049668, lr:  0.000843, elapsed time:  42717
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 88000, eval loss: 0.01933903755969368, eval acc: 99.50897979736328
Step 88100, loss: 0.016166428167671255, acc: 99.50043234229088, p_norm: 1700.8794018317299, g_norm: 0.19019501225592475, lr:  0.000842, elapsed time:  42772
Step 88200, loss: 0.01494669688574504, acc: 99.54509833455086, p_norm: 1701.2905814357575, g_norm: 0.1937821040561748, lr:  0.000842, elapsed time:  42820
Step 88300, loss: 0.015974088024013327, acc: 99.51077172160149, p_norm: 1701.7085530189047, g_norm: 0.2711989266490044, lr:  0.000841, elapsed time:  42868
Step 88400, loss: 0.01619888780347537, acc: 99.51402731239796, p_norm: 1702.1469391340977, g_norm: 0.18408757160384503, lr:  0.000841, elapsed time:  42916
Step 88500, loss: 0.014989408230903792, acc: 99.54769988358021, p_norm: 1702.5771348230332, g_norm: 0.31582501543922176, lr:  0.000840, elapsed time:  42965
Step 88600, loss: 0.015362491392879747, acc: 99.53391890227795, p_norm: 1702.9897610435694, g_norm: 0.20747485141284844, lr:  0.000840, elapsed time:  43013
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 88700, loss: 0.015070172654730105, acc: 99.54640448686496, p_norm: 1703.4084533081261, g_norm: 0.1524190247975023, lr:  0.000839, elapsed time:  43062
Step 88800, loss: 0.014202818460908019, acc: 99.56233994662762, p_norm: 1703.8202407401716, g_norm: 0.19223539556217312, lr:  0.000839, elapsed time:  43109
Step 88900, loss: 0.014660489294110448, acc: 99.55517210066319, p_norm: 1704.2448885440606, g_norm: 0.21476388623123183, lr:  0.000838, elapsed time:  43159
Step 89000, loss: 0.01455678965037805, acc: 99.56185305118561, p_norm: 1704.6739827894294, g_norm: 0.17318706186733213, lr:  0.000838, elapsed time:  43207
Step 89100, loss: 0.015139674900419777, acc: 99.5394937992096, p_norm: 1705.091028349471, g_norm: 0.23857684001539517, lr:  0.000837, elapsed time:  43256
Step 89200, loss: 0.014894530090678017, acc: 99.54392665624619, p_norm: 1705.58663251746, g_norm: 0.23181100734283433, lr:  0.000837, elapsed time:  43305
Step 89300, loss: 0.015680049584625523, acc: 99.52330462634563, p_norm: 1705.9748547271765, g_norm: 0.1825831119565239, lr:  0.000836, elapsed time:  43352
Step 89400, loss: 0.0162947952777904, acc: 99.50034639239311, p_norm: 1706.4086918170226, g_norm: 0.19533503845577824, lr:  0.000836, elapsed time:  43400
Step 89500, loss: 0.01525427811924601, acc: 99.53426696360111, p_norm: 1706.8332498023615, g_norm: 0.16240174303408508, lr:  0.000835, elapsed time:  43448
Step 89600, loss: 0.015552708114264534, acc: 99.53443802893162, p_norm: 1707.215311929909, g_norm: 0.18278388163993728, lr:  0.000835, elapsed time:  43496
Step 89700, loss: 0.015565521088283275, acc: 99.5339897274971, p_norm: 1707.6100521124695, g_norm: 0.2039688015846461, lr:  0.000834, elapsed time:  43544
Step 89800, loss: 0.015400431915477384, acc: 99.52438335120678, p_norm: 1708.0029924616372, g_norm: 0.169605832275416, lr:  0.000834, elapsed time:  43592
Step 89900, loss: 0.01561721090496576, acc: 99.52708329260349, p_norm: 1708.4272953833893, g_norm: 0.16344033531946392, lr:  0.000834, elapsed time:  43640
Step 90000, loss: 0.015910791884125502, acc: 99.51882456243038, p_norm: 1708.8225892301596, g_norm: 0.2471077099062927, lr:  0.000833, elapsed time:  43687
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 90000, eval loss: 0.017401048865867765, eval acc: 99.55524444580078
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 n c 2 c c ( C ( = O ) N C C c 3 c c c ( Cl ) c c 3 ) c c c 2 [nH] 1 _EOS
Predicted text: C c 1 n c 2 c c ( C ( = O ) N C C c 3 c c c ( Cl ) c c 3 ) c c c 2 [nH] 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( C ) C C ( c 2 c c c 3 c c ( C ( = O ) O ) c c c 3 c 2 ) C ( O ) c 2 c c c c c 2 1 _EOS
Predicted text: C C 1 ( C ) C C ( c 2 c c c 3 c c ( C ( = O ) O ) c c c 3 c 2 ) C ( O ) c 2 c c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( O c 1 c c c c 2 n c n c ( N c 3 c c c 4 c ( c n n 4 C c 4 c c c c c 4 C # N ) c 3 ) c 1 2 ) C ( = O ) N ( C ) C _EOS
Predicted text: C C ( O c 1 c c c c 2 n c n c ( N c 3 c c c 4 c ( c n n 4 C c 4 c c c c c 4 C # N ) c 3 ) c 1 2 ) C ( = O ) N ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: F C ( F ) ( F ) c 1 c c c ( - c 2 c c ( C ( F ) ( F ) F ) n c ( - n 3 c n c ( Br ) c 3 ) n 2 ) c c 1 _EOS
Predicted text: F C ( F ) ( F ) c 1 c c c ( - c 2 c c ( C ( F ) ( F ) F ) n c ( - n 3 c n c ( Br ) c 3 ) n 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C c 1 c [nH] c n 1 ) N C ( = O ) C ( C c 1 c c c c c 1 ) N C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C O C ( = O ) C ( C c 1 c [nH] c n 1 ) N C ( = O ) C ( C c 1 c c c c c 1 ) N C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 90000, eval acc (token): 0.9293927991946276, eval acc (sequence): 0.8732275489534098
Saving at step 90000
Step 90100, loss: 0.01500650866270007, acc: 99.53789502382278, p_norm: 1709.2343090391996, g_norm: 0.3082469877626981, lr:  0.000833, elapsed time:  43799
Step 90200, loss: 0.0151275417204306, acc: 99.54078669846058, p_norm: 1709.667235908322, g_norm: 0.17399927264649337, lr:  0.000832, elapsed time:  43846
Step 90300, loss: 0.015274500240775524, acc: 99.53987000882626, p_norm: 1710.0593115796926, g_norm: 0.25806288291126667, lr:  0.000832, elapsed time:  43894
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 90400, loss: 0.014719745014219606, acc: 99.54742320418062, p_norm: 1710.4279998661698, g_norm: 0.16648159815344485, lr:  0.000831, elapsed time:  43942
Step 90500, loss: 0.014430098759767133, acc: 99.56064334511757, p_norm: 1710.804685958461, g_norm: 0.14886489361170246, lr:  0.000831, elapsed time:  43989
Step 90600, loss: 0.014301263950510474, acc: 99.55720643699169, p_norm: 1711.2351732472894, g_norm: 0.3195329487511787, lr:  0.000830, elapsed time:  44037
Step 90700, loss: 0.014423452969131176, acc: 99.5568498969078, p_norm: 1711.6351299038324, g_norm: 0.15280872279300484, lr:  0.000830, elapsed time:  44084
Step 90800, loss: 0.01506945714550966, acc: 99.5431717634201, p_norm: 1712.0336508604562, g_norm: 0.14154682902525284, lr:  0.000829, elapsed time:  44131
Step 90900, loss: 0.014742869782276102, acc: 99.5552793443203, p_norm: 1712.4511795319652, g_norm: 0.18362875825308161, lr:  0.000829, elapsed time:  44179
Step 91000, loss: 0.014925727576046483, acc: 99.54715743660927, p_norm: 1712.8892177052526, g_norm: 0.20825817811233396, lr:  0.000828, elapsed time:  44227
Step 91100, loss: 0.015008291716949316, acc: 99.55249819159508, p_norm: 1713.3118155045258, g_norm: 0.2565352279227033, lr:  0.000828, elapsed time:  44274
Step 91200, loss: 0.015271508409059607, acc: 99.5269850641489, p_norm: 1713.7377069144964, g_norm: 0.18309729571384306, lr:  0.000828, elapsed time:  44322
Step 91300, loss: 0.015617335890201502, acc: 99.52187812328339, p_norm: 1714.1493911165603, g_norm: 0.16691902983623527, lr:  0.000827, elapsed time:  44370
Step 91400, loss: 0.0158961733126489, acc: 99.51851020753384, p_norm: 1714.553143042397, g_norm: 0.15603123660137957, lr:  0.000827, elapsed time:  44417
Step 91500, loss: 0.014899371697974857, acc: 99.54548697173595, p_norm: 1714.9395893160709, g_norm: 0.24529665296267592, lr:  0.000826, elapsed time:  44465
Step 91600, loss: 0.015070615929871564, acc: 99.53570355474949, p_norm: 1715.3402506813175, g_norm: 0.14636140176696422, lr:  0.000826, elapsed time:  44512
Step 91700, loss: 0.014371309588677833, acc: 99.55363801121712, p_norm: 1715.7383788044608, g_norm: 0.22005464347153295, lr:  0.000825, elapsed time:  44560
Step 91800, loss: 0.015218916975427418, acc: 99.53842541575432, p_norm: 1716.1730039548759, g_norm: 0.21429454043609794, lr:  0.000825, elapsed time:  44608
Step 91900, loss: 0.01532033892966865, acc: 99.52818250656128, p_norm: 1716.5864303076917, g_norm: 0.23642091497549939, lr:  0.000824, elapsed time:  44656
Step 92000, loss: 0.016229852796532215, acc: 99.50789786875248, p_norm: 1717.0050882874702, g_norm: 0.19688145332496917, lr:  0.000824, elapsed time:  44703
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 92000, eval loss: 0.01706013626106141, eval acc: 99.55909729003906
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 92100, loss: 0.014859288797867496, acc: 99.55630141215644, p_norm: 1717.3840525163057, g_norm: 0.16863849355013136, lr:  0.000824, elapsed time:  44759
Step 92200, loss: 0.014316502826841316, acc: 99.5547149181366, p_norm: 1717.7403808261581, g_norm: 0.1518616614491848, lr:  0.000823, elapsed time:  44806
Step 92300, loss: 0.014074221207483788, acc: 99.56469468772411, p_norm: 1718.1235025279984, g_norm: 0.19419766366396884, lr:  0.000823, elapsed time:  44854
Step 92400, loss: 0.014522652885207208, acc: 99.55146336555481, p_norm: 1718.508268874807, g_norm: 0.23344523179672447, lr:  0.000822, elapsed time:  44901
Step 92500, loss: 0.01434905882764724, acc: 99.56422297656536, p_norm: 1718.9107382037814, g_norm: 0.15223241281047942, lr:  0.000822, elapsed time:  44949
Step 92600, loss: 0.014857153630437096, acc: 99.54603457450867, p_norm: 1719.3206094422844, g_norm: 0.10973380094533934, lr:  0.000821, elapsed time:  44997
Step 92700, loss: 0.014756812335799624, acc: 99.55204141139984, p_norm: 1719.7374037092693, g_norm: 0.2525955255837236, lr:  0.000821, elapsed time:  45045
Step 92800, loss: 0.014155249862124037, acc: 99.56433720886707, p_norm: 1720.1302189901298, g_norm: 0.1608602510818198, lr:  0.000820, elapsed time:  45093
Step 92900, loss: 0.01430443923258281, acc: 99.55496177077293, p_norm: 1720.5246946543405, g_norm: 0.2864876999496055, lr:  0.000820, elapsed time:  45140
Step 93000, loss: 0.014918441623885883, acc: 99.55011899769306, p_norm: 1720.9205744687074, g_norm: 0.1470535186230846, lr:  0.000820, elapsed time:  45188
Step 93100, loss: 0.01526581605354295, acc: 99.53786428272724, p_norm: 1721.3295107167353, g_norm: 0.16863661460617327, lr:  0.000819, elapsed time:  45235
Step 93200, loss: 0.014046660360181705, acc: 99.5750144124031, p_norm: 1721.7008049905755, g_norm: 0.16963451919134093, lr:  0.000819, elapsed time:  45283
Step 93300, loss: 0.015973493873752888, acc: 99.50635313987732, p_norm: 1722.117341520658, g_norm: 0.16387221262350493, lr:  0.000818, elapsed time:  45330
Step 93400, loss: 0.01588745006170939, acc: 99.51800215244293, p_norm: 1722.5424932204255, g_norm: 0.16696517542501266, lr:  0.000818, elapsed time:  45377
Step 93500, loss: 0.014794252368046728, acc: 99.54621198773384, p_norm: 1722.9708855374379, g_norm: 0.17473176638613305, lr:  0.000817, elapsed time:  45425
Step 93600, loss: 0.01468822508075391, acc: 99.55475674569607, p_norm: 1723.3615111895822, g_norm: 0.2178356953213078, lr:  0.000817, elapsed time:  45473
Step 93700, loss: 0.01559162172874494, acc: 99.52593250572681, p_norm: 1723.780110521911, g_norm: 0.1648063238806572, lr:  0.000816, elapsed time:  45520
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 93800, loss: 0.015356484041995234, acc: 99.53322205970537, p_norm: 1724.1713958461135, g_norm: 0.24862137239953863, lr:  0.000816, elapsed time:  45568
Step 93900, loss: 0.014107326311568613, acc: 99.56507675349712, p_norm: 1724.5717449346535, g_norm: 0.15095989986344205, lr:  0.000816, elapsed time:  45616
Step 94000, loss: 0.014719951806982863, acc: 99.55059078335762, p_norm: 1724.9526386460573, g_norm: 0.21307081573954367, lr:  0.000815, elapsed time:  45663
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 94000, eval loss: 0.017384411335806364, eval acc: 99.5491943359375
Step 94100, loss: 0.014884380009607411, acc: 99.5548804551363, p_norm: 1725.310023442046, g_norm: 0.1893414518218727, lr:  0.000815, elapsed time:  45717
Step 94200, loss: 0.014438385861431015, acc: 99.55852419137955, p_norm: 1725.7126178174976, g_norm: 0.21934493144489695, lr:  0.000814, elapsed time:  45765
Step 94300, loss: 0.014485577682789881, acc: 99.55691780149937, p_norm: 1726.0862366325239, g_norm: 0.31696523425646217, lr:  0.000814, elapsed time:  45812
Step 94400, loss: 0.01477461837566807, acc: 99.5509547740221, p_norm: 1726.5010645826667, g_norm: 0.2007667458474462, lr:  0.000813, elapsed time:  45860
Step 94500, loss: 0.014517121625540313, acc: 99.55336816608906, p_norm: 1726.896101375672, g_norm: 0.19501555675713758, lr:  0.000813, elapsed time:  45907
Step 94600, loss: 0.01564732571176137, acc: 99.52841712534428, p_norm: 1727.3156637896482, g_norm: 0.30338803203884884, lr:  0.000813, elapsed time:  45954
Step 94700, loss: 0.014336449923102918, acc: 99.56946440041065, p_norm: 1727.7119410284956, g_norm: 0.16703286556839578, lr:  0.000812, elapsed time:  46002
Step 94800, loss: 0.014994556898163864, acc: 99.54540486633778, p_norm: 1728.1206834205682, g_norm: 0.21073800997074016, lr:  0.000812, elapsed time:  46050
Step 94900, loss: 0.014807994129732834, acc: 99.54669533669949, p_norm: 1728.5112245684643, g_norm: 0.23139840509486354, lr:  0.000811, elapsed time:  46097
Step 95000, loss: 0.015307029985124246, acc: 99.53201821446419, p_norm: 1728.8846878122602, g_norm: 0.21323775826125344, lr:  0.000811, elapsed time:  46144
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: O = [N+] ( [O-] ) c 1 c c c ( O C C C Cl ) c c 1 _EOS
Predicted text: O = [N+] ( [O-] ) c 1 c c c ( O C C C Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( C ) c c ( S c 2 c ( C ( C ) C ) c ( = O ) [nH] c ( = O ) n 2 C c 2 n c 3 c c c c c 3 o 2 ) c 1 _EOS
Predicted text: C c 1 c c ( C ) c c ( S c 2 c ( C ( C ) C ) c ( = O ) [nH] c ( = O ) n 2 C c 2 n c 3 c c c c c 3 o 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C c 1 c ( C ( = O ) O ) n c c 2 c 1 c 1 c ( O C c 3 c c c c c 3 ) c c c c 1 n 2 C C ( = O ) N ( C ) C c 1 c c c c c 1 _EOS
Predicted text: C O C c 1 c ( C ( = O ) O ) n c c 2 c 1 c 1 c ( O C c 3 c c c c c 3 ) c c c c 1 n 2 C C ( = O ) N ( C ) C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c 2 c c c c ( - c 3 c c c ( N 4 C C O C C 4 ) c c 3 ) c 2 s 1 _EOS
Predicted text: C O C ( = O ) c 1 c c 2 c c c c ( - c 3 c c c ( N 4 C C O C C 4 ) c c 3 ) c 2 s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O C C 1 O C ( n 2 c n c ( C ( = O ) C Cl ) c 2 N = C N ( C ) C ) C ( F ) C 1 O C ( C ) = O _EOS
Predicted text: C C ( = O ) O C C 1 O C ( n 2 c n c ( C ( = O ) C Cl ) c 2 N = C N ( C ) C ) C ( F ) C 1 O C ( C ) = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 95000, eval acc (token): 0.9249194513595005, eval acc (sequence): 0.8684087727484834
Saving at step 95000
Step 95100, loss: 0.015252628737507622, acc: 99.52622129023075, p_norm: 1729.2903288846173, g_norm: 0.17352712022236189, lr:  0.000810, elapsed time:  46244
Step 95200, loss: 0.01433318680850789, acc: 99.55859807133675, p_norm: 1729.6820814589291, g_norm: 0.26053535745176, lr:  0.000810, elapsed time:  46292
Step 95300, loss: 0.015121926309511764, acc: 99.53736872971058, p_norm: 1730.0560371140712, g_norm: 0.16086609522108872, lr:  0.000810, elapsed time:  46339
Step 95400, loss: 0.014937750402095844, acc: 99.55021484196186, p_norm: 1730.4547277026709, g_norm: 0.20566733944634374, lr:  0.000809, elapsed time:  46387
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 95500, loss: 0.013986633556707768, acc: 99.57748271395492, p_norm: 1730.854716763252, g_norm: 0.26255331153082107, lr:  0.000809, elapsed time:  46436
Step 95600, loss: 0.013072788742138073, acc: 99.5993607789278, p_norm: 1731.197475944447, g_norm: 0.161108744304689, lr:  0.000808, elapsed time:  46484
Step 95700, loss: 0.014310690515849274, acc: 99.56672491133213, p_norm: 1731.5877710819502, g_norm: 0.15681051935887927, lr:  0.000808, elapsed time:  46532
Step 95800, loss: 0.013909395855407639, acc: 99.57505269348621, p_norm: 1731.9644196285428, g_norm: 0.2384224275435121, lr:  0.000807, elapsed time:  46580
Step 95900, loss: 0.014469365130607911, acc: 99.56027717888355, p_norm: 1732.3325289759118, g_norm: 0.3867061153367008, lr:  0.000807, elapsed time:  46627
Step 96000, loss: 0.014005864901773748, acc: 99.57118882238865, p_norm: 1732.706985284569, g_norm: 0.15619568537920933, lr:  0.000807, elapsed time:  46674
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 96000, eval loss: 0.01954672135776491, eval acc: 99.5368423461914
Step 96100, loss: 0.013771747452847195, acc: 99.57942715287209, p_norm: 1733.113776638302, g_norm: 0.2116411622208098, lr:  0.000806, elapsed time:  46730
Step 96200, loss: 0.015171634304788312, acc: 99.53053165972233, p_norm: 1733.5112790777953, g_norm: 0.27197238396655815, lr:  0.000806, elapsed time:  46777
Step 96300, loss: 0.014067640722314536, acc: 99.5700810700655, p_norm: 1733.8990074228159, g_norm: 0.20618613945420375, lr:  0.000805, elapsed time:  46825
Step 96400, loss: 0.015200540582009125, acc: 99.52618558704853, p_norm: 1734.2870096701422, g_norm: 0.20920714310508054, lr:  0.000805, elapsed time:  46872
Step 96500, loss: 0.014307620514155133, acc: 99.56176476180553, p_norm: 1734.6778527523088, g_norm: 0.1990114060680182, lr:  0.000805, elapsed time:  46920
Step 96600, loss: 0.014417890066288236, acc: 99.55487616360188, p_norm: 1735.0344746659944, g_norm: 0.13482340813470703, lr:  0.000804, elapsed time:  46967
Step 96700, loss: 0.014752076405566186, acc: 99.54509809613228, p_norm: 1735.4153437306143, g_norm: 0.1891698104505912, lr:  0.000804, elapsed time:  47015
Step 96800, loss: 0.015431608161379699, acc: 99.52341821789742, p_norm: 1735.8037728234476, g_norm: 0.15388916747724293, lr:  0.000803, elapsed time:  47063
Step 96900, loss: 0.014302371198591573, acc: 99.56004276871681, p_norm: 1736.1621384126004, g_norm: 0.33097662506466147, lr:  0.000803, elapsed time:  47110
Step 97000, loss: 0.01474903943057143, acc: 99.55163018405437, p_norm: 1736.5313871302724, g_norm: 0.15471695496035182, lr:  0.000802, elapsed time:  47158
Step 97100, loss: 0.014919867810676805, acc: 99.55045120418072, p_norm: 1736.9075544768825, g_norm: 0.21469623991763356, lr:  0.000802, elapsed time:  47205
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 97200, loss: 0.014714725946538987, acc: 99.54996912118519, p_norm: 1737.2899626517324, g_norm: 0.20308880023361892, lr:  0.000802, elapsed time:  47254
Step 97300, loss: 0.014193806959374342, acc: 99.5681055188179, p_norm: 1737.6569992226216, g_norm: 0.23759113341627483, lr:  0.000801, elapsed time:  47301
Step 97400, loss: 0.013957367760649503, acc: 99.56641501188278, p_norm: 1738.0709556416261, g_norm: 0.2126707967621245, lr:  0.000801, elapsed time:  47350
Step 97500, loss: 0.014163364643172827, acc: 99.56913240253925, p_norm: 1738.433158733708, g_norm: 0.19028127990372282, lr:  0.000800, elapsed time:  47397
Step 97600, loss: 0.014359394458260795, acc: 99.55677455663681, p_norm: 1738.8056290695383, g_norm: 0.19098121650069438, lr:  0.000800, elapsed time:  47445
Step 97700, loss: 0.014359410095130443, acc: 99.57135066390038, p_norm: 1739.162326907681, g_norm: 0.16667149713257481, lr:  0.000800, elapsed time:  47492
Step 97800, loss: 0.01356825832852337, acc: 99.58752152323723, p_norm: 1739.548896291574, g_norm: 0.2056864719100301, lr:  0.000799, elapsed time:  47541
Step 97900, loss: 0.015028152460145066, acc: 99.54435439407825, p_norm: 1739.935583193255, g_norm: 0.20902018713382595, lr:  0.000799, elapsed time:  47588
Step 98000, loss: 0.01484556512965355, acc: 99.54549740254879, p_norm: 1740.3352848136149, g_norm: 0.27199195001391385, lr:  0.000798, elapsed time:  47636
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 98000, eval loss: 0.02031947201598087, eval acc: 99.49766540527344
Step 98100, loss: 0.013975184033915867, acc: 99.5748034119606, p_norm: 1740.7020562666874, g_norm: 0.20926312940033695, lr:  0.000798, elapsed time:  47690
Step 98200, loss: 0.01475958799932414, acc: 99.55344566702843, p_norm: 1741.0840027152842, g_norm: 0.16372004449254401, lr:  0.000798, elapsed time:  47737
Step 98300, loss: 0.014451659929472954, acc: 99.5629334449768, p_norm: 1741.4567918980508, g_norm: 0.1598554378492648, lr:  0.000797, elapsed time:  47785
Step 98400, loss: 0.014118436140161067, acc: 99.56717666983604, p_norm: 1741.8175659049796, g_norm: 0.24879554913451576, lr:  0.000797, elapsed time:  47832
Step 98500, loss: 0.014195638138480716, acc: 99.56653743982315, p_norm: 1742.1928150969543, g_norm: 0.26234533291433454, lr:  0.000796, elapsed time:  47881
Step 98600, loss: 0.014812249878741569, acc: 99.5372741818428, p_norm: 1742.5870939320878, g_norm: 0.21626003207582342, lr:  0.000796, elapsed time:  47928
Step 98700, loss: 0.014374268137617037, acc: 99.56792096793652, p_norm: 1742.9656107547455, g_norm: 0.23994290781915856, lr:  0.000796, elapsed time:  47975
Step 98800, loss: 0.01473891545596416, acc: 99.5454802364111, p_norm: 1743.3370054617844, g_norm: 0.226823008390866, lr:  0.000795, elapsed time:  48022
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 98900, loss: 0.014233092690047302, acc: 99.56901079371904, p_norm: 1743.7097398303408, g_norm: 0.1902211824802647, lr:  0.000795, elapsed time:  48070
Step 99000, loss: 0.01320860873307538, acc: 99.59011505544186, p_norm: 1744.0552760937808, g_norm: 0.17820269517564233, lr:  0.000794, elapsed time:  48117
Step 99100, loss: 0.013346837397130003, acc: 99.58806321024895, p_norm: 1744.3979600619334, g_norm: 0.1636475703977842, lr:  0.000794, elapsed time:  48164
Step 99200, loss: 0.014252877812687074, acc: 99.56107559800148, p_norm: 1744.796555098814, g_norm: 0.15316067438320094, lr:  0.000794, elapsed time:  48211
Step 99300, loss: 0.01327575927862199, acc: 99.5976731479168, p_norm: 1745.1524310901889, g_norm: 0.1973862199182244, lr:  0.000793, elapsed time:  48259
Step 99400, loss: 0.014047183055008645, acc: 99.57111202180386, p_norm: 1745.519856222634, g_norm: 0.15686952478213326, lr:  0.000793, elapsed time:  48306
Step 99500, loss: 0.01419678872978693, acc: 99.56756274402142, p_norm: 1745.8995408906146, g_norm: 0.23501369449827014, lr:  0.000792, elapsed time:  48354
Step 99600, loss: 0.014733788790872495, acc: 99.55562976002693, p_norm: 1746.2624241300966, g_norm: 0.15315077225863416, lr:  0.000792, elapsed time:  48401
Step 99700, loss: 0.014210772097940208, acc: 99.56891855597496, p_norm: 1746.6451796167403, g_norm: 0.16664227354283326, lr:  0.000792, elapsed time:  48449
Step 99800, loss: 0.013634482885245235, acc: 99.58014716207981, p_norm: 1746.9969130469506, g_norm: 0.19870086837099019, lr:  0.000791, elapsed time:  48497
Step 99900, loss: 0.014495302182185697, acc: 99.552793353796, p_norm: 1747.3756459817453, g_norm: 0.2620508162991996, lr:  0.000791, elapsed time:  48545
Step 100000, loss: 0.014865880031284178, acc: 99.5505078881979, p_norm: 1747.7416145775937, g_norm: 0.16222321179233973, lr:  0.000790, elapsed time:  48593
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 100000, eval loss: 0.019220946477944388, eval acc: 99.53765106201172
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c ( C ) c ( C ) c ( O C ) c ( C N ( C ) C C O c 2 c c ( C ) c ( N C ( C ) = O ) c c 2 C ( C ) C ) c 1 C _EOS
Predicted text: C O c 1 c ( C ) c ( C ) c ( O C ) c ( C N ( C ) C C O c 2 c c ( C ) c ( N C ( C ) = O ) c c 2 C ( C ) C ) c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( N N = C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c n 1 _EOS
Predicted text: C O c 1 c c c ( N N = C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C ( C C ) c 1 c c ( C ) n n 2 c ( - c 3 c c ( Br ) o c 3 C ) c ( C ) n c 1 2 _EOS
Predicted text: C C C ( C C ) c 1 c c ( C ) n n 2 c ( - c 3 c c ( Br ) o c 3 C ) c ( C ) n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 s c ( - c 2 c c c c ( N C ( = O ) N C ( C ) C ) c 2 ) c ( Br ) c 1 O C C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C O C ( = O ) c 1 s c ( - c 2 c c c c ( N C ( = O ) N C ( C ) C ) c 2 ) c ( Br ) c 1 O C C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C N ( C c 2 c c c ( N ) c c 2 ) C C N 1 C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C C 1 C N ( C c 2 c c c ( N ) c c 2 ) C C N 1 C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 100000, eval acc (token): 0.935209452812905, eval acc (sequence): 0.8815554762754192
Saving at step 100000
Step 100100, loss: 0.014994763895811048, acc: 99.5354169011116, p_norm: 1748.1263620684008, g_norm: 0.22464331251094838, lr:  0.000790, elapsed time:  48701
Step 100200, loss: 0.014163793095358415, acc: 99.57106366753578, p_norm: 1748.494389561878, g_norm: 0.142530297134063, lr:  0.000790, elapsed time:  48748
Step 100300, loss: 0.015114117453049403, acc: 99.53497695922852, p_norm: 1748.879765668742, g_norm: 0.20311074029152207, lr:  0.000789, elapsed time:  48796
Step 100400, loss: 0.014596217420184986, acc: 99.56271663308144, p_norm: 1749.216533519737, g_norm: 0.22847059065928702, lr:  0.000789, elapsed time:  48844
Step 100500, loss: 0.013930927254550625, acc: 99.58643518388271, p_norm: 1749.574077785037, g_norm: 0.23600512794338782, lr:  0.000788, elapsed time:  48891
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 100600, loss: 0.01525973302641749, acc: 99.53493926655594, p_norm: 1749.9329571155731, g_norm: 0.2724286624774114, lr:  0.000788, elapsed time:  48940
Step 100700, loss: 0.013613552351162071, acc: 99.57949288189411, p_norm: 1750.2742158193887, g_norm: 0.22395193747906164, lr:  0.000788, elapsed time:  48987
Step 100800, loss: 0.013863307580104447, acc: 99.57623179256916, p_norm: 1750.6400081615773, g_norm: 0.1455263936195388, lr:  0.000787, elapsed time:  49034
Step 100900, loss: 0.013736849558699759, acc: 99.57939617335796, p_norm: 1751.0136641917088, g_norm: 0.2597846724229707, lr:  0.000787, elapsed time:  49081
Step 101000, loss: 0.013587823785492219, acc: 99.59278635680676, p_norm: 1751.3718931964881, g_norm: 0.1639163337101055, lr:  0.000786, elapsed time:  49129
Step 101100, loss: 0.014142155028694106, acc: 99.56255197525024, p_norm: 1751.731576330731, g_norm: 0.18529210442713534, lr:  0.000786, elapsed time:  49176
Step 101200, loss: 0.013916825388077996, acc: 99.565877571702, p_norm: 1752.0965547921644, g_norm: 0.16172265921702947, lr:  0.000786, elapsed time:  49224
Step 101300, loss: 0.013844858753982408, acc: 99.58127261698246, p_norm: 1752.4432764657674, g_norm: 0.14964274375423678, lr:  0.000785, elapsed time:  49272
Step 101400, loss: 0.014284008260365227, acc: 99.55888171494007, p_norm: 1752.8059706054044, g_norm: 0.17064576595716568, lr:  0.000785, elapsed time:  49319
Step 101500, loss: 0.013506782872136682, acc: 99.58099853992462, p_norm: 1753.1810130114281, g_norm: 0.1799537154940486, lr:  0.000784, elapsed time:  49368
Step 101600, loss: 0.013982847816369031, acc: 99.57335233688354, p_norm: 1753.5692652632292, g_norm: 0.2047002032862756, lr:  0.000784, elapsed time:  49415
Step 101700, loss: 0.013985547635384137, acc: 99.56896831095219, p_norm: 1753.9473751763571, g_norm: 0.17635388598492058, lr:  0.000784, elapsed time:  49463
Step 101800, loss: 0.014277543201278603, acc: 99.56547826528549, p_norm: 1754.3284586738234, g_norm: 0.1878124497999113, lr:  0.000783, elapsed time:  49511
Step 101900, loss: 0.014634679526752735, acc: 99.54981949925423, p_norm: 1754.6861022492571, g_norm: 0.17528177948376075, lr:  0.000783, elapsed time:  49559
Step 102000, loss: 0.01434347393013013, acc: 99.5673725605011, p_norm: 1755.0605662145304, g_norm: 0.22040476560608746, lr:  0.000783, elapsed time:  49606
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 102000, eval loss: 0.01721573703536705, eval acc: 99.56835174560547
Step 102100, loss: 0.014918511579089681, acc: 99.55124345421791, p_norm: 1755.4336370994822, g_norm: 0.1599410756576231, lr:  0.000782, elapsed time:  49661
Step 102200, loss: 0.014362892463977914, acc: 99.56224745512009, p_norm: 1755.7825978489225, g_norm: 0.23136605464848692, lr:  0.000782, elapsed time:  49708
Step 102300, loss: 0.015456095686822664, acc: 99.52932703495026, p_norm: 1756.2004843351451, g_norm: 0.18056225785427726, lr:  0.000781, elapsed time:  49755
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 102400, loss: 0.013893958753325558, acc: 99.570987612083, p_norm: 1756.528628618618, g_norm: 0.1525154102815918, lr:  0.000781, elapsed time:  49803
Step 102500, loss: 0.012971729017444887, acc: 99.60411305725574, p_norm: 1756.841044071483, g_norm: 0.2234999063563757, lr:  0.000781, elapsed time:  49851
Step 102600, loss: 0.013655951339605963, acc: 99.58646906912327, p_norm: 1757.194310422112, g_norm: 0.17519607177252255, lr:  0.000780, elapsed time:  49899
Step 102700, loss: 0.01379770150186232, acc: 99.58138927817345, p_norm: 1757.5227582915586, g_norm: 0.18806376503014025, lr:  0.000780, elapsed time:  49947
Step 102800, loss: 0.013729094035807066, acc: 99.58442284166813, p_norm: 1757.8480751030409, g_norm: 0.18985008448463778, lr:  0.000779, elapsed time:  49995
Step 102900, loss: 0.013873121665528742, acc: 99.5805902928114, p_norm: 1758.2036011075677, g_norm: 0.16119350190581486, lr:  0.000779, elapsed time:  50042
Step 103000, loss: 0.013977502366506087, acc: 99.57149218022823, p_norm: 1758.572080465124, g_norm: 0.14621122784884474, lr:  0.000779, elapsed time:  50091
Step 103100, loss: 0.01407022600847995, acc: 99.57008136808872, p_norm: 1758.921043543127, g_norm: 0.1893999320187078, lr:  0.000778, elapsed time:  50138
Step 103200, loss: 0.013888533614299377, acc: 99.5757739841938, p_norm: 1759.291269015779, g_norm: 0.1955172780490364, lr:  0.000778, elapsed time:  50186
Step 103300, loss: 0.014718663478124654, acc: 99.54835356771946, p_norm: 1759.6614360044116, g_norm: 0.2216657877522867, lr:  0.000778, elapsed time:  50233
Step 103400, loss: 0.013820768482728453, acc: 99.58265310525894, p_norm: 1760.0080566339727, g_norm: 0.2176379138071849, lr:  0.000777, elapsed time:  50281
Step 103500, loss: 0.01365563227358507, acc: 99.58369378745556, p_norm: 1760.3546137517533, g_norm: 0.14823818010402298, lr:  0.000777, elapsed time:  50328
Step 103600, loss: 0.014371862112384406, acc: 99.56047943234444, p_norm: 1760.7063376773317, g_norm: 0.2408394420048048, lr:  0.000776, elapsed time:  50376
Step 103700, loss: 0.013993868465113336, acc: 99.57481165230274, p_norm: 1761.058004674952, g_norm: 0.2111271720542531, lr:  0.000776, elapsed time:  50424
Step 103800, loss: 0.013444292895001127, acc: 99.58812257647514, p_norm: 1761.4082236598256, g_norm: 0.3369961651606188, lr:  0.000776, elapsed time:  50473
Step 103900, loss: 0.014076621018321021, acc: 99.57339076697826, p_norm: 1761.7703722873264, g_norm: 0.1683702538720539, lr:  0.000775, elapsed time:  50521
Step 104000, loss: 0.014386429417791079, acc: 99.56619943678379, p_norm: 1762.140503633188, g_norm: 0.1310950478259881, lr:  0.000775, elapsed time:  50569
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 104000, eval loss: 0.01873863145767245, eval acc: 99.5208740234375
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 104100, loss: 0.012854340679674822, acc: 99.61224112344618, p_norm: 1762.4822870994524, g_norm: 0.2612689833882268, lr:  0.000775, elapsed time:  50625
Step 104200, loss: 0.013462350510963006, acc: 99.58438754081726, p_norm: 1762.8115541128018, g_norm: 0.19073449564767345, lr:  0.000774, elapsed time:  50673
Step 104300, loss: 0.013850252148786239, acc: 99.56664843857288, p_norm: 1763.1777665492416, g_norm: 0.21683087698383055, lr:  0.000774, elapsed time:  50720
Step 104400, loss: 0.013552262930534197, acc: 99.5850800126791, p_norm: 1763.4977286590677, g_norm: 0.16188814303954974, lr:  0.000774, elapsed time:  50767
Step 104500, loss: 0.014502513854313292, acc: 99.55990990996361, p_norm: 1763.849977691977, g_norm: 0.18695790046622407, lr:  0.000773, elapsed time:  50815
Step 104600, loss: 0.013762966195790795, acc: 99.5811732262373, p_norm: 1764.1974878827998, g_norm: 0.17572576944983287, lr:  0.000773, elapsed time:  50863
Step 104700, loss: 0.013993691685827798, acc: 99.57469503581524, p_norm: 1764.5316501597733, g_norm: 0.17671209392825624, lr:  0.000772, elapsed time:  50909
Step 104800, loss: 0.014304595360335952, acc: 99.56381291151047, p_norm: 1764.877308855374, g_norm: 0.22955624006938657, lr:  0.000772, elapsed time:  50956
Step 104900, loss: 0.014184240099493763, acc: 99.56890659034252, p_norm: 1765.2317601199263, g_norm: 0.30978627073849296, lr:  0.000772, elapsed time:  51004
Step 105000, loss: 0.013725627442363475, acc: 99.58242030441761, p_norm: 1765.6020226797011, g_norm: 0.19572172689188203, lr:  0.000771, elapsed time:  51052
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C O c 1 c c ( C ( C ) ( C ) C ) n c c 1 C 1 = N C ( C ) ( c 2 c c c ( Cl ) c c 2 ) C ( C ) ( c 2 c c c ( Cl ) c c 2 ) N 1 C ( = O ) N 1 C C N ( C ( = O ) C N c 2 n c c s 2 ) C C 1 _EOS
Predicted text: C C O c 1 c c ( C ( C ) ( C ) C ) n c c 1 C 1 = N C ( C ) ( c 2 c c c ( Cl ) c c 2 ) C ( C ) ( c 2 c c c ( Cl ) c c 2 ) N 1 C ( = O ) N 1 C C N ( C ( = O ) C N c 2 n c c s 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c 2 c c ( C ( F ) ( F ) F ) c ( Cl ) c c 2 n 1 - c 1 c c c ( C C O C ( = O ) N S ( = O ) ( = O ) c 2 c n ( C ) c ( C ) n 2 ) c c 1 _EOS
Predicted text: C C c 1 n c 2 c c ( C ( F ) ( F ) F ) c ( Cl ) c c 2 n 1 - c 1 c c c ( C C O C ( = O ) N S ( = O ) ( = O ) c 2 c n ( C ) c ( C ) n 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c n 2 n c ( - c 3 c c c c c 3 ) n c 2 c c 1 N C ( = O ) c 1 c ( C ( = O ) N 2 C C C 2 ) c n n 1 C _EOS
Predicted text: C c 1 c n 2 n c ( - c 3 c c c c c 3 ) n c 2 c c 1 N C ( = O ) c 1 c ( C ( = O ) N 2 C C C 2 ) c n n 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C S ( = O ) ( = O ) n 1 c c c ( N C ( = O ) C ( C C 2 C C C C 2 ) c 2 c c c ( S ( C ) ( = O ) = O ) c ( Cl ) c 2 ) n 1 _EOS
Predicted text: C C S ( = O ) ( = O ) n 1 c c c ( N C ( = O ) C ( C C 2 C C C C 2 ) c 2 c c c ( S ( C ) ( = O ) = O ) c ( Cl ) c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C C 1 ( C ) C C ( c 2 c c c c ( Cl ) c 2 ) C ( c 2 c c c ( Cl ) c c 2 ) N ( c 2 c n c c n 2 ) C 1 = O _EOS
Predicted text: C = C C C 1 ( C ) C C ( c 2 c c c c ( Cl ) c 2 ) C ( c 2 c c c ( Cl ) c c 2 ) N ( c 2 c n c c n 2 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 105000, eval acc (token): 0.9390162469016092, eval acc (sequence): 0.8877730796335448
Saving at step 105000
Step 105100, loss: 0.014132058492032229, acc: 99.572782933712, p_norm: 1765.958806899549, g_norm: 0.16912461157861977, lr:  0.000771, elapsed time:  51153
Step 105200, loss: 0.013804348741468858, acc: 99.57515852153301, p_norm: 1766.307516718486, g_norm: 0.18411926247292074, lr:  0.000771, elapsed time:  51201
Step 105300, loss: 0.012970835831874866, acc: 99.60454076528549, p_norm: 1766.655974174636, g_norm: 0.19802710210709562, lr:  0.000770, elapsed time:  51249
Step 105400, loss: 0.01449870417745842, acc: 99.56617699563503, p_norm: 1767.039204402888, g_norm: 0.1609231898031947, lr:  0.000770, elapsed time:  51302
Step 105500, loss: 0.014126795588672393, acc: 99.56967560946941, p_norm: 1767.3732022824377, g_norm: 0.198254535101893, lr:  0.000769, elapsed time:  51359
Step 105600, loss: 0.013252922573301476, acc: 99.59305989742279, p_norm: 1767.7052779302292, g_norm: 0.1518826453276445, lr:  0.000769, elapsed time:  51407
Step 105700, loss: 0.01375972741181613, acc: 99.58019679784775, p_norm: 1768.0439309003702, g_norm: 0.20443643083522642, lr:  0.000769, elapsed time:  51454
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 105800, loss: 0.01380952894685486, acc: 99.56775742488227, p_norm: 1768.4189702906992, g_norm: 0.2028320942174871, lr:  0.000768, elapsed time:  51503
Step 105900, loss: 0.013101116790348897, acc: 99.59827396273613, p_norm: 1768.7674244069174, g_norm: 0.20098260747939065, lr:  0.000768, elapsed time:  51552
Step 106000, loss: 0.013001241647943971, acc: 99.60117730498314, p_norm: 1769.0889769344308, g_norm: 0.23283168552157296, lr:  0.000768, elapsed time:  51600
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 106000, eval loss: 0.017924096272254254, eval acc: 99.55365753173828
Step 106100, loss: 0.014440035584048019, acc: 99.5562380105257, p_norm: 1769.4567712711298, g_norm: 0.17602056790517795, lr:  0.000767, elapsed time:  51654
Step 106200, loss: 0.013662172870099312, acc: 99.57881651818752, p_norm: 1769.784404392009, g_norm: 0.16425750227150424, lr:  0.000767, elapsed time:  51702
Step 106300, loss: 0.013647173798963195, acc: 99.5800021737814, p_norm: 1770.130298691233, g_norm: 0.1639322617758279, lr:  0.000767, elapsed time:  51749
Step 106400, loss: 0.013447953154682182, acc: 99.58274804055691, p_norm: 1770.4485981361802, g_norm: 0.2017087588044965, lr:  0.000766, elapsed time:  51797
Step 106500, loss: 0.013611410307057668, acc: 99.5796230584383, p_norm: 1770.7789359452565, g_norm: 0.12762074862440007, lr:  0.000766, elapsed time:  51844
Step 106600, loss: 0.013211390967771876, acc: 99.5961330384016, p_norm: 1771.0897238214593, g_norm: 0.16463254062813595, lr:  0.000765, elapsed time:  51892
Step 106700, loss: 0.013024487618313287, acc: 99.5958872884512, p_norm: 1771.4262064402915, g_norm: 0.21530646822840305, lr:  0.000765, elapsed time:  51940
Step 106800, loss: 0.014403270415859879, acc: 99.55264322459698, p_norm: 1771.782890235097, g_norm: 0.21860657683058646, lr:  0.000765, elapsed time:  51987
Step 106900, loss: 0.013974476580988266, acc: 99.57140785455704, p_norm: 1772.1538139217748, g_norm: 0.22486544238252318, lr:  0.000764, elapsed time:  52036
Step 107000, loss: 0.013883719171572011, acc: 99.57312749326229, p_norm: 1772.4684022414747, g_norm: 0.16857594236982296, lr:  0.000764, elapsed time:  52083
Step 107100, loss: 0.01366648749819433, acc: 99.58270418643951, p_norm: 1772.7838229651254, g_norm: 0.12129405165767067, lr:  0.000764, elapsed time:  52131
Step 107200, loss: 0.014060432688274886, acc: 99.58360409736633, p_norm: 1773.1331141064773, g_norm: 0.1458526305169696, lr:  0.000763, elapsed time:  52179
Step 107300, loss: 0.013994225712813203, acc: 99.57175979018211, p_norm: 1773.477241654007, g_norm: 0.13554610603651732, lr:  0.000763, elapsed time:  52226
Step 107400, loss: 0.013398874859994976, acc: 99.58980967104435, p_norm: 1773.8135310281589, g_norm: 0.1650265935660518, lr:  0.000763, elapsed time:  52274
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 107500, loss: 0.012581806678932146, acc: 99.61181776990962, p_norm: 1774.1584552969673, g_norm: 0.15106023589016437, lr:  0.000762, elapsed time:  52323
Step 107600, loss: 0.01381808382622694, acc: 99.57915818691254, p_norm: 1774.4801313523449, g_norm: 0.22103513908722613, lr:  0.000762, elapsed time:  52369
Step 107700, loss: 0.013718849683173176, acc: 99.58513033390045, p_norm: 1774.8427155619802, g_norm: 0.15398261062481544, lr:  0.000762, elapsed time:  52417
Step 107800, loss: 0.014006587784169824, acc: 99.56525255739689, p_norm: 1775.1689006215058, g_norm: 0.1886646763893592, lr:  0.000761, elapsed time:  52464
Step 107900, loss: 0.013278588151442818, acc: 99.59956188499928, p_norm: 1775.5075688598304, g_norm: 0.18728823594658747, lr:  0.000761, elapsed time:  52511
Step 108000, loss: 0.013441319374760497, acc: 99.58941008150578, p_norm: 1775.8059079688949, g_norm: 0.20841751124209387, lr:  0.000761, elapsed time:  52559
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 108000, eval loss: 0.017079170097713363, eval acc: 99.57965087890625
Step 108100, loss: 0.013684163239668123, acc: 99.57824936509132, p_norm: 1776.1481914800602, g_norm: 0.22487120928739202, lr:  0.000760, elapsed time:  52614
Step 108200, loss: 0.01412883720939135, acc: 99.56476132571697, p_norm: 1776.5226241442692, g_norm: 0.2203270338533855, lr:  0.000760, elapsed time:  52662
Step 108300, loss: 0.01373029387093993, acc: 99.58120948076248, p_norm: 1776.8656561679998, g_norm: 0.2140388697698, lr:  0.000759, elapsed time:  52709
Step 108400, loss: 0.013532698205017369, acc: 99.58609734475613, p_norm: 1777.1785203625893, g_norm: 0.1982732339310953, lr:  0.000759, elapsed time:  52757
Step 108500, loss: 0.013286846396076725, acc: 99.59716093540192, p_norm: 1777.5120399260013, g_norm: 0.24584925920958656, lr:  0.000759, elapsed time:  52804
Step 108600, loss: 0.013758211024614865, acc: 99.57509380578995, p_norm: 1777.869666871992, g_norm: 0.3336076755238915, lr:  0.000758, elapsed time:  52852
Step 108700, loss: 0.013047030121160787, acc: 99.59966287016869, p_norm: 1778.1975523408973, g_norm: 0.2129024151675112, lr:  0.000758, elapsed time:  52900
Step 108800, loss: 0.014170867414286477, acc: 99.56224024295807, p_norm: 1778.5142124909453, g_norm: 0.1612856856952236, lr:  0.000758, elapsed time:  52947
Step 108900, loss: 0.013330308135264203, acc: 99.58447641134262, p_norm: 1778.860975259615, g_norm: 0.15238525081146567, lr:  0.000757, elapsed time:  52995
Step 109000, loss: 0.013513584566608188, acc: 99.59438762068748, p_norm: 1779.204553612168, g_norm: 0.19252942668115838, lr:  0.000757, elapsed time:  53043
Step 109100, loss: 0.014113067144207889, acc: 99.57280968129635, p_norm: 1779.5347055017555, g_norm: 0.3425043200022957, lr:  0.000757, elapsed time:  53090
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 109200, loss: 0.012960242699035061, acc: 99.6090025599323, p_norm: 1779.8523437336194, g_norm: 0.18764489117507935, lr:  0.000756, elapsed time:  53139
Step 109300, loss: 0.013416954681888455, acc: 99.58074449002743, p_norm: 1780.155564403554, g_norm: 0.23057081730820222, lr:  0.000756, elapsed time:  53187
Step 109400, loss: 0.013521751638691057, acc: 99.58652822673321, p_norm: 1780.4755534495305, g_norm: 0.24044381213109817, lr:  0.000756, elapsed time:  53234
Step 109500, loss: 0.012845559076413337, acc: 99.60187247395515, p_norm: 1780.8153056770366, g_norm: 0.1449905133382964, lr:  0.000755, elapsed time:  53282
Step 109600, loss: 0.013485967536980751, acc: 99.58584527671337, p_norm: 1781.1684052812268, g_norm: 0.22087729149400498, lr:  0.000755, elapsed time:  53329
Step 109700, loss: 0.01340033654931176, acc: 99.59914210438728, p_norm: 1781.5364263006682, g_norm: 0.26624250297354796, lr:  0.000755, elapsed time:  53377
Step 109800, loss: 0.013428002540313172, acc: 99.58397962152958, p_norm: 1781.8885418652098, g_norm: 0.15896418981374194, lr:  0.000754, elapsed time:  53425
Step 109900, loss: 0.01364912213943171, acc: 99.5756368637085, p_norm: 1782.2202004725902, g_norm: 0.19853713687194877, lr:  0.000754, elapsed time:  53472
Step 110000, loss: 0.01346480994790909, acc: 99.5820404291153, p_norm: 1782.5614941733027, g_norm: 0.16336779275108915, lr:  0.000754, elapsed time:  53519
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 110000, eval loss: 0.018949186102836385, eval acc: 99.5290756225586
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: N N = C 1 c 2 c c c c c 2 - c 2 c c c ( F ) c c 2 1 _EOS
Predicted text: N N = C 1 c 2 c c c c c 2 - c 2 c c c ( F ) c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C C ( C ( = O ) N N 1 C ( = O ) N C ( C ) ( C ) C 1 = O ) C ( C C C c 1 c c c c c 1 ) C ( = O ) N O _EOS
Predicted text: C C O C ( = O ) C ( C ) ( C ) N C ( = O ) N N C ( = O ) C ( C C ( C ) C ) C ( C C C c 1 c c c c c 1 ) C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 0.2857142857142857, acc_seq: False

Target text: C O C C ( = O ) N 1 C C C ( N C ( = O ) c 2 c [nH] c 3 c ( - c 4 c ( O C C 5 C C 5 ) c c c 5 c 4 O C O 5 ) n c n c 2 3 ) C 1 _EOS
Predicted text: C O C C ( = O ) N 1 C C C ( N C ( = O ) c 2 c [nH] c 3 c ( - c 4 c ( O C C 5 C C 5 ) c c c 5 c 4 O C O 5 ) n c n c 2 3 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c n c 2 [nH] c c ( C c 3 c c c ( N C c 4 c c c ( C ( F ) ( F ) F ) n c 4 ) n c 3 F ) c 2 c 1 _EOS
Predicted text: C O c 1 c n c 2 [nH] c c ( C c 3 c c c ( N C c 4 c c c ( C ( F ) ( F ) F ) n c 4 ) n c 3 F ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c c ( - c 2 c c 3 c n c ( N ) n c 3 n c 2 N C ( = O ) N C ( C ) ( C ) C ) c 1 _EOS
Predicted text: C O c 1 c c c c ( - c 2 c c 3 c n c ( N ) n c 3 n c 2 N C ( = O ) N C ( C ) ( C ) C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 110000, eval acc (token): 0.9357621414913835, eval acc (sequence): 0.8827939294203694
Saving at step 110000
Step 110100, loss: 0.01314788678617333, acc: 99.59482830762863, p_norm: 1782.865905242234, g_norm: 0.1667128207573314, lr:  0.000753, elapsed time:  53628
Step 110200, loss: 0.0136989387644644, acc: 99.57561686635017, p_norm: 1783.2036330993178, g_norm: 0.2741923628386131, lr:  0.000753, elapsed time:  53675
Step 110300, loss: 0.013347949260169117, acc: 99.59343835711479, p_norm: 1783.5414476734907, g_norm: 0.134351846442453, lr:  0.000753, elapsed time:  53722
Step 110400, loss: 0.013212084641345427, acc: 99.59310798346996, p_norm: 1783.8671326322683, g_norm: 0.1616544201641712, lr:  0.000752, elapsed time:  53770
Step 110500, loss: 0.013883802756608929, acc: 99.57490725815296, p_norm: 1784.221580807184, g_norm: 0.15323302199342065, lr:  0.000752, elapsed time:  53818
Step 110600, loss: 0.014352385928650619, acc: 99.56697091460228, p_norm: 1784.5453423947426, g_norm: 0.13541704772264374, lr:  0.000752, elapsed time:  53865
Step 110700, loss: 0.01403525030676974, acc: 99.57708942890167, p_norm: 1784.8757408138363, g_norm: 0.19323195004049373, lr:  0.000751, elapsed time:  53913
Step 110800, loss: 0.013134383262004121, acc: 99.59479643404484, p_norm: 1785.186406734506, g_norm: 0.21177205394038576, lr:  0.000751, elapsed time:  53961
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 110900, loss: 0.013038962754616213, acc: 99.60161990326628, p_norm: 1785.4792296984663, g_norm: 0.16094244407459599, lr:  0.000750, elapsed time:  54009
Step 111000, loss: 0.01287897272799455, acc: 99.6042552292347, p_norm: 1785.7878553569253, g_norm: 0.1947209531640957, lr:  0.000750, elapsed time:  54056
Step 111100, loss: 0.013002793098858092, acc: 99.60081560909748, p_norm: 1786.1156327767642, g_norm: 0.30047276449703586, lr:  0.000750, elapsed time:  54103
Step 111200, loss: 0.013340986504081229, acc: 99.59258602559566, p_norm: 1786.4526462838344, g_norm: 0.17748078370210638, lr:  0.000749, elapsed time:  54151
Step 111300, loss: 0.013333249151874043, acc: 99.58303773403168, p_norm: 1786.7779968583159, g_norm: 0.17608570634827786, lr:  0.000749, elapsed time:  54198
Step 111400, loss: 0.013323651616228744, acc: 99.59303545951843, p_norm: 1787.1076606058655, g_norm: 0.23350669266736834, lr:  0.000749, elapsed time:  54245
Step 111500, loss: 0.01264559396498953, acc: 99.60805869102478, p_norm: 1787.4251275896443, g_norm: 0.22827535784932415, lr:  0.000748, elapsed time:  54293
Step 111600, loss: 0.013635890144378209, acc: 99.58072631061077, p_norm: 1787.7407138437177, g_norm: 0.186119597243262, lr:  0.000748, elapsed time:  54341
Step 111700, loss: 0.012371321149912547, acc: 99.61889244616032, p_norm: 1788.055521855836, g_norm: 0.1653914381931131, lr:  0.000748, elapsed time:  54389
Step 111800, loss: 0.013709818383867969, acc: 99.58172690868378, p_norm: 1788.3706431750256, g_norm: 0.2227122892598374, lr:  0.000747, elapsed time:  54436
Step 111900, loss: 0.013121967889164808, acc: 99.59480085968971, p_norm: 1788.703157957069, g_norm: 0.2997810721326186, lr:  0.000747, elapsed time:  54484
Step 112000, loss: 0.013008418693498242, acc: 99.60722209513187, p_norm: 1789.0393431514913, g_norm: 0.1632670952043612, lr:  0.000747, elapsed time:  54532
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 112000, eval loss: 0.01689821540439879, eval acc: 99.57575225830078
Step 112100, loss: 0.013265008281668997, acc: 99.60000719130039, p_norm: 1789.3858791340754, g_norm: 0.2197282744671291, lr:  0.000746, elapsed time:  54587
Step 112200, loss: 0.013985541458241641, acc: 99.56985999643803, p_norm: 1789.7155314750148, g_norm: 0.20230016937209952, lr:  0.000746, elapsed time:  54635
Step 112300, loss: 0.013541845643339911, acc: 99.58983521163464, p_norm: 1790.062186407898, g_norm: 0.19684871111145946, lr:  0.000746, elapsed time:  54683
Step 112400, loss: 0.013815528756949788, acc: 99.57976087927818, p_norm: 1790.3790372294623, g_norm: 0.24183804107090148, lr:  0.000745, elapsed time:  54730
Step 112500, loss: 0.013452016817464028, acc: 99.5894465893507, p_norm: 1790.6958687112822, g_norm: 0.22645113917549947, lr:  0.000745, elapsed time:  54777
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 112600, loss: 0.012957456710032218, acc: 99.60319272321254, p_norm: 1791.0108703197525, g_norm: 0.22082324254905528, lr:  0.000745, elapsed time:  54826
Step 112700, loss: 0.012461718140912126, acc: 99.61408765614033, p_norm: 1791.307956022519, g_norm: 0.1883403078757489, lr:  0.000744, elapsed time:  54874
Step 112800, loss: 0.012692181172969868, acc: 99.61204253137112, p_norm: 1791.6083691356248, g_norm: 0.19894722013299238, lr:  0.000744, elapsed time:  54922
Step 112900, loss: 0.012620394096738891, acc: 99.6182034611702, p_norm: 1791.928748253141, g_norm: 0.20281808773374554, lr:  0.000744, elapsed time:  54970
Step 113000, loss: 0.013143089488257828, acc: 99.60162578523159, p_norm: 1792.247672475585, g_norm: 0.1253994574275971, lr:  0.000743, elapsed time:  55017
Step 113100, loss: 0.012827482648135628, acc: 99.60251249372959, p_norm: 1792.5626511743292, g_norm: 0.19606848162291862, lr:  0.000743, elapsed time:  55065
Step 113200, loss: 0.013027669735820382, acc: 99.59663666784763, p_norm: 1792.8727348459863, g_norm: 0.16467085347788246, lr:  0.000743, elapsed time:  55112
Step 113300, loss: 0.013747665264454555, acc: 99.5825936794281, p_norm: 1793.1959744903568, g_norm: 0.23453126015663767, lr:  0.000743, elapsed time:  55159
Step 113400, loss: 0.013620813964080299, acc: 99.58154003322124, p_norm: 1793.5310373702375, g_norm: 0.19482671507692245, lr:  0.000742, elapsed time:  55207
Step 113500, loss: 0.013405120597453787, acc: 99.59110128879547, p_norm: 1793.8598547883214, g_norm: 0.2155778651595048, lr:  0.000742, elapsed time:  55254
Step 113600, loss: 0.013302031747152797, acc: 99.5984757244587, p_norm: 1794.168503645807, g_norm: 0.21045662741826243, lr:  0.000742, elapsed time:  55302
Step 113700, loss: 0.01288144705540617, acc: 99.59733965992928, p_norm: 1794.4770205828556, g_norm: 0.42241887852090687, lr:  0.000741, elapsed time:  55350
Step 113800, loss: 0.01314462190726772, acc: 99.6049563139677, p_norm: 1794.8049163952182, g_norm: 0.17294721903641902, lr:  0.000741, elapsed time:  55397
Step 113900, loss: 0.013167370209630462, acc: 99.59401129186153, p_norm: 1795.1069953022568, g_norm: 0.2157694738304372, lr:  0.000741, elapsed time:  55445
Step 114000, loss: 0.013368983105174266, acc: 99.5874692350626, p_norm: 1795.4548299905236, g_norm: 0.25385684725355084, lr:  0.000740, elapsed time:  55492
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 114000, eval loss: 0.017085940408942412, eval acc: 99.57328796386719
Step 114100, loss: 0.013624330925304094, acc: 99.57869485020638, p_norm: 1795.8008401540949, g_norm: 0.38565553230042987, lr:  0.000740, elapsed time:  55547
Step 114200, loss: 0.014159973829810041, acc: 99.56760723888874, p_norm: 1796.1271357933176, g_norm: 0.2153736575043816, lr:  0.000740, elapsed time:  55595
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 114300, loss: 0.01311299808821334, acc: 99.59745715506634, p_norm: 1796.4531030972237, g_norm: 0.17191864651218422, lr:  0.000739, elapsed time:  55643
Step 114400, loss: 0.01233995111702825, acc: 99.6152516156435, p_norm: 1796.7914047916272, g_norm: 0.19601050375588336, lr:  0.000739, elapsed time:  55691
Step 114500, loss: 0.01284203862232971, acc: 99.60301585495472, p_norm: 1797.0947980649519, g_norm: 0.1625454441679919, lr:  0.000739, elapsed time:  55738
Step 114600, loss: 0.01367382028925931, acc: 99.58854055404663, p_norm: 1797.4237966287337, g_norm: 0.17524727195901918, lr:  0.000738, elapsed time:  55785
Step 114700, loss: 0.012996867108195148, acc: 99.60980807244778, p_norm: 1797.7311310386415, g_norm: 0.2416643979017227, lr:  0.000738, elapsed time:  55833
Step 114800, loss: 0.012296435475363979, acc: 99.62305901944637, p_norm: 1798.032660403281, g_norm: 0.20153819628488526, lr:  0.000738, elapsed time:  55881
Step 114900, loss: 0.013533537962430273, acc: 99.58339650928974, p_norm: 1798.3436354986873, g_norm: 0.19223004137320454, lr:  0.000737, elapsed time:  55928
Step 115000, loss: 0.0135009075205744, acc: 99.58772496879101, p_norm: 1798.6568182729022, g_norm: 0.14957414977716893, lr:  0.000737, elapsed time:  55975
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c ( - c 2 o c 3 c c c c c 3 c ( = O ) c 2 C ( = O ) N 2 C C N ( C c 3 c c c c c 3 ) C C 2 ) c c ( O C ) c 1 O C _EOS
Predicted text: C O c 1 c c ( - c 2 o c 3 c c c c c 3 c ( = O ) c 2 C ( = O ) N 2 C C N ( C c 3 c c c c c 3 ) C C 2 ) c c ( O C ) c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 s c ( C ( = O ) N C ( C c 2 c c c ( F ) c c 2 ) C N 2 C ( = O ) c 3 c c c c c 3 C 2 = O ) c c 1 - c 1 c ( Br ) c n n 1 C _EOS
Predicted text: C c 1 s c ( C ( = O ) N C ( C c 2 c c c ( F ) c c 2 ) C N 2 C ( = O ) c 3 c c c c c 3 C 2 = O ) c c 1 - c 1 c ( Br ) c n n 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c ( N 2 C C N ( C ( = O ) N 3 C C C ( c 4 c n [nH] c 4 ) C 3 ) c 3 c c c c c 3 2 ) c c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c ( N 2 C C N ( C ( = O ) N 3 C C C ( c 4 c n [nH] c 4 ) C 3 ) c 3 c c c c c 3 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( O C ) n c ( O c 2 c c c n c 2 C ( = O ) O N = C ( C ) C ) n 1 _EOS
Predicted text: C O c 1 c c ( O C ) n c ( O c 2 c c c n c 2 C ( = O ) O N = C ( C ) C ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 n c c ( - c 2 n c ( N 3 C C O C C 3 ) n c 3 c 2 C C N 3 C ( = O ) N c 2 c c c ( N C C N 3 C C O C C 3 ) c c 2 ) c n 1 _EOS
Predicted text: N c 1 n c c ( - c 2 n c ( N 3 C C O C C 3 ) n c 3 c 2 C C N 3 C ( = O ) N c 2 c c c ( N C C N 3 C C O C C 3 ) c c 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 115000, eval acc (token): 0.9349485585174627, eval acc (sequence): 0.8795051102743411
Saving at step 115000
Step 115100, loss: 0.01269140443768265, acc: 99.60764472186565, p_norm: 1798.968153570371, g_norm: 0.24173441576505145, lr:  0.000737, elapsed time:  56076
Step 115200, loss: 0.013333290127120563, acc: 99.59563966095448, p_norm: 1799.2843986595271, g_norm: 0.1889163808964339, lr:  0.000736, elapsed time:  56124
Step 115300, loss: 0.012162171868712903, acc: 99.62953536212444, p_norm: 1799.587473742777, g_norm: 0.26546362388442657, lr:  0.000736, elapsed time:  56172
Step 115400, loss: 0.01327330109779723, acc: 99.59774695336819, p_norm: 1799.9081757075955, g_norm: 0.18623220683028033, lr:  0.000736, elapsed time:  56220
Step 115500, loss: 0.013183686301490525, acc: 99.60053902864456, p_norm: 1800.1952206600179, g_norm: 0.31875504266089083, lr:  0.000735, elapsed time:  56267
Step 115600, loss: 0.012716546183437458, acc: 99.61417083442211, p_norm: 1800.511649234549, g_norm: 0.15306249897541818, lr:  0.000735, elapsed time:  56315
Step 115700, loss: 0.013446714270030498, acc: 99.58752818405628, p_norm: 1800.807742784891, g_norm: 0.12575011392403077, lr:  0.000735, elapsed time:  56362
Step 115800, loss: 0.012595952626070358, acc: 99.6164056956768, p_norm: 1801.1092156732761, g_norm: 0.17864920194497752, lr:  0.000734, elapsed time:  56410
Step 115900, loss: 0.01280757506028749, acc: 99.60431857407093, p_norm: 1801.4150834831535, g_norm: 0.1846377736439948, lr:  0.000734, elapsed time:  56458
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 116000, loss: 0.012647532286665134, acc: 99.61737999275549, p_norm: 1801.7324666000382, g_norm: 0.16395103837239908, lr:  0.000734, elapsed time:  56506
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 116000, eval loss: 0.016596454645114132, eval acc: 99.60726165771484
Step 116100, loss: 0.012527201156517549, acc: 99.61495976150036, p_norm: 1802.0394200058304, g_norm: 0.18672093774172405, lr:  0.000733, elapsed time:  56561
Step 116200, loss: 0.012485548320255476, acc: 99.62044960260391, p_norm: 1802.3537091115038, g_norm: 0.20563495598264206, lr:  0.000733, elapsed time:  56608
Step 116300, loss: 0.013169393164862413, acc: 99.59395878016949, p_norm: 1802.6751583601276, g_norm: 0.23576439446288175, lr:  0.000733, elapsed time:  56656
Step 116400, loss: 0.012726655471051345, acc: 99.61303909122944, p_norm: 1802.9718226726477, g_norm: 0.19240993024548944, lr:  0.000733, elapsed time:  56703
Step 116500, loss: 0.012729845120120445, acc: 99.61047169566154, p_norm: 1803.290194279011, g_norm: 0.20339290786549147, lr:  0.000732, elapsed time:  56750
Step 116600, loss: 0.013368494541500695, acc: 99.58682881295681, p_norm: 1803.6126040032775, g_norm: 0.18144601213513964, lr:  0.000732, elapsed time:  56797
Step 116700, loss: 0.012788039876104449, acc: 99.61304178833961, p_norm: 1803.9166757316139, g_norm: 0.1746431917680014, lr:  0.000732, elapsed time:  56845
Step 116800, loss: 0.012668629341424093, acc: 99.61316207051277, p_norm: 1804.2352519195965, g_norm: 0.16784377896471134, lr:  0.000731, elapsed time:  56892
Step 116900, loss: 0.012735402779071592, acc: 99.60991378128529, p_norm: 1804.5450549665047, g_norm: 0.18905267959922215, lr:  0.000731, elapsed time:  56940
Step 117000, loss: 0.01322131647822971, acc: 99.59210719168186, p_norm: 1804.8507828001814, g_norm: 0.19158492613520034, lr:  0.000731, elapsed time:  56988
Step 117100, loss: 0.01302897346264217, acc: 99.59976816177368, p_norm: 1805.1677177598906, g_norm: 0.1585249916666588, lr:  0.000730, elapsed time:  57036
Step 117200, loss: 0.01281280445797165, acc: 99.60864597558975, p_norm: 1805.4759575593075, g_norm: 0.18682132699383985, lr:  0.000730, elapsed time:  57084
Step 117300, loss: 0.012682858682564984, acc: 99.61298877000809, p_norm: 1805.7543487561354, g_norm: 0.3211186973501694, lr:  0.000730, elapsed time:  57132
Step 117400, loss: 0.013861976882835733, acc: 99.57500620186329, p_norm: 1806.0773123493423, g_norm: 0.17588711908292712, lr:  0.000729, elapsed time:  57179
Step 117500, loss: 0.014198992031379021, acc: 99.56540477275848, p_norm: 1806.4197741015348, g_norm: 0.1406709354152651, lr:  0.000729, elapsed time:  57227
Step 117600, loss: 0.01275659626140623, acc: 99.61427327990532, p_norm: 1806.7008097856044, g_norm: 0.22687423396896617, lr:  0.000729, elapsed time:  57275
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 117700, loss: 0.012343686738098561, acc: 99.61539061726175, p_norm: 1807.0128116430278, g_norm: 0.15040515969066875, lr:  0.000728, elapsed time:  57324
Step 117800, loss: 0.012510421360930194, acc: 99.61973881721497, p_norm: 1807.2934400135978, g_norm: 0.15977133058420212, lr:  0.000728, elapsed time:  57372
Step 117900, loss: 0.012944626005773898, acc: 99.60202135145664, p_norm: 1807.6183345144295, g_norm: 0.19902839440318926, lr:  0.000728, elapsed time:  57419
Step 118000, loss: 0.01234763175722037, acc: 99.61963622272015, p_norm: 1807.9143151923395, g_norm: 0.21173670058372696, lr:  0.000728, elapsed time:  57467
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 118000, eval loss: 0.018422041839621667, eval acc: 99.564697265625
Step 118100, loss: 0.012193715247703948, acc: 99.62442272901535, p_norm: 1808.1962973076782, g_norm: 0.19867489672800664, lr:  0.000727, elapsed time:  57521
Step 118200, loss: 0.013190289447666146, acc: 99.5863916426897, p_norm: 1808.5224240989126, g_norm: 0.19565312377633862, lr:  0.000727, elapsed time:  57569
Step 118300, loss: 0.012694649276018027, acc: 99.60613287985325, p_norm: 1808.8139458223645, g_norm: 0.14213344372912254, lr:  0.000727, elapsed time:  57617
Step 118400, loss: 0.013062264994805445, acc: 99.59169240295887, p_norm: 1809.116249749612, g_norm: 0.1382815266554499, lr:  0.000726, elapsed time:  57664
Step 118500, loss: 0.012304179803177249, acc: 99.61824920773506, p_norm: 1809.4088546523537, g_norm: 0.20609314997234324, lr:  0.000726, elapsed time:  57713
Step 118600, loss: 0.012199218682799256, acc: 99.62097944319248, p_norm: 1809.71451868807, g_norm: 0.20995729311612454, lr:  0.000726, elapsed time:  57760
Step 118700, loss: 0.013051095517439534, acc: 99.59873884916306, p_norm: 1810.027413297894, g_norm: 0.19924191539517164, lr:  0.000725, elapsed time:  57807
Step 118800, loss: 0.012994451214908623, acc: 99.60334892570972, p_norm: 1810.3465358099727, g_norm: 0.20049546364377602, lr:  0.000725, elapsed time:  57855
Step 118900, loss: 0.012954347454578964, acc: 99.6010740250349, p_norm: 1810.639308481118, g_norm: 0.2214582152195339, lr:  0.000725, elapsed time:  57903
Step 119000, loss: 0.012740439247427276, acc: 99.61307969689369, p_norm: 1810.9290232044334, g_norm: 0.26971667329567184, lr:  0.000725, elapsed time:  57951
Step 119100, loss: 0.013021491846775462, acc: 99.6067932844162, p_norm: 1811.253663282228, g_norm: 0.14636782765824763, lr:  0.000724, elapsed time:  57998
Step 119200, loss: 0.013552448476402787, acc: 99.58476841449738, p_norm: 1811.5772250588807, g_norm: 0.37998034927351126, lr:  0.000724, elapsed time:  58045
Step 119300, loss: 0.012883641581065603, acc: 99.60068812966347, p_norm: 1811.8589484197132, g_norm: 0.14333623696528297, lr:  0.000724, elapsed time:  58093
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 119400, loss: 0.013047823541107314, acc: 99.59902383794832, p_norm: 1812.177251779029, g_norm: 0.1841855626901423, lr:  0.000723, elapsed time:  58141
Step 119500, loss: 0.012651341888631578, acc: 99.61207295954227, p_norm: 1812.4973735493963, g_norm: 0.15957998788101355, lr:  0.000723, elapsed time:  58189
Step 119600, loss: 0.012138919462959166, acc: 99.62510554492474, p_norm: 1812.7989734137475, g_norm: 0.3041243621371534, lr:  0.000723, elapsed time:  58237
Step 119700, loss: 0.011999236968840706, acc: 99.6334822922945, p_norm: 1813.0876453100875, g_norm: 0.1858230791795685, lr:  0.000722, elapsed time:  58285
Step 119800, loss: 0.012946651031670626, acc: 99.60720708966255, p_norm: 1813.3553838748307, g_norm: 0.222083913009431, lr:  0.000722, elapsed time:  58332
Step 119900, loss: 0.011929373685161409, acc: 99.63715393841267, p_norm: 1813.6256225667503, g_norm: 0.15773537316962227, lr:  0.000722, elapsed time:  58379
Step 120000, loss: 0.012702502543543232, acc: 99.60747121274471, p_norm: 1813.9193036772274, g_norm: 0.13401454595699885, lr:  0.000721, elapsed time:  58427
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 120000, eval loss: 0.019766302209682174, eval acc: 99.53693389892578
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C C C c 1 n n ( - c 2 c c c ( N ) c c 2 C ( F ) ( F ) F ) c ( = O ) n 1 C c 1 c c c ( - c 2 c c c c c 2 S ( = O ) ( = O ) N C ( = O ) O C ( C ) ( C ) C ) c c 1 _EOS
Predicted text: C C C C c 1 n n ( - c 2 c c c ( N ) c c 2 C ( F ) ( F ) F ) c ( = O ) n 1 C c 1 c c c ( - c 2 c c c c c 2 S ( = O ) ( = O ) N C ( = O ) O C ( C ) ( C ) C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N 1 C C N ( S ( = O ) ( = O ) c 2 c c c c ( Br ) c 2 ) C C 1 _EOS
Predicted text: C N 1 C C N ( S ( = O ) ( = O ) c 2 c c c c ( Br ) c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c c 1 - n 1 c ( C F ) n c 2 c c c ( N ) c c 2 c 1 = O _EOS
Predicted text: C c 1 c c c c c 1 - n 1 c ( C F ) n c 2 c c c ( N ) c c 2 c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( [N+] ( = O ) [O-] ) c ( C ) c 1 Br _EOS
Predicted text: C c 1 c c c ( [N+] ( = O ) [O-] ) c ( C ) c 1 Br _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( [N+] ( = O ) [O-] ) c c 1 O [Si] ( C ) ( C ) C ( C ) ( C ) C _EOS
Predicted text: C O c 1 c c c ( [N+] ( = O ) [O-] ) c c 1 O [Si] ( C ) ( C ) C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 120000, eval acc (token): 0.9300061286723589, eval acc (sequence): 0.8758158405362498
Saving at step 120000
Step 120100, loss: 0.013102048838954944, acc: 99.60217288136482, p_norm: 1814.2170552919383, g_norm: 0.20859824151468045, lr:  0.000721, elapsed time:  58535
Step 120200, loss: 0.01243557167268591, acc: 99.62192764878273, p_norm: 1814.5179426166906, g_norm: 0.15058740863857373, lr:  0.000721, elapsed time:  58582
Step 120300, loss: 0.012559222646450508, acc: 99.61979331076145, p_norm: 1814.8187024124609, g_norm: 0.2613508029052894, lr:  0.000721, elapsed time:  58630
Step 120400, loss: 0.01301393441237451, acc: 99.5998034030199, p_norm: 1815.130060958931, g_norm: 0.18138440982704518, lr:  0.000720, elapsed time:  58678
Step 120500, loss: 0.012683058622933459, acc: 99.61242036521435, p_norm: 1815.4158119691406, g_norm: 0.15787464314727265, lr:  0.000720, elapsed time:  58725
Step 120600, loss: 0.013662486766697839, acc: 99.57977366447449, p_norm: 1815.7656784714595, g_norm: 0.22175119304311203, lr:  0.000720, elapsed time:  58773
Step 120700, loss: 0.012308579777818523, acc: 99.62283858656883, p_norm: 1816.0479577475212, g_norm: 0.19705062406651527, lr:  0.000719, elapsed time:  58820
Step 120800, loss: 0.013511199685235625, acc: 99.58567225933075, p_norm: 1816.3451632750694, g_norm: 0.18548282400009955, lr:  0.000719, elapsed time:  58867
Step 120900, loss: 0.013083077565861459, acc: 99.60764583945274, p_norm: 1816.6379445011235, g_norm: 0.2683236737461841, lr:  0.000719, elapsed time:  58915
Step 121000, loss: 0.012988549002657238, acc: 99.59837794303894, p_norm: 1816.9534469003236, g_norm: 0.20825607510765914, lr:  0.000718, elapsed time:  58963
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6822
Step 121100, loss: 0.01186195173912922, acc: 99.6418561000682, p_norm: 1817.2380161906656, g_norm: 0.13566983230664342, lr:  0.000718, elapsed time:  59012
Step 121200, loss: 0.01245875825152325, acc: 99.6191303730011, p_norm: 1817.543061320873, g_norm: 0.21155169598898063, lr:  0.000718, elapsed time:  59060
Step 121300, loss: 0.012152991331604426, acc: 99.62564046680927, p_norm: 1817.8282305770638, g_norm: 0.16258877857663767, lr:  0.000718, elapsed time:  59108
Step 121400, loss: 0.012333928332300275, acc: 99.61913068592548, p_norm: 1818.1261171519436, g_norm: 0.21677375613459676, lr:  0.000717, elapsed time:  59155
Step 121500, loss: 0.012485614989382157, acc: 99.60934498906136, p_norm: 1818.411633043397, g_norm: 0.2504680574013983, lr:  0.000717, elapsed time:  59203
Step 121600, loss: 0.012437030109285842, acc: 99.6145795583725, p_norm: 1818.7082617679919, g_norm: 0.1471641734647763, lr:  0.000717, elapsed time:  59251
Step 121700, loss: 0.011800852441556344, acc: 99.63110469281673, p_norm: 1819.001310668844, g_norm: 0.16956858905685182, lr:  0.000716, elapsed time:  59298
Step 121800, loss: 0.012868839498551096, acc: 99.60063476860523, p_norm: 1819.318023723348, g_norm: 0.12803078583229052, lr:  0.000716, elapsed time:  59346
Step 121900, loss: 0.013224812894550268, acc: 99.59839586913586, p_norm: 1819.6216301579295, g_norm: 0.1981672334138439, lr:  0.000716, elapsed time:  59393
Step 122000, loss: 0.012445273365810862, acc: 99.61692649126053, p_norm: 1819.9327630408136, g_norm: 0.23896011300822562, lr:  0.000716, elapsed time:  59440
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 122000, eval loss: 0.019108526321615495, eval acc: 99.56057739257812
Step 122100, loss: 0.012026531443680141, acc: 99.634007781744, p_norm: 1820.2126691132748, g_norm: 0.2347499317869776, lr:  0.000715, elapsed time:  59495
Step 122200, loss: 0.013232166413363302, acc: 99.59422995150089, p_norm: 1820.5089980588125, g_norm: 0.1649523717100305, lr:  0.000715, elapsed time:  59542
Step 122300, loss: 0.012237479416435236, acc: 99.62202386558056, p_norm: 1820.8207484917423, g_norm: 0.24329021252810065, lr:  0.000715, elapsed time:  59589
Step 122400, loss: 0.012456185824848944, acc: 99.61773009598255, p_norm: 1821.1207615063636, g_norm: 0.1934025646807228, lr:  0.000714, elapsed time:  59637
Step 122500, loss: 0.012739717296644812, acc: 99.60672986507416, p_norm: 1821.4044161690217, g_norm: 0.19449857074382323, lr:  0.000714, elapsed time:  59685
Step 122600, loss: 0.012620957086837734, acc: 99.61140140891075, p_norm: 1821.718707280389, g_norm: 0.19654675748988468, lr:  0.000714, elapsed time:  59732
Step 122700, loss: 0.012984402435940866, acc: 99.60323689877987, p_norm: 1822.0174658770545, g_norm: 0.25003704537301563, lr:  0.000713, elapsed time:  59780
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 122800, loss: 0.012419449234422151, acc: 99.61581731317055, p_norm: 1822.3024776039797, g_norm: 0.20753009013848076, lr:  0.000713, elapsed time:  59828
Step 122900, loss: 0.012251834024791606, acc: 99.62076033651829, p_norm: 1822.614571879302, g_norm: 0.20038878759700673, lr:  0.000713, elapsed time:  59875
Step 123000, loss: 0.012359949441779462, acc: 99.61952993273735, p_norm: 1822.8975568041712, g_norm: 0.15775133835973823, lr:  0.000713, elapsed time:  59923
Step 123100, loss: 0.011947228246681334, acc: 99.62939763069153, p_norm: 1823.1654281832487, g_norm: 0.1642918270231151, lr:  0.000712, elapsed time:  59971
Step 123200, loss: 0.01207763842321583, acc: 99.62669931352139, p_norm: 1823.442345358442, g_norm: 0.1651021198853027, lr:  0.000712, elapsed time:  60018
Step 123300, loss: 0.012409407753148116, acc: 99.62136562168598, p_norm: 1823.735190382041, g_norm: 0.1670138464801979, lr:  0.000712, elapsed time:  60065
Step 123400, loss: 0.01160184204003599, acc: 99.64317806065083, p_norm: 1824.0253085788129, g_norm: 0.21218622852875832, lr:  0.000711, elapsed time:  60113
Step 123500, loss: 0.011819353822938866, acc: 99.6400586515665, p_norm: 1824.2756906148306, g_norm: 0.21033579235916716, lr:  0.000711, elapsed time:  60160
Step 123600, loss: 0.012197937508990436, acc: 99.62920382618904, p_norm: 1824.5509458761687, g_norm: 0.17792483395915504, lr:  0.000711, elapsed time:  60207
Step 123700, loss: 0.01278532396449009, acc: 99.6068878620863, p_norm: 1824.8571207327939, g_norm: 0.22935105167752357, lr:  0.000711, elapsed time:  60255
Step 123800, loss: 0.012295517836610087, acc: 99.62117019295692, p_norm: 1825.1492891426642, g_norm: 0.1599918102015457, lr:  0.000710, elapsed time:  60303
Step 123900, loss: 0.012769800202950137, acc: 99.60931821167469, p_norm: 1825.4371730644261, g_norm: 0.157274049038601, lr:  0.000710, elapsed time:  60350
Step 124000, loss: 0.01246943134432513, acc: 99.61412450671196, p_norm: 1825.7390368308068, g_norm: 0.2199714020621966, lr:  0.000710, elapsed time:  60398
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 124000, eval loss: 0.020028758754779125, eval acc: 99.53235626220703
Step 124100, loss: 0.012922152764531347, acc: 99.60247799754143, p_norm: 1826.0399742871707, g_norm: 0.15440468855811657, lr:  0.000709, elapsed time:  60452
Step 124200, loss: 0.012500455041190435, acc: 99.60856944322586, p_norm: 1826.340204377755, g_norm: 0.17301734970978386, lr:  0.000709, elapsed time:  60500
Step 124300, loss: 0.01266704690948245, acc: 99.61166894435883, p_norm: 1826.63174273796, g_norm: 0.18300646590301406, lr:  0.000709, elapsed time:  60548
Step 124400, loss: 0.012772002369802067, acc: 99.60206735134125, p_norm: 1826.9493499130735, g_norm: 0.2708083303803492, lr:  0.000709, elapsed time:  60596
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 124500, loss: 0.012856765256478482, acc: 99.60279085149813, p_norm: 1827.2410171881386, g_norm: 0.14002886016004018, lr:  0.000708, elapsed time:  60644
Step 124600, loss: 0.01189676526497351, acc: 99.6333539634943, p_norm: 1827.52529949543, g_norm: 0.15961184276443321, lr:  0.000708, elapsed time:  60691
Step 124700, loss: 0.012441491792487795, acc: 99.61716479063034, p_norm: 1827.7913143134188, g_norm: 0.17770406209867862, lr:  0.000708, elapsed time:  60739
Step 124800, loss: 0.01204056886061153, acc: 99.62842789292336, p_norm: 1828.0540281291778, g_norm: 0.27636050755986147, lr:  0.000707, elapsed time:  60787
Step 124900, loss: 0.012798532628803514, acc: 99.6092939376831, p_norm: 1828.3551543270526, g_norm: 0.21035101712599488, lr:  0.000707, elapsed time:  60834
Step 125000, loss: 0.012254888340030447, acc: 99.63027028739452, p_norm: 1828.6426942243636, g_norm: 0.19074646776839194, lr:  0.000707, elapsed time:  60882
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: N # C c 1 c c c ( N ( C C O c 2 c c c ( - c 3 n c c s 3 ) c c 2 ) C C ( F ) ( F ) F ) c c 1 C ( F ) ( F ) F _EOS
Predicted text: N # C c 1 c c c ( N ( C C O c 2 c c c ( - c 3 n c c s 3 ) c c 2 ) C C ( F ) ( F ) F ) c c 1 C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c n c ( N c 2 c c ( N 3 C C O C C 3 ) c ( - c 3 c c c c c 3 ) c n 2 ) c n 1 _EOS
Predicted text: N # C c 1 c n c ( N c 2 c c ( N 3 C C O C C 3 ) c ( - c 3 c c c c c 3 ) c n 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C c 1 c c c ( Cl ) c c 1 ) c 1 c n c 2 c n c ( C # C C O ) n c 2 c 1 O _EOS
Predicted text: O = C ( N C c 1 c c c ( Cl ) c c 1 ) c 1 c n c 2 c n c ( C # C C O ) n c 2 c 1 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C c 1 n c 2 c c c ( C 3 C C 4 c 5 c c c c c 5 C C N 4 O 3 ) c c 2 c ( = O ) n 1 C c 1 c c c ( - c 2 c c c c c 2 - c 2 n n n [nH] 2 ) c c 1 _EOS
Predicted text: C C C C c 1 n c 2 c c c ( C 3 C C 4 c 5 c c c c c 5 C C N 4 O 3 ) c c 2 c ( = O ) n 1 C c 1 c c c ( - c 2 c c c c c 2 - c 2 n n n [nH] 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C C ( = O ) N C C O c 2 c c c ( O C ) c ( O C ) c 2 ) c c 1 O C _EOS
Predicted text: C O c 1 c c c ( C C ( = O ) N C C O c 2 c c c ( O C ) c ( O C ) c 2 ) c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 125000, eval acc (token): 0.9378325297246565, eval acc (sequence): 0.8886679920477137
Saving at step 125000
Step 125100, loss: 0.012591874832942267, acc: 99.6157607883215, p_norm: 1828.9282305861718, g_norm: 0.17841434233588577, lr:  0.000707, elapsed time:  60982
Step 125200, loss: 0.011569759170961334, acc: 99.64420911669731, p_norm: 1829.2264541178522, g_norm: 0.17895723371540756, lr:  0.000706, elapsed time:  61029
Step 125300, loss: 0.012624107772535354, acc: 99.61221539974213, p_norm: 1829.5246440013243, g_norm: 0.19835211748984072, lr:  0.000706, elapsed time:  61077
Step 125400, loss: 0.012641482397466462, acc: 99.61556170880795, p_norm: 1829.7992711974264, g_norm: 0.15695979669107027, lr:  0.000706, elapsed time:  61124
Step 125500, loss: 0.011766922701790463, acc: 99.63844273984432, p_norm: 1830.091443349538, g_norm: 0.22885137914146753, lr:  0.000705, elapsed time:  61172
Step 125600, loss: 0.01214202395920438, acc: 99.63093982636929, p_norm: 1830.380932197412, g_norm: 0.13479301789033674, lr:  0.000705, elapsed time:  61220
Step 125700, loss: 0.013079801404310275, acc: 99.5941811054945, p_norm: 1830.6933392562648, g_norm: 0.1912635210470965, lr:  0.000705, elapsed time:  61268
Step 125800, loss: 0.012565211918990826, acc: 99.61825077235699, p_norm: 1830.9771437276015, g_norm: 0.18127289812081213, lr:  0.000705, elapsed time:  61315
Step 125900, loss: 0.012705267090859706, acc: 99.60119864344597, p_norm: 1831.2695801642901, g_norm: 0.2126735971180633, lr:  0.000704, elapsed time:  61362
Step 126000, loss: 0.012724681431427598, acc: 99.60607546567917, p_norm: 1831.5433532936934, g_norm: 0.16206802962519928, lr:  0.000704, elapsed time:  61410
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 126000, eval loss: 0.019286891450028626, eval acc: 99.52837371826172
Step 126100, loss: 0.012369219524007349, acc: 99.61407925188541, p_norm: 1831.821714052843, g_norm: 0.15175274079679238, lr:  0.000704, elapsed time:  61465
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 126200, loss: 0.011920620289662174, acc: 99.63141377292462, p_norm: 1832.0998310137948, g_norm: 0.16766014541448568, lr:  0.000704, elapsed time:  61513
Step 126300, loss: 0.01140363301790785, acc: 99.64969758689404, p_norm: 1832.3875252971634, g_norm: 0.19669958465753154, lr:  0.000703, elapsed time:  61561
Step 126400, loss: 0.011943186030075595, acc: 99.63136051595211, p_norm: 1832.6544818069956, g_norm: 0.2050262027745882, lr:  0.000703, elapsed time:  61608
Step 126500, loss: 0.012236439991902444, acc: 99.62130884826183, p_norm: 1832.9672840434696, g_norm: 0.21248000814293405, lr:  0.000703, elapsed time:  61655
Step 126600, loss: 0.01177770089940168, acc: 99.63600839674473, p_norm: 1833.2492428070516, g_norm: 0.17018707723450038, lr:  0.000702, elapsed time:  61703
Step 126700, loss: 0.0117728352803897, acc: 99.64062489569187, p_norm: 1833.5374279317102, g_norm: 0.25394797468861663, lr:  0.000702, elapsed time:  61751
Step 126800, loss: 0.012230940585795906, acc: 99.62048490345478, p_norm: 1833.831109565504, g_norm: 0.1572474372202856, lr:  0.000702, elapsed time:  61798
Step 126900, loss: 0.01230112547007593, acc: 99.61630603671074, p_norm: 1834.0842893560452, g_norm: 0.17257207627634158, lr:  0.000702, elapsed time:  61846
Step 127000, loss: 0.012573285053840665, acc: 99.61482360959053, p_norm: 1834.3581278564154, g_norm: 0.18769862347083047, lr:  0.000701, elapsed time:  61893
Step 127100, loss: 0.012799244544621615, acc: 99.61175191402435, p_norm: 1834.629910658169, g_norm: 0.15518221383528208, lr:  0.000701, elapsed time:  61941
Step 127200, loss: 0.012167428306092916, acc: 99.63431251049042, p_norm: 1834.9308440535779, g_norm: 0.3561014848380936, lr:  0.000701, elapsed time:  61989
Step 127300, loss: 0.011683269563363866, acc: 99.64166517555714, p_norm: 1835.197611166012, g_norm: 0.16808640094743996, lr:  0.000700, elapsed time:  62036
Step 127400, loss: 0.011502061704995868, acc: 99.63925798237324, p_norm: 1835.4721868236734, g_norm: 0.2699988779407833, lr:  0.000700, elapsed time:  62084
Step 127500, loss: 0.01285402443507337, acc: 99.60645334422588, p_norm: 1835.7431629366831, g_norm: 0.2601837394421134, lr:  0.000700, elapsed time:  62132
Step 127600, loss: 0.012038338589700288, acc: 99.6281341612339, p_norm: 1836.0226698605945, g_norm: 0.414429570395194, lr:  0.000700, elapsed time:  62180
Step 127700, loss: 0.012738943530421239, acc: 99.60229095816612, p_norm: 1836.292733854583, g_norm: 0.24735234895406175, lr:  0.000699, elapsed time:  62227
Step 127800, loss: 0.012370999062477494, acc: 99.62135036289692, p_norm: 1836.5762215805562, g_norm: 0.1767906510328759, lr:  0.000699, elapsed time:  62274
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 127900, loss: 0.012367397262626697, acc: 99.61634260549143, p_norm: 1836.8784426455181, g_norm: 0.17493303377632077, lr:  0.000699, elapsed time:  62323
Step 128000, loss: 0.011887573099666043, acc: 99.63722276687622, p_norm: 1837.1253124379189, g_norm: 0.20105667510235573, lr:  0.000699, elapsed time:  62370
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 128000, eval loss: 0.016424993193959375, eval acc: 99.60417175292969
Step 128100, loss: 0.011676317742676474, acc: 99.64236633479595, p_norm: 1837.4009914778908, g_norm: 0.15377278152470172, lr:  0.000698, elapsed time:  62425
Step 128200, loss: 0.012720914079873183, acc: 99.60584577918053, p_norm: 1837.71277529578, g_norm: 0.18684320016650724, lr:  0.000698, elapsed time:  62472
Step 128300, loss: 0.011634437020329642, acc: 99.64479552209377, p_norm: 1837.97996744617, g_norm: 0.17007461007949617, lr:  0.000698, elapsed time:  62519
Step 128400, loss: 0.012021751442880486, acc: 99.62185661494732, p_norm: 1838.2535252327623, g_norm: 0.17560104975739138, lr:  0.000697, elapsed time:  62566
Step 128500, loss: 0.012372212317641242, acc: 99.61891187727451, p_norm: 1838.532831830105, g_norm: 0.2572728241107766, lr:  0.000697, elapsed time:  62614
Step 128600, loss: 0.012682665563115734, acc: 99.61063329875469, p_norm: 1838.806656416361, g_norm: 0.19151630647654908, lr:  0.000697, elapsed time:  62661
Step 128700, loss: 0.011874673032871215, acc: 99.63217023015022, p_norm: 1839.077327324734, g_norm: 0.20346484815129676, lr:  0.000697, elapsed time:  62709
Step 128800, loss: 0.011761572238665394, acc: 99.64068691432476, p_norm: 1839.3648937164792, g_norm: 0.1666574928744537, lr:  0.000696, elapsed time:  62756
Step 128900, loss: 0.012463602242532942, acc: 99.61481708288193, p_norm: 1839.6679349275266, g_norm: 0.1908826548538423, lr:  0.000696, elapsed time:  62804
Step 129000, loss: 0.011732288001439883, acc: 99.64226326346397, p_norm: 1839.9234680001812, g_norm: 0.13018035634667624, lr:  0.000696, elapsed time:  62852
Step 129100, loss: 0.011987672965842648, acc: 99.63033026456833, p_norm: 1840.2078679068534, g_norm: 0.17749478736355914, lr:  0.000696, elapsed time:  62900
Step 129200, loss: 0.013396662656123225, acc: 99.58470706641674, p_norm: 1840.4884978818889, g_norm: 0.21377229327891348, lr:  0.000695, elapsed time:  62947
Step 129300, loss: 0.01224320396217081, acc: 99.62273770570755, p_norm: 1840.7754711763846, g_norm: 0.1837676999627098, lr:  0.000695, elapsed time:  62994
Step 129400, loss: 0.012150135788724583, acc: 99.62416705489159, p_norm: 1841.0584545532458, g_norm: 0.3106458276119978, lr:  0.000695, elapsed time:  63043
Step 129500, loss: 0.011927262964327383, acc: 99.63403336703777, p_norm: 1841.3417865156732, g_norm: 0.16839447557637272, lr:  0.000695, elapsed time:  63091
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 129600, loss: 0.011724527552391681, acc: 99.64071883457174, p_norm: 1841.603315827371, g_norm: 0.20164655503842716, lr:  0.000694, elapsed time:  63140
Step 129700, loss: 0.010902173686481546, acc: 99.66353645920753, p_norm: 1841.8541760671346, g_norm: 0.203900189669284, lr:  0.000694, elapsed time:  63188
Step 129800, loss: 0.011528795345075196, acc: 99.63736699521542, p_norm: 1842.1127161208287, g_norm: 0.18508269577129025, lr:  0.000694, elapsed time:  63235
Step 129900, loss: 0.011517888666130602, acc: 99.65501676499844, p_norm: 1842.3769631179925, g_norm: 0.20291384849520827, lr:  0.000693, elapsed time:  63283
Step 130000, loss: 0.011786042362509762, acc: 99.6406597495079, p_norm: 1842.6457456948901, g_norm: 0.18051207175324624, lr:  0.000693, elapsed time:  63331
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 130000, eval loss: 0.01971721388865263, eval acc: 99.53800964355469
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) C C n 1 n c c ( N C 2 C C 3 C C ( C 2 C ) C 3 ( C ) C ) c ( Br ) c 1 = O _EOS
Predicted text: C C O C ( = O ) C C n 1 n c c ( N C 2 C C 3 C C ( C 2 C ) C 3 ( C ) C ) c ( Br ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) n 1 c ( = O ) n ( - c 2 c c c 3 c ( c 2 ) C C N 3 c 2 n c 3 c c c n c 3 [nH] 2 ) c 2 n c c c c 2 1 _EOS
Predicted text: C C ( C ) n 1 c ( = O ) n ( - c 2 c c c 3 c ( c 2 ) C C N 3 c 2 n c 3 c c c n c 3 [nH] 2 ) c 2 n c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c c 1 C ( = C C Br ) c 1 c c c c c 1 _EOS
Predicted text: C c 1 c c c c c 1 C ( = C C Br ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c ( N C ( = O ) c 2 c c c ( C ) c ( - n 3 c c ( - c 4 c c c n c 4 ) n n 3 ) c 2 ) c c ( C ( C ) ( C ) C ) c c 1 N S ( C ) ( = O ) = O _EOS
Predicted text: C O c 1 c ( N C ( = O ) c 2 c c c ( C ) c ( - n 3 c c ( - c 4 c c c n c 4 ) n n 3 ) c 2 ) c c ( C ( C ) ( C ) C ) c c 1 N S ( C ) ( = O ) = O _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c c c ( C = N N C ( N ) = S ) s 1 _EOS
Predicted text: C = C C S C ( = N ) N N = C c 1 c c c ( C # N ) s 1 _EOS
acc_token: 0.13043478260869565, acc_seq: False

Evaluation (without teacher) at step 130000, eval acc (token): 0.9366977126493246, eval acc (sequence): 0.8817166782972784
Saving at step 130000
Step 130100, loss: 0.011751403404341545, acc: 99.63476678729057, p_norm: 1842.9172378533092, g_norm: 0.164529315144316, lr:  0.000693, elapsed time:  63438
Step 130200, loss: 0.012187118302717863, acc: 99.62237706780434, p_norm: 1843.1999671742772, g_norm: 0.1570447868305797, lr:  0.000693, elapsed time:  63485
Step 130300, loss: 0.012094029273357591, acc: 99.6324040144682, p_norm: 1843.488168895236, g_norm: 0.1688963381098535, lr:  0.000692, elapsed time:  63533
Step 130400, loss: 0.012278676335699856, acc: 99.62314954400063, p_norm: 1843.7839893371502, g_norm: 0.17740162572319687, lr:  0.000692, elapsed time:  63580
Step 130500, loss: 0.012166355450317497, acc: 99.62743723392487, p_norm: 1844.0569340473157, g_norm: 0.1613700761775439, lr:  0.000692, elapsed time:  63628
Step 130600, loss: 0.011133009273507924, acc: 99.66101303696632, p_norm: 1844.3046224163322, g_norm: 0.1762163143160891, lr:  0.000692, elapsed time:  63676
Step 130700, loss: 0.012832325964118353, acc: 99.60229420661926, p_norm: 1844.5705428865754, g_norm: 0.2712166493763451, lr:  0.000691, elapsed time:  63723
Step 130800, loss: 0.012722382178180851, acc: 99.6126118004322, p_norm: 1844.8634308150026, g_norm: 0.1831503845132998, lr:  0.000691, elapsed time:  63771
Step 130900, loss: 0.012407129697858182, acc: 99.6184755563736, p_norm: 1845.1566491516846, g_norm: 0.16893273054611377, lr:  0.000691, elapsed time:  63818
Step 131000, loss: 0.012316258739083423, acc: 99.62815840542316, p_norm: 1845.4232917472054, g_norm: 0.12904659637664925, lr:  0.000691, elapsed time:  63865
Step 131100, loss: 0.012416975464802818, acc: 99.61819614470005, p_norm: 1845.6988555935075, g_norm: 0.1770905125198472, lr:  0.000690, elapsed time:  63913
Step 131200, loss: 0.012003573984256945, acc: 99.63425643742085, p_norm: 1845.974780995294, g_norm: 0.2480601413463602, lr:  0.000690, elapsed time:  63961
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 131300, loss: 0.01261215262327561, acc: 99.61215582356525, p_norm: 1846.2377256901989, g_norm: 0.19074640888697666, lr:  0.000690, elapsed time:  64009
Step 131400, loss: 0.011060676630768285, acc: 99.6607045084238, p_norm: 1846.4900069296004, g_norm: 0.29687807960301155, lr:  0.000689, elapsed time:  64056
Step 131500, loss: 0.011478148545647856, acc: 99.64874339103699, p_norm: 1846.7499717367, g_norm: 0.1548478357056663, lr:  0.000689, elapsed time:  64104
Step 131600, loss: 0.011017969146560063, acc: 99.6577712148428, p_norm: 1847.014527465036, g_norm: 0.1627019652353009, lr:  0.000689, elapsed time:  64151
Step 131700, loss: 0.012117450153455138, acc: 99.63022416830063, p_norm: 1847.284953470245, g_norm: 0.3606918372213701, lr:  0.000689, elapsed time:  64199
Step 131800, loss: 0.011570130417876499, acc: 99.643196195364, p_norm: 1847.5598180079269, g_norm: 0.1734978181528881, lr:  0.000688, elapsed time:  64247
Step 131900, loss: 0.01204763966750761, acc: 99.62484936416149, p_norm: 1847.8302685065757, g_norm: 0.17504638090745908, lr:  0.000688, elapsed time:  64295
Step 132000, loss: 0.01208284000356798, acc: 99.62915994226933, p_norm: 1848.126682683358, g_norm: 0.2399484623069557, lr:  0.000688, elapsed time:  64342
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 132000, eval loss: 0.019755650190054437, eval acc: 99.54170227050781
Step 132100, loss: 0.01257069730112562, acc: 99.61149902641773, p_norm: 1848.4221850297224, g_norm: 0.23231721183751447, lr:  0.000688, elapsed time:  64397
Step 132200, loss: 0.011601543395809131, acc: 99.64017781615257, p_norm: 1848.6970905867609, g_norm: 0.13237826723947643, lr:  0.000687, elapsed time:  64444
Step 132300, loss: 0.01274318336551005, acc: 99.60677236318588, p_norm: 1848.9685655565156, g_norm: 0.2661659278592934, lr:  0.000687, elapsed time:  64492
Step 132400, loss: 0.011951052682434238, acc: 99.62381380796432, p_norm: 1849.2580213287567, g_norm: 0.21250265871029236, lr:  0.000687, elapsed time:  64540
Step 132500, loss: 0.012070985605932947, acc: 99.63401657342911, p_norm: 1849.5130211300832, g_norm: 0.14547921437285777, lr:  0.000687, elapsed time:  64587
Step 132600, loss: 0.012348241746294661, acc: 99.62639874219894, p_norm: 1849.7851190744534, g_norm: 0.2140026515221951, lr:  0.000686, elapsed time:  64635
Step 132700, loss: 0.012263435338099952, acc: 99.6268399655819, p_norm: 1850.0581570690729, g_norm: 0.24796118168341585, lr:  0.000686, elapsed time:  64682
Step 132800, loss: 0.011818018164849491, acc: 99.63941745460033, p_norm: 1850.3207075491077, g_norm: 0.2228493667731737, lr:  0.000686, elapsed time:  64730
Step 132900, loss: 0.011791883575151587, acc: 99.63720306754112, p_norm: 1850.5972176957841, g_norm: 0.18911088202156445, lr:  0.000686, elapsed time:  64777
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 133000, loss: 0.012240401232621179, acc: 99.61408194773843, p_norm: 1850.8711389118373, g_norm: 0.22407429524805833, lr:  0.000685, elapsed time:  64825
Step 133100, loss: 0.011401206900573016, acc: 99.65033087134361, p_norm: 1851.1350869171881, g_norm: 0.2100293437375587, lr:  0.000685, elapsed time:  64873
Step 133200, loss: 0.011743066697999894, acc: 99.63565275073051, p_norm: 1851.415953687296, g_norm: 0.19764142303387916, lr:  0.000685, elapsed time:  64921
Step 133300, loss: 0.011161896871399221, acc: 99.65368965268135, p_norm: 1851.6778016230733, g_norm: 0.19680531202349819, lr:  0.000685, elapsed time:  64969
Step 133400, loss: 0.01119352591176721, acc: 99.65851859748363, p_norm: 1851.9351373864001, g_norm: 0.24622412952320724, lr:  0.000684, elapsed time:  65017
Step 133500, loss: 0.012328026907234745, acc: 99.62331841886044, p_norm: 1852.22356088548, g_norm: 0.1497501595728951, lr:  0.000684, elapsed time:  65064
Step 133600, loss: 0.011191622727965296, acc: 99.65849098563194, p_norm: 1852.499842606446, g_norm: 0.17597496065236787, lr:  0.000684, elapsed time:  65112
Step 133700, loss: 0.012178359081517556, acc: 99.61911244690418, p_norm: 1852.7505371936, g_norm: 0.19552059030317015, lr:  0.000684, elapsed time:  65159
Step 133800, loss: 0.01208646141756617, acc: 99.63658092916012, p_norm: 1853.013507002, g_norm: 0.17643477652105297, lr:  0.000683, elapsed time:  65207
Step 133900, loss: 0.011662690240045777, acc: 99.62814140319824, p_norm: 1853.265587141309, g_norm: 0.19737584785658008, lr:  0.000683, elapsed time:  65254
Step 134000, loss: 0.011682113411734463, acc: 99.63652464747429, p_norm: 1853.5271422686612, g_norm: 0.2501507032913046, lr:  0.000683, elapsed time:  65302
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 134000, eval loss: 0.017560090493834654, eval acc: 99.56938934326172
Step 134100, loss: 0.011713741565072268, acc: 99.6372044980526, p_norm: 1853.7827219446528, g_norm: 0.304366033189389, lr:  0.000682, elapsed time:  65356
Step 134200, loss: 0.012562673356733285, acc: 99.61284001171589, p_norm: 1854.045066131628, g_norm: 0.1315618153522627, lr:  0.000682, elapsed time:  65403
Step 134300, loss: 0.011420472902536859, acc: 99.64052340388298, p_norm: 1854.325497320085, g_norm: 0.15853702590768695, lr:  0.000682, elapsed time:  65451
Step 134400, loss: 0.012185852520960907, acc: 99.626958578825, p_norm: 1854.5961551550333, g_norm: 0.22836120026443324, lr:  0.000682, elapsed time:  65499
Step 134500, loss: 0.012016394089805545, acc: 99.62617860734463, p_norm: 1854.862635794855, g_norm: 0.14746177070751165, lr:  0.000681, elapsed time:  65546
Step 134600, loss: 0.011347669983661036, acc: 99.65180578827858, p_norm: 1855.1211073327104, g_norm: 0.2070290976834013, lr:  0.000681, elapsed time:  65594
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 134700, loss: 0.012728616752751103, acc: 99.61315581751107, p_norm: 1855.397466425811, g_norm: 0.16396548511735512, lr:  0.000681, elapsed time:  65642
Step 134800, loss: 0.011338412177865393, acc: 99.6456543803215, p_norm: 1855.6557083101934, g_norm: 0.17162809591513295, lr:  0.000681, elapsed time:  65690
Step 134900, loss: 0.011566893600247567, acc: 99.6437811255455, p_norm: 1855.9132687885542, g_norm: 0.22190047525299686, lr:  0.000680, elapsed time:  65738
Step 135000, loss: 0.011594424592149153, acc: 99.64528812468052, p_norm: 1856.1589773351272, g_norm: 0.182353985511707, lr:  0.000680, elapsed time:  65785
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C 2 C C 1 C N 2 c 1 c c c ( - c 2 c c c c c 2 ) n n 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C 2 C C 1 C N 2 c 1 c c c ( - c 2 c c c c c 2 ) n n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C 1 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C C 1 N 1 C C C ( N C ( = O ) O C c 2 c c c c c 2 ) C 1 = O _EOS
Predicted text: C C C C 1 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C C 1 N 1 C C C ( N C ( = O ) O C c 2 c c c c c 2 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C C N 1 C ( = O ) c 2 c c c c 3 c c 4 c c c c ( N C ( = S ) N c 5 c c c ( Br ) c c 5 O C ( F ) ( F ) F ) c 4 c ( c 2 3 ) C 1 = O _EOS
Predicted text: C N ( C ) C C N 1 C ( = O ) c 2 c c c c 3 c c 4 c c c c ( N C ( = S ) N c 5 c c c ( Br ) c c 5 O C ( F ) ( F ) F ) c 4 c ( c 2 3 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C N 1 C C N ( C ( = O ) C S c 2 c n c ( N C ( = O ) C ( C C 3 C C C C 3 ) c 3 c c c ( S ( C ) ( = O ) = O ) c c 3 ) s 2 ) C C 1 _EOS
Predicted text: C N 1 C C N ( C ( = O ) C S c 2 c n c ( N C ( = O ) C ( C C 3 C C C C 3 ) c 3 c c c ( S ( C ) ( = O ) = O ) c c 3 ) s 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C # C C O c 1 c c c ( C ( = O ) O ) c ( O C C # C ) c 1 _EOS
Predicted text: C # C C O c 1 c c c ( C ( = O ) O ) c c 1 O C _EOS _PAD _PAD _PAD _PAD _PAD
acc_token: 0.6896551724137931, acc_seq: False

Evaluation (without teacher) at step 135000, eval acc (token): 0.9388596212132296, eval acc (sequence): 0.8895338291311445
Saving at step 135000
Step 135100, loss: 0.010933952222694642, acc: 99.66495418548584, p_norm: 1856.4095090012827, g_norm: 0.14612767860175627, lr:  0.000680, elapsed time:  65885
Step 135200, loss: 0.011777212788510951, acc: 99.63956750929356, p_norm: 1856.6649881276303, g_norm: 0.16426671602689685, lr:  0.000680, elapsed time:  65933
Step 135300, loss: 0.011939157968809013, acc: 99.63981266319752, p_norm: 1856.9512115213204, g_norm: 0.18259917317451474, lr:  0.000679, elapsed time:  65980
Step 135400, loss: 0.011744852587980859, acc: 99.63824693858624, p_norm: 1857.2209831851596, g_norm: 0.23640584074058055, lr:  0.000679, elapsed time:  66028
Step 135500, loss: 0.011740118607085605, acc: 99.63200469315052, p_norm: 1857.4877348379785, g_norm: 0.14641477613970844, lr:  0.000679, elapsed time:  66076
Step 135600, loss: 0.011716802062219358, acc: 99.63499251008034, p_norm: 1857.7628934851166, g_norm: 0.1928747342835947, lr:  0.000679, elapsed time:  66124
Step 135700, loss: 0.012030505873262883, acc: 99.62338089942932, p_norm: 1858.0125292091714, g_norm: 0.18944141939654774, lr:  0.000678, elapsed time:  66171
Step 135800, loss: 0.012209886698401532, acc: 99.62414455413818, p_norm: 1858.277785600605, g_norm: 0.1569590887078603, lr:  0.000678, elapsed time:  66219
Step 135900, loss: 0.011441517836174172, acc: 99.64653296768665, p_norm: 1858.530790987839, g_norm: 0.2342541899420972, lr:  0.000678, elapsed time:  66266
Step 136000, loss: 0.011774320929471288, acc: 99.63527819514275, p_norm: 1858.7942022010452, g_norm: 0.13144015990666122, lr:  0.000678, elapsed time:  66315
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 136000, eval loss: 0.018171076021972103, eval acc: 99.54594421386719
Step 136100, loss: 0.01155013834759302, acc: 99.64307163655758, p_norm: 1859.0491384561597, g_norm: 0.16498642135504965, lr:  0.000677, elapsed time:  66370
Step 136200, loss: 0.012278664575169386, acc: 99.62266580760479, p_norm: 1859.3384687968742, g_norm: 0.20141609785870976, lr:  0.000677, elapsed time:  66417
Step 136300, loss: 0.01141718453116482, acc: 99.64897878468037, p_norm: 1859.6041477008703, g_norm: 0.2057348892637192, lr:  0.000677, elapsed time:  66465
Step 136400, loss: 0.0119390155549263, acc: 99.63829532265663, p_norm: 1859.8576337227025, g_norm: 0.1918920932857176, lr:  0.000677, elapsed time:  66513
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 136500, loss: 0.011567940213181778, acc: 99.64629021746602, p_norm: 1860.1134315153326, g_norm: 0.21585563995916607, lr:  0.000676, elapsed time:  66561
Step 136600, loss: 0.01125995141104795, acc: 99.65204817056656, p_norm: 1860.3801446739158, g_norm: 0.25542720460393614, lr:  0.000676, elapsed time:  66609
Step 136700, loss: 0.011094104984549632, acc: 99.65635471045971, p_norm: 1860.6587168797064, g_norm: 0.2472154403048035, lr:  0.000676, elapsed time:  66657
Step 136800, loss: 0.011195071235924843, acc: 99.65393207967281, p_norm: 1860.9328288357583, g_norm: 0.19449386532262034, lr:  0.000676, elapsed time:  66704
Step 136900, loss: 0.011051592529984191, acc: 99.65442228317261, p_norm: 1861.2053197484586, g_norm: 0.15498888697932775, lr:  0.000675, elapsed time:  66753
Step 137000, loss: 0.01215454811201198, acc: 99.62021081149578, p_norm: 1861.462496715283, g_norm: 0.16322279609689097, lr:  0.000675, elapsed time:  66800
Step 137100, loss: 0.01153140949754743, acc: 99.63845930993557, p_norm: 1861.7007878081565, g_norm: 0.20545041145265322, lr:  0.000675, elapsed time:  66847
Step 137200, loss: 0.010983255838000331, acc: 99.65609410405159, p_norm: 1861.954684867796, g_norm: 0.37180629330374526, lr:  0.000675, elapsed time:  66895
Step 137300, loss: 0.011908223842146981, acc: 99.6339163184166, p_norm: 1862.2330316768157, g_norm: 0.2488441607272463, lr:  0.000674, elapsed time:  66943
Step 137400, loss: 0.011736875632086594, acc: 99.64095395803452, p_norm: 1862.4864803408127, g_norm: 0.222581770837696, lr:  0.000674, elapsed time:  66990
Step 137500, loss: 0.013465334281499963, acc: 99.57234235107899, p_norm: 1862.8658265538481, g_norm: 0.2571410650996122, lr:  0.000674, elapsed time:  67037
Step 137600, loss: 0.012192298093286808, acc: 99.6175961047411, p_norm: 1863.14579894494, g_norm: 0.33585797668902667, lr:  0.000674, elapsed time:  67085
Step 137700, loss: 0.01214364500836382, acc: 99.62649820744991, p_norm: 1863.4031607568293, g_norm: 0.23939008808716883, lr:  0.000674, elapsed time:  67133
Step 137800, loss: 0.012151717448869021, acc: 99.62422035634518, p_norm: 1863.661869370687, g_norm: 0.17113129001394164, lr:  0.000673, elapsed time:  67180
Step 137900, loss: 0.01244547813985264, acc: 99.61522395908833, p_norm: 1863.8916960565873, g_norm: 0.16328515540040084, lr:  0.000673, elapsed time:  67228
Step 138000, loss: 0.01146494586890185, acc: 99.64234142005444, p_norm: 1864.1152735262335, g_norm: 0.15804729515660387, lr:  0.000673, elapsed time:  67276
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 138000, eval loss: 0.018353362428097177, eval acc: 99.57110595703125
Step 138100, loss: 0.011948131011449733, acc: 99.63903926312923, p_norm: 1864.355950020758, g_norm: 0.15659151463253837, lr:  0.000673, elapsed time:  67331
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 138200, loss: 0.010519037193169664, acc: 99.67101265123996, p_norm: 1864.5959800795258, g_norm: 0.19432470774319194, lr:  0.000672, elapsed time:  67380
Step 138300, loss: 0.011275663136257209, acc: 99.6549546122551, p_norm: 1864.829833284129, g_norm: 0.41434406323458794, lr:  0.000672, elapsed time:  67428
Step 138400, loss: 0.010785804155530059, acc: 99.66391384601593, p_norm: 1865.0672272426516, g_norm: 0.19881392836941966, lr:  0.000672, elapsed time:  67475
Step 138500, loss: 0.010886445397118224, acc: 99.66101218760014, p_norm: 1865.314442287429, g_norm: 0.2028089103136174, lr:  0.000672, elapsed time:  67523
Step 138600, loss: 0.010967292150489812, acc: 99.66496308147907, p_norm: 1865.5551664954744, g_norm: 0.17361473083783813, lr:  0.000671, elapsed time:  67571
Step 138700, loss: 0.01194050985664944, acc: 99.62786743044853, p_norm: 1865.8128042852684, g_norm: 0.1188407105807891, lr:  0.000671, elapsed time:  67618
Step 138800, loss: 0.011695948059896181, acc: 99.63723760843277, p_norm: 1866.0351488557517, g_norm: 0.1696749639471507, lr:  0.000671, elapsed time:  67666
Step 138900, loss: 0.011540215930181149, acc: 99.64798744022846, p_norm: 1866.2870819492955, g_norm: 0.22048950591944055, lr:  0.000671, elapsed time:  67713
Step 139000, loss: 0.011759742425329022, acc: 99.63809256255627, p_norm: 1866.5591294183796, g_norm: 0.1746666528017963, lr:  0.000670, elapsed time:  67762
Step 139100, loss: 0.011118823577089643, acc: 99.65985038876534, p_norm: 1866.774318123888, g_norm: 0.18053803536937751, lr:  0.000670, elapsed time:  67809
Step 139200, loss: 0.011404912816033175, acc: 99.64296039938927, p_norm: 1867.0181238958219, g_norm: 0.2158010665577281, lr:  0.000670, elapsed time:  67857
Step 139300, loss: 0.01133164193470293, acc: 99.65144519507885, p_norm: 1867.280442530441, g_norm: 0.16988606550546004, lr:  0.000670, elapsed time:  67905
Step 139400, loss: 0.011802653652885055, acc: 99.63150396943092, p_norm: 1867.5169137572727, g_norm: 0.169434328026028, lr:  0.000669, elapsed time:  67952
Step 139500, loss: 0.012946229621284146, acc: 99.59543751180172, p_norm: 1867.7920157238962, g_norm: 0.20524197637836866, lr:  0.000669, elapsed time:  67999
Step 139600, loss: 0.011523910779069411, acc: 99.64463530480862, p_norm: 1868.044145934199, g_norm: 0.1884837492203042, lr:  0.000669, elapsed time:  68046
Step 139700, loss: 0.012247274762921733, acc: 99.6189541220665, p_norm: 1868.2973745915388, g_norm: 0.17843806681768215, lr:  0.000669, elapsed time:  68094
Step 139800, loss: 0.011295802160384482, acc: 99.65666127204895, p_norm: 1868.5448126820131, g_norm: 0.15577242382564582, lr:  0.000668, elapsed time:  68142
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 139900, loss: 0.011308279227936265, acc: 99.65003387844978, p_norm: 1868.7880392915245, g_norm: 0.2237578396446412, lr:  0.000668, elapsed time:  68191
Step 140000, loss: 0.011013812159108056, acc: 99.6609763354063, p_norm: 1869.0296407736923, g_norm: 0.14533173281368142, lr:  0.000668, elapsed time:  68238
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 140000, eval loss: 0.01859447432332672, eval acc: 99.58539581298828
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( = O ) C = C c 1 c ( Cl ) c c ( Cl ) c c 1 Cl _EOS
Predicted text: C C ( = O ) C = C c 1 c ( Cl ) c c ( Cl ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) c 1 c c c ( - c 2 n n c ( C S C C O c 3 c c c ( Cl ) c c 3 Cl ) o 2 ) c c 1 _EOS
Predicted text: O = C ( O ) c 1 c c c ( - c 2 n n c ( C S C C O c 3 c c c ( Cl ) c c 3 Cl ) o 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C c 1 c ( O C c 2 c c c ( C ( O C 3 C C C C O 3 ) c 3 c c c c ( C # N ) c 3 ) c c 2 ) c c c ( C ( C ) = O ) c 1 O _EOS
Predicted text: C C C c 1 c ( O C c 2 c c c ( C ( O C 3 C C C C O 3 ) c 3 c c c c ( C # N ) c 3 ) c c 2 ) c c c ( C ( C ) = O ) c 1 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( - c 2 c c ( S C C N C ( = O ) O C ( C ) ( C ) C ) n c ( N ) n 2 ) c ( C ) c c 1 O C _EOS
Predicted text: C O C ( = O ) c 1 c c ( - c 2 c c ( S C C N C ( = O ) O C ( C ) ( C ) C ) n c ( N ) n 2 ) c ( C ) c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N C 1 ( c 2 c c c ( - c 3 c ( - c 4 c c c ( N ) c c 4 ) n c 4 n 3 - c 3 c c c n c 3 N c 3 c c c c c 3 - 4 ) c c 2 ) C C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C 1 ( c 2 c c c ( - c 3 c ( - c 4 c c c ( N ) c c 4 ) n c 4 n 3 - c 3 c c c n c 3 N c 3 c c c c c 3 - 4 ) c c 2 ) C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 140000, eval acc (token): 0.9335175608958183, eval acc (sequence): 0.880184331797235
Saving at step 140000
Step 140100, loss: 0.010904902830952778, acc: 99.65951968729496, p_norm: 1869.2835777105513, g_norm: 0.15468732283544692, lr:  0.000668, elapsed time:  68347
Step 140200, loss: 0.011333486203184293, acc: 99.64612959325314, p_norm: 1869.5656692442374, g_norm: 0.21945090461579198, lr:  0.000667, elapsed time:  68394
Step 140300, loss: 0.010929190361384827, acc: 99.66736629605293, p_norm: 1869.805992799551, g_norm: 0.14829475179742568, lr:  0.000667, elapsed time:  68442
Step 140400, loss: 0.011515217378691886, acc: 99.64280615746975, p_norm: 1870.052401206844, g_norm: 0.19355133074146438, lr:  0.000667, elapsed time:  68490
Step 140500, loss: 0.011500282116248855, acc: 99.64038749039173, p_norm: 1870.2982842016677, g_norm: 0.197663191379259, lr:  0.000667, elapsed time:  68537
Step 140600, loss: 0.011247050528509136, acc: 99.64805129170418, p_norm: 1870.5559775894444, g_norm: 0.18990577950694706, lr:  0.000667, elapsed time:  68585
Step 140700, loss: 0.011877404673905403, acc: 99.63636626303196, p_norm: 1870.8164947393498, g_norm: 0.1645408956736227, lr:  0.000666, elapsed time:  68632
Step 140800, loss: 0.012029140152735636, acc: 99.62651991844177, p_norm: 1871.0894835290462, g_norm: 0.22151464385323485, lr:  0.000666, elapsed time:  68680
Step 140900, loss: 0.01121933557526063, acc: 99.65950630605221, p_norm: 1871.3269467241364, g_norm: 0.180717685272462, lr:  0.000666, elapsed time:  68728
Step 141000, loss: 0.01177150354920741, acc: 99.6358184069395, p_norm: 1871.5784980588803, g_norm: 0.22656694885846743, lr:  0.000666, elapsed time:  68775
Step 141100, loss: 0.011762903306080262, acc: 99.63715064525604, p_norm: 1871.8373729496495, g_norm: 0.18889074593167426, lr:  0.000665, elapsed time:  68823
Step 141200, loss: 0.01150081245934416, acc: 99.63722389936447, p_norm: 1872.088290289338, g_norm: 0.24915231662250906, lr:  0.000665, elapsed time:  68870
Step 141300, loss: 0.011273178896881291, acc: 99.6460989266634, p_norm: 1872.3349661778273, g_norm: 0.1765104788451554, lr:  0.000665, elapsed time:  68918
Step 141400, loss: 0.011835842163272901, acc: 99.6335214227438, p_norm: 1872.5935991703507, g_norm: 0.1869323004820991, lr:  0.000665, elapsed time:  68965
Step 141500, loss: 0.011576571980622247, acc: 99.64121580123901, p_norm: 1872.8463590994922, g_norm: 0.12999433231669238, lr:  0.000664, elapsed time:  69013
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 141600, loss: 0.010821441982924203, acc: 99.67025249235091, p_norm: 1873.0818104253267, g_norm: 0.8738388243543254, lr:  0.000664, elapsed time:  69062
Step 141700, loss: 0.011660885061937734, acc: 99.63600587844849, p_norm: 1873.3639015409774, g_norm: 0.1713806981153516, lr:  0.000664, elapsed time:  69110
Step 141800, loss: 0.011248207177814037, acc: 99.65573865175247, p_norm: 1873.6277401787868, g_norm: 0.1791225057124946, lr:  0.000664, elapsed time:  69157
Step 141900, loss: 0.011101460924874119, acc: 99.65459847450256, p_norm: 1873.869954144292, g_norm: 0.1775164709314709, lr:  0.000663, elapsed time:  69205
Step 142000, loss: 0.011475731139435084, acc: 99.6491003036499, p_norm: 1874.134892089153, g_norm: 0.13994947867162813, lr:  0.000663, elapsed time:  69253
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 142000, eval loss: 0.016129674013936897, eval acc: 99.61034393310547
Step 142100, loss: 0.010866030576489721, acc: 99.66797100007534, p_norm: 1874.3781643317925, g_norm: 0.18182978359627355, lr:  0.000663, elapsed time:  69308
Step 142200, loss: 0.011726964263361879, acc: 99.63743883371353, p_norm: 1874.624432402563, g_norm: 0.1716631529200024, lr:  0.000663, elapsed time:  69355
Step 142300, loss: 0.010806133255973691, acc: 99.66356934607029, p_norm: 1874.8672196163682, g_norm: 0.1991057022927867, lr:  0.000663, elapsed time:  69402
Step 142400, loss: 0.011886239958403166, acc: 99.63346725702286, p_norm: 1875.1265892111985, g_norm: 0.15177140211459295, lr:  0.000662, elapsed time:  69450
Step 142500, loss: 0.011447060430582497, acc: 99.64250637590885, p_norm: 1875.3838963869127, g_norm: 0.16986825588184395, lr:  0.000662, elapsed time:  69497
Step 142600, loss: 0.011484732814351447, acc: 99.64018864929676, p_norm: 1875.6463281107413, g_norm: 0.11419406794412258, lr:  0.000662, elapsed time:  69545
Step 142700, loss: 0.011698303355296957, acc: 99.64224600791931, p_norm: 1875.9011737211517, g_norm: 0.15272951515655606, lr:  0.000662, elapsed time:  69592
Step 142800, loss: 0.011586662570771296, acc: 99.64150686562061, p_norm: 1876.1739465601256, g_norm: 0.20289863503705882, lr:  0.000661, elapsed time:  69640
Step 142900, loss: 0.011488284493825631, acc: 99.64364996552467, p_norm: 1876.427582850566, g_norm: 0.24687892628017075, lr:  0.000661, elapsed time:  69688
Step 143000, loss: 0.011288500177761307, acc: 99.64812615513802, p_norm: 1876.6715954836839, g_norm: 0.12396803817382919, lr:  0.000661, elapsed time:  69736
Step 143100, loss: 0.011291772342810874, acc: 99.65186244249344, p_norm: 1876.9100115338285, g_norm: 0.20295872821966043, lr:  0.000661, elapsed time:  69783
Step 143200, loss: 0.011984641019007541, acc: 99.63622994720936, p_norm: 1877.1415777596183, g_norm: 0.2667130345302384, lr:  0.000660, elapsed time:  69831
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 143300, loss: 0.010740805194236104, acc: 99.66829525625735, p_norm: 1877.3737207140948, g_norm: 0.24531491839378, lr:  0.000660, elapsed time:  69879
Step 143400, loss: 0.01064811030166311, acc: 99.67020718753338, p_norm: 1877.6112866161593, g_norm: 0.21370301490005292, lr:  0.000660, elapsed time:  69927
Step 143500, loss: 0.011622867885416782, acc: 99.64059789478779, p_norm: 1877.8558838526992, g_norm: 0.20249076058954252, lr:  0.000660, elapsed time:  69974
Step 143600, loss: 0.011159328753092269, acc: 99.65161670744419, p_norm: 1878.1108902795984, g_norm: 0.1972611560526973, lr:  0.000660, elapsed time:  70022
Step 143700, loss: 0.011242237535079767, acc: 99.65819780528545, p_norm: 1878.3732202043054, g_norm: 0.1898266690051188, lr:  0.000659, elapsed time:  70070
Step 143800, loss: 0.010524553069553804, acc: 99.67575572431087, p_norm: 1878.6286346034442, g_norm: 0.24370712645260623, lr:  0.000659, elapsed time:  70118
Step 143900, loss: 0.010933469365518249, acc: 99.65979860723019, p_norm: 1878.8691583790842, g_norm: 0.15403629191888096, lr:  0.000659, elapsed time:  70166
Step 144000, loss: 0.011692750481088296, acc: 99.64083082973957, p_norm: 1879.121221676121, g_norm: 0.19554071480442028, lr:  0.000659, elapsed time:  70213
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 144000, eval loss: 0.01909078827113262, eval acc: 99.583984375
Step 144100, loss: 0.011229690301042865, acc: 99.64867129921913, p_norm: 1879.3577362601604, g_norm: 0.17469483663278226, lr:  0.000658, elapsed time:  70268
Step 144200, loss: 0.01136126053679618, acc: 99.65091191232204, p_norm: 1879.6056883324807, g_norm: 0.14563755303117956, lr:  0.000658, elapsed time:  70315
Step 144300, loss: 0.011765816052829906, acc: 99.63533714413643, p_norm: 1879.852750023969, g_norm: 0.29157379418778867, lr:  0.000658, elapsed time:  70362
Step 144400, loss: 0.010942732457060629, acc: 99.66323529183865, p_norm: 1880.0907460672543, g_norm: 0.21453404661282754, lr:  0.000658, elapsed time:  70410
Step 144500, loss: 0.01223756026061892, acc: 99.62055525183678, p_norm: 1880.3469125380068, g_norm: 0.2212438477107626, lr:  0.000657, elapsed time:  70457
Step 144600, loss: 0.01201177874181667, acc: 99.62902534008026, p_norm: 1880.6047473201186, g_norm: 0.20829408363645335, lr:  0.000657, elapsed time:  70505
Step 144700, loss: 0.011377132076377165, acc: 99.65148575603962, p_norm: 1880.8367191555992, g_norm: 0.17082745947668757, lr:  0.000657, elapsed time:  70552
Step 144800, loss: 0.011595542093018593, acc: 99.63867242634296, p_norm: 1881.0569694914477, g_norm: 0.14642822989430188, lr:  0.000657, elapsed time:  70600
Step 144900, loss: 0.010903005449454212, acc: 99.66435168683529, p_norm: 1881.2880708297157, g_norm: 0.1409333636940792, lr:  0.000657, elapsed time:  70648
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 145000, loss: 0.01053164469136102, acc: 99.66980190785884, p_norm: 1881.5335176034673, g_norm: 0.1298564022025639, lr:  0.000656, elapsed time:  70696
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c ( C ) c ( - c 2 c c c c 3 c 2 c ( = O ) c ( C ) c n 3 C c 2 c c c c c 2 ) c ( C ) c 1 _EOS
Predicted text: C c 1 c c ( C ) c ( - c 2 c c c c 3 c 2 c ( = O ) c ( C ) c n 3 C c 2 c c c c c 2 ) c ( C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N c 2 c c n ( C C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) c ( = O ) c 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 F _EOS
Predicted text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N c 2 c c n ( C C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) c ( = O ) c 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C N 2 C c 3 c c c c c 3 C 3 ( C c 4 c c c c c 4 O 3 ) C 2 ) c c ( O C ) c 1 O C _EOS
Predicted text: C O c 1 c c ( C N 2 C c 3 c c c c c 3 C 3 ( C c 4 c c c c c 4 O 3 ) C 2 ) c c ( O C ) c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c ( C # C c 2 c c c c ( C # N ) c 2 ) n 1 _EOS
Predicted text: C c 1 c c c c ( C # C c 2 c c c c ( C # N ) c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c c c ( N 2 C C N ( C 3 C C C ( C ) C C 3 ) C C 2 ) c c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c c c ( N 2 C C N ( C 3 C C C ( C ) C C 3 ) C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 145000, eval acc (token): 0.9368807588589173, eval acc (sequence): 0.8866558030056129
Saving at step 145000
Step 145100, loss: 0.011022048081867979, acc: 99.66327732801437, p_norm: 1881.7602133130426, g_norm: 0.26343959219325697, lr:  0.000656, elapsed time:  70802
Step 145200, loss: 0.011082089393312344, acc: 99.65315200388432, p_norm: 1882.0277921622044, g_norm: 0.1889334659368155, lr:  0.000656, elapsed time:  70850
Step 145300, loss: 0.011071429734511185, acc: 99.65424431860447, p_norm: 1882.2880507915283, g_norm: 0.20548603914452931, lr:  0.000656, elapsed time:  70898
Step 145400, loss: 0.011066867901881779, acc: 99.66069336235523, p_norm: 1882.5163378827303, g_norm: 0.16660788876393254, lr:  0.000655, elapsed time:  70945
Step 145500, loss: 0.011257871688612794, acc: 99.64725844562054, p_norm: 1882.7691294657193, g_norm: 0.4307973024959392, lr:  0.000655, elapsed time:  70993
Step 145600, loss: 0.011559968012952594, acc: 99.63625444471836, p_norm: 1883.0456633734343, g_norm: 0.18811461370621882, lr:  0.000655, elapsed time:  71041
Step 145700, loss: 0.011413787766796303, acc: 99.64695578813553, p_norm: 1883.2736505468026, g_norm: 0.18155926804085368, lr:  0.000655, elapsed time:  71088
Step 145800, loss: 0.01167741157918499, acc: 99.64149488508701, p_norm: 1883.512005760235, g_norm: 0.1781075230667786, lr:  0.000655, elapsed time:  71135
Step 145900, loss: 0.010973778094794398, acc: 99.65714108943939, p_norm: 1883.760177743198, g_norm: 0.18413109005996325, lr:  0.000654, elapsed time:  71183
Step 146000, loss: 0.010566282720901654, acc: 99.67355181276798, p_norm: 1883.9915940148314, g_norm: 0.21662371110645576, lr:  0.000654, elapsed time:  71231
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 146000, eval loss: 0.018722568984376263, eval acc: 99.57428741455078
Step 146100, loss: 0.010654845993849449, acc: 99.67324508726597, p_norm: 1884.2236378016364, g_norm: 0.16912199593855606, lr:  0.000654, elapsed time:  71285
Step 146200, loss: 0.01131486268935987, acc: 99.6474973410368, p_norm: 1884.470482794739, g_norm: 0.22974798901759888, lr:  0.000654, elapsed time:  71333
Step 146300, loss: 0.011542252097278834, acc: 99.6412945240736, p_norm: 1884.7118010729203, g_norm: 0.20683816153648868, lr:  0.000653, elapsed time:  71380
Step 146400, loss: 0.011311276473825273, acc: 99.64814127981663, p_norm: 1884.9573510447492, g_norm: 0.18049846472986933, lr:  0.000653, elapsed time:  71427
Step 146500, loss: 0.011516212593342061, acc: 99.64787094295025, p_norm: 1885.206457924209, g_norm: 0.18351380148605154, lr:  0.000653, elapsed time:  71475
Step 146600, loss: 0.011598191191224032, acc: 99.63445577025414, p_norm: 1885.429018806513, g_norm: 0.13809270417036354, lr:  0.000653, elapsed time:  71522
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 146700, loss: 0.010677546369672327, acc: 99.66557968908282, p_norm: 1885.6593174943098, g_norm: 0.24084655829911047, lr:  0.000653, elapsed time:  71571
Step 146800, loss: 0.010810154697683174, acc: 99.65923900902271, p_norm: 1885.9055011575704, g_norm: 0.2271058101982322, lr:  0.000652, elapsed time:  71619
Step 146900, loss: 0.010305299727879174, acc: 99.67955309152603, p_norm: 1886.1219589253062, g_norm: 0.26534773115698473, lr:  0.000652, elapsed time:  71667
Step 147000, loss: 0.010845814837957733, acc: 99.6638565659523, p_norm: 1886.367033456044, g_norm: 0.13709700723465829, lr:  0.000652, elapsed time:  71714
Step 147100, loss: 0.011332339402688376, acc: 99.64128053188324, p_norm: 1886.6201947190689, g_norm: 0.23553625461955904, lr:  0.000652, elapsed time:  71762
Step 147200, loss: 0.011239613516627287, acc: 99.6485501229763, p_norm: 1886.8617618159492, g_norm: 0.21445441681422997, lr:  0.000651, elapsed time:  71809
Step 147300, loss: 0.010799460601883765, acc: 99.66786253452301, p_norm: 1887.1010801230882, g_norm: 0.22213263674695033, lr:  0.000651, elapsed time:  71857
Step 147400, loss: 0.011548402093503683, acc: 99.64464254677296, p_norm: 1887.343578923908, g_norm: 0.25519416552992646, lr:  0.000651, elapsed time:  71904
Step 147500, loss: 0.010835405868328962, acc: 99.66874946653843, p_norm: 1887.5876174932278, g_norm: 0.16456623659932304, lr:  0.000651, elapsed time:  71952
Step 147600, loss: 0.011764680905107525, acc: 99.63974682986736, p_norm: 1887.8267921807774, g_norm: 0.23707176526271936, lr:  0.000651, elapsed time:  71999
Step 147700, loss: 0.011412861223361688, acc: 99.64262200891972, p_norm: 1888.0514209787693, g_norm: 0.1898133328022547, lr:  0.000650, elapsed time:  72047
Step 147800, loss: 0.01113507555150136, acc: 99.65577830374241, p_norm: 1888.2798657306212, g_norm: 0.221105458910952, lr:  0.000650, elapsed time:  72094
Step 147900, loss: 0.011029999094171216, acc: 99.6586579978466, p_norm: 1888.5287888038956, g_norm: 0.3140496833128871, lr:  0.000650, elapsed time:  72142
Step 148000, loss: 0.01103893166180569, acc: 99.6553814560175, p_norm: 1888.7745195444572, g_norm: 0.1572865087167978, lr:  0.000650, elapsed time:  72190
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 148000, eval loss: 0.01801147296762792, eval acc: 99.60553741455078
Step 148100, loss: 0.011367690213082824, acc: 99.65115903317928, p_norm: 1889.0325391684569, g_norm: 0.1568538202218742, lr:  0.000649, elapsed time:  72244
Step 148200, loss: 0.011414746471127729, acc: 99.6483519077301, p_norm: 1889.3030741181872, g_norm: 0.12654738859666256, lr:  0.000649, elapsed time:  72292
Step 148300, loss: 0.01151360297226347, acc: 99.63973891735077, p_norm: 1889.5609999169376, g_norm: 0.17402862414443787, lr:  0.000649, elapsed time:  72339
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 148400, loss: 0.010669061744193634, acc: 99.6733821503282, p_norm: 1889.818370685381, g_norm: 0.14104604367890874, lr:  0.000649, elapsed time:  72388
Step 148500, loss: 0.010521373036972363, acc: 99.67315888404846, p_norm: 1890.0552849230037, g_norm: 0.16508736734420115, lr:  0.000649, elapsed time:  72436
Step 148600, loss: 0.010894370211208298, acc: 99.66279871761799, p_norm: 1890.32287835435, g_norm: 0.16629557933204875, lr:  0.000648, elapsed time:  72483
Step 148700, loss: 0.010947381847217911, acc: 99.6571079492569, p_norm: 1890.5442891625946, g_norm: 0.172936741873444, lr:  0.000648, elapsed time:  72531
Step 148800, loss: 0.011055389895045665, acc: 99.6532329916954, p_norm: 1890.7799970821968, g_norm: 0.1452419300877663, lr:  0.000648, elapsed time:  72578
Step 148900, loss: 0.011441344960549032, acc: 99.64309111237526, p_norm: 1891.0222154235496, g_norm: 0.13351383837129716, lr:  0.000648, elapsed time:  72626
Step 149000, loss: 0.011507430070123519, acc: 99.64616675674915, p_norm: 1891.26390790523, g_norm: 0.2336162715979757, lr:  0.000647, elapsed time:  72673
Step 149100, loss: 0.010933782918618818, acc: 99.66177585721016, p_norm: 1891.4823801591315, g_norm: 0.21669599031730816, lr:  0.000647, elapsed time:  72720
Step 149200, loss: 0.01118600897039869, acc: 99.65422251820564, p_norm: 1891.712003520331, g_norm: 0.16037062846881253, lr:  0.000647, elapsed time:  72768
Step 149300, loss: 0.01028921608129167, acc: 99.67997533082962, p_norm: 1891.9510574855835, g_norm: 0.1690794811882875, lr:  0.000647, elapsed time:  72816
Step 149400, loss: 0.011476979476283304, acc: 99.63852348923683, p_norm: 1892.182153395391, g_norm: 0.14983568364288422, lr:  0.000647, elapsed time:  72863
Step 149500, loss: 0.011257673959062232, acc: 99.64149583876133, p_norm: 1892.39921882903, g_norm: 0.2146479604827449, lr:  0.000646, elapsed time:  72911
Step 149600, loss: 0.01079220832856663, acc: 99.66703887283802, p_norm: 1892.623238315121, g_norm: 0.17350038654792643, lr:  0.000646, elapsed time:  72959
Step 149700, loss: 0.01117965784855187, acc: 99.65991304814816, p_norm: 1892.8566887212448, g_norm: 0.2558321667796824, lr:  0.000646, elapsed time:  73006
Step 149800, loss: 0.011031934204002027, acc: 99.65921823680401, p_norm: 1893.1064916699818, g_norm: 0.16118339917081387, lr:  0.000646, elapsed time:  73053
Step 149900, loss: 0.01138245838435978, acc: 99.64943999052048, p_norm: 1893.3499360901124, g_norm: 0.1877909031647133, lr:  0.000646, elapsed time:  73101
Step 150000, loss: 0.011271454383022501, acc: 99.64990878105164, p_norm: 1893.594450975342, g_norm: 0.204051812447879, lr:  0.000645, elapsed time:  73148
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 150000, eval loss: 0.018557864660906497, eval acc: 99.57018280029297
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( C N C ( = S ) N N ) O C _EOS
Predicted text: C O C ( C N C ( = S ) N N ) O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C ( C ( = O ) O C C ) c 1 c c ( O c 2 c c c ( F ) c c 2 ) c c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c 1 _EOS
Predicted text: C C C C ( C ( = O ) O C C ) c 1 c c ( O c 2 c c c ( F ) c c 2 ) c c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: c 1 c c c ( C 2 ( N 3 C C N C C 3 ) C C C C C 2 ) c c 1 _EOS
Predicted text: c 1 c c c ( C 2 ( N 3 C C N C C 3 ) C C C C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) c 1 c c c 2 c ( c 1 ) C C N ( c 1 c c ( F ) c c ( Br ) c 1 C = O ) C 2 = O _EOS
Predicted text: C N ( C ) c 1 c c c 2 c ( c 1 ) C C N ( c 1 c c ( F ) c c ( Br ) c 1 C = O ) C 2 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C n 1 c c ( - c 2 c c c c c 2 ) c ( C ) c ( N ) c 1 = O _EOS
Predicted text: C C C C C C n 1 c c ( - c 2 c c c c c 2 ) c ( C ) c ( N ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 150000, eval acc (token): 0.9351214535825475, eval acc (sequence): 0.8851602023608769
Saving at step 150000
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 150100, loss: 0.010214346110054971, acc: 99.6776394009886, p_norm: 1893.8130366810658, g_norm: 0.2228261112490732, lr:  0.000645, elapsed time:  73256
Step 150200, loss: 0.01073941249276686, acc: 99.67207124829292, p_norm: 1894.0539361992257, g_norm: 0.210097325643778, lr:  0.000645, elapsed time:  73303
Step 150300, loss: 0.01089539750784752, acc: 99.66032315790653, p_norm: 1894.2840326644648, g_norm: 0.21998335548285033, lr:  0.000645, elapsed time:  73351
Step 150400, loss: 0.010365217105136253, acc: 99.67846347391605, p_norm: 1894.5093125831734, g_norm: 0.2250259373729051, lr:  0.000644, elapsed time:  73398
Step 150500, loss: 0.010810879052260134, acc: 99.66413788497448, p_norm: 1894.7497210441195, g_norm: 0.2330458526120609, lr:  0.000644, elapsed time:  73446
Step 150600, loss: 0.010534173495580034, acc: 99.66968470811844, p_norm: 1894.981893566068, g_norm: 0.20871717735672454, lr:  0.000644, elapsed time:  73494
Step 150700, loss: 0.010691335510327917, acc: 99.6733104288578, p_norm: 1895.2273025622956, g_norm: 0.18940416412190728, lr:  0.000644, elapsed time:  73541
Step 150800, loss: 0.010794459114167694, acc: 99.662622615695, p_norm: 1895.45276312396, g_norm: 0.16042833497307438, lr:  0.000644, elapsed time:  73589
Step 150900, loss: 0.010627915158984251, acc: 99.67345549166203, p_norm: 1895.6696587405531, g_norm: 0.1781957991710038, lr:  0.000643, elapsed time:  73637
Step 151000, loss: 0.010916188365154084, acc: 99.66592498123646, p_norm: 1895.9019215607825, g_norm: 0.16540176028597772, lr:  0.000643, elapsed time:  73685
Step 151100, loss: 0.01184268832046655, acc: 99.63063541054726, p_norm: 1896.1660097557622, g_norm: 0.1903987794595893, lr:  0.000643, elapsed time:  73732
Step 151200, loss: 0.011481844119898596, acc: 99.64062617719173, p_norm: 1896.4095932437278, g_norm: 0.17597599945553724, lr:  0.000643, elapsed time:  73779
Step 151300, loss: 0.011009584725106833, acc: 99.65762378275394, p_norm: 1896.6300126973629, g_norm: 0.22564760368492098, lr:  0.000643, elapsed time:  73827
Step 151400, loss: 0.01107555993627102, acc: 99.66252355277538, p_norm: 1896.8618544935548, g_norm: 0.19418405331578237, lr:  0.000642, elapsed time:  73874
Step 151500, loss: 0.010543714371051465, acc: 99.66552512347698, p_norm: 1897.097418103771, g_norm: 0.23447374884008104, lr:  0.000642, elapsed time:  73922
Step 151600, loss: 0.011308063705000678, acc: 99.6516879349947, p_norm: 1897.346829265249, g_norm: 0.10732981185079093, lr:  0.000642, elapsed time:  73969
Step 151700, loss: 0.010877655076728842, acc: 99.6578008979559, p_norm: 1897.5716865384575, g_norm: 0.21426315092649362, lr:  0.000642, elapsed time:  74017
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 151800, loss: 0.0108221291827856, acc: 99.6599818281737, p_norm: 1897.8233098711955, g_norm: 0.19669247249898125, lr:  0.000641, elapsed time:  74065
Step 151900, loss: 0.010543091462168377, acc: 99.67720782756805, p_norm: 1898.060479644709, g_norm: 0.18459408947910563, lr:  0.000641, elapsed time:  74114
Step 152000, loss: 0.010303835212180274, acc: 99.68684601783752, p_norm: 1898.2856314115652, g_norm: 0.21356125824954753, lr:  0.000641, elapsed time:  74162
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 152000, eval loss: 0.017629280730252505, eval acc: 99.60232543945312
Step 152100, loss: 0.010735578515159432, acc: 99.66726849973202, p_norm: 1898.5034364996493, g_norm: 0.18564278544342336, lr:  0.000641, elapsed time:  74216
Step 152200, loss: 0.010067197416665294, acc: 99.68503294885159, p_norm: 1898.7197266490575, g_norm: 0.3002718354372163, lr:  0.000641, elapsed time:  74264
Step 152300, loss: 0.010965275374255725, acc: 99.65881286561489, p_norm: 1898.9548336515343, g_norm: 0.19598686635735654, lr:  0.000640, elapsed time:  74311
Step 152400, loss: 0.01069523373465927, acc: 99.66959127783775, p_norm: 1899.176104177991, g_norm: 0.16227622638241113, lr:  0.000640, elapsed time:  74359
Step 152500, loss: 0.010965830573641143, acc: 99.65951162576675, p_norm: 1899.4003239969709, g_norm: 0.1671106016501741, lr:  0.000640, elapsed time:  74407
Step 152600, loss: 0.010899247862980702, acc: 99.66001178324223, p_norm: 1899.6253870670594, g_norm: 0.2636641803091876, lr:  0.000640, elapsed time:  74454
Step 152700, loss: 0.01147572711633984, acc: 99.64396430552006, p_norm: 1899.8600934407996, g_norm: 0.18409207440835312, lr:  0.000640, elapsed time:  74501
Step 152800, loss: 0.010784610596965649, acc: 99.66337275505066, p_norm: 1900.090239944369, g_norm: 0.34121762955686585, lr:  0.000639, elapsed time:  74548
Step 152900, loss: 0.010873577354941518, acc: 99.66297514736652, p_norm: 1900.3261104825026, g_norm: 0.21671238507924756, lr:  0.000639, elapsed time:  74596
Step 153000, loss: 0.011246477489185053, acc: 99.64998038113117, p_norm: 1900.5582653216975, g_norm: 0.22727098406616203, lr:  0.000639, elapsed time:  74643
Step 153100, loss: 0.010351029460216522, acc: 99.68148086965084, p_norm: 1900.7879178137684, g_norm: 0.17962534835633484, lr:  0.000639, elapsed time:  74691
Step 153200, loss: 0.011557636174002255, acc: 99.636070266366, p_norm: 1901.0411305718633, g_norm: 0.17402193667488483, lr:  0.000639, elapsed time:  74739
Step 153300, loss: 0.010930925811262569, acc: 99.6636952906847, p_norm: 1901.264486766546, g_norm: 0.17851540259045906, lr:  0.000638, elapsed time:  74787
Step 153400, loss: 0.010634312532638433, acc: 99.66923029720783, p_norm: 1901.4971321226894, g_norm: 0.19860065625869608, lr:  0.000638, elapsed time:  74834
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 153500, loss: 0.010623291658775456, acc: 99.6743273646305, p_norm: 1901.7113740188818, g_norm: 0.15502680676989855, lr:  0.000638, elapsed time:  74882
Step 153600, loss: 0.010425887555320514, acc: 99.68092657625675, p_norm: 1901.9418789076171, g_norm: 0.28145709864140883, lr:  0.000638, elapsed time:  74930
Step 153700, loss: 0.010185358943126631, acc: 99.68083849549294, p_norm: 1902.173896978613, g_norm: 0.1561732321901659, lr:  0.000637, elapsed time:  74978
Step 153800, loss: 0.010750498145462188, acc: 99.66721445322037, p_norm: 1902.395531947128, g_norm: 0.13580179073601847, lr:  0.000637, elapsed time:  75025
Step 153900, loss: 0.010918301775382134, acc: 99.65954911708832, p_norm: 1902.6123905864995, g_norm: 0.18858330424310019, lr:  0.000637, elapsed time:  75072
Step 154000, loss: 0.010238607814899296, acc: 99.68886895477772, p_norm: 1902.8269899439833, g_norm: 0.21304849150987917, lr:  0.000637, elapsed time:  75120
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 154000, eval loss: 0.01786295529018389, eval acc: 99.59185028076172
Step 154100, loss: 0.010459560069321014, acc: 99.67279763519764, p_norm: 1903.0410245764685, g_norm: 0.2194639465496035, lr:  0.000637, elapsed time:  75175
Step 154200, loss: 0.010268335096025111, acc: 99.6807195097208, p_norm: 1903.2636478263182, g_norm: 0.22510932594365268, lr:  0.000636, elapsed time:  75222
Step 154300, loss: 0.010782309386195265, acc: 99.6637052744627, p_norm: 1903.5030926318086, g_norm: 0.22935024999069442, lr:  0.000636, elapsed time:  75270
Step 154400, loss: 0.011577219122991665, acc: 99.6364408582449, p_norm: 1903.728776284239, g_norm: 0.16468420913282703, lr:  0.000636, elapsed time:  75317
Step 154500, loss: 0.010329723531467607, acc: 99.67567472159863, p_norm: 1903.940693255583, g_norm: 0.2415265349565976, lr:  0.000636, elapsed time:  75365
Step 154600, loss: 0.010479054882016498, acc: 99.67697696387768, p_norm: 1904.1771591831753, g_norm: 0.20961208726658878, lr:  0.000636, elapsed time:  75413
Step 154700, loss: 0.011572064121100994, acc: 99.64771494269371, p_norm: 1904.426019394384, g_norm: 0.1625682793639942, lr:  0.000635, elapsed time:  75460
Step 154800, loss: 0.010887722045772534, acc: 99.6616730093956, p_norm: 1904.6537275105252, g_norm: 0.1779480413534366, lr:  0.000635, elapsed time:  75507
Step 154900, loss: 0.010689200090819213, acc: 99.6668266505003, p_norm: 1904.9089608300585, g_norm: 0.2003793662522051, lr:  0.000635, elapsed time:  75555
Step 155000, loss: 0.011207999321923125, acc: 99.65574289858341, p_norm: 1905.132530817702, g_norm: 0.17560026455274094, lr:  0.000635, elapsed time:  75603
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c c c 2 n c ( S C c 3 c c c ( C ( = O ) c 4 c c c ( O C ( = O ) N ( C ) C ) c c 4 ) c c 3 ) n ( C ) c ( = O ) c 1 2 _EOS
Predicted text: C c 1 c c c c 2 n c ( S C c 3 c c c ( C ( = O ) c 4 c c c ( O C ( = O ) N ( C ) C ) c c 4 ) c c 3 ) n ( C ) c ( = O ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C c 1 c c c ( - c 2 c ( C # N ) c c c c 2 C # N ) c c 1 ) N C ( = O ) c 1 c ( Cl ) c c c c 1 Cl _EOS
Predicted text: C O C ( = O ) C ( C c 1 c c c ( - c 2 c c ( C # N ) c c ( C # N ) c 2 ) c c 1 ) N C ( = O ) c 1 c ( Cl ) c c c c 1 Cl _EOS
acc_token: 0.43859649122807015, acc_seq: False

Target text: C c 1 c c c ( N c 2 c n c c ( F ) c 2 ) c ( C ( = O ) N c 2 c c c ( F ) c n 2 ) n 1 _EOS
Predicted text: C c 1 c c c ( N c 2 c n c c ( F ) c 2 ) c ( C ( = O ) N c 2 c c c ( F ) c n 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C ( C ) C ) c c 1 - c 1 c c c ( O C c 2 c c c c c 2 ) c c 1 C N ( C c 1 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 1 ) c 1 n c c ( N 2 C C O C C 2 ) c n 1 _EOS
Predicted text: C O c 1 c c c ( C ( C ) C ) c c 1 - c 1 c c c ( O C c 2 c c c c c 2 ) c c 1 C N ( C c 1 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 1 ) c 1 n c c ( N 2 C C O C C 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C c 1 n c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) s c 1 C O c 1 c c c ( C # N ) c ( S C ) c 1 _EOS
Predicted text: C C C C c 1 n c ( - c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) s c 1 C O c 1 c c c ( C # N ) c ( S C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 155000, eval acc (token): 0.9366230798029261, eval acc (sequence): 0.8847246891651865
Saving at step 155000
Step 155100, loss: 0.011246894196228823, acc: 99.65281561017036, p_norm: 1905.3606790391316, g_norm: 0.2406640501007982, lr:  0.000635, elapsed time:  75702
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 155200, loss: 0.011223484296893306, acc: 99.6550989653869, p_norm: 1905.614711406265, g_norm: 0.18483440084603706, lr:  0.000634, elapsed time:  75751
Step 155300, loss: 0.010498749060207046, acc: 99.67570628225803, p_norm: 1905.831441882539, g_norm: 0.28431324281418013, lr:  0.000634, elapsed time:  75799
Step 155400, loss: 0.01040422102989396, acc: 99.67686040699482, p_norm: 1906.063399089997, g_norm: 0.16188855355744972, lr:  0.000634, elapsed time:  75847
Step 155500, loss: 0.010665069607748592, acc: 99.66797140240669, p_norm: 1906.2860309469393, g_norm: 0.28943819517467706, lr:  0.000634, elapsed time:  75894
Step 155600, loss: 0.01067615235444464, acc: 99.66919316351414, p_norm: 1906.5147913533879, g_norm: 0.19676456862667266, lr:  0.000634, elapsed time:  75942
Step 155700, loss: 0.010318247832838096, acc: 99.680301040411, p_norm: 1906.7328393591358, g_norm: 0.13675254134614456, lr:  0.000633, elapsed time:  75990
Step 155800, loss: 0.010010385835321357, acc: 99.68774549663067, p_norm: 1906.945675117396, g_norm: 0.16091898344752328, lr:  0.000633, elapsed time:  76038
Step 155900, loss: 0.010803488795700105, acc: 99.66625165939331, p_norm: 1907.1605814825455, g_norm: 0.1604422891829315, lr:  0.000633, elapsed time:  76085
Step 156000, loss: 0.010515688957420935, acc: 99.66578468680382, p_norm: 1907.3966748846, g_norm: 0.19036771642819542, lr:  0.000633, elapsed time:  76133
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 156000, eval loss: 0.017585226912633523, eval acc: 99.58340454101562
Step 156100, loss: 0.011358438095667224, acc: 99.65150675177574, p_norm: 1907.637713366247, g_norm: 0.09377877858827612, lr:  0.000633, elapsed time:  76187
Step 156200, loss: 0.010807545267198293, acc: 99.66565711796284, p_norm: 1907.8451059445997, g_norm: 0.20611075047820418, lr:  0.000632, elapsed time:  76234
Step 156300, loss: 0.011139938314736355, acc: 99.65138171613216, p_norm: 1908.0708405985974, g_norm: 0.26814819516786187, lr:  0.000632, elapsed time:  76281
Step 156400, loss: 0.010313784240406677, acc: 99.6801842302084, p_norm: 1908.280589863978, g_norm: 0.13464130205447455, lr:  0.000632, elapsed time:  76329
Step 156500, loss: 0.010872857603317243, acc: 99.66793967783451, p_norm: 1908.5004137451588, g_norm: 0.23019703603572894, lr:  0.000632, elapsed time:  76376
Step 156600, loss: 0.011102211205943603, acc: 99.64993764460087, p_norm: 1908.734426484933, g_norm: 0.1942224372631926, lr:  0.000632, elapsed time:  76425
Step 156700, loss: 0.010460351710607938, acc: 99.6787778288126, p_norm: 1908.9596637974778, g_norm: 0.23747004148413364, lr:  0.000631, elapsed time:  76471
Step 156800, loss: 0.011021638095844537, acc: 99.65314289927483, p_norm: 1909.1819868955263, g_norm: 0.17249884105509788, lr:  0.000631, elapsed time:  76519
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 156900, loss: 0.010564043778581956, acc: 99.67835960696586, p_norm: 1909.4071429713706, g_norm: 0.15675295399583813, lr:  0.000631, elapsed time:  76567
Step 157000, loss: 0.0109425706500042, acc: 99.6585506349802, p_norm: 1909.6166598366037, g_norm: 0.2252849077103011, lr:  0.000631, elapsed time:  76614
Step 157100, loss: 0.010130669490645233, acc: 99.68607087433338, p_norm: 1909.8434342482633, g_norm: 0.18057245994243154, lr:  0.000631, elapsed time:  76662
Step 157200, loss: 0.011195964800954243, acc: 99.64845730364323, p_norm: 1910.0784687767386, g_norm: 0.2449294818849583, lr:  0.000630, elapsed time:  76709
Step 157300, loss: 0.010332348790288961, acc: 99.67797109484673, p_norm: 1910.2962741958088, g_norm: 0.15389621605244214, lr:  0.000630, elapsed time:  76756
Step 157400, loss: 0.010573529821012926, acc: 99.67666444182396, p_norm: 1910.5176121760067, g_norm: 0.23066347703363144, lr:  0.000630, elapsed time:  76804
Step 157500, loss: 0.010317779589004204, acc: 99.68327769637108, p_norm: 1910.7516019652421, g_norm: 0.17803843886977794, lr:  0.000630, elapsed time:  76851
Step 157600, loss: 0.010281645175928134, acc: 99.68061292171478, p_norm: 1910.97193639183, g_norm: 0.1368105807280816, lr:  0.000630, elapsed time:  76899
Step 157700, loss: 0.010333966650505318, acc: 99.67871122062206, p_norm: 1911.2116425326974, g_norm: 0.21009085116958973, lr:  0.000629, elapsed time:  76947
Step 157800, loss: 0.010403405879478668, acc: 99.67048306763172, p_norm: 1911.4393400338547, g_norm: 0.19357374803398208, lr:  0.000629, elapsed time:  76995
Step 157900, loss: 0.010571862388378577, acc: 99.67663472890854, p_norm: 1911.6712191437314, g_norm: 0.3155904303073962, lr:  0.000629, elapsed time:  77042
Step 158000, loss: 0.010658082860754804, acc: 99.66853971779346, p_norm: 1911.9012010383842, g_norm: 0.12232386940576749, lr:  0.000629, elapsed time:  77090
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 158000, eval loss: 0.0181477258601808, eval acc: 99.58861541748047
Step 158100, loss: 0.010661318460915937, acc: 99.66377528011799, p_norm: 1912.120212906058, g_norm: 0.19185431051807644, lr:  0.000629, elapsed time:  77145
Step 158200, loss: 0.011482289407249482, acc: 99.64360719919205, p_norm: 1912.3576378943528, g_norm: 0.19621002324481648, lr:  0.000628, elapsed time:  77192
Step 158300, loss: 0.010707279278503847, acc: 99.67262460291386, p_norm: 1912.5666869320025, g_norm: 0.264271647079372, lr:  0.000628, elapsed time:  77240
Step 158400, loss: 0.010375757950860133, acc: 99.67714786529541, p_norm: 1912.7788303595444, g_norm: 0.14439087312478582, lr:  0.000628, elapsed time:  77287
Step 158500, loss: 0.010986305669030116, acc: 99.66144950687885, p_norm: 1912.9890586483896, g_norm: 0.1114095032745253, lr:  0.000628, elapsed time:  77335
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 158600, loss: 0.010613586659508031, acc: 99.67113285515438, p_norm: 1913.222763656413, g_norm: 0.12230069159006376, lr:  0.000628, elapsed time:  77383
Step 158700, loss: 0.010399549318908612, acc: 99.67143103480339, p_norm: 1913.432609420781, g_norm: 0.23052526609985852, lr:  0.000627, elapsed time:  77431
Step 158800, loss: 0.010689139967144, acc: 99.66831028461456, p_norm: 1913.6715721623068, g_norm: 0.181078927625051, lr:  0.000627, elapsed time:  77479
Step 158900, loss: 0.010340472735842923, acc: 99.67698991298676, p_norm: 1913.8664498456358, g_norm: 0.1969534138246361, lr:  0.000627, elapsed time:  77527
Step 159000, loss: 0.010692282594645804, acc: 99.66763466596603, p_norm: 1914.083185512923, g_norm: 0.205395610075513, lr:  0.000627, elapsed time:  77574
Step 159100, loss: 0.010380262343642244, acc: 99.6770211160183, p_norm: 1914.3105529648822, g_norm: 0.2010078997126826, lr:  0.000627, elapsed time:  77621
Step 159200, loss: 0.010323713806646992, acc: 99.67959496378899, p_norm: 1914.5335404689195, g_norm: 0.23356838239002978, lr:  0.000626, elapsed time:  77669
Step 159300, loss: 0.011229998000380874, acc: 99.65134246647358, p_norm: 1914.7619862004956, g_norm: 0.1163324504657836, lr:  0.000626, elapsed time:  77716
Step 159400, loss: 0.010369368265073717, acc: 99.67379634082317, p_norm: 1914.9709045502698, g_norm: 0.20111100330524473, lr:  0.000626, elapsed time:  77764
Step 159500, loss: 0.010764389159921848, acc: 99.6604655534029, p_norm: 1915.1902143760099, g_norm: 0.24936422487750007, lr:  0.000626, elapsed time:  77812
Step 159600, loss: 0.010869321400678018, acc: 99.65876923501492, p_norm: 1915.414689307995, g_norm: 0.19505826250155958, lr:  0.000626, elapsed time:  77859
Step 159700, loss: 0.010172443855190068, acc: 99.68710319697857, p_norm: 1915.6253864767277, g_norm: 0.21013084344852898, lr:  0.000625, elapsed time:  77906
Step 159800, loss: 0.010076267297590676, acc: 99.68260762095451, p_norm: 1915.8424597893836, g_norm: 0.1723076723910788, lr:  0.000625, elapsed time:  77954
Step 159900, loss: 0.01152146662621817, acc: 99.6426677852869, p_norm: 1916.0630392719938, g_norm: 0.22903914709304798, lr:  0.000625, elapsed time:  78001
Step 160000, loss: 0.010333584655891173, acc: 99.68034912645817, p_norm: 1916.2937610168358, g_norm: 0.19141330747358895, lr:  0.000625, elapsed time:  78049
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 160000, eval loss: 0.017763019779231396, eval acc: 99.59292602539062
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( = O ) N C C C O C C 1 C C N ( C C 2 C N ( C c 3 c c c ( Cl ) c c 3 Cl ) C C 2 c 2 c c s c 2 ) C C 1 _EOS
Predicted text: C C ( = O ) N C C C O C C 1 C C N ( C C 2 C N ( C c 3 c c c ( Cl ) c c 3 Cl ) C C 2 c 2 c c s c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) C c 1 c ( F ) c c c 2 c ( C ( C C C # N ) c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) c [nH] c 1 2 _EOS
Predicted text: C S ( = O ) C c 1 c ( F ) c c c 2 c ( C ( C C C # N ) c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) c [nH] c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( O C ) c 2 c ( Cl ) n c ( - c 3 c c ( C ) c ( O C C O C c 4 c c c c c 4 ) c ( C ) c 3 ) n c 2 c 1 _EOS
Predicted text: C O c 1 c c ( O C ) c 2 c ( Cl ) n c ( - c 3 c c ( C ) c ( O C C O C c 4 c c c c c 4 ) c ( C ) c 3 ) n c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C N ( C C C c 2 c n 3 n c ( - c 4 c c c o 4 ) n c 3 c ( N ) n 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C N ( C C C c 2 c n 3 n c ( - c 4 c c c o 4 ) n c 3 c ( N ) n 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C S ( = O ) ( = O ) c 1 c c c ( C ( = C C ( C ) C ) c 2 c c 3 c c ( F ) c n c 3 n 2 S ( = O ) ( = O ) c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: C O C C S ( = O ) ( = O ) c 1 c c c ( C ( = C C ( C ) C ) c 2 c c 3 c c ( F ) c n c 3 n 2 S ( = O ) ( = O ) c 2 c c c c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 160000, eval acc (token): 0.9386111109283746, eval acc (sequence): 0.8860580325548478
Saving at step 160000
Step 160100, loss: 0.011084914898310672, acc: 99.65481498837471, p_norm: 1916.5169544304479, g_norm: 0.24380476074027485, lr:  0.000625, elapsed time:  78156
Step 160200, loss: 0.010330952086878824, acc: 99.6783739477396, p_norm: 1916.7254091831599, g_norm: 0.16962023656468045, lr:  0.000624, elapsed time:  78203
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 160300, loss: 0.010569936344322052, acc: 99.67422683540704, p_norm: 1916.9328819956813, g_norm: 0.1527160810952025, lr:  0.000624, elapsed time:  78252
Step 160400, loss: 0.010913647626512101, acc: 99.66372820734978, p_norm: 1917.1662391145203, g_norm: 0.16371247207226847, lr:  0.000624, elapsed time:  78298
Step 160500, loss: 0.0097097586061318, acc: 99.69993880391121, p_norm: 1917.364152481005, g_norm: 0.24420057958054395, lr:  0.000624, elapsed time:  78346
Step 160600, loss: 0.010785079068518826, acc: 99.6668032258749, p_norm: 1917.6128388136892, g_norm: 0.12069958120117805, lr:  0.000624, elapsed time:  78393
Step 160700, loss: 0.010001047351470333, acc: 99.68492493033409, p_norm: 1917.8359510095656, g_norm: 0.16348281547793786, lr:  0.000623, elapsed time:  78441
Step 160800, loss: 0.010381818735459092, acc: 99.67234371602535, p_norm: 1918.0738382899463, g_norm: 0.2099900320354369, lr:  0.000623, elapsed time:  78488
Step 160900, loss: 0.010148351621901384, acc: 99.68165144324303, p_norm: 1918.292437887288, g_norm: 0.08526323698496882, lr:  0.000623, elapsed time:  78536
Step 161000, loss: 0.010022526313150593, acc: 99.68769277632236, p_norm: 1918.4868812246516, g_norm: 0.22881532639882754, lr:  0.000623, elapsed time:  78584
Step 161100, loss: 0.01074243137252779, acc: 99.6702928096056, p_norm: 1918.7058775884261, g_norm: 0.18136837186335464, lr:  0.000623, elapsed time:  78632
Step 161200, loss: 0.010437413354648015, acc: 99.66757442057133, p_norm: 1918.9179311480127, g_norm: 0.266828882938559, lr:  0.000622, elapsed time:  78680
Step 161300, loss: 0.010584226413084253, acc: 99.67661063373089, p_norm: 1919.1387032170062, g_norm: 0.16533486597070005, lr:  0.000622, elapsed time:  78727
Step 161400, loss: 0.01072028349402899, acc: 99.67101716995239, p_norm: 1919.3726408337411, g_norm: 0.1329550351620848, lr:  0.000622, elapsed time:  78775
Step 161500, loss: 0.010788630616543742, acc: 99.66301843523979, p_norm: 1919.6005065741506, g_norm: 0.20253329587424987, lr:  0.000622, elapsed time:  78823
Step 161600, loss: 0.010685535072843777, acc: 99.66957107186317, p_norm: 1919.8212800076526, g_norm: 0.16424592661216186, lr:  0.000622, elapsed time:  78870
Step 161700, loss: 0.011282714594271966, acc: 99.65514287352562, p_norm: 1920.0338950193002, g_norm: 0.14826371157241788, lr:  0.000622, elapsed time:  78917
Step 161800, loss: 0.010595457920335321, acc: 99.67284269630909, p_norm: 1920.2378572755586, g_norm: 0.20424002897755356, lr:  0.000621, elapsed time:  78965
Step 161900, loss: 0.01097795329098517, acc: 99.66592732071877, p_norm: 1920.4529553566674, g_norm: 0.17462022197685706, lr:  0.000621, elapsed time:  79012
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 162000, loss: 0.010367515901059273, acc: 99.67624203442935, p_norm: 1920.6694640108806, g_norm: 0.16013863295536154, lr:  0.000621, elapsed time:  79061
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 162000, eval loss: 0.017469395366169923, eval acc: 99.59324645996094
Step 162100, loss: 0.010010697851030273, acc: 99.6873938292265, p_norm: 1920.8717455722713, g_norm: 0.34235988601633477, lr:  0.000621, elapsed time:  79116
Step 162200, loss: 0.010039867649975349, acc: 99.69265732169151, p_norm: 1921.0801911584497, g_norm: 0.18802799554734798, lr:  0.000621, elapsed time:  79163
Step 162300, loss: 0.010503860466014885, acc: 99.6752881705761, p_norm: 1921.2967703011795, g_norm: 0.17981500121840668, lr:  0.000620, elapsed time:  79211
Step 162400, loss: 0.010400708131819557, acc: 99.67201206088066, p_norm: 1921.504257950821, g_norm: 0.13304701402355523, lr:  0.000620, elapsed time:  79258
Step 162500, loss: 0.010794163905375171, acc: 99.66633222997189, p_norm: 1921.7240870985656, g_norm: 0.1739688460778038, lr:  0.000620, elapsed time:  79306
Step 162600, loss: 0.01086600543523673, acc: 99.66485524177551, p_norm: 1921.9427613596806, g_norm: 0.21086771720145991, lr:  0.000620, elapsed time:  79353
Step 162700, loss: 0.010394188341597327, acc: 99.67918375134468, p_norm: 1922.1391615542304, g_norm: 0.2950556282489558, lr:  0.000620, elapsed time:  79401
Step 162800, loss: 0.010178083692844666, acc: 99.68824927508831, p_norm: 1922.356838909755, g_norm: 0.20592132345430203, lr:  0.000619, elapsed time:  79448
Step 162900, loss: 0.010267863180624772, acc: 99.681018486619, p_norm: 1922.5586482532378, g_norm: 0.16649503302242266, lr:  0.000619, elapsed time:  79496
Step 163000, loss: 0.010435567128151888, acc: 99.6779316663742, p_norm: 1922.769690680891, g_norm: 0.1417020132397611, lr:  0.000619, elapsed time:  79543
Step 163100, loss: 0.010151290716603398, acc: 99.68459767103195, p_norm: 1922.9948257224823, g_norm: 0.18886475931157412, lr:  0.000619, elapsed time:  79591
Step 163200, loss: 0.009819252448469342, acc: 99.68885144591331, p_norm: 1923.1916153161783, g_norm: 0.218502239041279, lr:  0.000619, elapsed time:  79639
Step 163300, loss: 0.010170213358433102, acc: 99.68717578053474, p_norm: 1923.4119703949114, g_norm: 0.11901743748449649, lr:  0.000618, elapsed time:  79686
Step 163400, loss: 0.010811467264938984, acc: 99.66822227835655, p_norm: 1923.6540460496594, g_norm: 0.23869264224102563, lr:  0.000618, elapsed time:  79733
Step 163500, loss: 0.010789928554695507, acc: 99.66451300680637, p_norm: 1923.8655383326488, g_norm: 0.23187635426307976, lr:  0.000618, elapsed time:  79780
Step 163600, loss: 0.010252600191124657, acc: 99.67626605927944, p_norm: 1924.0607570272944, g_norm: 0.19962534228656106, lr:  0.000618, elapsed time:  79828
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 163700, loss: 0.010819429502336865, acc: 99.66676653762609, p_norm: 1924.2528267161506, g_norm: 0.19451254695273307, lr:  0.000618, elapsed time:  79877
Step 163800, loss: 0.009865214702076628, acc: 99.69522126019001, p_norm: 1924.461474814046, g_norm: 0.1642177646713047, lr:  0.000618, elapsed time:  79925
Step 163900, loss: 0.010315870963095221, acc: 99.68056364357471, p_norm: 1924.6666726251788, g_norm: 0.15585070673024384, lr:  0.000617, elapsed time:  79973
Step 164000, loss: 0.010025101745250141, acc: 99.68596413731575, p_norm: 1924.8885875384221, g_norm: 0.22217221790142014, lr:  0.000617, elapsed time:  80020
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 164000, eval loss: 0.018615113233972812, eval acc: 99.61090087890625
Step 164100, loss: 0.010746567721266729, acc: 99.65914826095104, p_norm: 1925.1032771440962, g_norm: 0.15729054426641928, lr:  0.000617, elapsed time:  80075
Step 164200, loss: 0.009926742012412433, acc: 99.68652892112732, p_norm: 1925.3212806484662, g_norm: 0.15170415966693115, lr:  0.000617, elapsed time:  80122
Step 164300, loss: 0.010337435592991823, acc: 99.67784477770329, p_norm: 1925.5262547092827, g_norm: 0.1692496937322342, lr:  0.000617, elapsed time:  80169
Step 164400, loss: 0.010169189417501912, acc: 99.68402661383152, p_norm: 1925.7446070697413, g_norm: 0.1806763058194729, lr:  0.000616, elapsed time:  80217
Step 164500, loss: 0.010609336158340739, acc: 99.67051693797112, p_norm: 1925.951689751878, g_norm: 0.19849910459153616, lr:  0.000616, elapsed time:  80264
Step 164600, loss: 0.010024853032846295, acc: 99.68840554356575, p_norm: 1926.147701813657, g_norm: 0.13695300396254892, lr:  0.000616, elapsed time:  80312
Step 164700, loss: 0.010185743362599168, acc: 99.67921648919582, p_norm: 1926.3776053276497, g_norm: 0.2910556616314123, lr:  0.000616, elapsed time:  80360
Step 164800, loss: 0.010504927258480165, acc: 99.67165479063988, p_norm: 1926.6043208082024, g_norm: 0.23189966685921326, lr:  0.000616, elapsed time:  80407
Step 164900, loss: 0.010178424786299729, acc: 99.68829999864101, p_norm: 1926.8076588058216, g_norm: 0.1341356438478032, lr:  0.000615, elapsed time:  80455
Step 165000, loss: 0.01063241740099329, acc: 99.67099837958813, p_norm: 1927.0067274627306, g_norm: 0.1388180967206817, lr:  0.000615, elapsed time:  80502
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: N c 1 c c c ( C ( = O ) N 2 C C C ( C ( O ) c 3 c c c ( F ) c c 3 ) C C 2 ) c c 1 _EOS
Predicted text: N c 1 c c c ( C ( = O ) N 2 C C C ( C ( O ) c 3 c c c ( F ) c c 3 ) C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C 1 2 C C C 3 C 4 C C C ( = O ) C = C 4 C C C 3 C 1 C ( O C ( = O ) c 1 c c c c c 1 ) C C 2 = O _EOS
Predicted text: C C C 1 2 C C C 3 C 4 C C C ( = O ) C = C 4 C C C 3 C 1 C ( O C ( = O ) c 1 c c c c c 1 ) C C 2 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C C ( C c 1 c [nH] c 2 c c c c c 1 2 ) C ( = O ) O _EOS
Predicted text: O = C ( O ) C C ( C c 1 c [nH] c 2 c c c c c 1 2 ) C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: C S c 1 n c c 2 c c c ( - c 3 c c c ( C ) c c 3 [N+] ( = O ) [O-] ) n 2 n 1 _EOS
Predicted text: C S c 1 n c c 2 c c c ( - c 3 c c c ( C ) c c 3 [N+] ( = O ) [O-] ) n 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( N c 2 c n c n c 2 ) c ( C ( = O ) N c 2 c c n ( - c 3 c c c ( F ) c c 3 ) n 2 ) n 1 _EOS
Predicted text: C c 1 c c c ( N c 2 c n c n c 2 ) c ( C ( = O ) N c 2 c c n ( - c 3 c c c ( F ) c c 3 ) n 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 165000, eval acc (token): 0.9390983770473945, eval acc (sequence): 0.891151284490961
Saving at step 165000
Step 165100, loss: 0.010496042242302793, acc: 99.67144578695297, p_norm: 1927.2419593772622, g_norm: 0.2112319100941469, lr:  0.000615, elapsed time:  80604
Step 165200, loss: 0.01049206582334591, acc: 99.67382682859898, p_norm: 1927.4739172942793, g_norm: 0.1837007440161432, lr:  0.000615, elapsed time:  80651
Step 165300, loss: 0.010913788510297309, acc: 99.66792587935925, p_norm: 1927.6712423236777, g_norm: 0.1956977426285551, lr:  0.000615, elapsed time:  80698
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 165400, loss: 0.010504123188087125, acc: 99.6694113865088, p_norm: 1927.8821348772628, g_norm: 0.25261662332662893, lr:  0.000615, elapsed time:  80747
Step 165500, loss: 0.009403909838802064, acc: 99.69922548532486, p_norm: 1928.0737197125784, g_norm: 0.20004438120147253, lr:  0.000614, elapsed time:  80795
Step 165600, loss: 0.010394795824322501, acc: 99.6773308813572, p_norm: 1928.27335297087, g_norm: 0.17676201018553067, lr:  0.000614, elapsed time:  80843
Step 165700, loss: 0.010053028638030809, acc: 99.68702912330627, p_norm: 1928.4806812115116, g_norm: 0.18464385709146425, lr:  0.000614, elapsed time:  80890
Step 165800, loss: 0.01038713550711691, acc: 99.67602732777596, p_norm: 1928.690544523606, g_norm: 0.32577269721851687, lr:  0.000614, elapsed time:  80937
Step 165900, loss: 0.0099247970153192, acc: 99.69054600596428, p_norm: 1928.9003366805605, g_norm: 0.15468976792763314, lr:  0.000614, elapsed time:  80985
Step 166000, loss: 0.010095744990867388, acc: 99.68319131433964, p_norm: 1929.117091178868, g_norm: 0.23652142018482186, lr:  0.000613, elapsed time:  81033
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 166000, eval loss: 0.017919702607759973, eval acc: 99.60679626464844
Step 166100, loss: 0.0100626486110923, acc: 99.67755277454853, p_norm: 1929.3280503384717, g_norm: 0.1753023143554192, lr:  0.000613, elapsed time:  81087
Step 166200, loss: 0.010098293337068753, acc: 99.68540884554386, p_norm: 1929.5634916979252, g_norm: 0.14145060264756645, lr:  0.000613, elapsed time:  81135
Step 166300, loss: 0.010196305412937362, acc: 99.68853810429573, p_norm: 1929.7808564836414, g_norm: 0.1798698949764372, lr:  0.000613, elapsed time:  81182
Step 166400, loss: 0.010548312527425878, acc: 99.66751396656036, p_norm: 1929.9887070411392, g_norm: 0.25263094406947645, lr:  0.000613, elapsed time:  81230
Step 166500, loss: 0.010178875997553405, acc: 99.679718375206, p_norm: 1930.1934967592538, g_norm: 0.18785582067532136, lr:  0.000612, elapsed time:  81277
Step 166600, loss: 0.01005420043346021, acc: 99.68770691752434, p_norm: 1930.4210903251662, g_norm: 0.1850215717632062, lr:  0.000612, elapsed time:  81325
Step 166700, loss: 0.01043934771010754, acc: 99.6658468991518, p_norm: 1930.6294037808225, g_norm: 0.20832855344080242, lr:  0.000612, elapsed time:  81372
Step 166800, loss: 0.010511590546084335, acc: 99.67357529699802, p_norm: 1930.8451872468281, g_norm: 0.1482841616310447, lr:  0.000612, elapsed time:  81419
Step 166900, loss: 0.010900027168099768, acc: 99.66122624278069, p_norm: 1931.056460964982, g_norm: 0.14003458669282218, lr:  0.000612, elapsed time:  81466
Step 167000, loss: 0.010885943412213238, acc: 99.66829523444176, p_norm: 1931.2758500083444, g_norm: 0.1971802476268808, lr:  0.000612, elapsed time:  81514
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 167100, loss: 0.009941422435981645, acc: 99.68788570432521, p_norm: 1931.4778475617281, g_norm: 0.20048817453519155, lr:  0.000611, elapsed time:  81562
Step 167200, loss: 0.010266611351107712, acc: 99.68157973885536, p_norm: 1931.6715188454161, g_norm: 0.1706921154773375, lr:  0.000611, elapsed time:  81609
Step 167300, loss: 0.00962779606848926, acc: 99.69787168502808, p_norm: 1931.867717426151, g_norm: 0.21609536850366337, lr:  0.000611, elapsed time:  81657
Step 167400, loss: 0.009686060262065439, acc: 99.70574869215488, p_norm: 1932.078917349644, g_norm: 0.15173306227857616, lr:  0.000611, elapsed time:  81704
Step 167500, loss: 0.010277549808270123, acc: 99.67911663651466, p_norm: 1932.3017311907904, g_norm: 0.23615017475995145, lr:  0.000611, elapsed time:  81751
Step 167600, loss: 0.010179808263619633, acc: 99.68476535379887, p_norm: 1932.5019237270922, g_norm: 0.19580896558035332, lr:  0.000610, elapsed time:  81799
Step 167700, loss: 0.009819231672317984, acc: 99.69038866460323, p_norm: 1932.69568758139, g_norm: 0.17927385299031373, lr:  0.000610, elapsed time:  81846
Step 167800, loss: 0.009897712899655743, acc: 99.6937372982502, p_norm: 1932.8920756872983, g_norm: 0.14513743534398557, lr:  0.000610, elapsed time:  81893
Step 167900, loss: 0.010436022154790408, acc: 99.67519138753414, p_norm: 1933.119412754221, g_norm: 0.17102444367847577, lr:  0.000610, elapsed time:  81941
Step 168000, loss: 0.010288319475494063, acc: 99.67634250223637, p_norm: 1933.3262175840325, g_norm: 0.2291937649051452, lr:  0.000610, elapsed time:  81988
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 168000, eval loss: 0.018037017224123705, eval acc: 99.58861541748047
Step 168100, loss: 0.009904119861894288, acc: 99.6852290481329, p_norm: 1933.558176579092, g_norm: 0.395516683591374, lr:  0.000610, elapsed time:  82042
Step 168200, loss: 0.010161113741814916, acc: 99.68237021565437, p_norm: 1933.7667038488287, g_norm: 0.19281992477592486, lr:  0.000609, elapsed time:  82090
Step 168300, loss: 0.01053596550351358, acc: 99.6671545356512, p_norm: 1933.9962709507686, g_norm: 0.15613708643610724, lr:  0.000609, elapsed time:  82138
Step 168400, loss: 0.011797233426914317, acc: 99.63714399933815, p_norm: 1934.2110251162585, g_norm: 0.16043098669395314, lr:  0.000609, elapsed time:  82185
Step 168500, loss: 0.009951491276788148, acc: 99.68606175482273, p_norm: 1934.4023369409954, g_norm: 0.20815439657873308, lr:  0.000609, elapsed time:  82233
Step 168600, loss: 0.009737381349114003, acc: 99.69694660604, p_norm: 1934.5885223357466, g_norm: 0.1497208071293138, lr:  0.000609, elapsed time:  82281
Step 168700, loss: 0.009837347089669492, acc: 99.69618751108646, p_norm: 1934.797728198012, g_norm: 0.3018535888735246, lr:  0.000608, elapsed time:  82328
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 168800, loss: 0.010316681141626245, acc: 99.6831878686957, p_norm: 1935.0062449576833, g_norm: 0.1898545227800341, lr:  0.000608, elapsed time:  82378
Step 168900, loss: 0.00939721204169473, acc: 99.70222416520119, p_norm: 1935.1901733512839, g_norm: 0.1915583930067294, lr:  0.000608, elapsed time:  82425
Step 169000, loss: 0.009181738061997749, acc: 99.70927239954472, p_norm: 1935.3863844106704, g_norm: 0.14111737216328915, lr:  0.000608, elapsed time:  82471
Step 169100, loss: 0.009434800057133543, acc: 99.70504479110241, p_norm: 1935.601681526903, g_norm: 0.20555288020834195, lr:  0.000608, elapsed time:  82518
Step 169200, loss: 0.009681825695561202, acc: 99.68919035792351, p_norm: 1935.8163590972558, g_norm: 0.1839917861921879, lr:  0.000608, elapsed time:  82565
Step 169300, loss: 0.0101897845059284, acc: 99.68451555073261, p_norm: 1936.036261758247, g_norm: 0.1848541092105212, lr:  0.000607, elapsed time:  82612
Step 169400, loss: 0.010553784621733939, acc: 99.66870646178722, p_norm: 1936.255636238328, g_norm: 0.21731353564946923, lr:  0.000607, elapsed time:  82657
Step 169500, loss: 0.010545453235827153, acc: 99.66718244552612, p_norm: 1936.4583804218453, g_norm: 0.2740760398751748, lr:  0.000607, elapsed time:  82704
Step 169600, loss: 0.010141430174990092, acc: 99.68703129887581, p_norm: 1936.6719606506151, g_norm: 0.21612646322877788, lr:  0.000607, elapsed time:  82750
Step 169700, loss: 0.010455148501314397, acc: 99.67188726365566, p_norm: 1936.8921853009706, g_norm: 0.12377876750090465, lr:  0.000607, elapsed time:  82796
Step 169800, loss: 0.010236614693712908, acc: 99.67665222287178, p_norm: 1937.1045074640306, g_norm: 0.23466450879285553, lr:  0.000607, elapsed time:  82842
Step 169900, loss: 0.009780470140867692, acc: 99.7016875743866, p_norm: 1937.316025586576, g_norm: 0.23856907086106263, lr:  0.000606, elapsed time:  82890
Step 170000, loss: 0.010708823180793843, acc: 99.67223146557808, p_norm: 1937.528042236886, g_norm: 0.1775081299834316, lr:  0.000606, elapsed time:  82936
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 170000, eval loss: 0.019296589679543105, eval acc: 99.57537841796875
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C N ( C ) C C C N c 1 c c c c c 1 C ( = N c 1 c c c n c 1 Cl ) c 1 c c c c c 1 _EOS
Predicted text: C N ( C ) C C C N c 1 c c c c c 1 C ( = N c 1 c c c n c 1 Cl ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C C c 1 c c c ( C # N ) c c 1 Cl _EOS
Predicted text: C C O C ( = O ) C C c 1 c c c ( C # N ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C C C N ( c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 C N 2 C ( = O ) O C ( c 3 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 3 ) C 2 C ) C 1 _EOS
Predicted text: C C 1 C C C N ( c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 C N 2 C ( = O ) O C ( c 3 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 3 ) C 2 C ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C N ( C C C ) C ( = O ) c 1 c c ( C ( = O ) O C ) c c ( - c 2 n c c n 2 C O C C ) c 1 _EOS
Predicted text: C C C N ( C C C ) C ( = O ) c 1 c c ( C ( = O ) O C ) c c ( - c 2 n c c n 2 C O C C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) c 1 c c c ( C N ( C C c 2 c c ( C ( F ) ( F ) F ) c c c 2 F ) C ( = O ) c 2 c c c c 3 c c [nH] c 2 3 ) c c 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c c ( C N ( C C c 2 c c ( C ( F ) ( F ) F ) c c c 2 F ) C ( = O ) c 2 c c c c 3 c c [nH] c 2 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 170000, eval acc (token): 0.936729485830021, eval acc (sequence): 0.8849557522123894
Saving at step 170000
Step 170100, loss: 0.010530424077724093, acc: 99.67312029004097, p_norm: 1937.7321862145068, g_norm: 0.17240003873799137, lr:  0.000606, elapsed time:  83039
Step 170200, loss: 0.010298007736000727, acc: 99.68401983380318, p_norm: 1937.9490504015962, g_norm: 0.21205862137547565, lr:  0.000606, elapsed time:  83086
Step 170300, loss: 0.010931927864585305, acc: 99.659463301301, p_norm: 1938.15979362515, g_norm: 0.17828632194883948, lr:  0.000606, elapsed time:  83132
Step 170400, loss: 0.010064884183557297, acc: 99.68105418980122, p_norm: 1938.368307724986, g_norm: 0.14862256100816917, lr:  0.000605, elapsed time:  83179
Step 170500, loss: 0.010227033135415696, acc: 99.68026824295521, p_norm: 1938.5626608631278, g_norm: 0.1878839580854548, lr:  0.000605, elapsed time:  83225
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 170600, loss: 0.009648693438003212, acc: 99.69902196829727, p_norm: 1938.765476163983, g_norm: 0.1882733358205324, lr:  0.000605, elapsed time:  83273
Step 170700, loss: 0.010036294764850026, acc: 99.67548924684525, p_norm: 1938.970294536028, g_norm: 0.17338183645423758, lr:  0.000605, elapsed time:  83319
Step 170800, loss: 0.009837408602361392, acc: 99.68762472271919, p_norm: 1939.1438358355513, g_norm: 0.14450261443147022, lr:  0.000605, elapsed time:  83376
Step 170900, loss: 0.00974832280906412, acc: 99.6918814778328, p_norm: 1939.340677399504, g_norm: 0.1676366723175819, lr:  0.000605, elapsed time:  83427
Step 171000, loss: 0.009531684042485722, acc: 99.70300534367561, p_norm: 1939.5341647326134, g_norm: 0.1284833607300473, lr:  0.000604, elapsed time:  83475
Step 171100, loss: 0.00988179180147199, acc: 99.68671301007271, p_norm: 1939.7330084061434, g_norm: 0.17071947108840932, lr:  0.000604, elapsed time:  83523
Step 171200, loss: 0.010207365171499987, acc: 99.68070036172867, p_norm: 1939.941686893081, g_norm: 0.29409240842178963, lr:  0.000604, elapsed time:  83570
Step 171300, loss: 0.01061564162500872, acc: 99.67378503084183, p_norm: 1940.1549667334455, g_norm: 0.1742772932035212, lr:  0.000604, elapsed time:  83618
Step 171400, loss: 0.009506436035571823, acc: 99.70605772733688, p_norm: 1940.3581467466488, g_norm: 0.19317688778001524, lr:  0.000604, elapsed time:  83666
Step 171500, loss: 0.00994389308791142, acc: 99.6937146037817, p_norm: 1940.5631682962767, g_norm: 0.1833273504747034, lr:  0.000604, elapsed time:  83713
Step 171600, loss: 0.009725752595695667, acc: 99.69253984093666, p_norm: 1940.7602138579562, g_norm: 0.16875740169058728, lr:  0.000603, elapsed time:  83761
Step 171700, loss: 0.010490604033293494, acc: 99.67034929990768, p_norm: 1940.9768908513545, g_norm: 0.1605349580145312, lr:  0.000603, elapsed time:  83809
Step 171800, loss: 0.010207657853616183, acc: 99.68551893532276, p_norm: 1941.1864694746118, g_norm: 0.13770653152121734, lr:  0.000603, elapsed time:  83866
Step 171900, loss: 0.010470779026145466, acc: 99.67910124361515, p_norm: 1941.3803530269408, g_norm: 0.18545172528870663, lr:  0.000603, elapsed time:  83914
Step 172000, loss: 0.010969216128985408, acc: 99.65541782975197, p_norm: 1941.591243301499, g_norm: 0.34477005709298003, lr:  0.000603, elapsed time:  83962
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 172000, eval loss: 0.01876146522175986, eval acc: 99.54938507080078
Step 172100, loss: 0.010112379510574102, acc: 99.6906713694334, p_norm: 1941.7972017867328, g_norm: 0.19460754251500156, lr:  0.000602, elapsed time:  84018
Step 172200, loss: 0.010655776023195358, acc: 99.67067083716393, p_norm: 1942.0112735716123, g_norm: 0.2043992670048212, lr:  0.000602, elapsed time:  84067
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 172300, loss: 0.01008024656566388, acc: 99.6825407811489, p_norm: 1942.2143781633292, g_norm: 0.1278801088166926, lr:  0.000602, elapsed time:  84125
Step 172400, loss: 0.01007489749988963, acc: 99.68500426411629, p_norm: 1942.4242775214686, g_norm: 0.15411042678064069, lr:  0.000602, elapsed time:  84175
Step 172500, loss: 0.00916952704101277, acc: 99.71726602315903, p_norm: 1942.615410481454, g_norm: 0.17969176502973605, lr:  0.000602, elapsed time:  84224
Step 172600, loss: 0.00984657224806142, acc: 99.69889970123768, p_norm: 1942.8251052640453, g_norm: 0.20316750625498725, lr:  0.000602, elapsed time:  84273
Step 172700, loss: 0.010006436767653212, acc: 99.69371485710144, p_norm: 1943.0129827748146, g_norm: 0.25624253347402615, lr:  0.000601, elapsed time:  84332
Step 172800, loss: 0.009799226975792408, acc: 99.690315335989, p_norm: 1943.213302465312, g_norm: 0.16798763602021188, lr:  0.000601, elapsed time:  84390
Step 172900, loss: 0.009789737312748912, acc: 99.69723604619503, p_norm: 1943.4189149941324, g_norm: 0.22415519451919022, lr:  0.000601, elapsed time:  84437
Step 173000, loss: 0.010051454686326906, acc: 99.68316331505775, p_norm: 1943.6242469861822, g_norm: 0.18530983346810354, lr:  0.000601, elapsed time:  84485
Step 173100, loss: 0.010123288553095335, acc: 99.69021712243557, p_norm: 1943.8122512264135, g_norm: 0.17193085735391783, lr:  0.000601, elapsed time:  84532
Step 173200, loss: 0.010376789380898118, acc: 99.67659583687782, p_norm: 1944.0136330186342, g_norm: 0.16172785960338829, lr:  0.000601, elapsed time:  84579
Step 173300, loss: 0.009619510671254829, acc: 99.70413634181023, p_norm: 1944.2060417192051, g_norm: 0.193527924799859, lr:  0.000600, elapsed time:  84627
Step 173400, loss: 0.010153638254505494, acc: 99.68642570078373, p_norm: 1944.3963476128376, g_norm: 0.1639992492158576, lr:  0.000600, elapsed time:  84675
Step 173500, loss: 0.01050848282633524, acc: 99.6684095710516, p_norm: 1944.6085635822287, g_norm: 0.24063738544774796, lr:  0.000600, elapsed time:  84723
Step 173600, loss: 0.009986621678690426, acc: 99.68277959525585, p_norm: 1944.8158878313484, g_norm: 0.271842947222114, lr:  0.000600, elapsed time:  84771
Step 173700, loss: 0.010228438533340522, acc: 99.68146488070488, p_norm: 1945.035311904036, g_norm: 0.33705558848506256, lr:  0.000600, elapsed time:  84820
Step 173800, loss: 0.01050918115881359, acc: 99.66802990436554, p_norm: 1945.2417742232892, g_norm: 0.4047461530067792, lr:  0.000599, elapsed time:  84867
Step 173900, loss: 0.010212728828973923, acc: 99.68482412397861, p_norm: 1945.4588678007428, g_norm: 0.19873652958368518, lr:  0.000599, elapsed time:  84917
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 174000, loss: 0.009936012943401221, acc: 99.68144827090185, p_norm: 1945.660421800554, g_norm: 0.11836532314350999, lr:  0.000599, elapsed time:  84966
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 174000, eval loss: 0.017098603350968914, eval acc: 99.60453796386719
Step 174100, loss: 0.009675440932187484, acc: 99.69723963737488, p_norm: 1945.8783798506697, g_norm: 0.4647337336599594, lr:  0.000599, elapsed time:  85022
Step 174200, loss: 0.01047752933072843, acc: 99.67867155373096, p_norm: 1946.0742736305795, g_norm: 0.22559965160817322, lr:  0.000599, elapsed time:  85070
Step 174300, loss: 0.01010433001370984, acc: 99.68565663695335, p_norm: 1946.2658345076723, g_norm: 0.16056959653114108, lr:  0.000599, elapsed time:  85118
Step 174400, loss: 0.009303503520968662, acc: 99.71325869858265, p_norm: 1946.4578165263692, g_norm: 0.16687538448006348, lr:  0.000598, elapsed time:  85167
Step 174500, loss: 0.00994209640975896, acc: 99.68244116008282, p_norm: 1946.6619272976677, g_norm: 0.1911591277748144, lr:  0.000598, elapsed time:  85216
Step 174600, loss: 0.009796570631997382, acc: 99.68760773539543, p_norm: 1946.8674667171251, g_norm: 0.1916691646792335, lr:  0.000598, elapsed time:  85264
Step 174700, loss: 0.009951971283226158, acc: 99.69249439239502, p_norm: 1947.071941612046, g_norm: 0.17018442465215222, lr:  0.000598, elapsed time:  85313
Step 174800, loss: 0.009689680880655941, acc: 99.69765534996986, p_norm: 1947.262683989402, g_norm: 0.14783670101681431, lr:  0.000598, elapsed time:  85361
Step 174900, loss: 0.009785015717334318, acc: 99.68999643623829, p_norm: 1947.4792435645197, g_norm: 0.1933677115864132, lr:  0.000598, elapsed time:  85410
Step 175000, loss: 0.01018512462702347, acc: 99.68276807665825, p_norm: 1947.6769720873929, g_norm: 0.2286137598679305, lr:  0.000597, elapsed time:  85458
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) ( C ) O C ( = O ) C O c 1 c c c c ( C N ) c 1 _EOS
Predicted text: N C ( = O ) C O c 1 c c c c ( C = N O ) c 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.13793103448275862, acc_seq: False

Target text: C O c 1 c c c ( C 2 ( C ) C S c 3 c c ( O C ) c c c 3 C 2 ( O ) C # C C C C C C C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C 2 ( C ) C S c 3 c c ( O C ) c c c 3 C 2 ( O ) C # C C C C C C C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) c 1 c c c c ( - c 2 c c c 3 [nH] n c ( - c 4 n c 5 c c c c c 5 [nH] 4 ) c 3 c 2 ) c 1 _EOS
Predicted text: C S ( = O ) ( = O ) c 1 c c c c ( - c 2 c c c 3 [nH] n c ( - c 4 n c 5 c c c c c 5 [nH] 4 ) c 3 c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( Cl ) c ( O C C O c 2 c c c ( C C ( C N ) C ( = O ) N ( C c 3 c c n c 4 c c c c c 3 4 ) C 3 C C 3 ) c c 2 ) c ( Cl ) c 1 _EOS
Predicted text: C c 1 c c ( Cl ) c ( O C C O c 2 c c c ( C C ( C N ) C ( = O ) N ( C c 3 c c n c 4 c c c c c 3 4 ) C 3 C C 3 ) c c 2 ) c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: F c 1 c c ( S C c 2 c c c c c 2 ) c ( Cl ) c ( N 2 C C C C 2 ) c 1 _EOS
Predicted text: F c 1 c c ( S C c 2 c c c c c 2 ) c ( Cl ) c ( N 2 C C C C 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 175000, eval acc (token): 0.939617946804, eval acc (sequence): 0.8917114778416466
Saving at step 175000
Step 175100, loss: 0.010247013263251574, acc: 99.6757497638464, p_norm: 1947.8733338525012, g_norm: 0.1912472748350264, lr:  0.000597, elapsed time:  85563
Step 175200, loss: 0.010290746976406808, acc: 99.67977933585644, p_norm: 1948.0713690230828, g_norm: 0.1974566529246273, lr:  0.000597, elapsed time:  85611
Step 175300, loss: 0.009630632191656332, acc: 99.69889287650585, p_norm: 1948.2532244178894, g_norm: 0.17626028775446603, lr:  0.000597, elapsed time:  85660
Step 175400, loss: 0.010042911950949928, acc: 99.69012174010277, p_norm: 1948.4383906672003, g_norm: 0.18304335970406188, lr:  0.000597, elapsed time:  85708
Step 175500, loss: 0.009760256713052513, acc: 99.69449961185455, p_norm: 1948.6346294628559, g_norm: 0.19563388195393022, lr:  0.000597, elapsed time:  85757
Step 175600, loss: 0.009822095887102478, acc: 99.69225309789181, p_norm: 1948.838095569218, g_norm: 0.26145652380289763, lr:  0.000596, elapsed time:  85805
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 175700, loss: 0.009918640745421165, acc: 99.70039034364235, p_norm: 1949.047262014141, g_norm: 0.12683618017061118, lr:  0.000596, elapsed time:  85855
Step 175800, loss: 0.00944571536481817, acc: 99.70610500872135, p_norm: 1949.2221372451756, g_norm: 0.15291970319635892, lr:  0.000596, elapsed time:  85903
Step 175900, loss: 0.0101214085283209, acc: 99.6855001449585, p_norm: 1949.433373814338, g_norm: 0.22404367301249697, lr:  0.000596, elapsed time:  85952
Step 176000, loss: 0.009650440813711612, acc: 99.70457535982132, p_norm: 1949.6165421864923, g_norm: 0.23496463365299375, lr:  0.000596, elapsed time:  86000
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 176000, eval loss: 0.016727607214124876, eval acc: 99.6287612915039
Step 176100, loss: 0.010105027082063315, acc: 99.6861375272274, p_norm: 1949.8246854662038, g_norm: 0.3974346350609229, lr:  0.000596, elapsed time:  86056
Step 176200, loss: 0.009887529534607893, acc: 99.69134968519211, p_norm: 1950.0222291626917, g_norm: 0.19362570753480446, lr:  0.000595, elapsed time:  86104
Step 176300, loss: 0.009368322361369792, acc: 99.7049983292818, p_norm: 1950.212018987451, g_norm: 0.1819141532137689, lr:  0.000595, elapsed time:  86152
Step 176400, loss: 0.009631548260931594, acc: 99.69441945850849, p_norm: 1950.4114306352494, g_norm: 0.1227689002981126, lr:  0.000595, elapsed time:  86201
Step 176500, loss: 0.009804216711017943, acc: 99.69196172058582, p_norm: 1950.6180539501959, g_norm: 0.17439327717964656, lr:  0.000595, elapsed time:  86249
Step 176600, loss: 0.009707542358883074, acc: 99.69256298244, p_norm: 1950.8310015125655, g_norm: 0.17733298350544993, lr:  0.000595, elapsed time:  86297
Step 176700, loss: 0.009890336827811552, acc: 99.69295661151409, p_norm: 1951.0259148522139, g_norm: 0.13640771514894995, lr:  0.000595, elapsed time:  86346
Step 176800, loss: 0.009974634478476218, acc: 99.69018819928169, p_norm: 1951.2218716055052, g_norm: 0.1977927746207916, lr:  0.000594, elapsed time:  86394
Step 176900, loss: 0.009958250241179484, acc: 99.68852569162846, p_norm: 1951.4136843439026, g_norm: 0.16356271650137028, lr:  0.000594, elapsed time:  86442
Step 177000, loss: 0.01044532850091855, acc: 99.67326001822948, p_norm: 1951.616564879558, g_norm: 0.1553326879345128, lr:  0.000594, elapsed time:  86490
Step 177100, loss: 0.009782016644567192, acc: 99.69556415081024, p_norm: 1951.85685742916, g_norm: 0.17955185926462966, lr:  0.000594, elapsed time:  86539
Step 177200, loss: 0.010752145386795746, acc: 99.65903975069523, p_norm: 1952.0672577714397, g_norm: 0.228947528797982, lr:  0.000594, elapsed time:  86586
Step 177300, loss: 0.009654513549176045, acc: 99.69552558660507, p_norm: 1952.2570304992198, g_norm: 0.21008342878719574, lr:  0.000594, elapsed time:  86634
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 177400, loss: 0.010665666376469915, acc: 99.66592510639882, p_norm: 1952.4697515978553, g_norm: 0.24851311311747026, lr:  0.000593, elapsed time:  86683
Step 177500, loss: 0.009570504876755877, acc: 99.69761322438717, p_norm: 1952.6388344684324, g_norm: 0.20404037942988756, lr:  0.000593, elapsed time:  86731
Step 177600, loss: 0.009139693739089126, acc: 99.71927510201931, p_norm: 1952.8342268335928, g_norm: 0.20923984976501475, lr:  0.000593, elapsed time:  86779
Step 177700, loss: 0.009076300248052576, acc: 99.7138943374157, p_norm: 1953.0038969020154, g_norm: 0.2005063637962714, lr:  0.000593, elapsed time:  86828
Step 177800, loss: 0.010053255179482221, acc: 99.68403123319149, p_norm: 1953.195667301825, g_norm: 0.121282222374056, lr:  0.000593, elapsed time:  86876
Step 177900, loss: 0.009809698713106628, acc: 99.69372348487377, p_norm: 1953.3866481394905, g_norm: 0.166259508920095, lr:  0.000593, elapsed time:  86925
Step 178000, loss: 0.00979718037735438, acc: 99.6926117837429, p_norm: 1953.5759325463769, g_norm: 0.2891113124823146, lr:  0.000592, elapsed time:  86973
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 178000, eval loss: 0.019000964792276125, eval acc: 99.59302520751953
Step 178100, loss: 0.009582706464534567, acc: 99.69533781707287, p_norm: 1953.760842673605, g_norm: 0.2120872022786919, lr:  0.000592, elapsed time:  87028
Step 178200, loss: 0.009823028094542679, acc: 99.69335481524467, p_norm: 1953.9684327930254, g_norm: 0.21117532807868591, lr:  0.000592, elapsed time:  87076
Step 178300, loss: 0.00948580569394835, acc: 99.70197884738445, p_norm: 1954.1746153962754, g_norm: 0.15642728704422668, lr:  0.000592, elapsed time:  87124
Step 178400, loss: 0.010005543125625991, acc: 99.68929606676102, p_norm: 1954.3564418561332, g_norm: 0.12530279411308315, lr:  0.000592, elapsed time:  87171
Step 178500, loss: 0.010022415255843953, acc: 99.68191403150558, p_norm: 1954.5471804308913, g_norm: 0.22409407461258815, lr:  0.000592, elapsed time:  87219
Step 178600, loss: 0.009920474633272534, acc: 99.6915230602026, p_norm: 1954.7572240318177, g_norm: 0.18396886905603999, lr:  0.000591, elapsed time:  87267
Step 178700, loss: 0.009513986720194226, acc: 99.69573214650154, p_norm: 1954.9462102326304, g_norm: 0.1917265881758281, lr:  0.000591, elapsed time:  87315
Step 178800, loss: 0.009968200845651153, acc: 99.69248032569885, p_norm: 1955.1360846301463, g_norm: 0.13602265986566703, lr:  0.000591, elapsed time:  87363
Step 178900, loss: 0.010052648595665232, acc: 99.68592981994152, p_norm: 1955.3483726863105, g_norm: 0.2935980914778403, lr:  0.000591, elapsed time:  87411
Step 179000, loss: 0.009797394328561495, acc: 99.69069135189056, p_norm: 1955.5477102060584, g_norm: 0.16320317214286273, lr:  0.000591, elapsed time:  87459
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6822
Step 179100, loss: 0.01007611946420297, acc: 99.68264653018458, p_norm: 1955.7394304711902, g_norm: 0.18047993593263964, lr:  0.000591, elapsed time:  87508
Step 179200, loss: 0.010033940280409296, acc: 99.69245716929436, p_norm: 1955.9299319952338, g_norm: 0.2189101597347932, lr:  0.000590, elapsed time:  87556
Step 179300, loss: 0.009482846583669016, acc: 99.7035804092884, p_norm: 1956.107908080878, g_norm: 0.119556906672135, lr:  0.000590, elapsed time:  87603
Step 179400, loss: 0.009495732037976268, acc: 99.7018514573574, p_norm: 1956.3000736744123, g_norm: 0.1935352987600864, lr:  0.000590, elapsed time:  87651
Step 179500, loss: 0.008965472059753666, acc: 99.72184017300606, p_norm: 1956.4914256182644, g_norm: 0.15320921826665565, lr:  0.000590, elapsed time:  87699
Step 179600, loss: 0.00999654643201211, acc: 99.68393993377686, p_norm: 1956.6908319912257, g_norm: 0.32327496167861647, lr:  0.000590, elapsed time:  87747
Step 179700, loss: 0.009993109867937165, acc: 99.6893669962883, p_norm: 1956.8875423872114, g_norm: 0.20196606933679026, lr:  0.000590, elapsed time:  87794
Step 179800, loss: 0.009633833183252137, acc: 99.69985464215279, p_norm: 1957.0682316419782, g_norm: 0.1931512733148438, lr:  0.000589, elapsed time:  87842
Step 179900, loss: 0.009414640708055231, acc: 99.7069129049778, p_norm: 1957.2534690692664, g_norm: 0.15679881630576012, lr:  0.000589, elapsed time:  87889
Step 180000, loss: 0.009364379797916626, acc: 99.70676583051682, p_norm: 1957.459299970171, g_norm: 0.18255905760372515, lr:  0.000589, elapsed time:  87937
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 180000, eval loss: 0.018353602778806825, eval acc: 99.58111572265625
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C 1 C C C C C 1 O C ( = O ) c 1 c c ( N C S c 2 c c c c c 2 ) c c c 1 Cl _EOS
Predicted text: C C 1 C C C C C 1 O C ( = O ) c 1 c c ( N C ( = S ) c 2 c c c c c 2 ) c c c 1 Cl _EOS
acc_token: 0.6842105263157895, acc_seq: False

Target text: N c 1 c c n 2 c c ( - c 3 c c c c ( O C C F ) c 3 ) n c 2 n 1 _EOS
Predicted text: N c 1 c c n 2 c c ( - c 3 c c c c ( O C C F ) c 3 ) n c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) C 1 = C C C 2 C 3 = C C = C 4 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C 4 ( C ) C 3 C C C 1 2 C _EOS
Predicted text: C C 1 = C C C 2 C 3 = C C = C 4 C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C C ( O [Si] ( C ) ( C ) C ( C ) ( C ) C ) C 4 ( C ) C 3 C C C 1 2 C _EOS _PAD _PAD _PAD _PAD _PAD
acc_token: 0.30666666666666664, acc_seq: False

Target text: C C ( C ) ( C ) O C ( = O ) N c 1 c c ( N ) c n c 1 Cl _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N c 1 c c ( N ) c n c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( N C ( = O ) O C c 1 c c c c c 1 ) C ( = O ) N C 1 C C c 2 c c c c c 2 N C 1 = O _EOS
Predicted text: C C ( C ) ( N C ( = O ) O C c 1 c c c c c 1 ) C ( = O ) N C 1 C C c 2 c c c c c 2 N C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 180000, eval acc (token): 0.945379644426008, eval acc (sequence): 0.8950307091010609
Saving at step 180000
Step 180100, loss: 0.009895261922010831, acc: 99.69068185985088, p_norm: 1957.6567644932459, g_norm: 0.2066015970007277, lr:  0.000589, elapsed time:  88060
Step 180200, loss: 0.010189746881478641, acc: 99.68291933834553, p_norm: 1957.8642809271787, g_norm: 0.21758376277794889, lr:  0.000589, elapsed time:  88113
Step 180300, loss: 0.009752983212856635, acc: 99.6969762146473, p_norm: 1958.040630741294, g_norm: 0.13755250951705286, lr:  0.000589, elapsed time:  88162
Step 180400, loss: 0.009718926882596861, acc: 99.7000273168087, p_norm: 1958.227991540647, g_norm: 0.15949137374561242, lr:  0.000588, elapsed time:  88209
Step 180500, loss: 0.009652329400105374, acc: 99.69702829420567, p_norm: 1958.4135477420723, g_norm: 0.4065133426764274, lr:  0.000588, elapsed time:  88257
Step 180600, loss: 0.00942481241931091, acc: 99.70859874784946, p_norm: 1958.6309150252687, g_norm: 0.24069592210236448, lr:  0.000588, elapsed time:  88305
Step 180700, loss: 0.010232195329372189, acc: 99.67875628173351, p_norm: 1958.8320528818344, g_norm: 0.2004801029077943, lr:  0.000588, elapsed time:  88353
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 180800, loss: 0.009349283620232105, acc: 99.70163753376671, p_norm: 1959.0177412866583, g_norm: 0.1398200636528982, lr:  0.000588, elapsed time:  88402
Step 180900, loss: 0.009031503598907874, acc: 99.71397022902966, p_norm: 1959.1971437236764, g_norm: 0.14597628616065822, lr:  0.000588, elapsed time:  88449
Step 181000, loss: 0.009514279811683082, acc: 99.70017309486866, p_norm: 1959.3825204488007, g_norm: 0.17095042841570146, lr:  0.000587, elapsed time:  88497
Step 181100, loss: 0.009879220107404763, acc: 99.69067569077015, p_norm: 1959.5817787203812, g_norm: 0.17366994814679004, lr:  0.000587, elapsed time:  88544
Step 181200, loss: 0.009165317490678717, acc: 99.71477700769901, p_norm: 1959.7692666550524, g_norm: 0.23731967476860763, lr:  0.000587, elapsed time:  88591
Step 181300, loss: 0.00969155106045946, acc: 99.69743850827217, p_norm: 1959.9598164623314, g_norm: 0.1857383329941571, lr:  0.000587, elapsed time:  88639
Step 181400, loss: 0.008986421178233285, acc: 99.72258906066418, p_norm: 1960.1695061781245, g_norm: 0.21741535018081612, lr:  0.000587, elapsed time:  88687
Step 181500, loss: 0.009650210778527252, acc: 99.69868209958076, p_norm: 1960.358056014834, g_norm: 0.20159742985188758, lr:  0.000587, elapsed time:  88734
Step 181600, loss: 0.009499763926214655, acc: 99.70149935781956, p_norm: 1960.5391038299292, g_norm: 0.21521962023749194, lr:  0.000586, elapsed time:  88782
Step 181700, loss: 0.00956320000164851, acc: 99.7035513818264, p_norm: 1960.7288341121507, g_norm: 0.22486262072192512, lr:  0.000586, elapsed time:  88829
Step 181800, loss: 0.009716347958674305, acc: 99.69498492777348, p_norm: 1960.914371312194, g_norm: 0.15659488634384633, lr:  0.000586, elapsed time:  88877
Step 181900, loss: 0.010021139175005373, acc: 99.68655183911324, p_norm: 1961.1079272625293, g_norm: 0.235659420615332, lr:  0.000586, elapsed time:  88925
Step 182000, loss: 0.010198809614394122, acc: 99.67686150968075, p_norm: 1961.292795865425, g_norm: 0.2708852789157883, lr:  0.000586, elapsed time:  88972
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 182000, eval loss: 0.017871900269099118, eval acc: 99.59872436523438
Step 182100, loss: 0.010764028756457265, acc: 99.66211706399918, p_norm: 1961.5130984893867, g_norm: 0.1537498556319464, lr:  0.000586, elapsed time:  89027
Step 182200, loss: 0.00969140895333112, acc: 99.69880892336369, p_norm: 1961.7042103697647, g_norm: 0.17608266321696675, lr:  0.000586, elapsed time:  89074
Step 182300, loss: 0.010182541090525774, acc: 99.67673829197884, p_norm: 1961.8934104411017, g_norm: 0.25471453523721344, lr:  0.000585, elapsed time:  89122
Step 182400, loss: 0.009784613596548298, acc: 99.69793990254402, p_norm: 1962.080000612139, g_norm: 0.3498173150029961, lr:  0.000585, elapsed time:  89169
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 182500, loss: 0.009280004898313243, acc: 99.71606095434714, p_norm: 1962.2577859900614, g_norm: 0.16278929520631638, lr:  0.000585, elapsed time:  89218
Step 182600, loss: 0.00904201508335973, acc: 99.71720589697361, p_norm: 1962.450817754604, g_norm: 0.22540320919585377, lr:  0.000585, elapsed time:  89265
Step 182700, loss: 0.009641549486441364, acc: 99.69787032902241, p_norm: 1962.635992229171, g_norm: 0.17068445784329686, lr:  0.000585, elapsed time:  89313
Step 182800, loss: 0.008997270986328658, acc: 99.71432235836983, p_norm: 1962.836820165826, g_norm: 0.2649656010910277, lr:  0.000585, elapsed time:  89362
Step 182900, loss: 0.01001506129072368, acc: 99.682073071599, p_norm: 1963.0363210468092, g_norm: 0.17369093866702798, lr:  0.000584, elapsed time:  89409
Step 183000, loss: 0.009427976516890339, acc: 99.70324456691742, p_norm: 1963.218086984881, g_norm: 0.20704183242719687, lr:  0.000584, elapsed time:  89457
Step 183100, loss: 0.009413516258136951, acc: 99.70943051576614, p_norm: 1963.4058212157709, g_norm: 0.1842313285749213, lr:  0.000584, elapsed time:  89504
Step 183200, loss: 0.009886069200438214, acc: 99.69703897833824, p_norm: 1963.5900015660854, g_norm: 0.15266917812494293, lr:  0.000584, elapsed time:  89552
Step 183300, loss: 0.009512428050202288, acc: 99.70712146162987, p_norm: 1963.77802843517, g_norm: 0.18036816353741084, lr:  0.000584, elapsed time:  89600
Step 183400, loss: 0.009707806260230427, acc: 99.69217233359814, p_norm: 1963.958787269135, g_norm: 0.1365724735199344, lr:  0.000584, elapsed time:  89648
Step 183500, loss: 0.009703684700361918, acc: 99.68882362544537, p_norm: 1964.1465661239354, g_norm: 0.16865864495316601, lr:  0.000583, elapsed time:  89695
Step 183600, loss: 0.009240668697584624, acc: 99.70882230997086, p_norm: 1964.3332951711866, g_norm: 0.1892110665690771, lr:  0.000583, elapsed time:  89742
Step 183700, loss: 0.009533901613176568, acc: 99.70334389805794, p_norm: 1964.5319331141795, g_norm: 0.21150649289183635, lr:  0.000583, elapsed time:  89790
Step 183800, loss: 0.010106430416817603, acc: 99.68683341145515, p_norm: 1964.7255745043399, g_norm: 0.2411980986638374, lr:  0.000583, elapsed time:  89838
Step 183900, loss: 0.010167388321933686, acc: 99.68383374810219, p_norm: 1964.9165327148398, g_norm: 0.19181308314967796, lr:  0.000583, elapsed time:  89886
Step 184000, loss: 0.009601896260137436, acc: 99.69858680665493, p_norm: 1965.0895552285924, g_norm: 0.23109849568222746, lr:  0.000583, elapsed time:  89933
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 184000, eval loss: 0.01874566453084299, eval acc: 99.58216094970703
Step 184100, loss: 0.010065464975778014, acc: 99.6901433467865, p_norm: 1965.279151794299, g_norm: 0.23756559630352572, lr:  0.000582, elapsed time:  89988
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 184200, loss: 0.00976022946567849, acc: 99.69346623858506, p_norm: 1965.4772683483443, g_norm: 0.16967374741770613, lr:  0.000582, elapsed time:  90036
Step 184300, loss: 0.00920461971869372, acc: 99.71285918354988, p_norm: 1965.6603176049646, g_norm: 0.18002903213970378, lr:  0.000582, elapsed time:  90084
Step 184400, loss: 0.009221497102480498, acc: 99.71250605583191, p_norm: 1965.8475662319988, g_norm: 0.21386577707630797, lr:  0.000582, elapsed time:  90132
Step 184500, loss: 0.009274361469579162, acc: 99.70958726108074, p_norm: 1966.0405719434825, g_norm: 0.17957706023602166, lr:  0.000582, elapsed time:  90180
Step 184600, loss: 0.00898601150696777, acc: 99.73103919625282, p_norm: 1966.2175643861442, g_norm: 0.18381955231673097, lr:  0.000582, elapsed time:  90229
Step 184700, loss: 0.009769498646601277, acc: 99.6953250169754, p_norm: 1966.4125871057065, g_norm: 0.1964311840898183, lr:  0.000582, elapsed time:  90277
Step 184800, loss: 0.009723993406423688, acc: 99.69250063598156, p_norm: 1966.5983934216467, g_norm: 0.17130241446426903, lr:  0.000581, elapsed time:  90325
Step 184900, loss: 0.009543643754914228, acc: 99.70400270819664, p_norm: 1966.8003239539191, g_norm: 0.09829814173836744, lr:  0.000581, elapsed time:  90373
Step 185000, loss: 0.009406037252138049, acc: 99.69564440846443, p_norm: 1966.979479156278, g_norm: 0.20611101686305752, lr:  0.000581, elapsed time:  90421
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) C = C 1 C C 1 _EOS
Predicted text: C C O C ( = O ) C = C 1 C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N C C C C ( = O ) c 1 c c c ( Cl ) c c 1 C ( C C ( = O ) O ) c 1 c c c c c 1 _EOS
Predicted text: O = C 1 C C ( c 2 c c c c c 2 ) c 2 c c ( Cl ) c c c 2 C ( = O ) C C C N 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.15555555555555556, acc_seq: False

Target text: C c 1 c c c c c 1 N = C 1 N C C N 1 O _EOS
Predicted text: C c 1 c c c c c 1 N = C 1 N C C N 1 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C N ( C c 2 c c c ( N ( C ) C ( = O ) N 3 C C C ( N c 4 c c c c ( F ) c 4 ) C C 3 ) c c 2 ) C C N 1 _EOS
Predicted text: C C 1 C N ( C c 2 c c c ( N ( C ) C ( = O ) N 3 C C C ( N c 4 c c c c ( F ) c 4 ) C C 3 ) c c 2 ) C C N 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c c ( F ) c c c 1 N C ( = O ) c 1 c c c ( Cl ) n c 1 _EOS
Predicted text: N c 1 c c ( F ) c c c 1 N C ( = O ) c 1 c c c ( Cl ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 185000, eval acc (token): 0.9423446548372085, eval acc (sequence): 0.8970021771897505
Saving at step 185000
Step 185100, loss: 0.009731404330941586, acc: 99.69951459765434, p_norm: 1967.1733085379276, g_norm: 0.1722761197774229, lr:  0.000581, elapsed time:  90523
Step 185200, loss: 0.009792715371886515, acc: 99.69446931779385, p_norm: 1967.3569209958105, g_norm: 0.1284945466364646, lr:  0.000581, elapsed time:  90571
Step 185300, loss: 0.009497082357447652, acc: 99.6996778845787, p_norm: 1967.5400571933785, g_norm: 0.1512267548624292, lr:  0.000581, elapsed time:  90619
Step 185400, loss: 0.009274012309779209, acc: 99.70802368223667, p_norm: 1967.7500109583464, g_norm: 0.1730932610824672, lr:  0.000580, elapsed time:  90667
Step 185500, loss: 0.00963127872291807, acc: 99.70117555558681, p_norm: 1967.9426234548482, g_norm: 0.31071080900757303, lr:  0.000580, elapsed time:  90716
Step 185600, loss: 0.010035156901103619, acc: 99.68059988319874, p_norm: 1968.1320628724745, g_norm: 0.1953400664226646, lr:  0.000580, elapsed time:  90764
Step 185700, loss: 0.010492307030135635, acc: 99.67242775857449, p_norm: 1968.3322699845764, g_norm: 0.17465947690745512, lr:  0.000580, elapsed time:  90812
Step 185800, loss: 0.009529941805703856, acc: 99.70301181077957, p_norm: 1968.5223590630858, g_norm: 0.2333754601322739, lr:  0.000580, elapsed time:  90860
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 185900, loss: 0.008838118398596738, acc: 99.71794222779664, p_norm: 1968.6940620005178, g_norm: 0.19190758813784453, lr:  0.000580, elapsed time:  90909
Step 186000, loss: 0.009255557573687838, acc: 99.71474768221378, p_norm: 1968.881077619406, g_norm: 0.230874156942885, lr:  0.000580, elapsed time:  90957
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 186000, eval loss: 0.018633764982223515, eval acc: 99.59484100341797
Step 186100, loss: 0.008982703740148281, acc: 99.71916878223419, p_norm: 1969.0665242663088, g_norm: 0.16010538811509817, lr:  0.000579, elapsed time:  91013
Step 186200, loss: 0.009501731778764224, acc: 99.69960795342922, p_norm: 1969.2422554085733, g_norm: 0.166397364392564, lr:  0.000579, elapsed time:  91061
Step 186300, loss: 0.009859018362876669, acc: 99.6874677091837, p_norm: 1969.434074947548, g_norm: 0.12396990066535994, lr:  0.000579, elapsed time:  91109
Step 186400, loss: 0.009984790713933761, acc: 99.68877816200256, p_norm: 1969.6140219221413, g_norm: 0.13691288189042242, lr:  0.000579, elapsed time:  91157
Step 186500, loss: 0.008917002820671769, acc: 99.7227434515953, p_norm: 1969.7974665893666, g_norm: 0.3075852454050706, lr:  0.000579, elapsed time:  91205
Step 186600, loss: 0.009954397168949072, acc: 99.69049344956875, p_norm: 1969.9913238140443, g_norm: 0.15737348153066733, lr:  0.000579, elapsed time:  91254
Step 186700, loss: 0.009305846355164248, acc: 99.70760452747345, p_norm: 1970.1912374600627, g_norm: 0.16654126663939783, lr:  0.000578, elapsed time:  91302
Step 186800, loss: 0.00926584844277386, acc: 99.70735736191273, p_norm: 1970.3712892029746, g_norm: 0.2062299340231723, lr:  0.000578, elapsed time:  91351
Step 186900, loss: 0.009730134028068278, acc: 99.69834357500076, p_norm: 1970.5575312763765, g_norm: 0.14437887436010807, lr:  0.000578, elapsed time:  91399
Step 187000, loss: 0.010098344337111485, acc: 99.68461106717587, p_norm: 1970.7727170539902, g_norm: 0.16293267846844453, lr:  0.000578, elapsed time:  91447
Step 187100, loss: 0.009516604203708994, acc: 99.70107939839363, p_norm: 1970.9338818887368, g_norm: 0.17596854991103797, lr:  0.000578, elapsed time:  91495
Step 187200, loss: 0.009860495138564147, acc: 99.68889677524567, p_norm: 1971.1146399181039, g_norm: 0.21687392014993614, lr:  0.000578, elapsed time:  91543
Step 187300, loss: 0.009612778483497095, acc: 99.69795912504196, p_norm: 1971.316553737253, g_norm: 0.173783601758956, lr:  0.000577, elapsed time:  91591
Step 187400, loss: 0.009568824715533992, acc: 99.70170179009438, p_norm: 1971.5068453082295, g_norm: 0.16897994504824856, lr:  0.000577, elapsed time:  91640
Step 187500, loss: 0.009798724964730355, acc: 99.69284345209599, p_norm: 1971.6851811773065, g_norm: 0.18548184482771582, lr:  0.000577, elapsed time:  91688
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 187600, loss: 0.009286821020064267, acc: 99.70739745620463, p_norm: 1971.8774768997096, g_norm: 0.17385387288988927, lr:  0.000577, elapsed time:  91737
Step 187700, loss: 0.009174131274412502, acc: 99.7140157520771, p_norm: 1972.0551294284967, g_norm: 0.22764683984495557, lr:  0.000577, elapsed time:  91785
Step 187800, loss: 0.009451663321660817, acc: 99.70733487606049, p_norm: 1972.2369248245845, g_norm: 0.11021425363049756, lr:  0.000577, elapsed time:  91834
Step 187900, loss: 0.009078374128512224, acc: 99.71901682019234, p_norm: 1972.420241344497, g_norm: 0.18604881364352308, lr:  0.000577, elapsed time:  91882
Step 188000, loss: 0.009103603226967606, acc: 99.7180263698101, p_norm: 1972.6131944945935, g_norm: 0.22160449565963225, lr:  0.000576, elapsed time:  91930
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 188000, eval loss: 0.017605656040868785, eval acc: 99.61042022705078
Step 188100, loss: 0.009195489497033122, acc: 99.71152825653553, p_norm: 1972.804293742679, g_norm: 0.2235536983513476, lr:  0.000576, elapsed time:  91985
Step 188200, loss: 0.008970572344478569, acc: 99.72298195958138, p_norm: 1972.9970037516864, g_norm: 0.5750014774321152, lr:  0.000576, elapsed time:  92033
Step 188300, loss: 0.00931950297138428, acc: 99.71068549156189, p_norm: 1973.1720030623055, g_norm: 0.20280236856938508, lr:  0.000576, elapsed time:  92081
Step 188400, loss: 0.00936585777446453, acc: 99.70562727749348, p_norm: 1973.3617173869172, g_norm: 0.1530288106417189, lr:  0.000576, elapsed time:  92129
Step 188500, loss: 0.009876764469590854, acc: 99.69029924273491, p_norm: 1973.5570798113436, g_norm: 0.244239496523532, lr:  0.000576, elapsed time:  92177
Step 188600, loss: 0.00966313390614232, acc: 99.69103421270847, p_norm: 1973.734196624591, g_norm: 0.20165118736040824, lr:  0.000575, elapsed time:  92226
Step 188700, loss: 0.010153284024927416, acc: 99.68098275363445, p_norm: 1973.9325170578293, g_norm: 0.15093651470573546, lr:  0.000575, elapsed time:  92273
Step 188800, loss: 0.009310745709044568, acc: 99.71647453308105, p_norm: 1974.1093578980297, g_norm: 0.17599086763307245, lr:  0.000575, elapsed time:  92321
Step 188900, loss: 0.009584196086252631, acc: 99.7019219994545, p_norm: 1974.2894623359014, g_norm: 0.19809060265554182, lr:  0.000575, elapsed time:  92370
Step 189000, loss: 0.009528652530134423, acc: 99.70532831549644, p_norm: 1974.4812127662603, g_norm: 0.22202425216121685, lr:  0.000575, elapsed time:  92418
Step 189100, loss: 0.009887299653346417, acc: 99.69272370636463, p_norm: 1974.6725955818683, g_norm: 0.14338705025089032, lr:  0.000575, elapsed time:  92465
Step 189200, loss: 0.009542845572250372, acc: 99.6988100707531, p_norm: 1974.8719070874172, g_norm: 0.28507528574675334, lr:  0.000575, elapsed time:  92514
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 189300, loss: 0.009139738257321681, acc: 99.71422968668027, p_norm: 1975.0354732325457, g_norm: 0.17360579009535787, lr:  0.000574, elapsed time:  92563
Step 189400, loss: 0.009159861709867982, acc: 99.71152819693089, p_norm: 1975.215503459393, g_norm: 0.16857254994435886, lr:  0.000574, elapsed time:  92611
Step 189500, loss: 0.009044874588726088, acc: 99.72201409935951, p_norm: 1975.4174634765138, g_norm: 0.20281612879073374, lr:  0.000574, elapsed time:  92660
Step 189600, loss: 0.009175894022646389, acc: 99.71422825753689, p_norm: 1975.5964644449018, g_norm: 0.18972246784270796, lr:  0.000574, elapsed time:  92709
Step 189700, loss: 0.009196841452103399, acc: 99.71411789953709, p_norm: 1975.769979027377, g_norm: 0.1877055466720697, lr:  0.000574, elapsed time:  92757
Step 189800, loss: 0.00955455176725991, acc: 99.70313446223736, p_norm: 1975.96472877191, g_norm: 0.20921207277773435, lr:  0.000574, elapsed time:  92805
Step 189900, loss: 0.009003410153854929, acc: 99.72137935459614, p_norm: 1976.1326796343185, g_norm: 0.1341133293283617, lr:  0.000574, elapsed time:  92854
Step 190000, loss: 0.00915145090468286, acc: 99.7093803435564, p_norm: 1976.3221130401475, g_norm: 0.1450508723727826, lr:  0.000573, elapsed time:  92902
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 190000, eval loss: 0.016336161311483004, eval acc: 99.62018585205078
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: Cl c 1 c c c ( - c 2 c c c ( C # C c 3 c c c 4 c ( c 3 ) C C N 4 C C N 3 C C C C 3 ) n c 2 ) c c 1 _EOS
Predicted text: Cl c 1 c c c ( - c 2 c c c ( C # C c 3 c c c 4 c ( c 3 ) C C N 4 C C N 3 C C C C 3 ) n c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C 1 ( c 2 c c c ( C ( F ) ( F ) F ) c c 2 C N ( C c 2 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 2 ) c 2 n n n ( C ) n 2 ) C C C ( C # N ) C C 1 _EOS
Predicted text: C O C 1 ( c 2 c c c ( C ( F ) ( F ) F ) c c 2 C N ( C c 2 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 2 ) c 2 n n n ( C ) n 2 ) C C C ( C # N ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 n c c c ( O c 2 c c c 3 c ( C ( = O ) N c 4 c c c c ( C ( F ) ( F ) F ) c 4 ) c n n 3 c 2 ) n 1 _EOS
Predicted text: N c 1 n c c c ( O c 2 c c c 3 c ( C ( = O ) N c 4 c c c c ( C ( F ) ( F ) F ) c 4 ) c n n 3 c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( F ) c c ( C ( = O ) N C 2 C C 2 ) c c 1 - c 1 n c ( N C ( C O ) C O ) n c 2 c 1 c c c ( = O ) n 2 - c 1 c ( F ) c c c c 1 F _EOS
Predicted text: C c 1 c ( F ) c c ( C ( = O ) N C 2 C C 2 ) c c 1 - c 1 n c ( N C ( C O ) C O ) n c 2 c 1 c c c ( = O ) n 2 - c 1 c ( F ) c c c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 C ( = O ) C ( c 2 c c ( F ) c c ( F ) c 2 F ) N ( c 2 c c c 3 [nH] c n c 3 c 2 ) C 1 = O _EOS
Predicted text: C C O C ( = O ) C 1 C ( = O ) C ( c 2 c c ( F ) c c ( F ) c 2 F ) N ( c 2 c c c 3 [nH] c n c 3 c 2 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 190000, eval acc (token): 0.9393964093515879, eval acc (sequence): 0.8906382258337565
Saving at step 190000
Step 190100, loss: 0.00920955417026562, acc: 99.71461454033852, p_norm: 1976.5002859548597, g_norm: 0.1789855546257445, lr:  0.000573, elapsed time:  93010
Step 190200, loss: 0.009241753917995083, acc: 99.71509139239788, p_norm: 1976.665961399244, g_norm: 0.17895637593181365, lr:  0.000573, elapsed time:  93058
Step 190300, loss: 0.009279862977709854, acc: 99.70755364000797, p_norm: 1976.8635909131642, g_norm: 0.15937474911725216, lr:  0.000573, elapsed time:  93106
Step 190400, loss: 0.00951433667964011, acc: 99.70053060352802, p_norm: 1977.0330723029954, g_norm: 0.16028573589498762, lr:  0.000573, elapsed time:  93153
Step 190500, loss: 0.009461581993746223, acc: 99.70590372383595, p_norm: 1977.2053584091752, g_norm: 0.14110984940167565, lr:  0.000573, elapsed time:  93201
Step 190600, loss: 0.00978696097026841, acc: 99.69491568207741, p_norm: 1977.3914675819713, g_norm: 0.22380430509869095, lr:  0.000572, elapsed time:  93249
Step 190700, loss: 0.009464162947479053, acc: 99.70602805912495, p_norm: 1977.583991671025, g_norm: 0.20826519627469745, lr:  0.000572, elapsed time:  93297
Step 190800, loss: 0.009432877793733497, acc: 99.70769916474819, p_norm: 1977.7810205848145, g_norm: 0.24989641863979192, lr:  0.000572, elapsed time:  93344
Step 190900, loss: 0.010081991426704916, acc: 99.68277528882027, p_norm: 1977.9705552526898, g_norm: 0.19846803207555652, lr:  0.000572, elapsed time:  93391
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 191000, loss: 0.009409559889035114, acc: 99.7052122556155, p_norm: 1978.145230740229, g_norm: 0.19880210498113837, lr:  0.000572, elapsed time:  93440
Step 191100, loss: 0.008962044023046473, acc: 99.71943233907223, p_norm: 1978.3268292447553, g_norm: 0.2383319005245547, lr:  0.000572, elapsed time:  93489
Step 191200, loss: 0.009024445046761684, acc: 99.71748854219913, p_norm: 1978.505876645652, g_norm: 0.19709834072259402, lr:  0.000572, elapsed time:  93537
Step 191300, loss: 0.008906000946481071, acc: 99.72639113664627, p_norm: 1978.6870959527967, g_norm: 0.13512435564950137, lr:  0.000571, elapsed time:  93585
Step 191400, loss: 0.009544500809970486, acc: 99.69952315092087, p_norm: 1978.8566587708704, g_norm: 0.17186281862720054, lr:  0.000571, elapsed time:  93633
Step 191500, loss: 0.009376744611581672, acc: 99.7082000374794, p_norm: 1979.0341315742642, g_norm: 0.14739204668197176, lr:  0.000571, elapsed time:  93680
Step 191600, loss: 0.009806162508903071, acc: 99.6901956051588, p_norm: 1979.215746387463, g_norm: 0.33015238186342805, lr:  0.000571, elapsed time:  93727
Step 191700, loss: 0.009324375114829309, acc: 99.70810094475746, p_norm: 1979.4152453779664, g_norm: 0.1655925788126552, lr:  0.000571, elapsed time:  93775
Step 191800, loss: 0.009325000884928158, acc: 99.70710450410843, p_norm: 1979.6009411028604, g_norm: 0.1945228124998821, lr:  0.000571, elapsed time:  93822
Step 191900, loss: 0.00908238332172914, acc: 99.70981986820698, p_norm: 1979.809450455296, g_norm: 0.16228939553974758, lr:  0.000571, elapsed time:  93870
Step 192000, loss: 0.009466660493781092, acc: 99.70243832468987, p_norm: 1979.9793587310414, g_norm: 0.20167364840674043, lr:  0.000570, elapsed time:  93917
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 192000, eval loss: 0.01821734539815225, eval acc: 99.58631896972656
Step 192100, loss: 0.009612230760394596, acc: 99.69983418285847, p_norm: 1980.1770034243193, g_norm: 0.12122245846104635, lr:  0.000570, elapsed time:  93972
Step 192200, loss: 0.009726684284814838, acc: 99.68830356001854, p_norm: 1980.3816581265628, g_norm: 0.18178432986070533, lr:  0.000570, elapsed time:  94019
Step 192300, loss: 0.008992619541113528, acc: 99.71894459426403, p_norm: 1980.5429256185334, g_norm: 0.30629054569486514, lr:  0.000570, elapsed time:  94067
Step 192400, loss: 0.009375236071573454, acc: 99.70874501764774, p_norm: 1980.7119089545936, g_norm: 0.2184059045026362, lr:  0.000570, elapsed time:  94115
Step 192500, loss: 0.009961282038202625, acc: 99.68879003822803, p_norm: 1980.9076232359084, g_norm: 0.21050768452339583, lr:  0.000570, elapsed time:  94163
Step 192600, loss: 0.009606463416748739, acc: 99.69450770318508, p_norm: 1981.0799396824423, g_norm: 0.1581772745451816, lr:  0.000569, elapsed time:  94211
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 192700, loss: 0.009120059432208467, acc: 99.71365225848866, p_norm: 1981.2541036164444, g_norm: 0.18031087721081387, lr:  0.000569, elapsed time:  94259
Step 192800, loss: 0.009392917322220456, acc: 99.70524793863297, p_norm: 1981.4392604498325, g_norm: 0.207055973252552, lr:  0.000569, elapsed time:  94307
Step 192900, loss: 0.008762908877288282, acc: 99.71813508868217, p_norm: 1981.615197488347, g_norm: 0.17179831465817755, lr:  0.000569, elapsed time:  94354
Step 193000, loss: 0.00878005498841958, acc: 99.72075344622135, p_norm: 1981.7837316311618, g_norm: 0.183120605848586, lr:  0.000569, elapsed time:  94402
Step 193100, loss: 0.008789211069233716, acc: 99.72480010986328, p_norm: 1981.9508942382677, g_norm: 0.2087799378303468, lr:  0.000569, elapsed time:  94450
Step 193200, loss: 0.009333361797616816, acc: 99.71032239496708, p_norm: 1982.1382558781718, g_norm: 0.159113733681056, lr:  0.000569, elapsed time:  94498
Step 193300, loss: 0.009710436767909414, acc: 99.691226541996, p_norm: 1982.3246057417223, g_norm: 0.19208392563158755, lr:  0.000568, elapsed time:  94545
Step 193400, loss: 0.009293293364244164, acc: 99.7045515626669, p_norm: 1982.4983893857338, g_norm: 0.17498424446308633, lr:  0.000568, elapsed time:  94593
Step 193500, loss: 0.0091128182074317, acc: 99.71323683857918, p_norm: 1982.6825565288996, g_norm: 0.1651868525986457, lr:  0.000568, elapsed time:  94640
Step 193600, loss: 0.009261943565215916, acc: 99.70697270333767, p_norm: 1982.846587434712, g_norm: 0.17447240331499453, lr:  0.000568, elapsed time:  94688
Step 193700, loss: 0.009297144435076916, acc: 99.71529541909695, p_norm: 1983.0337180677036, g_norm: 0.16206455296359476, lr:  0.000568, elapsed time:  94736
Step 193800, loss: 0.009600273140931677, acc: 99.69888326525688, p_norm: 1983.212649649193, g_norm: 0.17849470069568932, lr:  0.000568, elapsed time:  94783
Step 193900, loss: 0.00869698228483685, acc: 99.72307002544403, p_norm: 1983.385290538412, g_norm: 0.17291605101271593, lr:  0.000568, elapsed time:  94831
Step 194000, loss: 0.010063738344942976, acc: 99.6837585568428, p_norm: 1983.576170210527, g_norm: 0.26414751523699775, lr:  0.000567, elapsed time:  94879
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 194000, eval loss: 0.017446457863279644, eval acc: 99.61978149414062
Step 194100, loss: 0.009222366682442952, acc: 99.71334441006184, p_norm: 1983.7698989081273, g_norm: 0.12445962029382972, lr:  0.000567, elapsed time:  94934
Step 194200, loss: 0.009296635155269541, acc: 99.70985050499439, p_norm: 1983.9360156589896, g_norm: 0.18066642083842793, lr:  0.000567, elapsed time:  94982
Step 194300, loss: 0.009427283164623077, acc: 99.70844881236553, p_norm: 1984.1131483836984, g_norm: 0.15619647847045143, lr:  0.000567, elapsed time:  95029
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 194400, loss: 0.009386444552795758, acc: 99.70012639292437, p_norm: 1984.3052101842009, g_norm: 0.13382095386429355, lr:  0.000567, elapsed time:  95078
Step 194500, loss: 0.009501102532049117, acc: 99.7064820677042, p_norm: 1984.4740978983039, g_norm: 0.14540937660690392, lr:  0.000567, elapsed time:  95126
Step 194600, loss: 0.009222788188217236, acc: 99.71257489919662, p_norm: 1984.6640091673835, g_norm: 0.21075245945081234, lr:  0.000567, elapsed time:  95174
Step 194700, loss: 0.009522620166499109, acc: 99.69610011577606, p_norm: 1984.8460237406587, g_norm: 0.1947182377201774, lr:  0.000566, elapsed time:  95222
Step 194800, loss: 0.008541458518393483, acc: 99.73378068208694, p_norm: 1985.018441341993, g_norm: 0.19417972247524112, lr:  0.000566, elapsed time:  95270
Step 194900, loss: 0.009529258800339448, acc: 99.70294038951397, p_norm: 1985.1945011948083, g_norm: 0.21675137947907228, lr:  0.000566, elapsed time:  95318
Step 195000, loss: 0.008871628822180355, acc: 99.72397194802761, p_norm: 1985.3671463932335, g_norm: 0.22394368841651563, lr:  0.000566, elapsed time:  95366
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C n 1 c ( N 2 C C N ( C C C C C 3 ( C ( = O ) N C C ( F ) ( F ) F ) c 4 c c c c c 4 - c 4 c c c c c 4 3 ) C C 2 ) n c 2 c c ( Cl ) c c c 2 1 _EOS
Predicted text: C n 1 c ( N 2 C C N ( C C C C C 3 ( C ( = O ) N C C ( F ) ( F ) F ) c 4 c c c c c 4 - c 4 c c c c c 4 3 ) C C 2 ) n c 2 c c ( Cl ) c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C 1 C C C ( = N N c 2 c c c ( Br ) c c 2 ) C C 1 _EOS
Predicted text: C N ( C ) C 1 C C C ( = N N c 2 c c c ( Br ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C ) c ( N c 2 n c c c ( N c 3 c c ( - c 4 c c c c c 4 ) o n 3 ) n 2 ) c c 1 O C _EOS
Predicted text: C O c 1 c c ( C ) c ( N c 2 n c c c ( N c 3 c c ( - c 4 c c c c c 4 ) o n 3 ) n 2 ) c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C ( = O ) N O ) c ( O ) c 1 _EOS
Predicted text: C O c 1 c c c ( C ( = O ) N O ) c ( O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C N N C ( = O ) C ( C C ( C ) C ) C ( C C = C c 1 c c c c c 1 ) C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C C ( C ) C N N C ( = O ) C ( C C ( C ) C ) C ( C C = C c 1 c c c c c 1 ) C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 195000, eval acc (token): 0.9402985372982283, eval acc (sequence): 0.8900496660387053
Saving at step 195000
Step 195100, loss: 0.009079547397650458, acc: 99.71521157026291, p_norm: 1985.538995779326, g_norm: 0.18581922777631715, lr:  0.000566, elapsed time:  95469
Step 195200, loss: 0.009122293357177114, acc: 99.71621331572533, p_norm: 1985.7247930473204, g_norm: 0.19054448449955935, lr:  0.000566, elapsed time:  95517
Step 195300, loss: 0.009271830602156115, acc: 99.71340130269527, p_norm: 1985.900981981011, g_norm: 0.1821992463404853, lr:  0.000566, elapsed time:  95565
Step 195400, loss: 0.009370521246637509, acc: 99.70840236544609, p_norm: 1986.0827838267357, g_norm: 0.2117317564381256, lr:  0.000565, elapsed time:  95614
Step 195500, loss: 0.00879684756451752, acc: 99.72979389131069, p_norm: 1986.2383029947766, g_norm: 0.1690571641643621, lr:  0.000565, elapsed time:  95662
Step 195600, loss: 0.008786579268962669, acc: 99.72924818098545, p_norm: 1986.39913534831, g_norm: 0.14539906252281015, lr:  0.000565, elapsed time:  95710
Step 195700, loss: 0.00928270441294444, acc: 99.70809154212475, p_norm: 1986.5816369702172, g_norm: 0.17282962707590158, lr:  0.000565, elapsed time:  95758
Step 195800, loss: 0.008989514214990777, acc: 99.72340570390224, p_norm: 1986.739712382785, g_norm: 0.17987206100724773, lr:  0.000565, elapsed time:  95806
Step 195900, loss: 0.009638663347523106, acc: 99.69766825437546, p_norm: 1986.9241126498655, g_norm: 0.15832059068365292, lr:  0.000565, elapsed time:  95854
Step 196000, loss: 0.009616428420522426, acc: 99.70186296105385, p_norm: 1987.1048489921843, g_norm: 0.1681590004555607, lr:  0.000565, elapsed time:  95903
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 196000, eval loss: 0.01821778084407924, eval acc: 99.60430908203125
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 196100, loss: 0.009323501252426345, acc: 99.70511125391396, p_norm: 1987.2685248034586, g_norm: 0.14653642833891453, lr:  0.000564, elapsed time:  95958
Step 196200, loss: 0.009084337668755325, acc: 99.71896988153458, p_norm: 1987.4449169898833, g_norm: 0.142891852877267, lr:  0.000564, elapsed time:  96006
Step 196300, loss: 0.009357604387150786, acc: 99.70466350018978, p_norm: 1987.6154063237077, g_norm: 0.1465061938184479, lr:  0.000564, elapsed time:  96054
Step 196400, loss: 0.009280351549714396, acc: 99.71192206442356, p_norm: 1987.7931916057619, g_norm: 0.1607419908774269, lr:  0.000564, elapsed time:  96103
Step 196500, loss: 0.008697749301445583, acc: 99.72870114445686, p_norm: 1987.9918743390663, g_norm: 0.2679573090656368, lr:  0.000564, elapsed time:  96152
Step 196600, loss: 0.009314858231009566, acc: 99.71118992567062, p_norm: 1988.1725615617624, g_norm: 0.14747585346079245, lr:  0.000564, elapsed time:  96200
Step 196700, loss: 0.009538950278838457, acc: 99.70033344626427, p_norm: 1988.351757199552, g_norm: 0.1431725278202924, lr:  0.000564, elapsed time:  96248
Step 196800, loss: 0.00849112678720303, acc: 99.72899679839611, p_norm: 1988.5160454437041, g_norm: 0.21245829858229004, lr:  0.000563, elapsed time:  96297
Step 196900, loss: 0.009370745662290575, acc: 99.70624831318855, p_norm: 1988.6991619634582, g_norm: 0.2516380491693923, lr:  0.000563, elapsed time:  96344
Step 197000, loss: 0.00904894763854827, acc: 99.71686305105686, p_norm: 1988.8734099417395, g_norm: 0.21009090534235034, lr:  0.000563, elapsed time:  96392
Step 197100, loss: 0.009320989357329381, acc: 99.7011960297823, p_norm: 1989.0492635396774, g_norm: 0.25057146016348664, lr:  0.000563, elapsed time:  96440
Step 197200, loss: 0.00877923812586232, acc: 99.72110596299171, p_norm: 1989.2262309355237, g_norm: 0.23785603105548142, lr:  0.000563, elapsed time:  96488
Step 197300, loss: 0.00886804587498773, acc: 99.72089006006718, p_norm: 1989.398228497028, g_norm: 0.14029381824170695, lr:  0.000563, elapsed time:  96536
Step 197400, loss: 0.009723969778660831, acc: 99.69135271012783, p_norm: 1989.571054069518, g_norm: 0.16213757273381152, lr:  0.000563, elapsed time:  96583
Step 197500, loss: 0.008953222929249023, acc: 99.72223551571369, p_norm: 1989.7354760179528, g_norm: 0.12444830117888767, lr:  0.000562, elapsed time:  96631
Step 197600, loss: 0.00938533623647345, acc: 99.70497281849384, p_norm: 1989.909962905022, g_norm: 0.24124333290761374, lr:  0.000562, elapsed time:  96679
Step 197700, loss: 0.009154192426067312, acc: 99.71420578658581, p_norm: 1990.102146947816, g_norm: 0.19370622951271366, lr:  0.000562, elapsed time:  96726
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 197800, loss: 0.009320334707677902, acc: 99.71185329534279, p_norm: 1990.2836635995097, g_norm: 0.1988057933845415, lr:  0.000562, elapsed time:  96775
Step 197900, loss: 0.00907518043298296, acc: 99.71289996802807, p_norm: 1990.4518914606087, g_norm: 0.210813456686138, lr:  0.000562, elapsed time:  96822
Step 198000, loss: 0.008949865162612695, acc: 99.7155467569828, p_norm: 1990.6307146843747, g_norm: 0.13079440761220357, lr:  0.000562, elapsed time:  96870
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 198000, eval loss: 0.019097401062017526, eval acc: 99.59984588623047
Step 198100, loss: 0.008627332372889214, acc: 99.73055057227612, p_norm: 1990.7875685376669, g_norm: 0.2219472487596072, lr:  0.000562, elapsed time:  96924
Step 198200, loss: 0.009062009717235925, acc: 99.72217936813831, p_norm: 1990.970398650989, g_norm: 0.12092391694850922, lr:  0.000561, elapsed time:  96972
Step 198300, loss: 0.00916869078835589, acc: 99.71145096421242, p_norm: 1991.1444767886735, g_norm: 0.1290738471690669, lr:  0.000561, elapsed time:  97019
Step 198400, loss: 0.008935766786817113, acc: 99.71775825321674, p_norm: 1991.3128608703512, g_norm: 0.17388175410909887, lr:  0.000561, elapsed time:  97067
Step 198500, loss: 0.009093226003024028, acc: 99.72166237235069, p_norm: 1991.4851579341566, g_norm: 0.16389006511631385, lr:  0.000561, elapsed time:  97115
Step 198600, loss: 0.008799684401674312, acc: 99.72551806271076, p_norm: 1991.6597575590608, g_norm: 0.2872230096782941, lr:  0.000561, elapsed time:  97162
Step 198700, loss: 0.009172605700205167, acc: 99.71787841618061, p_norm: 1991.827745506918, g_norm: 0.20690964564676195, lr:  0.000561, elapsed time:  97209
Step 198800, loss: 0.008843506909634015, acc: 99.72179648280144, p_norm: 1992.0046169011587, g_norm: 0.26772553638117425, lr:  0.000561, elapsed time:  97257
Step 198900, loss: 0.008922106173704378, acc: 99.71855676174164, p_norm: 1992.1796885889948, g_norm: 0.19036001913777184, lr:  0.000560, elapsed time:  97304
Step 199000, loss: 0.00865412184766683, acc: 99.7348320633173, p_norm: 1992.3532098593316, g_norm: 0.23026759612438238, lr:  0.000560, elapsed time:  97352
Step 199100, loss: 0.009939866068871197, acc: 99.68858388066292, p_norm: 1992.5461942591223, g_norm: 0.2583568943838373, lr:  0.000560, elapsed time:  97399
Step 199200, loss: 0.009297692512081995, acc: 99.71601176261902, p_norm: 1992.7247035853645, g_norm: 0.14988233612078958, lr:  0.000560, elapsed time:  97447
Step 199300, loss: 0.00917719166038296, acc: 99.71025262773037, p_norm: 1992.8856658413536, g_norm: 0.18918810660603821, lr:  0.000560, elapsed time:  97495
Step 199400, loss: 0.00943606245025876, acc: 99.699746504426, p_norm: 1993.0612498040905, g_norm: 0.4673391503812269, lr:  0.000560, elapsed time:  97542
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 199500, loss: 0.00940181554168958, acc: 99.70424077646904, p_norm: 1993.2324201919225, g_norm: 0.233711060484079, lr:  0.000560, elapsed time:  97591
Step 199600, loss: 0.0087505397579298, acc: 99.72461692988873, p_norm: 1993.4136517286993, g_norm: 0.13682136985870122, lr:  0.000559, elapsed time:  97638
Step 199700, loss: 0.008599649135558139, acc: 99.72925260663033, p_norm: 1993.5860972954172, g_norm: 0.1602640152094322, lr:  0.000559, elapsed time:  97686
Step 199800, loss: 0.008939220210450002, acc: 99.7173602283001, p_norm: 1993.7489473279377, g_norm: 0.1927854859692049, lr:  0.000559, elapsed time:  97733
Step 199900, loss: 0.008954552397954103, acc: 99.72526821494102, p_norm: 1993.9206210955163, g_norm: 0.1912050658654036, lr:  0.000559, elapsed time:  97780
Step 200000, loss: 0.0085186725022686, acc: 99.72770822048187, p_norm: 1994.0874112126219, g_norm: 0.19566723662653682, lr:  0.000559, elapsed time:  97828
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 200000, eval loss: 0.020323832785361446, eval acc: 99.55421447753906
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) ( O ) C C 1 ( c 2 c c c c c 2 ) C C N ( C 2 C C N ( c 3 c c c ( C ( F ) ( F ) F ) c n 3 ) C 2 ) C ( = O ) O 1 _EOS
Predicted text: C C ( C ) ( O ) C C 1 ( c 2 c c c c c 2 ) C C N ( C 2 C C N ( c 3 c c c ( C ( F ) ( F ) F ) c n 3 ) C 2 ) C ( = O ) O 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c 2 c ( c 1 ) N ( C C O ) C ( C ) ( C ) C = C 2 C _EOS
Predicted text: C O c 1 c c c 2 c ( c 1 ) N ( C C O ) C ( C ) ( C ) C = C 2 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C C C C C c 1 c [nH] c ( C ( = O ) N ( N ) S ( = O ) ( = O ) c 2 c c c ( C ) c c 2 ) c 1 _EOS
Predicted text: C C C C C C C C C C C C c 1 c [nH] c ( C ( = O ) N N S ( = O ) ( = O ) c 2 c c c ( C ) c c 2 ) c 1 _EOS _PAD _PAD
acc_token: 0.5098039215686274, acc_seq: False

Target text: O = C ( O ) C C c 1 c c ( - c 2 c c c ( O C ( F ) ( F ) F ) c c 2 ) c c c 1 O C c 1 c c c c c 1 _EOS
Predicted text: O = C ( O ) C C c 1 c c ( - c 2 c c c ( O C ( F ) ( F ) F ) c c 2 ) c c c 1 O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) C ( = C c 1 c c c ( Cl ) c ( F ) c 1 ) C ( N ) = O _EOS
Predicted text: C C ( = O ) C ( = C c 1 c c c ( Cl ) c ( F ) c 1 ) C ( N ) = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 200000, eval acc (token): 0.9399012555246598, eval acc (sequence): 0.8891957197100449
Saving at step 200000
Step 200100, loss: 0.008855313034582651, acc: 99.72446449100971, p_norm: 1994.244632229029, g_norm: 0.190851152531337, lr:  0.000559, elapsed time:  97957
Step 200200, loss: 0.008829893021811586, acc: 99.72166885435581, p_norm: 1994.4278322186567, g_norm: 0.21493618410113868, lr:  0.000559, elapsed time:  98008
Step 200300, loss: 0.009407086303808683, acc: 99.70087139308453, p_norm: 1994.6149475866412, g_norm: 0.28493251292285116, lr:  0.000558, elapsed time:  98056
Step 200400, loss: 0.009482722227371596, acc: 99.70331574976444, p_norm: 1994.7939274699902, g_norm: 0.2545264468656419, lr:  0.000558, elapsed time:  98104
Step 200500, loss: 0.009115744022310537, acc: 99.7144055813551, p_norm: 1994.9591847289714, g_norm: 0.21319016403981964, lr:  0.000558, elapsed time:  98151
Step 200600, loss: 0.008757505599205614, acc: 99.72301590442657, p_norm: 1995.1310867497953, g_norm: 0.20598524027150514, lr:  0.000558, elapsed time:  98199
Step 200700, loss: 0.009395697199761344, acc: 99.69841282069683, p_norm: 1995.3223032328706, g_norm: 0.22923523696471376, lr:  0.000558, elapsed time:  98247
Step 200800, loss: 0.008592553759208386, acc: 99.73248602449894, p_norm: 1995.4880347101348, g_norm: 0.14177868571406652, lr:  0.000558, elapsed time:  98294
Step 200900, loss: 0.009037632404324541, acc: 99.71826957166195, p_norm: 1995.6551355672075, g_norm: 0.16055827809285986, lr:  0.000558, elapsed time:  98342
Step 201000, loss: 0.009756592695739528, acc: 99.69146747887135, p_norm: 1995.825183813768, g_norm: 0.18819946143291044, lr:  0.000557, elapsed time:  98389
Step 201100, loss: 0.009704474413883873, acc: 99.690892547369, p_norm: 1996.0081707301742, g_norm: 0.18404484310746946, lr:  0.000557, elapsed time:  98436
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 201200, loss: 0.009065593303011953, acc: 99.71441139950055, p_norm: 1996.1879208061694, g_norm: 0.1317889091360788, lr:  0.000557, elapsed time:  98485
Step 201300, loss: 0.008581404092037701, acc: 99.73168784379959, p_norm: 1996.3574158820775, g_norm: 0.1386891126273837, lr:  0.000557, elapsed time:  98532
Step 201400, loss: 0.008663690963530826, acc: 99.73026353120804, p_norm: 1996.5309925917254, g_norm: 0.17262939220888546, lr:  0.000557, elapsed time:  98580
Step 201500, loss: 0.008523955680502696, acc: 99.73356375098228, p_norm: 1996.703627203981, g_norm: 0.1577892809323565, lr:  0.000557, elapsed time:  98627
Step 201600, loss: 0.009369608765700832, acc: 99.71464022994041, p_norm: 1996.8861145685394, g_norm: 0.13411583851232295, lr:  0.000557, elapsed time:  98674
Step 201700, loss: 0.009241545431414123, acc: 99.7065628618002, p_norm: 1997.056276355697, g_norm: 0.21706641774578422, lr:  0.000556, elapsed time:  98722
Step 201800, loss: 0.00901823561944184, acc: 99.72041057050228, p_norm: 1997.2222052858313, g_norm: 0.2144369051828199, lr:  0.000556, elapsed time:  98769
Step 201900, loss: 0.008811219112940307, acc: 99.72340980172157, p_norm: 1997.3873417046145, g_norm: 0.1784659307080314, lr:  0.000556, elapsed time:  98816
Step 202000, loss: 0.00893533529596425, acc: 99.72218284010887, p_norm: 1997.5586683279894, g_norm: 0.1691569617889022, lr:  0.000556, elapsed time:  98864
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 202000, eval loss: 0.021184022898814867, eval acc: 99.5628433227539
Step 202100, loss: 0.0087244129181272, acc: 99.72711032629013, p_norm: 1997.7142667306907, g_norm: 0.1750822443587078, lr:  0.000556, elapsed time:  98918
Step 202200, loss: 0.008842675883533957, acc: 99.72223448753357, p_norm: 1997.8884664426614, g_norm: 0.16609732391952864, lr:  0.000556, elapsed time:  98966
Step 202300, loss: 0.008786251873234506, acc: 99.72380267083645, p_norm: 1998.0513060887351, g_norm: 0.14690960860663266, lr:  0.000556, elapsed time:  99013
Step 202400, loss: 0.008555202707630088, acc: 99.73297856748104, p_norm: 1998.2082707865327, g_norm: 0.16686338703740097, lr:  0.000556, elapsed time:  99070
Step 202500, loss: 0.009733491078477527, acc: 99.69001591205597, p_norm: 1998.3878204978275, g_norm: 0.1440594091113757, lr:  0.000555, elapsed time:  99124
Step 202600, loss: 0.00871379604905087, acc: 99.72829326987267, p_norm: 1998.5419206398526, g_norm: 0.1855905544505066, lr:  0.000555, elapsed time:  99178
Step 202700, loss: 0.009372483954784912, acc: 99.70192404091358, p_norm: 1998.7024673805747, g_norm: 0.22502586258818993, lr:  0.000555, elapsed time:  99225
Step 202800, loss: 0.008972843694755284, acc: 99.71681588888168, p_norm: 1998.8716281509633, g_norm: 0.156995622654984, lr:  0.000555, elapsed time:  99273
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 202900, loss: 0.009138983308653799, acc: 99.70926973719159, p_norm: 1999.0529570032281, g_norm: 0.13368756661658318, lr:  0.000555, elapsed time:  99321
Step 203000, loss: 0.008313334940175991, acc: 99.73987470567226, p_norm: 1999.2080722538224, g_norm: 0.15454631404103572, lr:  0.000555, elapsed time:  99369
Step 203100, loss: 0.008504491382955165, acc: 99.73432871699333, p_norm: 1999.380421169397, g_norm: 0.1457757990584359, lr:  0.000555, elapsed time:  99417
Step 203200, loss: 0.008762820006722905, acc: 99.72533351182938, p_norm: 1999.5355624034235, g_norm: 0.17556809106119625, lr:  0.000554, elapsed time:  99464
Step 203300, loss: 0.008929894837283427, acc: 99.71858136355877, p_norm: 1999.7086161607967, g_norm: 0.14874719035557474, lr:  0.000554, elapsed time:  99511
Step 203400, loss: 0.009229549205956573, acc: 99.7106556147337, p_norm: 1999.8860861718376, g_norm: 0.15296202196090694, lr:  0.000554, elapsed time:  99559
Step 203500, loss: 0.009045884958104579, acc: 99.7162767201662, p_norm: 2000.0740240148198, g_norm: 0.20528755721590597, lr:  0.000554, elapsed time:  99606
Step 203600, loss: 0.009163436565613666, acc: 99.71144326031208, p_norm: 2000.2634884691342, g_norm: 0.16496374428073507, lr:  0.000554, elapsed time:  99654
Step 203700, loss: 0.008735059847240337, acc: 99.7267682403326, p_norm: 2000.4236712881147, g_norm: 0.13954858398399486, lr:  0.000554, elapsed time:  99701
Step 203800, loss: 0.008882755983431707, acc: 99.71807239949703, p_norm: 2000.5845496895838, g_norm: 0.12518974623204657, lr:  0.000554, elapsed time:  99749
Step 203900, loss: 0.00888005621782213, acc: 99.72178694605827, p_norm: 2000.7699323543725, g_norm: 0.1238879138287101, lr:  0.000553, elapsed time:  99796
Step 204000, loss: 0.009163175395206053, acc: 99.71070285141468, p_norm: 2000.9426022166301, g_norm: 0.14859521786040658, lr:  0.000553, elapsed time:  99843
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 204000, eval loss: 0.018778392142448867, eval acc: 99.62671661376953
Step 204100, loss: 0.009009776554994459, acc: 99.71412694454193, p_norm: 2001.1161337711426, g_norm: 0.22533454629651473, lr:  0.000553, elapsed time:  99898
Step 204200, loss: 0.00895926532926751, acc: 99.71580596268177, p_norm: 2001.289564221872, g_norm: 0.17216294643138894, lr:  0.000553, elapsed time:  99945
Step 204300, loss: 0.008996055183015415, acc: 99.72209879755974, p_norm: 2001.4559865512306, g_norm: 0.21491839448593947, lr:  0.000553, elapsed time:  99993
Step 204400, loss: 0.008577312531415374, acc: 99.73173017799854, p_norm: 2001.6243058883995, g_norm: 0.23325411493232434, lr:  0.000553, elapsed time:  100041
Step 204500, loss: 0.00949613697532186, acc: 99.6976777613163, p_norm: 2001.8025208635672, g_norm: 0.23518401509270112, lr:  0.000553, elapsed time:  100088
Step 204600, loss: 0.009440920320830628, acc: 99.70068500936031, p_norm: 2001.9889966297983, g_norm: 0.20685477698830648, lr:  0.000553, elapsed time:  100136
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 204700, loss: 0.00823317393780066, acc: 99.7427028402797, p_norm: 2002.1496762448687, g_norm: 0.1427934236200607, lr:  0.000552, elapsed time:  100185
Step 204800, loss: 0.0086478467060806, acc: 99.71979033946991, p_norm: 2002.327523027133, g_norm: 0.2814045502178349, lr:  0.000552, elapsed time:  100232
Step 204900, loss: 0.008437401471128396, acc: 99.73210270702839, p_norm: 2002.4888360855293, g_norm: 0.2399906221374297, lr:  0.000552, elapsed time:  100280
Step 205000, loss: 0.008515772987138917, acc: 99.7307730615139, p_norm: 2002.650266951924, g_norm: 0.1501766259180149, lr:  0.000552, elapsed time:  100327
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C 1 C N N ( C ( = O ) C c 2 c c c ( F ) c c 2 ) C 1 _EOS
Predicted text: O = C 1 C N N ( C ( = O ) C c 2 c c c ( F ) c c 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C N 2 C C ( C ) ( C ( = O ) O ) O c 3 c c c ( O C ( F ) ( F ) F ) c c 3 2 ) c c 1 _EOS
Predicted text: C O c 1 c c c ( C N 2 C C ( C ) ( C ( = O ) O ) O c 3 c c c ( O C ( F ) ( F ) F ) c c 3 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C c 1 c c c c c 1 N c 1 c c c ( Cl ) c c 1 [N+] ( = O ) [O-] _EOS
Predicted text: N # C c 1 c c c c c 1 N c 1 c c c ( Cl ) c c 1 [N+] ( = O ) [O-] _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C C C C C C C C C C C O c 1 c c c ( - c 2 c c c ( C ( = O ) O ) c c 2 ) c c 1 _EOS
Predicted text: C C C C C C C C C C C C C C C C C C O c 1 c c c ( - c 2 c c c ( C ( = O ) O ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( O ) C ( N C ( = O ) O C C 1 c 2 c c c c c 2 - c 2 c c c c c 2 1 ) C ( = O ) C = [N+] = [N-] _EOS
Predicted text: C C ( O ) C ( N C ( = O ) O C C 1 c 2 c c c c c 2 - c 2 c c c c c 2 1 ) C ( = O ) C = [N+] = [N-] _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 205000, eval acc (token): 0.9417278903768538, eval acc (sequence): 0.8951965065502183
Saving at step 205000
Step 205100, loss: 0.009297455232863286, acc: 99.70637236535549, p_norm: 2002.8061342305734, g_norm: 0.15741906540792427, lr:  0.000552, elapsed time:  100440
Step 205200, loss: 0.008962947552900004, acc: 99.71745789051056, p_norm: 2002.9829349560343, g_norm: 0.13787580829856957, lr:  0.000552, elapsed time:  100489
Step 205300, loss: 0.008680604486944504, acc: 99.72573839128017, p_norm: 2003.1492908650505, g_norm: 0.18008416911119882, lr:  0.000552, elapsed time:  100537
Step 205400, loss: 0.00872736472345423, acc: 99.72507815063, p_norm: 2003.3048335796118, g_norm: 0.18445218414106276, lr:  0.000551, elapsed time:  100584
Step 205500, loss: 0.008902851499296958, acc: 99.72045117616653, p_norm: 2003.4614652482237, g_norm: 0.16085321388724444, lr:  0.000551, elapsed time:  100631
Step 205600, loss: 0.009160294413813972, acc: 99.71222814917564, p_norm: 2003.6386578163188, g_norm: 0.21810841790374177, lr:  0.000551, elapsed time:  100678
Step 205700, loss: 0.009101957710863645, acc: 99.71121023595333, p_norm: 2003.8163196855267, g_norm: 0.28933848459095907, lr:  0.000551, elapsed time:  100726
Step 205800, loss: 0.008651141280115553, acc: 99.7300665974617, p_norm: 2003.966059670885, g_norm: 0.14218947940513385, lr:  0.000551, elapsed time:  100773
Step 205900, loss: 0.00899164949223632, acc: 99.7127323448658, p_norm: 2004.1323147863782, g_norm: 0.1860896550063343, lr:  0.000551, elapsed time:  100820
Step 206000, loss: 0.008880968472294627, acc: 99.71676969528198, p_norm: 2004.3045391003025, g_norm: 0.22230448484480733, lr:  0.000551, elapsed time:  100868
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 206000, eval loss: 0.017838517912950918, eval acc: 99.62796783447266
Step 206100, loss: 0.009333226952494443, acc: 99.70920285582542, p_norm: 2004.4767293611487, g_norm: 0.36903499317033245, lr:  0.000551, elapsed time:  100922
Step 206200, loss: 0.009092357754452678, acc: 99.71594633162022, p_norm: 2004.6409696149592, g_norm: 0.1751020426454831, lr:  0.000550, elapsed time:  100970
Step 206300, loss: 0.009367390164998142, acc: 99.70541690289974, p_norm: 2004.8132773632738, g_norm: 0.16375327095344336, lr:  0.000550, elapsed time:  101018
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 206400, loss: 0.008759369896338217, acc: 99.72376176966957, p_norm: 2004.983734918542, g_norm: 0.19976635083243105, lr:  0.000550, elapsed time:  101066
Step 206500, loss: 0.008839206593729615, acc: 99.7241035848856, p_norm: 2005.1518373760027, g_norm: 0.17913683802905173, lr:  0.000550, elapsed time:  101114
Step 206600, loss: 0.008654315446474357, acc: 99.72592908143997, p_norm: 2005.322186641095, g_norm: 0.15797592480066222, lr:  0.000550, elapsed time:  101162
Step 206700, loss: 0.009041494096636597, acc: 99.71746045351028, p_norm: 2005.482140792932, g_norm: 0.12588738112432118, lr:  0.000550, elapsed time:  101209
Step 206800, loss: 0.008499506969237701, acc: 99.73906108736992, p_norm: 2005.6354654427096, g_norm: 0.19989447407729968, lr:  0.000550, elapsed time:  101256
Step 206900, loss: 0.008677386697854672, acc: 99.72681538760662, p_norm: 2005.802944098467, g_norm: 0.1616639069813018, lr:  0.000549, elapsed time:  101304
Step 207000, loss: 0.008438821412019024, acc: 99.73346230387688, p_norm: 2005.9628121695605, g_norm: 0.1751012746435115, lr:  0.000549, elapsed time:  101351
Step 207100, loss: 0.00877712715024245, acc: 99.7223393023014, p_norm: 2006.127870944027, g_norm: 0.1943968105941409, lr:  0.000549, elapsed time:  101398
Step 207200, loss: 0.008491374864988757, acc: 99.73324067890644, p_norm: 2006.2832827932355, g_norm: 0.1700953307829066, lr:  0.000549, elapsed time:  101446
Step 207300, loss: 0.00870080538403272, acc: 99.72583419084549, p_norm: 2006.4456569111069, g_norm: 0.1870296527870781, lr:  0.000549, elapsed time:  101494
Step 207400, loss: 0.009129032739110698, acc: 99.71110777556896, p_norm: 2006.6155085078074, g_norm: 0.16383317223158841, lr:  0.000549, elapsed time:  101541
Step 207500, loss: 0.009122576424815634, acc: 99.70795464515686, p_norm: 2006.7807231516078, g_norm: 0.2025173624793292, lr:  0.000549, elapsed time:  101589
Step 207600, loss: 0.008926965630198538, acc: 99.71841961145401, p_norm: 2006.9339430906534, g_norm: 0.13457111281849857, lr:  0.000549, elapsed time:  101636
Step 207700, loss: 0.008615979876631173, acc: 99.72972854971886, p_norm: 2007.0990459586078, g_norm: 0.31592792867436165, lr:  0.000548, elapsed time:  101683
Step 207800, loss: 0.008902135707776324, acc: 99.71113239228725, p_norm: 2007.279697131971, g_norm: 0.19238456785072933, lr:  0.000548, elapsed time:  101731
Step 207900, loss: 0.009256188284780364, acc: 99.71089470386505, p_norm: 2007.435465893559, g_norm: 0.20540236932863393, lr:  0.000548, elapsed time:  101778
Step 208000, loss: 0.009554275887057883, acc: 99.69849695265293, p_norm: 2007.605834940859, g_norm: 0.18162238902015196, lr:  0.000548, elapsed time:  101826
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 208000, eval loss: 0.017995106714806756, eval acc: 99.60844421386719
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 208100, loss: 0.008981635803919344, acc: 99.71286586437273, p_norm: 2007.799108615072, g_norm: 0.15053211558177715, lr:  0.000548, elapsed time:  101881
Step 208200, loss: 0.008994898362143431, acc: 99.71486705541611, p_norm: 2007.9622639502206, g_norm: 0.18169250035185955, lr:  0.000548, elapsed time:  101927
Step 208300, loss: 0.00892968466813727, acc: 99.71949398517609, p_norm: 2008.1288582138902, g_norm: 0.1431434985237301, lr:  0.000548, elapsed time:  101975
Step 208400, loss: 0.00898512234693044, acc: 99.72021166980267, p_norm: 2008.302521137738, g_norm: 0.2542157512431488, lr:  0.000547, elapsed time:  102022
Step 208500, loss: 0.008743811422646105, acc: 99.72686478495598, p_norm: 2008.4627264839492, g_norm: 0.14955561868664277, lr:  0.000547, elapsed time:  102069
Step 208600, loss: 0.008531025922893605, acc: 99.72805282473564, p_norm: 2008.6050805759485, g_norm: 0.1868244896752555, lr:  0.000547, elapsed time:  102117
Step 208700, loss: 0.00833213805935884, acc: 99.73678523302078, p_norm: 2008.7677315670853, g_norm: 0.16026997395226056, lr:  0.000547, elapsed time:  102165
Step 208800, loss: 0.008232950719502696, acc: 99.73745755851269, p_norm: 2008.916302949936, g_norm: 0.16813810551029185, lr:  0.000547, elapsed time:  102212
Step 208900, loss: 0.008639103694804362, acc: 99.73587045073509, p_norm: 2009.0672049014975, g_norm: 0.23191011072119014, lr:  0.000547, elapsed time:  102260
Step 209000, loss: 0.008930542406069435, acc: 99.71792632341385, p_norm: 2009.2592423536762, g_norm: 0.2615889822268122, lr:  0.000547, elapsed time:  102307
Step 209100, loss: 0.008804436270529549, acc: 99.72459284961224, p_norm: 2009.4272585611068, g_norm: 0.18437694509054084, lr:  0.000547, elapsed time:  102355
Step 209200, loss: 0.008868063032314239, acc: 99.72657006978989, p_norm: 2009.59681105227, g_norm: 0.17266510569252483, lr:  0.000546, elapsed time:  102402
Step 209300, loss: 0.008903710982012853, acc: 99.72212915122509, p_norm: 2009.767006712674, g_norm: 0.15055293354496135, lr:  0.000546, elapsed time:  102450
Step 209400, loss: 0.008482735251454869, acc: 99.73037669062614, p_norm: 2009.9222766434477, g_norm: 0.14254025108136295, lr:  0.000546, elapsed time:  102497
Step 209500, loss: 0.009227262841486663, acc: 99.7119000852108, p_norm: 2010.0884256222942, g_norm: 0.1717199007171995, lr:  0.000546, elapsed time:  102545
Step 209600, loss: 0.009188991077098762, acc: 99.71369355916977, p_norm: 2010.259255523079, g_norm: 0.20323738073413636, lr:  0.000546, elapsed time:  102593
Step 209700, loss: 0.008961283524076862, acc: 99.72433008253574, p_norm: 2010.4234295642646, g_norm: 0.21050326514593123, lr:  0.000546, elapsed time:  102640
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 209800, loss: 0.008593848581819722, acc: 99.72891210030681, p_norm: 2010.579033396058, g_norm: 0.2065222308357254, lr:  0.000546, elapsed time:  102689
Step 209900, loss: 0.008764920208632248, acc: 99.71769642829895, p_norm: 2010.7513797179922, g_norm: 0.11690318427776586, lr:  0.000546, elapsed time:  102736
Step 210000, loss: 0.008431039354709355, acc: 99.72514094412327, p_norm: 2010.9068933496915, g_norm: 0.20111783338768563, lr:  0.000545, elapsed time:  102783
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 210000, eval loss: 0.01803244264530804, eval acc: 99.61260223388672
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C N ( c 1 c c c ( [N+] ( = O ) [O-] ) c c 1 [N+] ( = O ) [O-] ) S ( = O ) ( = O ) c 1 c c c c c 1 _EOS
Predicted text: C N ( c 1 c c c ( [N+] ( = O ) [O-] ) c c 1 [N+] ( = O ) [O-] ) S ( = O ) ( = O ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) c 1 n n c ( - c 2 c c n c c 2 ) n 1 C 1 C C 1 _EOS
Predicted text: C S ( = O ) ( = O ) c 1 n n c ( - c 2 c c n c c 2 ) n 1 C 1 C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C 1 C C C ( N C ( = O ) C ( C C S C ) N C ( = O ) O C c 2 c c c c c 2 ) C ( C N C ( = O ) O C ( C ) ( C ) C ) C 1 _EOS
Predicted text: C O C 1 C C C ( N C ( = O ) C ( C C S C ) N C ( = O ) O C c 2 c c c c c 2 ) C ( C N C ( = O ) O C ( C ) ( C ) C ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C 1 ( c 2 c c c c c 2 ) C C C ( C N C ( = O ) N 2 C C C ( c 3 c [nH] c 4 c c c ( F ) c c 3 4 ) C C 2 ) C C 1 _EOS
Predicted text: C N ( C ) C 1 ( c 2 c c c c c 2 ) C C C ( C N C ( = O ) N 2 C C C ( c 3 c [nH] c 4 c c c ( F ) c c 3 4 ) C C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( O C C = O ) c c 1 C _EOS
Predicted text: C c 1 c c c ( O C C = O ) c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 210000, eval acc (token): 0.9396072497833384, eval acc (sequence): 0.8916247304097772
Saving at step 210000
Step 210100, loss: 0.008691793220550607, acc: 99.72818121314049, p_norm: 2011.0702418570816, g_norm: 0.1824799627875946, lr:  0.000545, elapsed time:  102895
Step 210200, loss: 0.008598050516648073, acc: 99.73004262149334, p_norm: 2011.233771591113, g_norm: 0.12005808997364031, lr:  0.000545, elapsed time:  102942
Step 210300, loss: 0.008371540715361335, acc: 99.73866556584835, p_norm: 2011.395137172831, g_norm: 0.20641990838830282, lr:  0.000545, elapsed time:  102990
Step 210400, loss: 0.00838948073195752, acc: 99.73747099936008, p_norm: 2011.5583121074474, g_norm: 0.1997759941695198, lr:  0.000545, elapsed time:  103038
Step 210500, loss: 0.008980042878174572, acc: 99.71816822886467, p_norm: 2011.736037970941, g_norm: 0.14609771913215702, lr:  0.000545, elapsed time:  103085
Step 210600, loss: 0.008158847107142719, acc: 99.74441565573215, p_norm: 2011.8851261991288, g_norm: 0.2587852276032633, lr:  0.000545, elapsed time:  103132
Step 210700, loss: 0.008885560286144028, acc: 99.72051775455475, p_norm: 2012.0600603894156, g_norm: 0.197428735952035, lr:  0.000544, elapsed time:  103181
Step 210800, loss: 0.008604162894916953, acc: 99.73057951033115, p_norm: 2012.2240680628397, g_norm: 0.13428718788995628, lr:  0.000544, elapsed time:  103229
Step 210900, loss: 0.009104617025104744, acc: 99.71477815508842, p_norm: 2012.3900361154617, g_norm: 0.250732975443284, lr:  0.000544, elapsed time:  103276
Step 211000, loss: 0.008603559813909669, acc: 99.72898060083389, p_norm: 2012.544141164751, g_norm: 0.1521856146481024, lr:  0.000544, elapsed time:  103323
Step 211100, loss: 0.008480717334514339, acc: 99.73982593417168, p_norm: 2012.719187649543, g_norm: 0.18158610672173295, lr:  0.000544, elapsed time:  103371
Step 211200, loss: 0.00913868705441928, acc: 99.70750665664673, p_norm: 2012.8804549657814, g_norm: 0.191456580354501, lr:  0.000544, elapsed time:  103419
Step 211300, loss: 0.008856029667476832, acc: 99.71995183825493, p_norm: 2013.046082345421, g_norm: 0.146147748974287, lr:  0.000544, elapsed time:  103466
Step 211400, loss: 0.00872502948888723, acc: 99.73102681338787, p_norm: 2013.196999598446, g_norm: 0.19474798895994883, lr:  0.000544, elapsed time:  103513
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 211500, loss: 0.008584991023210212, acc: 99.72897253320471, p_norm: 2013.3720707938285, g_norm: 0.20486219647983325, lr:  0.000543, elapsed time:  103562
Step 211600, loss: 0.00860539176108432, acc: 99.72839568555355, p_norm: 2013.532347502012, g_norm: 0.2080017379086257, lr:  0.000543, elapsed time:  103609
Step 211700, loss: 0.008152955945060967, acc: 99.74851167201996, p_norm: 2013.6821914698432, g_norm: 0.150957704716315, lr:  0.000543, elapsed time:  103657
Step 211800, loss: 0.008284100062205653, acc: 99.74383722245693, p_norm: 2013.8377224003889, g_norm: 0.2529853929198837, lr:  0.000543, elapsed time:  103705
Step 211900, loss: 0.008344125143248676, acc: 99.73721240460873, p_norm: 2013.98063063149, g_norm: 0.20100373733989638, lr:  0.000543, elapsed time:  103752
Step 212000, loss: 0.008620889536650793, acc: 99.7263595610857, p_norm: 2014.1392764546663, g_norm: 0.15299887044202143, lr:  0.000543, elapsed time:  103800
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 212000, eval loss: 0.017164057428635717, eval acc: 99.61199188232422
Step 212100, loss: 0.008753438046169322, acc: 99.71948367357254, p_norm: 2014.3238590639098, g_norm: 0.15846374012571066, lr:  0.000543, elapsed time:  103854
Step 212200, loss: 0.009241722111764829, acc: 99.7102161347866, p_norm: 2014.5031209805907, g_norm: 0.17889003487671393, lr:  0.000543, elapsed time:  103901
Step 212300, loss: 0.00870210775884516, acc: 99.72286339104176, p_norm: 2014.6587853349938, g_norm: 0.139950332820744, lr:  0.000542, elapsed time:  103949
Step 212400, loss: 0.008651505983866627, acc: 99.72591182589531, p_norm: 2014.8217642164304, g_norm: 0.44285674241308365, lr:  0.000542, elapsed time:  104004
Step 212500, loss: 0.008920525594112405, acc: 99.71857964992523, p_norm: 2014.9903457229188, g_norm: 0.19268460369307178, lr:  0.000542, elapsed time:  104051
Step 212600, loss: 0.008755133073918842, acc: 99.72350898385048, p_norm: 2015.1584448716508, g_norm: 0.1048569533917021, lr:  0.000542, elapsed time:  104098
Step 212700, loss: 0.008899105827731546, acc: 99.7218065559864, p_norm: 2015.329881838211, g_norm: 0.2019924004971317, lr:  0.000542, elapsed time:  104145
Step 212800, loss: 0.008401421174130518, acc: 99.73527257144451, p_norm: 2015.4971825893613, g_norm: 0.23519906629923337, lr:  0.000542, elapsed time:  104191
Step 212900, loss: 0.008793565347004914, acc: 99.7220303863287, p_norm: 2015.6498920125598, g_norm: 0.15394680283949036, lr:  0.000542, elapsed time:  104238
Step 213000, loss: 0.008666963624164055, acc: 99.73064234852791, p_norm: 2015.8241412294647, g_norm: 0.2511293440248444, lr:  0.000542, elapsed time:  104285
Step 213100, loss: 0.008927763502397284, acc: 99.7169793099165, p_norm: 2015.9814968905707, g_norm: 0.11438709809650632, lr:  0.000541, elapsed time:  104331
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 213200, loss: 0.009018246587160767, acc: 99.71865335705854, p_norm: 2016.1566676036575, g_norm: 0.3405693604174793, lr:  0.000541, elapsed time:  104379
Step 213300, loss: 0.008358767463359982, acc: 99.73904867470264, p_norm: 2016.3171789912824, g_norm: 0.23285057321800143, lr:  0.000541, elapsed time:  104426
Step 213400, loss: 0.008524725723491429, acc: 99.72696894407272, p_norm: 2016.4710179616497, g_norm: 0.24790916794641635, lr:  0.000541, elapsed time:  104472
Step 213500, loss: 0.008457673507691651, acc: 99.73808488249779, p_norm: 2016.6317621399685, g_norm: 0.150143224021729, lr:  0.000541, elapsed time:  104519
Step 213600, loss: 0.008789930379680299, acc: 99.71926622092724, p_norm: 2016.7970741499307, g_norm: 0.248459060929279, lr:  0.000541, elapsed time:  104566
Step 213700, loss: 0.008292857673695834, acc: 99.73885148763657, p_norm: 2016.956342348916, g_norm: 0.21512114966747456, lr:  0.000541, elapsed time:  104612
Step 213800, loss: 0.009257873043998189, acc: 99.71371093392372, p_norm: 2017.1141424091215, g_norm: 0.24184230285945274, lr:  0.000541, elapsed time:  104658
Step 213900, loss: 0.008356067274944508, acc: 99.74183923006058, p_norm: 2017.2650465076304, g_norm: 0.15467354580414325, lr:  0.000540, elapsed time:  104705
Step 214000, loss: 0.00874708536171056, acc: 99.72435331344604, p_norm: 2017.4175386621455, g_norm: 0.21874325146486623, lr:  0.000540, elapsed time:  104751
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 214000, eval loss: 0.018152114575259476, eval acc: 99.6228256225586
Step 214100, loss: 0.008355495641881134, acc: 99.73568688333035, p_norm: 2017.5736340867595, g_norm: 0.1680775916038545, lr:  0.000540, elapsed time:  104805
Step 214200, loss: 0.008801841942004103, acc: 99.72614271938801, p_norm: 2017.73158866641, g_norm: 0.1286168180299764, lr:  0.000540, elapsed time:  104851
Step 214300, loss: 0.008982274786703784, acc: 99.7167675793171, p_norm: 2017.9086787015442, g_norm: 0.1375193007701639, lr:  0.000540, elapsed time:  104898
Step 214400, loss: 0.008696874911038321, acc: 99.73001125454903, p_norm: 2018.0830854367734, g_norm: 0.17969304795505142, lr:  0.000540, elapsed time:  104944
Step 214500, loss: 0.008676302258299984, acc: 99.72160114347935, p_norm: 2018.2476422023674, g_norm: 0.11543790107767339, lr:  0.000540, elapsed time:  104992
Step 214600, loss: 0.008932802214512776, acc: 99.71639519929886, p_norm: 2018.4072637726726, g_norm: 0.17100176135632203, lr:  0.000540, elapsed time:  105038
Step 214700, loss: 0.009069682025256043, acc: 99.71571883559227, p_norm: 2018.57652675412, g_norm: 0.16603652162146557, lr:  0.000539, elapsed time:  105084
Step 214800, loss: 0.00875851080090797, acc: 99.72505836188793, p_norm: 2018.7320566735943, g_norm: 0.2595776232331387, lr:  0.000539, elapsed time:  105131
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 214900, loss: 0.008752526521100807, acc: 99.72356414023916, p_norm: 2018.896408244496, g_norm: 0.3131802619243433, lr:  0.000539, elapsed time:  105178
Step 215000, loss: 0.00870995344246694, acc: 99.7214416116476, p_norm: 2019.0593587704223, g_norm: 0.28124477769107453, lr:  0.000539, elapsed time:  105224
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( O ) C S c 1 c n c ( N C ( = O ) N ( C C 2 C C C C 2 ) c 2 c c c ( F ) c ( C ( F ) ( F ) F ) c 2 ) s 1 _EOS
Predicted text: O = C ( O ) C S c 1 c n c ( N C ( = O ) N ( C C 2 C C C C 2 ) c 2 c c c ( F ) c ( C ( F ) ( F ) F ) c 2 ) s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C ( = O ) N C ( = O ) C ( C C 1 C C C C 1 ) c 1 c c c ( S ( C ) ( = O ) = O ) c ( C # N ) c 1 _EOS
Predicted text: C N C ( = O ) N C ( = O ) C ( C C 1 C C C C 1 ) c 1 c c c ( S ( C ) ( = O ) = O ) c ( C # N ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( C ) O C ( C = C c 2 c c c ( F ) c c 2 ) = C C 1 = O _EOS
Predicted text: C C 1 ( C ) O C ( C = C c 2 c c c ( F ) c c 2 ) = C C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C c 1 c c c c c 1 ) N C ( = S ) N c 1 c c c ( O c 2 c c n c 3 c c s c 2 3 ) c ( F ) c 1 _EOS
Predicted text: O = C ( C c 1 c c c c c 1 ) N C ( = S ) N c 1 c c c ( O c 2 c c n c 3 c c s c 2 3 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C C c 2 c ( N 3 C C C ( N ) C C 3 ) c ( F ) c c 3 c ( = O ) c ( C ( = O ) O ) c n 1 c 2 3 _EOS
Predicted text: C C 1 C C c 2 c ( N 3 C C C ( N ) C C 3 ) c ( F ) c c 3 c ( = O ) c ( C ( = O ) O ) c n 1 c 2 3 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 215000, eval acc (token): 0.9401461342558295, eval acc (sequence): 0.8948287910552062
Saving at step 215000
Step 215100, loss: 0.007964065586784273, acc: 99.746367841959, p_norm: 2019.215036631467, g_norm: 0.16314162962773215, lr:  0.000539, elapsed time:  105323
Step 215200, loss: 0.008440490125249198, acc: 99.73012924194336, p_norm: 2019.3751402579692, g_norm: 0.2541095391214704, lr:  0.000539, elapsed time:  105369
Step 215300, loss: 0.008712639147433946, acc: 99.72782436013222, p_norm: 2019.5365424031077, g_norm: 0.16947132711736357, lr:  0.000539, elapsed time:  105416
Step 215400, loss: 0.008628959031448176, acc: 99.72457419335842, p_norm: 2019.7022617660218, g_norm: 0.11643375234737012, lr:  0.000539, elapsed time:  105463
Step 215500, loss: 0.00881422073250178, acc: 99.72097031772137, p_norm: 2019.8770495906526, g_norm: 0.21469555815208102, lr:  0.000538, elapsed time:  105509
Step 215600, loss: 0.008494284440876071, acc: 99.73082533478737, p_norm: 2020.0397674177837, g_norm: 0.2213058849767246, lr:  0.000538, elapsed time:  105556
Step 215700, loss: 0.008646115206502145, acc: 99.72544230520725, p_norm: 2020.2112654285006, g_norm: 0.13646677024327214, lr:  0.000538, elapsed time:  105602
Step 215800, loss: 0.008549649625374514, acc: 99.72717170417309, p_norm: 2020.3797480589162, g_norm: 0.15845799580649494, lr:  0.000538, elapsed time:  105649
Step 215900, loss: 0.008370856201545394, acc: 99.73779813945293, p_norm: 2020.5314995871433, g_norm: 0.19514273735098006, lr:  0.000538, elapsed time:  105696
Step 216000, loss: 0.008619760111196228, acc: 99.72598451375961, p_norm: 2020.6990856750629, g_norm: 0.20813335575338773, lr:  0.000538, elapsed time:  105744
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 216000, eval loss: 0.018774741860852373, eval acc: 99.59579467773438
Step 216100, loss: 0.00890051968559419, acc: 99.72244863212109, p_norm: 2020.8581506370115, g_norm: 0.17085070265617996, lr:  0.000538, elapsed time:  105800
Step 216200, loss: 0.008338113118734327, acc: 99.73920015990734, p_norm: 2021.0180678827246, g_norm: 0.14927149167457213, lr:  0.000538, elapsed time:  105847
Step 216300, loss: 0.0086690475677824, acc: 99.72795213758945, p_norm: 2021.1720572208603, g_norm: 0.15511303741957816, lr:  0.000537, elapsed time:  105894
Step 216400, loss: 0.008773086853834685, acc: 99.72932188212872, p_norm: 2021.3277922176633, g_norm: 0.22200916046240105, lr:  0.000537, elapsed time:  105941
Step 216500, loss: 0.008886477474188723, acc: 99.71997617185116, p_norm: 2021.4916503849802, g_norm: 0.19539298370780062, lr:  0.000537, elapsed time:  105989
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 216600, loss: 0.007993641375539134, acc: 99.74320879326531, p_norm: 2021.657640885187, g_norm: 0.1827057297593825, lr:  0.000537, elapsed time:  106038
Step 216700, loss: 0.008779977491631143, acc: 99.72394035756588, p_norm: 2021.8097544831523, g_norm: 0.2773402738865973, lr:  0.000537, elapsed time:  106084
Step 216800, loss: 0.008268060213740682, acc: 99.74197299778461, p_norm: 2021.9576264261464, g_norm: 0.24980038695899087, lr:  0.000537, elapsed time:  106130
Step 216900, loss: 0.008437491719232639, acc: 99.73231665790081, p_norm: 2022.1142179462367, g_norm: 0.16139389566526602, lr:  0.000537, elapsed time:  106176
Step 217000, loss: 0.008752967215659737, acc: 99.72612953186035, p_norm: 2022.2781651613836, g_norm: 0.16465041787592952, lr:  0.000537, elapsed time:  106223
Step 217100, loss: 0.008609183640091942, acc: 99.73320627212524, p_norm: 2022.4456848484758, g_norm: 0.1676898638573527, lr:  0.000536, elapsed time:  106269
Step 217200, loss: 0.008152387495319999, acc: 99.74029161036015, p_norm: 2022.5826678533715, g_norm: 0.19427289166499492, lr:  0.000536, elapsed time:  106316
Step 217300, loss: 0.008474089912706404, acc: 99.73461437225342, p_norm: 2022.7492641972344, g_norm: 0.18973060918917817, lr:  0.000536, elapsed time:  106362
Step 217400, loss: 0.00837587216279644, acc: 99.73874324560165, p_norm: 2022.9066906647458, g_norm: 0.1861854879556739, lr:  0.000536, elapsed time:  106409
Step 217500, loss: 0.008455438321871043, acc: 99.7298705726862, p_norm: 2023.0693280836026, g_norm: 0.2343199923929296, lr:  0.000536, elapsed time:  106455
Step 217600, loss: 0.008332031627141988, acc: 99.7400556653738, p_norm: 2023.223557361158, g_norm: 0.1712302074900213, lr:  0.000536, elapsed time:  106502
Step 217700, loss: 0.008371658278410904, acc: 99.73875513672829, p_norm: 2023.3814991421539, g_norm: 0.11134713452458352, lr:  0.000536, elapsed time:  106548
Step 217800, loss: 0.00842646945395245, acc: 99.73352977633476, p_norm: 2023.5297476121882, g_norm: 0.2052094039742811, lr:  0.000536, elapsed time:  106594
Step 217900, loss: 0.008607075743584573, acc: 99.72881883382797, p_norm: 2023.7005541379049, g_norm: 0.14986261496867237, lr:  0.000535, elapsed time:  106641
Step 218000, loss: 0.008286226159907529, acc: 99.7425248324871, p_norm: 2023.8495590627833, g_norm: 0.1520497991639923, lr:  0.000535, elapsed time:  106688
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 218000, eval loss: 0.018371319796951863, eval acc: 99.5978012084961
Step 218100, loss: 0.008970378742160392, acc: 99.71870164573193, p_norm: 2024.0021606946875, g_norm: 0.3169532260940228, lr:  0.000535, elapsed time:  106741
Step 218200, loss: 0.00866482883815479, acc: 99.72841423749924, p_norm: 2024.1449975056676, g_norm: 0.1305067044808284, lr:  0.000535, elapsed time:  106788
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 218300, loss: 0.008503004100948466, acc: 99.72912141170454, p_norm: 2024.3100344322024, g_norm: 0.17773883596287335, lr:  0.000535, elapsed time:  106836
Step 218400, loss: 0.009077117977540183, acc: 99.716488301754, p_norm: 2024.4672037242938, g_norm: 0.18343925508137274, lr:  0.000535, elapsed time:  106883
Step 218500, loss: 0.008322285653011931, acc: 99.73632189631462, p_norm: 2024.6528261759765, g_norm: 0.14718902609561935, lr:  0.000535, elapsed time:  106940
Step 218600, loss: 0.008730990090989509, acc: 99.72505205869675, p_norm: 2024.834243626929, g_norm: 0.1942592854945506, lr:  0.000535, elapsed time:  106990
Step 218700, loss: 0.008198090754904115, acc: 99.74435652792454, p_norm: 2024.9870895925978, g_norm: 0.15410312170156265, lr:  0.000534, elapsed time:  107038
Step 218800, loss: 0.008106179620617694, acc: 99.74794471263885, p_norm: 2025.1292383930816, g_norm: 0.1801273447068473, lr:  0.000534, elapsed time:  107086
Step 218900, loss: 0.0081853877319827, acc: 99.73914062976837, p_norm: 2025.2780603053436, g_norm: 0.14309184581425505, lr:  0.000534, elapsed time:  107133
Step 219000, loss: 0.00805677931426544, acc: 99.74963922798634, p_norm: 2025.4247482126834, g_norm: 0.33537329375542885, lr:  0.000534, elapsed time:  107181
Step 219100, loss: 0.00883664575369039, acc: 99.71993018686771, p_norm: 2025.5889417368712, g_norm: 0.15295793058507515, lr:  0.000534, elapsed time:  107228
Step 219200, loss: 0.00877375264535658, acc: 99.71674937009811, p_norm: 2025.7461331343345, g_norm: 0.17808211062314153, lr:  0.000534, elapsed time:  107275
Step 219300, loss: 0.008765959977536113, acc: 99.72505760192871, p_norm: 2025.8964277160849, g_norm: 0.17492144803256277, lr:  0.000534, elapsed time:  107322
Step 219400, loss: 0.009009624390946555, acc: 99.71283842623234, p_norm: 2026.0407482474084, g_norm: 0.19571168244808357, lr:  0.000534, elapsed time:  107369
Step 219500, loss: 0.00828203512061009, acc: 99.7415901273489, p_norm: 2026.191120635816, g_norm: 0.13616140695430007, lr:  0.000533, elapsed time:  107417
Step 219600, loss: 0.008480935579445941, acc: 99.7326140999794, p_norm: 2026.3441722198056, g_norm: 0.20667074046892828, lr:  0.000533, elapsed time:  107465
Step 219700, loss: 0.008797696753390483, acc: 99.71294693648815, p_norm: 2026.501623517867, g_norm: 0.14274628067234726, lr:  0.000533, elapsed time:  107512
Step 219800, loss: 0.008450073420153786, acc: 99.73583926260471, p_norm: 2026.6546399864826, g_norm: 0.16285355515222288, lr:  0.000533, elapsed time:  107560
Step 219900, loss: 0.008507509694591136, acc: 99.73414574563503, p_norm: 2026.81929761326, g_norm: 0.1724950429498144, lr:  0.000533, elapsed time:  107608
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 220000, loss: 0.008078867908042239, acc: 99.74151496260102, p_norm: 2026.970405615205, g_norm: 0.22032381585430705, lr:  0.000533, elapsed time:  107657
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 220000, eval loss: 0.018593050832896543, eval acc: 99.6156234741211
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( Cl ) c 1 c c c c c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1 _EOS
Predicted text: O = C ( Cl ) c 1 c c c c c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C c 1 c c 2 c ( s 1 ) c ( = O ) c ( C ( = O ) N C c 1 c c c ( Cl ) c c 1 ) c n 2 C ) C ( C O ) C c 1 c c c c c 1 _EOS
Predicted text: C N ( C c 1 c c 2 c ( s 1 ) c ( = O ) c ( C ( = O ) N C c 1 c c c ( Cl ) c c 1 ) c n 2 C ) C ( C O ) C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) c 1 c c c c ( S ( = O ) ( = O ) N C c 2 c c c c c 2 - c 2 c c c c c 2 C ( = O ) N C c 2 c c c c c 2 ) c 1 _EOS
Predicted text: C C ( = O ) c 1 c c c c ( S ( = O ) ( = O ) N C c 2 c c c c c 2 - c 2 c c c c c 2 C ( = O ) N C c 2 c c c c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C n 1 c c 2 c ( n 1 ) - c 1 c c c c c 1 N ( C ( = O ) c 1 c c c ( N C ( = O ) c 3 c c c ( Cl ) c c 3 Cl ) c c 1 ) C C 2 _EOS
Predicted text: C C O C ( = O ) C n 1 c c 2 c ( n 1 ) - c 1 c c c c c 1 N ( C ( = O ) c 1 c c c ( N C ( = O ) c 3 c c c ( Cl ) c c 3 Cl ) c c 1 ) C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N c 2 c c n ( C C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) n 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 2 C ( = O ) N c 1 c c ( Cl ) c c c 1 2 _EOS
Predicted text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N c 2 c c n ( C C O [Si] ( C ) ( C ) C ( C ) ( C ) C ) n 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 2 C ( = O ) N c 1 c c ( Cl ) c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 220000, eval acc (token): 0.9411150163491092, eval acc (sequence): 0.8966299982538851
Saving at step 220000
Step 220100, loss: 0.0083187826608264, acc: 99.74299754202366, p_norm: 2027.1221534824053, g_norm: 0.21028451701243842, lr:  0.000533, elapsed time:  107764
Step 220200, loss: 0.008141628377397864, acc: 99.7395800948143, p_norm: 2027.2723647707917, g_norm: 0.15603888979257424, lr:  0.000533, elapsed time:  107812
Step 220300, loss: 0.007961490939342184, acc: 99.75224797427654, p_norm: 2027.426446543255, g_norm: 0.24014381315951908, lr:  0.000532, elapsed time:  107860
Step 220400, loss: 0.008387652677811275, acc: 99.73173969984055, p_norm: 2027.5709149583315, g_norm: 0.275239203049271, lr:  0.000532, elapsed time:  107907
Step 220500, loss: 0.00857328543350377, acc: 99.73031912744045, p_norm: 2027.7431682448632, g_norm: 0.18644416999558663, lr:  0.000532, elapsed time:  107955
Step 220600, loss: 0.008354701046755508, acc: 99.73946040868759, p_norm: 2027.8836791174695, g_norm: 0.1769947409850357, lr:  0.000532, elapsed time:  108003
Step 220700, loss: 0.008636145611708343, acc: 99.7276906222105, p_norm: 2028.0450603251213, g_norm: 0.14812473371209134, lr:  0.000532, elapsed time:  108050
Step 220800, loss: 0.00862442927153097, acc: 99.72442469000816, p_norm: 2028.20123294924, g_norm: 0.15108094166836028, lr:  0.000532, elapsed time:  108098
Step 220900, loss: 0.008889529371772368, acc: 99.71566735208035, p_norm: 2028.361021950594, g_norm: 0.21197123776244328, lr:  0.000532, elapsed time:  108145
Step 221000, loss: 0.009187207685190515, acc: 99.71068476140499, p_norm: 2028.5184892228388, g_norm: 0.18194766622730693, lr:  0.000532, elapsed time:  108192
Step 221100, loss: 0.008744629216071189, acc: 99.72094164788723, p_norm: 2028.6718705673993, g_norm: 0.40441313157369424, lr:  0.000532, elapsed time:  108239
Step 221200, loss: 0.00835909419651216, acc: 99.73052045702934, p_norm: 2028.8343706474675, g_norm: 0.1398528505132804, lr:  0.000531, elapsed time:  108287
Step 221300, loss: 0.008026827241583306, acc: 99.75133454799652, p_norm: 2028.9910620727796, g_norm: 0.16524617753985468, lr:  0.000531, elapsed time:  108335
Step 221400, loss: 0.008029647767307324, acc: 99.74225555360317, p_norm: 2029.1483804908792, g_norm: 0.2637399476375009, lr:  0.000531, elapsed time:  108384
Step 221500, loss: 0.009119997486122884, acc: 99.71156947314739, p_norm: 2029.2984439531942, g_norm: 0.2587137250809483, lr:  0.000531, elapsed time:  108430
Step 221600, loss: 0.008548175967807764, acc: 99.73336155712605, p_norm: 2029.442711982624, g_norm: 0.12675247742829548, lr:  0.000531, elapsed time:  108478
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 221700, loss: 0.007954294303900085, acc: 99.74745385978946, p_norm: 2029.5981303330277, g_norm: 0.15253110311592494, lr:  0.000531, elapsed time:  108527
Step 221800, loss: 0.008362659669564891, acc: 99.7351982742548, p_norm: 2029.7593771127308, g_norm: 0.16136609034320185, lr:  0.000531, elapsed time:  108574
Step 221900, loss: 0.007939983039887012, acc: 99.74934230744839, p_norm: 2029.9148768560788, g_norm: 0.16922705287782575, lr:  0.000531, elapsed time:  108622
Step 222000, loss: 0.008623834319878369, acc: 99.72592048346996, p_norm: 2030.0792189121985, g_norm: 0.23613520366255225, lr:  0.000530, elapsed time:  108670
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 222000, eval loss: 0.01971183167072013, eval acc: 99.5556640625
Step 222100, loss: 0.008510518209368457, acc: 99.72837826609612, p_norm: 2030.2321184939995, g_norm: 0.13212418274667462, lr:  0.000530, elapsed time:  108724
Step 222200, loss: 0.00904048991932541, acc: 99.71336886286736, p_norm: 2030.3805624186368, g_norm: 0.18739035398528542, lr:  0.000530, elapsed time:  108771
Step 222300, loss: 0.008267825919683674, acc: 99.73757563531399, p_norm: 2030.5515927484776, g_norm: 0.15489822793135977, lr:  0.000530, elapsed time:  108819
Step 222400, loss: 0.008643321996551094, acc: 99.72397154569626, p_norm: 2030.7190080230246, g_norm: 0.16041191045216033, lr:  0.000530, elapsed time:  108860
Step 222500, loss: 0.008138260752120914, acc: 99.74126149713993, p_norm: 2030.8726276268237, g_norm: 0.14263530145481926, lr:  0.000530, elapsed time:  108902
Step 222600, loss: 0.008216146715130889, acc: 99.73497453331947, p_norm: 2031.0324685099195, g_norm: 0.22508798138371056, lr:  0.000530, elapsed time:  108950
Step 222700, loss: 0.008424317979752231, acc: 99.73496940732002, p_norm: 2031.184602162241, g_norm: 0.1487287210315019, lr:  0.000530, elapsed time:  108998
Step 222800, loss: 0.008355478022494936, acc: 99.73878937959671, p_norm: 2031.3430572199482, g_norm: 0.1861391314031469, lr:  0.000529, elapsed time:  109045
Step 222900, loss: 0.008274344960591406, acc: 99.74300599098206, p_norm: 2031.4950302035236, g_norm: 0.2518939787784969, lr:  0.000529, elapsed time:  109093
Step 223000, loss: 0.00874735115619842, acc: 99.72581695020199, p_norm: 2031.6455713870844, g_norm: 0.24025006646379996, lr:  0.000529, elapsed time:  109140
Step 223100, loss: 0.008585742966424732, acc: 99.72770231962204, p_norm: 2031.8010129369197, g_norm: 0.2967523797026473, lr:  0.000529, elapsed time:  109187
Step 223200, loss: 0.008220220072216762, acc: 99.74225707352161, p_norm: 2031.9530717562052, g_norm: 0.23902907430814455, lr:  0.000529, elapsed time:  109235
Step 223300, loss: 0.008522957632139878, acc: 99.72755575180054, p_norm: 2032.114999289779, g_norm: 0.17352967926871027, lr:  0.000529, elapsed time:  109283
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 223400, loss: 0.008435416572457024, acc: 99.73348916020642, p_norm: 2032.2650920281583, g_norm: 0.1370475131575165, lr:  0.000529, elapsed time:  109331
Step 223500, loss: 0.008217961245718471, acc: 99.73874109983444, p_norm: 2032.4320669554736, g_norm: 0.11415414988524035, lr:  0.000529, elapsed time:  109379
Step 223600, loss: 0.007735948274985276, acc: 99.75915892422199, p_norm: 2032.5613693690245, g_norm: 0.3429187137652036, lr:  0.000529, elapsed time:  109426
Step 223700, loss: 0.008528663870156378, acc: 99.74002158641815, p_norm: 2032.71949720369, g_norm: 0.13069865431177294, lr:  0.000528, elapsed time:  109473
Step 223800, loss: 0.008325142203830183, acc: 99.73510077595711, p_norm: 2032.8899810733499, g_norm: 0.18689996737559406, lr:  0.000528, elapsed time:  109521
Step 223900, loss: 0.008438239209426683, acc: 99.73156504333019, p_norm: 2033.0484140605106, g_norm: 0.11189112539862706, lr:  0.000528, elapsed time:  109569
Step 224000, loss: 0.008536053846291906, acc: 99.72913083434105, p_norm: 2033.2099071475607, g_norm: 0.1618699033972407, lr:  0.000528, elapsed time:  109617
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 224000, eval loss: 0.02087608347361992, eval acc: 99.58541870117188
Step 224100, loss: 0.008049072639769292, acc: 99.74360406398773, p_norm: 2033.3637936864882, g_norm: 0.18680268477292603, lr:  0.000528, elapsed time:  109672
Step 224200, loss: 0.008731749055550608, acc: 99.72013898193836, p_norm: 2033.5131939945784, g_norm: 0.309693992215242, lr:  0.000528, elapsed time:  109720
Step 224300, loss: 0.008595823759642372, acc: 99.72921957075596, p_norm: 2033.6669478240926, g_norm: 0.1911064990913389, lr:  0.000528, elapsed time:  109767
Step 224400, loss: 0.008131873141310279, acc: 99.74565893411636, p_norm: 2033.8157506622617, g_norm: 0.2531260873480343, lr:  0.000528, elapsed time:  109815
Step 224500, loss: 0.00825009220463471, acc: 99.73639419674873, p_norm: 2033.9684090399182, g_norm: 0.2001532312532936, lr:  0.000527, elapsed time:  109862
Step 224600, loss: 0.008128362410607224, acc: 99.74226777255535, p_norm: 2034.107131551556, g_norm: 0.20235446193031834, lr:  0.000527, elapsed time:  109910
Step 224700, loss: 0.008795060802840452, acc: 99.72008606791496, p_norm: 2034.2719225349615, g_norm: 0.17228117221723852, lr:  0.000527, elapsed time:  109957
Step 224800, loss: 0.00809378435294093, acc: 99.74161437153816, p_norm: 2034.42679809961, g_norm: 0.22350894668367974, lr:  0.000527, elapsed time:  110005
Step 224900, loss: 0.008678076122687345, acc: 99.72421379387379, p_norm: 2034.5739814055978, g_norm: 0.17799101575034343, lr:  0.000527, elapsed time:  110053
Step 225000, loss: 0.008264375564995135, acc: 99.74117603898048, p_norm: 2034.7211152170646, g_norm: 0.18793879863223617, lr:  0.000527, elapsed time:  110101
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) C S c 1 c c c 2 c ( c 1 ) n c ( C C ( C ) ( C ) C ) n 2 C C 1 C C 1 _EOS
Predicted text: C O C ( = O ) C S c 1 c c c 2 c ( c 1 ) n c ( C C ( C ) ( C ) C ) n 2 C C 1 C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 = C ( C O C c 2 n n n ( C C N S ( C ) ( = O ) = O ) n 2 ) N C ( C ) = C ( C ( = O ) O C ) C 1 c 1 c c c c ( Cl ) c 1 Cl _EOS
Predicted text: C C O C ( = O ) C 1 = C ( C O C c 2 n n n ( C C N S ( C ) ( = O ) = O ) n 2 ) N C ( C ) = C ( C ( = O ) O C ) C 1 c 1 c c c c ( Cl ) c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c 2 c ( O c 3 c c c 4 [nH] c ( C ) c c 4 c 3 F ) n c n c 2 c c 1 O C C C N 1 C C C C 1 _EOS
Predicted text: C O c 1 c c 2 c ( O c 3 c c c 4 [nH] c ( C ) c c 4 c 3 F ) n c n c 2 c c 1 O C C C C N 1 C C C 1 _EOS
acc_token: 0.9375, acc_seq: False

Target text: C C ( C ) ( C C = O ) C C O [Si] ( C ) ( C ) C ( C ) ( C ) C _EOS
Predicted text: C C ( C ) ( C C = O ) C C O [Si] ( C ) ( C ) C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( = C c 1 c c c ( O ) c c 1 ) C ( = O ) O C _EOS
Predicted text: C O C ( = O ) C ( = C c 1 c c c ( O ) c c 1 ) C ( = O ) O C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 225000, eval acc (token): 0.9408257045052717, eval acc (sequence): 0.8900914349692107
Saving at step 225000
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 225100, loss: 0.00852193906509786, acc: 99.73384561526835, p_norm: 2034.8742252682391, g_norm: 0.2316842291300026, lr:  0.000527, elapsed time:  110202
Step 225200, loss: 0.00819602893829142, acc: 99.74970854818821, p_norm: 2035.0161286975613, g_norm: 0.31517088078793865, lr:  0.000527, elapsed time:  110250
Step 225300, loss: 0.00871351448877249, acc: 99.72278390824795, p_norm: 2035.1641987288988, g_norm: 0.12860929428939896, lr:  0.000527, elapsed time:  110297
Step 225400, loss: 0.008377756340887572, acc: 99.73404887318611, p_norm: 2035.3320113292152, g_norm: 0.1772877774191713, lr:  0.000526, elapsed time:  110344
Step 225500, loss: 0.008637069422438798, acc: 99.7285343259573, p_norm: 2035.4749815612122, g_norm: 0.1518009057984394, lr:  0.000526, elapsed time:  110391
Step 225600, loss: 0.007960640063975006, acc: 99.7503632903099, p_norm: 2035.6361661441763, g_norm: 0.1688303771759941, lr:  0.000526, elapsed time:  110439
Step 225700, loss: 0.00779577040750155, acc: 99.75448679924011, p_norm: 2035.7993557233647, g_norm: 0.19615903499192638, lr:  0.000526, elapsed time:  110487
Step 225800, loss: 0.008157551897065787, acc: 99.74173906445503, p_norm: 2035.9362300333817, g_norm: 0.19120429621446142, lr:  0.000526, elapsed time:  110534
Step 225900, loss: 0.008708732194245386, acc: 99.72786059975624, p_norm: 2036.0945300130854, g_norm: 0.1630549461682395, lr:  0.000526, elapsed time:  110582
Step 226000, loss: 0.008368636438126487, acc: 99.73559191823006, p_norm: 2036.2556575195927, g_norm: 0.2119630789026981, lr:  0.000526, elapsed time:  110629
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 226000, eval loss: 0.01905540575404302, eval acc: 99.60435485839844
Step 226100, loss: 0.008689728131685115, acc: 99.73185336589813, p_norm: 2036.3979663572634, g_norm: 0.20444202327336064, lr:  0.000526, elapsed time:  110683
Step 226200, loss: 0.008844820106678525, acc: 99.71880452334881, p_norm: 2036.5636362132238, g_norm: 0.31241125391503943, lr:  0.000525, elapsed time:  110731
Step 226300, loss: 0.00869767697793577, acc: 99.71701075136662, p_norm: 2036.726740174424, g_norm: 0.19384614919218304, lr:  0.000525, elapsed time:  110778
Step 226400, loss: 0.007980142611486371, acc: 99.74598529934883, p_norm: 2036.8683951909902, g_norm: 0.22154992691831615, lr:  0.000525, elapsed time:  110826
Step 226500, loss: 0.008169814120101364, acc: 99.7409007102251, p_norm: 2037.0177871285457, g_norm: 0.16209729575195062, lr:  0.000525, elapsed time:  110874
Step 226600, loss: 0.008063038963991858, acc: 99.74224388599396, p_norm: 2037.1712547401291, g_norm: 0.1286777567012117, lr:  0.000525, elapsed time:  110921
Step 226700, loss: 0.008511337100535456, acc: 99.73275826871395, p_norm: 2037.3096345088431, g_norm: 0.21085901130091325, lr:  0.000525, elapsed time:  110969
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 226800, loss: 0.008341694829376781, acc: 99.74011182785034, p_norm: 2037.471750670804, g_norm: 0.17956297737514498, lr:  0.000525, elapsed time:  111017
Step 226900, loss: 0.007974014609244478, acc: 99.75164180994034, p_norm: 2037.6144240244382, g_norm: 0.1587882658029264, lr:  0.000525, elapsed time:  111065
Step 227000, loss: 0.007614027722647734, acc: 99.75761899352074, p_norm: 2037.7633695736235, g_norm: 0.08136492351281402, lr:  0.000525, elapsed time:  111113
Step 227100, loss: 0.008379118793172893, acc: 99.73019324243069, p_norm: 2037.9172091159155, g_norm: 0.1791453198955144, lr:  0.000524, elapsed time:  111160
Step 227200, loss: 0.00764062272341107, acc: 99.75791421532631, p_norm: 2038.059982369858, g_norm: 0.16961955034150594, lr:  0.000524, elapsed time:  111208
Step 227300, loss: 0.008103641347770463, acc: 99.74435067176819, p_norm: 2038.2134508147426, g_norm: 0.2141065681395714, lr:  0.000524, elapsed time:  111255
Step 227400, loss: 0.008222096882091136, acc: 99.73389123380184, p_norm: 2038.3651296521844, g_norm: 0.22600196174573514, lr:  0.000524, elapsed time:  111303
Step 227500, loss: 0.008457964653134696, acc: 99.73247189819813, p_norm: 2038.502629100476, g_norm: 0.20415390179985438, lr:  0.000524, elapsed time:  111350
Step 227600, loss: 0.008156247348015313, acc: 99.7406349927187, p_norm: 2038.644063860495, g_norm: 0.24645711756995153, lr:  0.000524, elapsed time:  111398
Step 227700, loss: 0.007899075617315248, acc: 99.75308978557587, p_norm: 2038.8009010826718, g_norm: 0.2146516436504514, lr:  0.000524, elapsed time:  111446
Step 227800, loss: 0.007961119886076631, acc: 99.74767243862152, p_norm: 2038.9420217258348, g_norm: 0.31988914754183073, lr:  0.000524, elapsed time:  111493
Step 227900, loss: 0.008092501613027707, acc: 99.74415473639965, p_norm: 2039.103233928573, g_norm: 0.193088742150353, lr:  0.000524, elapsed time:  111541
Step 228000, loss: 0.007994032924470958, acc: 99.74495543539524, p_norm: 2039.249628236024, g_norm: 0.19654004232471062, lr:  0.000523, elapsed time:  111588
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 228000, eval loss: 0.018556342931515243, eval acc: 99.6112289428711
Step 228100, loss: 0.008623830129090492, acc: 99.7311608940363, p_norm: 2039.406178945508, g_norm: 0.21953193833495482, lr:  0.000523, elapsed time:  111643
Step 228200, loss: 0.008434551499012741, acc: 99.7371629178524, p_norm: 2039.571894370117, g_norm: 0.13738574154389466, lr:  0.000523, elapsed time:  111691
Step 228300, loss: 0.008827984506660868, acc: 99.72376504540443, p_norm: 2039.7333116164577, g_norm: 0.17959015480445406, lr:  0.000523, elapsed time:  111739
Step 228400, loss: 0.008502672597514901, acc: 99.7269755601883, p_norm: 2039.8833807069582, g_norm: 0.24453697195625967, lr:  0.000523, elapsed time:  111786
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 228500, loss: 0.00909123932911255, acc: 99.71334459769785, p_norm: 2040.0467726819275, g_norm: 0.24738775752958247, lr:  0.000523, elapsed time:  111835
Step 228600, loss: 0.0075593608787676205, acc: 99.75930525362492, p_norm: 2040.207652589083, g_norm: 0.17455994723593132, lr:  0.000523, elapsed time:  111882
Step 228700, loss: 0.007858168492621189, acc: 99.74928526580334, p_norm: 2040.3652582954971, g_norm: 0.14509886393649868, lr:  0.000523, elapsed time:  111930
Step 228800, loss: 0.00847590759916784, acc: 99.7281478792429, p_norm: 2040.5269129955282, g_norm: 0.22538372723262096, lr:  0.000522, elapsed time:  111977
Step 228900, loss: 0.008148339147574006, acc: 99.7406997680664, p_norm: 2040.6601787903264, g_norm: 0.24939761396461574, lr:  0.000522, elapsed time:  112025
Step 229000, loss: 0.008202852774011261, acc: 99.73404863476753, p_norm: 2040.8300424022261, g_norm: 0.13063150407676552, lr:  0.000522, elapsed time:  112072
Step 229100, loss: 0.008072133136811316, acc: 99.7398983836174, p_norm: 2040.9894800836505, g_norm: 0.14175832232835578, lr:  0.000522, elapsed time:  112120
Step 229200, loss: 0.008641080097077066, acc: 99.73238818347454, p_norm: 2041.1311565275946, g_norm: 0.16034687442112303, lr:  0.000522, elapsed time:  112167
Step 229300, loss: 0.008480296524758159, acc: 99.73590563237667, p_norm: 2041.3053574530304, g_norm: 0.12489665250149325, lr:  0.000522, elapsed time:  112215
Step 229400, loss: 0.008127407703723293, acc: 99.73720401525497, p_norm: 2041.4649059949745, g_norm: 0.2647604336771405, lr:  0.000522, elapsed time:  112263
Step 229500, loss: 0.007944145991768892, acc: 99.7502648383379, p_norm: 2041.6083829988409, g_norm: 0.18051290814171786, lr:  0.000522, elapsed time:  112311
Step 229600, loss: 0.008552588836664654, acc: 99.728744789958, p_norm: 2041.7540916649264, g_norm: 0.2591255047350363, lr:  0.000522, elapsed time:  112359
Step 229700, loss: 0.008764113784363871, acc: 99.71985667943954, p_norm: 2041.9040378077186, g_norm: 0.1285263720318553, lr:  0.000521, elapsed time:  112406
Step 229800, loss: 0.008435544469066372, acc: 99.73773938417435, p_norm: 2042.0557100717574, g_norm: 0.19148446168679478, lr:  0.000521, elapsed time:  112453
Step 229900, loss: 0.00805743376056853, acc: 99.7474430501461, p_norm: 2042.1845462214033, g_norm: 0.24914068754288107, lr:  0.000521, elapsed time:  112501
Step 230000, loss: 0.008692551957174145, acc: 99.72233913838863, p_norm: 2042.3438314804207, g_norm: 0.15480888629048378, lr:  0.000521, elapsed time:  112549
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 230000, eval loss: 0.019849798464310873, eval acc: 99.57945251464844
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: O = [N+] ( [O-] ) c 1 c c c c ( [N+] ( = O ) [O-] ) c 1 I _EOS
Predicted text: O = [N+] ( [O-] ) c 1 c c c c ( [N+] ( = O ) [O-] ) c 1 I _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C ( = O ) C ( = N O C ) c 1 c c c c c 1 C O c 1 c c ( C ) c c c 1 C _EOS
Predicted text: C N C ( = O ) C ( = N O C ) c 1 c c c c c 1 C O c 1 c c ( C ) c c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c n 2 n c ( S C c 3 c c c c c 3 ) n c 2 n c 1 Cl _EOS
Predicted text: C c 1 c n 2 n c ( S C c 3 c c c c c 3 ) n c 2 n c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 = C ( C ( = O ) N C C N ( C ) C ) C ( c 2 c c c c ( Cl ) c 2 ) C ( C ( = O ) O C C C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) = C ( C ) N 1 _EOS
Predicted text: C C 1 = C ( C ( = O ) N C C N ( C ) C ) C ( c 2 c c c c ( Cl ) c 2 ) C ( C ( = O ) O C C C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) = C ( C ) N 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C C c 1 c c c ( O ) c c 1 ) c 1 c c c 2 n 1 C c 1 c c c c c 1 N ( C ( = O ) C S c 1 c c c ( Br ) c c 1 ) C 2 _EOS
Predicted text: O = C ( N C C c 1 c c c ( O ) c c 1 ) c 1 c c c 2 n 1 C c 1 c c c c c 1 N ( C ( = O ) C S c 1 c c c ( Br ) c c 1 ) C 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 230000, eval acc (token): 0.9395475710771006, eval acc (sequence): 0.8897704253882511
Saving at step 230000
Step 230100, loss: 0.008193281286403363, acc: 99.74393403530121, p_norm: 2042.4964049957089, g_norm: 0.1235598739892196, lr:  0.000521, elapsed time:  112667
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 230200, loss: 0.008725260360200023, acc: 99.7207813150254, p_norm: 2042.6395032034195, g_norm: 0.17009599222862595, lr:  0.000521, elapsed time:  112716
Step 230300, loss: 0.008099180271728982, acc: 99.7445997595787, p_norm: 2042.793445488856, g_norm: 0.17817105682176557, lr:  0.000521, elapsed time:  112764
Step 230400, loss: 0.007775414635734706, acc: 99.750956594944, p_norm: 2042.9390063258463, g_norm: 0.18397819913158195, lr:  0.000521, elapsed time:  112812
Step 230500, loss: 0.007813419528301892, acc: 99.7494974732399, p_norm: 2043.0785114717023, g_norm: 0.18874211510640496, lr:  0.000521, elapsed time:  112860
Step 230600, loss: 0.008232239583030605, acc: 99.74002119898796, p_norm: 2043.2297405393604, g_norm: 0.25275316020821303, lr:  0.000520, elapsed time:  112907
Step 230700, loss: 0.007899588651707746, acc: 99.75078237056732, p_norm: 2043.3938477761922, g_norm: 0.253602891795003, lr:  0.000520, elapsed time:  112955
Step 230800, loss: 0.0081197847778094, acc: 99.74214497208595, p_norm: 2043.5433907432287, g_norm: 0.20452158821121266, lr:  0.000520, elapsed time:  113002
Step 230900, loss: 0.007944791395348148, acc: 99.74561007320881, p_norm: 2043.6987408024193, g_norm: 0.18868278731841548, lr:  0.000520, elapsed time:  113050
Step 231000, loss: 0.008525716253097925, acc: 99.73024174571037, p_norm: 2043.8459446131506, g_norm: 0.19603780388177433, lr:  0.000520, elapsed time:  113098
Step 231100, loss: 0.008483837719631992, acc: 99.73445838689804, p_norm: 2044.0077991916999, g_norm: 0.19864717945790678, lr:  0.000520, elapsed time:  113145
Step 231200, loss: 0.008815999817052216, acc: 99.72362296283245, p_norm: 2044.171045068688, g_norm: 0.1945142271923675, lr:  0.000520, elapsed time:  113193
Step 231300, loss: 0.008449266002317017, acc: 99.73289845883846, p_norm: 2044.3061797116934, g_norm: 0.16473326866164337, lr:  0.000520, elapsed time:  113240
Step 231400, loss: 0.008297691727711935, acc: 99.74226801097393, p_norm: 2044.4616552334348, g_norm: 0.17083540242915005, lr:  0.000520, elapsed time:  113287
Step 231500, loss: 0.008464929551646492, acc: 99.7298395037651, p_norm: 2044.6074587955243, g_norm: 0.19453445043733322, lr:  0.000519, elapsed time:  113335
Step 231600, loss: 0.008308562105867168, acc: 99.73865731060505, p_norm: 2044.749644939254, g_norm: 0.28764832955379266, lr:  0.000519, elapsed time:  113382
Step 231700, loss: 0.008046794834826869, acc: 99.75007893145084, p_norm: 2044.8910511159127, g_norm: 0.12255645197612731, lr:  0.000519, elapsed time:  113429
Step 231800, loss: 0.008652130106002005, acc: 99.72321812808514, p_norm: 2045.0453524005338, g_norm: 0.20321000569634587, lr:  0.000519, elapsed time:  113476
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 231900, loss: 0.008244620150824503, acc: 99.73762156951487, p_norm: 2045.1854079613981, g_norm: 0.20266401251154484, lr:  0.000519, elapsed time:  113525
Step 232000, loss: 0.007893899589107604, acc: 99.751196667552, p_norm: 2045.347222648771, g_norm: 0.21168981964149, lr:  0.000519, elapsed time:  113572
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 232000, eval loss: 0.020246642309452917, eval acc: 99.57167053222656
Step 232100, loss: 0.007611401320318691, acc: 99.7625844925642, p_norm: 2045.4831491022705, g_norm: 0.1601855584587366, lr:  0.000519, elapsed time:  113627
Step 232200, loss: 0.007563458883732892, acc: 99.75964578986168, p_norm: 2045.6247519209344, g_norm: 0.18219828098381105, lr:  0.000519, elapsed time:  113675
Step 232300, loss: 0.008100510891763406, acc: 99.73939023911953, p_norm: 2045.7747293389073, g_norm: 0.16379553876893252, lr:  0.000519, elapsed time:  113722
Step 232400, loss: 0.008110758376169543, acc: 99.74870298802853, p_norm: 2045.9209851788682, g_norm: 0.17495677410755298, lr:  0.000518, elapsed time:  113770
Step 232500, loss: 0.008250147473881952, acc: 99.74001879990101, p_norm: 2046.0740599567391, g_norm: 0.16549946706004717, lr:  0.000518, elapsed time:  113818
Step 232600, loss: 0.008170545364851022, acc: 99.74028649926186, p_norm: 2046.223309971689, g_norm: 0.1783105819672669, lr:  0.000518, elapsed time:  113865
Step 232700, loss: 0.008112282884121668, acc: 99.73732939362526, p_norm: 2046.3740399431833, g_norm: 0.21547981427453458, lr:  0.000518, elapsed time:  113913
Step 232800, loss: 0.008052418167717406, acc: 99.7478234320879, p_norm: 2046.5205449500427, g_norm: 0.1517006581574616, lr:  0.000518, elapsed time:  113960
Step 232900, loss: 0.00842513952004083, acc: 99.7323435395956, p_norm: 2046.6750565910345, g_norm: 0.25731524761454755, lr:  0.000518, elapsed time:  114008
Step 233000, loss: 0.00841675626070355, acc: 99.72903694212437, p_norm: 2046.819956165556, g_norm: 0.20596054701279132, lr:  0.000518, elapsed time:  114055
Step 233100, loss: 0.008407951243571006, acc: 99.73409333825111, p_norm: 2046.9607126826004, g_norm: 0.17410223500380048, lr:  0.000518, elapsed time:  114103
Step 233200, loss: 0.008065901506561203, acc: 99.73682337999344, p_norm: 2047.1158754172286, g_norm: 0.22129307434291354, lr:  0.000518, elapsed time:  114150
Step 233300, loss: 0.008188133970143098, acc: 99.74299566447735, p_norm: 2047.2736248238953, g_norm: 0.225482337565951, lr:  0.000517, elapsed time:  114197
Step 233400, loss: 0.008489780474010332, acc: 99.7294884622097, p_norm: 2047.4138557560534, g_norm: 0.15905154725992865, lr:  0.000517, elapsed time:  114245
Step 233500, loss: 0.008252696981717236, acc: 99.7392636090517, p_norm: 2047.5597597351284, g_norm: 0.17259476828029865, lr:  0.000517, elapsed time:  114293
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 233600, loss: 0.008499605871913075, acc: 99.727013736815, p_norm: 2047.7045948115567, g_norm: 0.26728686949137437, lr:  0.000517, elapsed time:  114341
Step 233700, loss: 0.008070965733668344, acc: 99.74220915138721, p_norm: 2047.8719414517172, g_norm: 0.18580410798040167, lr:  0.000517, elapsed time:  114388
Step 233800, loss: 0.007998091237932386, acc: 99.7538571357727, p_norm: 2048.016166521949, g_norm: 0.21295422771788922, lr:  0.000517, elapsed time:  114436
Step 233900, loss: 0.008400097127159825, acc: 99.73422087728977, p_norm: 2048.1643653731153, g_norm: 0.18533357734826061, lr:  0.000517, elapsed time:  114483
Step 234000, loss: 0.007744606060732621, acc: 99.7587902545929, p_norm: 2048.295624181215, g_norm: 0.18846707144259914, lr:  0.000517, elapsed time:  114531
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 234000, eval loss: 0.017622103666362816, eval acc: 99.62623596191406
Step 234100, loss: 0.008101135852957669, acc: 99.7458211183548, p_norm: 2048.4553149524077, g_norm: 0.2779728741030273, lr:  0.000517, elapsed time:  114585
Step 234200, loss: 0.008195679271238987, acc: 99.74661037325859, p_norm: 2048.6106753733925, g_norm: 0.15604904093108857, lr:  0.000516, elapsed time:  114632
Step 234300, loss: 0.008497882472802303, acc: 99.73371250927448, p_norm: 2048.7485849204263, g_norm: 0.1946565432702572, lr:  0.000516, elapsed time:  114679
Step 234400, loss: 0.008330656952393838, acc: 99.73515924811363, p_norm: 2048.901929534602, g_norm: 0.2533339963522332, lr:  0.000516, elapsed time:  114726
Step 234500, loss: 0.007976431738297833, acc: 99.73907834291458, p_norm: 2049.0546428813454, g_norm: 0.11311404873708432, lr:  0.000516, elapsed time:  114774
Step 234600, loss: 0.008196576609138901, acc: 99.74246862530708, p_norm: 2049.196399656065, g_norm: 0.1647023494855896, lr:  0.000516, elapsed time:  114822
Step 234700, loss: 0.008470905219510313, acc: 99.72513899207115, p_norm: 2049.345691722663, g_norm: 0.2549166884245646, lr:  0.000516, elapsed time:  114869
Step 234800, loss: 0.008505482826767547, acc: 99.73010797798634, p_norm: 2049.4837915691933, g_norm: 0.21325030627623034, lr:  0.000516, elapsed time:  114917
Step 234900, loss: 0.007982468751488342, acc: 99.75240214169025, p_norm: 2049.6257110010606, g_norm: 0.21665884758512516, lr:  0.000516, elapsed time:  114965
Step 235000, loss: 0.008146329514565877, acc: 99.7425140440464, p_norm: 2049.757460994395, g_norm: 0.1871049958695281, lr:  0.000516, elapsed time:  115012
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) C C N C ( = O ) c 1 c c c ( N C ( c 2 o c 3 c c c ( Br ) n c 3 c 2 C ) C 2 C C C C C 2 ) c c 1 _EOS
Predicted text: C C O C ( = O ) C C N C ( = O ) c 1 c c c ( N C ( c 2 o c 3 c c c ( Br ) n c 3 c 2 C ) C 2 C C C C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C # C c 1 n c ( C ( F ) ( F ) F ) c c c 1 C ( = O ) N ( C ) O C _EOS
Predicted text: C O C C # C c 1 n c ( C ( F ) ( F ) F ) c c c 1 C ( = O ) N ( C ) O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c c ( F ) c ( N 2 C C ( C ) C ( N C ( = O ) O C ( C ) ( C ) C ) C 2 ) c ( C ) c 1 F _EOS
Predicted text: C C O C ( = O ) c 1 c c ( F ) c ( N 2 C C ( C ) C ( N C ( = O ) O C ( C ) ( C ) C ) C 2 ) c ( C ) c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C C C ( = O ) c 1 c c c ( N C ( = O ) c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: O = C ( O ) C C C ( = O ) c 1 c c c ( N C ( = O ) c 2 c c c c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 [nH] c 2 c c c c c 2 c 1 Br _EOS
Predicted text: C C O C ( = O ) c 1 [nH] c 2 c c c c c 2 c 1 Br _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 235000, eval acc (token): 0.9393699131364237, eval acc (sequence): 0.8918875758543596
Saving at step 235000
Step 235100, loss: 0.00801686062506633, acc: 99.74207226932049, p_norm: 2049.894463639143, g_norm: 0.17416754653005787, lr:  0.000515, elapsed time:  115110
Step 235200, loss: 0.00824309601164714, acc: 99.74224324524403, p_norm: 2050.039588072455, g_norm: 0.25245811746212665, lr:  0.000515, elapsed time:  115158
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 235300, loss: 0.008020358691752452, acc: 99.74661726809613, p_norm: 2050.1920640127055, g_norm: 0.14978417388685186, lr:  0.000515, elapsed time:  115206
Step 235400, loss: 0.007639969834799558, acc: 99.76020088791847, p_norm: 2050.3331759628127, g_norm: 0.16492459557037467, lr:  0.000515, elapsed time:  115254
Step 235500, loss: 0.007827204819677717, acc: 99.75072976946831, p_norm: 2050.479669948686, g_norm: 0.2753585808182725, lr:  0.000515, elapsed time:  115302
Step 235600, loss: 0.00801156426061425, acc: 99.73832109570503, p_norm: 2050.623668543783, g_norm: 0.26658242740584276, lr:  0.000515, elapsed time:  115349
Step 235700, loss: 0.007702234255116309, acc: 99.75550110638142, p_norm: 2050.767823802347, g_norm: 0.11268975854328682, lr:  0.000515, elapsed time:  115397
Step 235800, loss: 0.007952842938757386, acc: 99.74707499146461, p_norm: 2050.9079233926377, g_norm: 0.14513149457658372, lr:  0.000515, elapsed time:  115444
Step 235900, loss: 0.008216907905516563, acc: 99.73838469386101, p_norm: 2051.0517908359398, g_norm: 0.20024376576582706, lr:  0.000515, elapsed time:  115491
Step 236000, loss: 0.007659182287716249, acc: 99.7551579773426, p_norm: 2051.189745532566, g_norm: 0.1698018058180589, lr:  0.000514, elapsed time:  115539
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 236000, eval loss: 0.02082367980066921, eval acc: 99.5948715209961
Step 236100, loss: 0.007900367931179063, acc: 99.74893715977669, p_norm: 2051.3372511505495, g_norm: 0.1023338036737422, lr:  0.000514, elapsed time:  115593
Step 236200, loss: 0.00817329457744563, acc: 99.74047976732254, p_norm: 2051.483015327664, g_norm: 0.15891947904386244, lr:  0.000514, elapsed time:  115641
Step 236300, loss: 0.008169433635266614, acc: 99.73727308213711, p_norm: 2051.6503314607235, g_norm: 0.2302490382168807, lr:  0.000514, elapsed time:  115688
Step 236400, loss: 0.008638891087211959, acc: 99.72775229811668, p_norm: 2051.786531731995, g_norm: 0.20780995780264533, lr:  0.000514, elapsed time:  115735
Step 236500, loss: 0.007686029675496684, acc: 99.76092648506165, p_norm: 2051.914780424939, g_norm: 0.22367167453413114, lr:  0.000514, elapsed time:  115783
Step 236600, loss: 0.008088345673331786, acc: 99.74699859321117, p_norm: 2052.072828915911, g_norm: 0.18665101928824074, lr:  0.000514, elapsed time:  115831
Step 236700, loss: 0.008682069673450315, acc: 99.72705046832561, p_norm: 2052.21320867333, g_norm: 0.20289321621276468, lr:  0.000514, elapsed time:  115878
Step 236800, loss: 0.008144629941689345, acc: 99.74183385074139, p_norm: 2052.36403761328, g_norm: 0.2501228177921324, lr:  0.000514, elapsed time:  115925
Step 236900, loss: 0.008332663088958725, acc: 99.73446635901928, p_norm: 2052.51134725359, g_norm: 0.24618951598858174, lr:  0.000513, elapsed time:  115973
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 237000, loss: 0.008435823933248331, acc: 99.73760773589954, p_norm: 2052.6537059526845, g_norm: 0.14079133908401004, lr:  0.000513, elapsed time:  116022
Step 237100, loss: 0.007812448929162202, acc: 99.75022888183594, p_norm: 2052.776567187257, g_norm: 0.25885234279379005, lr:  0.000513, elapsed time:  116069
Step 237200, loss: 0.00705145273155722, acc: 99.77696852385998, p_norm: 2052.9147463189897, g_norm: 0.17220563422138893, lr:  0.000513, elapsed time:  116117
Step 237300, loss: 0.0074243357152045065, acc: 99.76449218392372, p_norm: 2053.0445507657732, g_norm: 0.14000830591151245, lr:  0.000513, elapsed time:  116165
Step 237400, loss: 0.00759125040814979, acc: 99.7610170096159, p_norm: 2053.186332530972, g_norm: 0.19642112261308609, lr:  0.000513, elapsed time:  116213
Step 237500, loss: 0.008134482048189966, acc: 99.74364699423313, p_norm: 2053.335109405951, g_norm: 0.15384994098935922, lr:  0.000513, elapsed time:  116260
Step 237600, loss: 0.008262350008371867, acc: 99.74039936065674, p_norm: 2053.4802220398556, g_norm: 0.26257214592723616, lr:  0.000513, elapsed time:  116307
Step 237700, loss: 0.008271509283331398, acc: 99.74137111008167, p_norm: 2053.6391807101913, g_norm: 0.18200239279524147, lr:  0.000513, elapsed time:  116354
Step 237800, loss: 0.007741245282450109, acc: 99.75457707047462, p_norm: 2053.7988622217217, g_norm: 0.15896786893173898, lr:  0.000513, elapsed time:  116403
Step 237900, loss: 0.008091353025120042, acc: 99.73830354213715, p_norm: 2053.941811851891, g_norm: 0.13613603462004717, lr:  0.000512, elapsed time:  116450
Step 238000, loss: 0.00839522532596675, acc: 99.73143546283245, p_norm: 2054.073009140322, g_norm: 0.16649401036974643, lr:  0.000512, elapsed time:  116497
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 238000, eval loss: 0.019562342002318468, eval acc: 99.6045150756836
Step 238100, loss: 0.00778111612579778, acc: 99.75315977633, p_norm: 2054.226678233991, g_norm: 0.17958457620922955, lr:  0.000512, elapsed time:  116552
Step 238200, loss: 0.008405837246409647, acc: 99.73831748962402, p_norm: 2054.3678850725605, g_norm: 0.32241747911954277, lr:  0.000512, elapsed time:  116599
Step 238300, loss: 0.00792153692806096, acc: 99.74987784028053, p_norm: 2054.511260724054, g_norm: 0.12949434357342926, lr:  0.000512, elapsed time:  116646
Step 238400, loss: 0.007989869508110132, acc: 99.74542446434498, p_norm: 2054.6598154629105, g_norm: 0.32911201692854836, lr:  0.000512, elapsed time:  116694
Step 238500, loss: 0.008540601723052533, acc: 99.72884555161, p_norm: 2054.801208894371, g_norm: 0.12563970132629296, lr:  0.000512, elapsed time:  116742
Step 238600, loss: 0.008585635796589487, acc: 99.73004642128944, p_norm: 2054.950840913861, g_norm: 0.21332920148896925, lr:  0.000512, elapsed time:  116789
Step 238700, loss: 0.008517535003302329, acc: 99.72784574329853, p_norm: 2055.1035972081386, g_norm: 0.15075326659322255, lr:  0.000512, elapsed time:  116836
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 238800, loss: 0.007493254660766528, acc: 99.76444961711135, p_norm: 2055.253686124244, g_norm: 0.16893306309953718, lr:  0.000511, elapsed time:  116884
Step 238900, loss: 0.007384887101943604, acc: 99.76477397978306, p_norm: 2055.3791165805287, g_norm: 0.28156798674720085, lr:  0.000511, elapsed time:  116932
Step 239000, loss: 0.007902339032316377, acc: 99.74977719783783, p_norm: 2055.5175514848684, g_norm: 0.17471300944138263, lr:  0.000511, elapsed time:  116980
Step 239100, loss: 0.008140736570567242, acc: 99.7441228479147, p_norm: 2055.686103309867, g_norm: 0.19973188951138762, lr:  0.000511, elapsed time:  117028
Step 239200, loss: 0.008429091447287646, acc: 99.73204949498177, p_norm: 2055.8365673553094, g_norm: 0.15538063608937397, lr:  0.000511, elapsed time:  117074
Step 239300, loss: 0.008420836397208404, acc: 99.73410412669182, p_norm: 2055.97475981644, g_norm: 0.17909882592428955, lr:  0.000511, elapsed time:  117122
Step 239400, loss: 0.007958215874841698, acc: 99.7448711246252, p_norm: 2056.109452722703, g_norm: 0.1682568205993893, lr:  0.000511, elapsed time:  117169
Step 239500, loss: 0.00815919961135478, acc: 99.74143590033054, p_norm: 2056.251411562825, g_norm: 0.13939962571717784, lr:  0.000511, elapsed time:  117217
Step 239600, loss: 0.007918227270929492, acc: 99.75153639912605, p_norm: 2056.396963251334, g_norm: 0.19419644633520255, lr:  0.000511, elapsed time:  117264
Step 239700, loss: 0.0076398495704415835, acc: 99.7612286657095, p_norm: 2056.539933293369, g_norm: 0.18126026754518756, lr:  0.000510, elapsed time:  117312
Step 239800, loss: 0.007954309790584375, acc: 99.7471998333931, p_norm: 2056.6858891218662, g_norm: 0.21103626829736308, lr:  0.000510, elapsed time:  117359
Step 239900, loss: 0.00825107070908416, acc: 99.74071750044823, p_norm: 2056.8173103375166, g_norm: 0.18801016645727794, lr:  0.000510, elapsed time:  117407
Step 240000, loss: 0.008019919623184251, acc: 99.74592144787312, p_norm: 2056.958803016733, g_norm: 0.23185296742325748, lr:  0.000510, elapsed time:  117454
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 240000, eval loss: 0.018000613274052744, eval acc: 99.61790466308594
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C O C ( = O ) c 1 c c c 2 c ( c 1 ) C C ( C ) ( C ) C ( c 1 c n c c ( - c 3 c c c ( C ( C ) ( C ) C ) c c 3 ) c 1 ) N 2 _EOS
Predicted text: C C O C ( = O ) c 1 c c c 2 c ( c 1 ) C C ( C ) ( C ) C ( c 1 c n c c ( - c 3 c c c ( C ( C ) ( C ) C ) c c 3 ) c 1 ) N 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C c 1 c c c ( - c 2 c ( C # N ) c c c c 2 C # N ) c c 1 ) N C ( = O ) c 1 c ( Cl ) c c c c 1 Cl _EOS
Predicted text: C O C ( = O ) C ( C c 1 c c c ( - c 2 c c ( C # N ) c c ( C # N ) c 2 ) c c 1 ) N C ( = O ) c 1 c ( Cl ) c c c c 1 Cl _EOS
acc_token: 0.43859649122807015, acc_seq: False

Target text: C O C ( = O ) c 1 c c ( - c 2 c c c c c 2 ) c c c 1 C _EOS
Predicted text: C O C ( = O ) c 1 c c ( - c 2 c c c c c 2 ) c c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: c 1 c c c ( - c 2 n c c ( - c 3 c n c ( C 4 C C N C C 4 ) [nH] 3 ) c n 2 ) c c 1 _EOS
Predicted text: c 1 c c c ( - c 2 n c c ( - c 3 c [nH] c ( C 4 C C N C C 4 ) n 3 ) c n 2 ) c c 1 _EOS
acc_token: 0.95, acc_seq: False

Target text: O = C ( O ) c 1 c c c ( C ( O ) ( c 2 c c c ( Cl ) c c 2 ) c 2 c c c ( Cl ) c c 2 ) c c 1 C ( = O ) O _EOS
Predicted text: O = C ( O ) c 1 ) ( c 1 c c c ( Cl ) c c 1 ) c 1 c c c 2 c ( c 1 ) C ( = O ) O C 2 = O _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.27450980392156865, acc_seq: False

Evaluation (without teacher) at step 240000, eval acc (token): 0.9380865388057583, eval acc (sequence): 0.8888498065423848
Saving at step 240000
Step 240100, loss: 0.008278528199916764, acc: 99.73550501465797, p_norm: 2057.116474087803, g_norm: 0.176213340897521, lr:  0.000510, elapsed time:  117560
Step 240200, loss: 0.008041570579589461, acc: 99.74735443294048, p_norm: 2057.2624681529137, g_norm: 0.16793859097279543, lr:  0.000510, elapsed time:  117608
Step 240300, loss: 0.008087241179505327, acc: 99.74323871731758, p_norm: 2057.404233822284, g_norm: 0.18611231004614823, lr:  0.000510, elapsed time:  117656
Step 240400, loss: 0.008082213104789843, acc: 99.74724911153316, p_norm: 2057.542109549969, g_norm: 0.18847451576795798, lr:  0.000510, elapsed time:  117703
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 240500, loss: 0.007697724438353011, acc: 99.75167291040161, p_norm: 2057.6902425142566, g_norm: 0.20070815196262182, lr:  0.000510, elapsed time:  117752
Step 240600, loss: 0.007756507681497169, acc: 99.7468490600586, p_norm: 2057.8282924144687, g_norm: 0.10282420186432024, lr:  0.000510, elapsed time:  117799
Step 240700, loss: 0.007661673697948572, acc: 99.75971238315105, p_norm: 2057.9662777074504, g_norm: 0.14151762847427385, lr:  0.000509, elapsed time:  117847
Step 240800, loss: 0.007423753933217085, acc: 99.76497921347618, p_norm: 2058.0922757517915, g_norm: 0.15788139355654382, lr:  0.000509, elapsed time:  117895
Step 240900, loss: 0.007576648959566228, acc: 99.76296402513981, p_norm: 2058.2261039848436, g_norm: 0.12248447953725698, lr:  0.000509, elapsed time:  117942
Step 241000, loss: 0.00806083654347276, acc: 99.73744870722294, p_norm: 2058.3831614788633, g_norm: 0.18687347002704047, lr:  0.000509, elapsed time:  117990
Step 241100, loss: 0.00797729391226312, acc: 99.74742455780506, p_norm: 2058.5214661581767, g_norm: 0.16339820602590555, lr:  0.000509, elapsed time:  118037
Step 241200, loss: 0.008533594181058106, acc: 99.73170383274555, p_norm: 2058.6580556389235, g_norm: 0.38025570358322525, lr:  0.000509, elapsed time:  118084
Step 241300, loss: 0.007835288337546445, acc: 99.74746282398701, p_norm: 2058.8130950985537, g_norm: 0.15523403501722924, lr:  0.000509, elapsed time:  118132
Step 241400, loss: 0.008027289208366711, acc: 99.74808253347874, p_norm: 2058.9602455772683, g_norm: 0.18942478449303046, lr:  0.000509, elapsed time:  118179
Step 241500, loss: 0.008218618425453315, acc: 99.7370717972517, p_norm: 2059.1116839631823, g_norm: 0.16537751812534682, lr:  0.000509, elapsed time:  118227
Step 241600, loss: 0.008227637812688045, acc: 99.73543716967106, p_norm: 2059.261297310241, g_norm: 0.1976537697161202, lr:  0.000508, elapsed time:  118274
Step 241700, loss: 0.008777892448051716, acc: 99.72191753983498, p_norm: 2059.404726655614, g_norm: 0.17478955848393327, lr:  0.000508, elapsed time:  118321
Step 241800, loss: 0.008363319729432987, acc: 99.72808900475502, p_norm: 2059.5477231195287, g_norm: 0.17011253442438648, lr:  0.000508, elapsed time:  118368
Step 241900, loss: 0.007440841498955706, acc: 99.76649576425552, p_norm: 2059.693638325859, g_norm: 0.18978378499122073, lr:  0.000508, elapsed time:  118416
Step 242000, loss: 0.008395919588620017, acc: 99.73511093854904, p_norm: 2059.8480334095793, g_norm: 0.16194305252968388, lr:  0.000508, elapsed time:  118464
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 242000, eval loss: 0.0202816158902715, eval acc: 99.58624267578125
Step 242100, loss: 0.008293696943328542, acc: 99.73678514361382, p_norm: 2059.989749563728, g_norm: 0.12174925388149134, lr:  0.000508, elapsed time:  118519
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 242200, loss: 0.007836379048362676, acc: 99.74386958271339, p_norm: 2060.127072150587, g_norm: 0.2428588370382118, lr:  0.000508, elapsed time:  118567
Step 242300, loss: 0.007542312064324506, acc: 99.76058858633041, p_norm: 2060.254590187324, g_norm: 0.17875295739197872, lr:  0.000508, elapsed time:  118614
Step 242400, loss: 0.007644408843334532, acc: 99.75424446165562, p_norm: 2060.3939976110273, g_norm: 0.2298663643647861, lr:  0.000508, elapsed time:  118663
Step 242500, loss: 0.007995676211830869, acc: 99.74702359735966, p_norm: 2060.528128360114, g_norm: 0.2528394128830323, lr:  0.000508, elapsed time:  118710
Step 242600, loss: 0.008152151209033036, acc: 99.73993034660816, p_norm: 2060.6695620550627, g_norm: 0.2016652068638956, lr:  0.000507, elapsed time:  118758
Step 242700, loss: 0.0074722348227442125, acc: 99.76091541349888, p_norm: 2060.82041109305, g_norm: 0.13545815418100204, lr:  0.000507, elapsed time:  118806
Step 242800, loss: 0.007518441731535859, acc: 99.75814917683601, p_norm: 2060.9465024379997, g_norm: 0.16605809515969006, lr:  0.000507, elapsed time:  118854
Step 242900, loss: 0.00781320552676334, acc: 99.75168633460999, p_norm: 2061.0792208864414, g_norm: 0.16748363343524614, lr:  0.000507, elapsed time:  118901
Step 243000, loss: 0.008775082397041842, acc: 99.72088214755058, p_norm: 2061.2291313444807, g_norm: 0.12257858129256731, lr:  0.000507, elapsed time:  118948
Step 243100, loss: 0.007703237339901534, acc: 99.75819346308708, p_norm: 2061.3659702581613, g_norm: 0.15436674564957006, lr:  0.000507, elapsed time:  118995
Step 243200, loss: 0.008111989610752062, acc: 99.74209134280682, p_norm: 2061.505411510171, g_norm: 0.22921019081446573, lr:  0.000507, elapsed time:  119042
Step 243300, loss: 0.008266586127083428, acc: 99.74273605644703, p_norm: 2061.656210220792, g_norm: 0.09581536067298983, lr:  0.000507, elapsed time:  119090
Step 243400, loss: 0.007920489564930903, acc: 99.74676187336445, p_norm: 2061.8071819256634, g_norm: 0.17448026649808673, lr:  0.000507, elapsed time:  119137
Step 243500, loss: 0.007742117976995359, acc: 99.75402180850506, p_norm: 2061.952793522228, g_norm: 0.1427793303123491, lr:  0.000506, elapsed time:  119185
Step 243600, loss: 0.008244933234254858, acc: 99.73703534901142, p_norm: 2062.0853594189853, g_norm: 0.16163627749399267, lr:  0.000506, elapsed time:  119232
Step 243700, loss: 0.008001108130101783, acc: 99.74622522294521, p_norm: 2062.234325686788, g_norm: 0.20374964587062142, lr:  0.000506, elapsed time:  119280
Step 243800, loss: 0.008042600404733093, acc: 99.74714136123657, p_norm: 2062.368510958958, g_norm: 0.19936197141409126, lr:  0.000506, elapsed time:  119327
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 243900, loss: 0.0076757762171882635, acc: 99.75311412147029, p_norm: 2062.5256554745274, g_norm: 0.17586626162764127, lr:  0.000506, elapsed time:  119376
Step 244000, loss: 0.0075315734001469535, acc: 99.76024870574474, p_norm: 2062.667518340737, g_norm: 0.2902425214093739, lr:  0.000506, elapsed time:  119424
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 244000, eval loss: 0.01746228015770613, eval acc: 99.63288879394531
Step 244100, loss: 0.008000827974756248, acc: 99.74682462215424, p_norm: 2062.814702696575, g_norm: 0.1605971324156695, lr:  0.000506, elapsed time:  119479
Step 244200, loss: 0.007617340666292875, acc: 99.75942797958851, p_norm: 2062.9546479778455, g_norm: 0.15630156621509975, lr:  0.000506, elapsed time:  119526
Step 244300, loss: 0.008274919345840317, acc: 99.73609499633312, p_norm: 2063.0978047036456, g_norm: 0.1770898135773741, lr:  0.000506, elapsed time:  119574
Step 244400, loss: 0.007362284674090915, acc: 99.76864778995514, p_norm: 2063.2432392173628, g_norm: 0.19380128240367783, lr:  0.000506, elapsed time:  119621
Step 244500, loss: 0.008061922161959955, acc: 99.74542355537415, p_norm: 2063.381948429467, g_norm: 0.1522721208259409, lr:  0.000505, elapsed time:  119669
Step 244600, loss: 0.0077039674640218435, acc: 99.76104602217674, p_norm: 2063.50099844271, g_norm: 0.1757881677839604, lr:  0.000505, elapsed time:  119716
Step 244700, loss: 0.008497961365865194, acc: 99.73614272475243, p_norm: 2063.6524079794085, g_norm: 0.13563254452340215, lr:  0.000505, elapsed time:  119763
Step 244800, loss: 0.008389179420537402, acc: 99.73410569131374, p_norm: 2063.8026073525125, g_norm: 0.20020395309317907, lr:  0.000505, elapsed time:  119810
Step 244900, loss: 0.0077406444902135265, acc: 99.75276903808117, p_norm: 2063.9399614587737, g_norm: 0.2080936735874797, lr:  0.000505, elapsed time:  119858
Step 245000, loss: 0.0076928892576506765, acc: 99.75876532495022, p_norm: 2064.0685266650044, g_norm: 0.222089485702438, lr:  0.000505, elapsed time:  119906
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C C C C 1 C C N ( C C C n 2 c ( = O ) o c 3 c ( Br ) c c ( Br ) c c 3 2 ) C C 1 _EOS
Predicted text: C C C C C 1 C C N ( C C C n 2 c ( = O ) o c 3 c ( Br ) c c ( Br ) c c 3 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = c 1 c ( O c 2 c c c c c 2 ) c c ( - c 2 c c c c n 2 ) c n 1 - c 1 c c c c c 1 _EOS
Predicted text: O = c 1 c ( O c 2 c c c c c 2 ) c c ( - c 2 c c c c n 2 ) c n 1 - c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C = N c 1 c ( C # N ) c ( = O ) n ( C ) c ( = O ) n 1 C _EOS
Predicted text: C N ( C ) C = N c 1 c ( C # N ) c ( = O ) n ( C ) c ( = O ) n 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C ( = O ) O ) s c 2 n c n c ( N c 3 c c c ( F ) c c 3 O C 3 C C O C C 3 ) c 1 2 _EOS
Predicted text: C c 1 c ( C ( = O ) O ) s c 2 n c n c ( N c 3 c c c ( F ) c c 3 O C 3 C C O C C 3 ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 N C C ( C O c 2 c c c c ( Cl ) c 2 ) O 1 _EOS
Predicted text: O = C 1 N C C ( C O c 2 c c c c ( Cl ) c 2 ) O 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 245000, eval acc (token): 0.9421164279739707, eval acc (sequence): 0.8973152022315202
Saving at step 245000
Step 245100, loss: 0.007798621194924635, acc: 99.75571498274803, p_norm: 2064.2194462255898, g_norm: 0.10897878811377282, lr:  0.000505, elapsed time:  120019
Step 245200, loss: 0.008178767378612974, acc: 99.74167843163013, p_norm: 2064.3544777964958, g_norm: 0.15948853132721594, lr:  0.000505, elapsed time:  120067
Step 245300, loss: 0.00800390994811096, acc: 99.74296949803829, p_norm: 2064.50610728886, g_norm: 0.20066141030554352, lr:  0.000505, elapsed time:  120114
Step 245400, loss: 0.007906219485703333, acc: 99.74259366095066, p_norm: 2064.6557991463774, g_norm: 0.18050478260411007, lr:  0.000505, elapsed time:  120162
Step 245500, loss: 0.008666115639789496, acc: 99.72427020967007, p_norm: 2064.7953185142915, g_norm: 0.22426179785153524, lr:  0.000504, elapsed time:  120209
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 245600, loss: 0.007681818609447282, acc: 99.75601974551199, p_norm: 2064.931057492511, g_norm: 0.18429210739188992, lr:  0.000504, elapsed time:  120258
Step 245700, loss: 0.00767598273706426, acc: 99.75351478159428, p_norm: 2065.0666336925756, g_norm: 0.17709538010914874, lr:  0.000504, elapsed time:  120305
Step 245800, loss: 0.007657996011967043, acc: 99.76307171583176, p_norm: 2065.188568339967, g_norm: 0.15917393692547255, lr:  0.000504, elapsed time:  120353
Step 245900, loss: 0.007639293510255812, acc: 99.75596870481968, p_norm: 2065.322281026179, g_norm: 0.15271055862517632, lr:  0.000504, elapsed time:  120400
Step 246000, loss: 0.00746666922057102, acc: 99.75926458835602, p_norm: 2065.4575680373814, g_norm: 0.14020986512983233, lr:  0.000504, elapsed time:  120449
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 246000, eval loss: 0.018324942423641924, eval acc: 99.60704040527344
Step 246100, loss: 0.008221225763227267, acc: 99.73885206878185, p_norm: 2065.6031727902937, g_norm: 0.1396716840352523, lr:  0.000504, elapsed time:  120503
Step 246200, loss: 0.00765871722216616, acc: 99.75957022607327, p_norm: 2065.762296828413, g_norm: 0.16698635418549143, lr:  0.000504, elapsed time:  120551
Step 246300, loss: 0.007751031418065395, acc: 99.75143595039845, p_norm: 2065.9080335881754, g_norm: 0.23326873758707864, lr:  0.000504, elapsed time:  120598
Step 246400, loss: 0.0076968247391505425, acc: 99.754435390234, p_norm: 2066.042067214871, g_norm: 0.2904424197796805, lr:  0.000503, elapsed time:  120646
Step 246500, loss: 0.007971985820186092, acc: 99.74219603836536, p_norm: 2066.1749490694897, g_norm: 0.12623413560470026, lr:  0.000503, elapsed time:  120692
Step 246600, loss: 0.007575566494924715, acc: 99.75928355753422, p_norm: 2066.2984523105915, g_norm: 0.14805741973972167, lr:  0.000503, elapsed time:  120740
Step 246700, loss: 0.007480589755705296, acc: 99.76740334928036, p_norm: 2066.436553661121, g_norm: 0.1990743919879119, lr:  0.000503, elapsed time:  120787
Step 246800, loss: 0.007988284067323548, acc: 99.74493269622326, p_norm: 2066.5821928420323, g_norm: 0.10278166008288826, lr:  0.000503, elapsed time:  120834
Step 246900, loss: 0.008009676287510956, acc: 99.74930499494076, p_norm: 2066.721238519097, g_norm: 0.15079307193356162, lr:  0.000503, elapsed time:  120882
Step 247000, loss: 0.008749881802868913, acc: 99.723299279809, p_norm: 2066.870257280321, g_norm: 0.307087312693936, lr:  0.000503, elapsed time:  120929
Step 247100, loss: 0.008263674964327948, acc: 99.73624187707901, p_norm: 2067.009925589887, g_norm: 0.13544410099169243, lr:  0.000503, elapsed time:  120976
Step 247200, loss: 0.007885371357115218, acc: 99.74751175940037, p_norm: 2067.1444296019554, g_norm: 0.25611876136578365, lr:  0.000503, elapsed time:  121024
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 247300, loss: 0.007673853758605406, acc: 99.7564407939059, p_norm: 2067.272511152296, g_norm: 0.1649873673123548, lr:  0.000503, elapsed time:  121073
Step 247400, loss: 0.007714426238235319, acc: 99.75616462528706, p_norm: 2067.402254742039, g_norm: 0.2611833598160197, lr:  0.000502, elapsed time:  121120
Step 247500, loss: 0.007852844723147427, acc: 99.754354596138, p_norm: 2067.557587501528, g_norm: 0.17891427072529725, lr:  0.000502, elapsed time:  121168
Step 247600, loss: 0.007435771640484745, acc: 99.75764687359333, p_norm: 2067.6856761182794, g_norm: 0.20949786056446423, lr:  0.000502, elapsed time:  121215
Step 247700, loss: 0.00790828750471519, acc: 99.74908782541752, p_norm: 2067.827887562123, g_norm: 0.2088539944861185, lr:  0.000502, elapsed time:  121262
Step 247800, loss: 0.008046363824105356, acc: 99.74765744805336, p_norm: 2067.964008944835, g_norm: 0.13123375256937356, lr:  0.000502, elapsed time:  121310
Step 247900, loss: 0.007785569483821746, acc: 99.75048775970936, p_norm: 2068.110111824742, g_norm: 0.23400062642904407, lr:  0.000502, elapsed time:  121357
Step 248000, loss: 0.007357486761902692, acc: 99.76335237920284, p_norm: 2068.249003228273, g_norm: 0.2881299619036721, lr:  0.000502, elapsed time:  121405
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 248000, eval loss: 0.01767977638709454, eval acc: 99.64851379394531
Step 248100, loss: 0.007869780846267532, acc: 99.75259967148304, p_norm: 2068.388252491703, g_norm: 0.21613830733712958, lr:  0.000502, elapsed time:  121459
Step 248200, loss: 0.007845146327108523, acc: 99.7525130212307, p_norm: 2068.5297818531017, g_norm: 0.22424421659921073, lr:  0.000502, elapsed time:  121507
Step 248300, loss: 0.007899831656795869, acc: 99.74390086531639, p_norm: 2068.655384129794, g_norm: 0.1294112833227206, lr:  0.000502, elapsed time:  121554
Step 248400, loss: 0.007817846816651581, acc: 99.75838531553745, p_norm: 2068.8294167911845, g_norm: 0.14441189411830554, lr:  0.000501, elapsed time:  121601
Step 248500, loss: 0.008082478992200777, acc: 99.74006325006485, p_norm: 2068.9846842192032, g_norm: 0.1544037546790758, lr:  0.000501, elapsed time:  121649
Step 248600, loss: 0.008422253547578293, acc: 99.73203510046005, p_norm: 2069.1135567885403, g_norm: 0.1854744940607595, lr:  0.000501, elapsed time:  121706
Step 248700, loss: 0.0079110684591069, acc: 99.74836422502995, p_norm: 2069.253199401747, g_norm: 0.17699193892808956, lr:  0.000501, elapsed time:  121755
Step 248800, loss: 0.007737240334536182, acc: 99.75689454376698, p_norm: 2069.391680346488, g_norm: 0.20190015489453017, lr:  0.000501, elapsed time:  121802
Step 248900, loss: 0.007660610782331787, acc: 99.75577820837498, p_norm: 2069.5153064291303, g_norm: 0.26198462666705874, lr:  0.000501, elapsed time:  121849
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 249000, loss: 0.007705981516459536, acc: 99.75912519187548, p_norm: 2069.654733371629, g_norm: 0.30741752307520887, lr:  0.000501, elapsed time:  121897
Step 249100, loss: 0.007357552685461997, acc: 99.76447792351246, p_norm: 2069.768298678076, g_norm: 0.15562070602160866, lr:  0.000501, elapsed time:  121944
Step 249200, loss: 0.007193214166109101, acc: 99.77302481234074, p_norm: 2069.9006120180284, g_norm: 0.19289671982227374, lr:  0.000501, elapsed time:  121992
Step 249300, loss: 0.007792818388243177, acc: 99.74711337685585, p_norm: 2070.029953666892, g_norm: 0.1964063982004435, lr:  0.000501, elapsed time:  122039
Step 249400, loss: 0.007865778109116945, acc: 99.74309575557709, p_norm: 2070.1700585348744, g_norm: 0.20336366472995127, lr:  0.000500, elapsed time:  122087
Step 249500, loss: 0.007474253577474883, acc: 99.76804485917091, p_norm: 2070.2952549228826, g_norm: 0.21709933068327145, lr:  0.000500, elapsed time:  122134
Step 249600, loss: 0.008067587652876683, acc: 99.75091996788979, p_norm: 2070.4262378431868, g_norm: 0.13956201509094723, lr:  0.000500, elapsed time:  122181
Step 249700, loss: 0.008119809035670188, acc: 99.74276886880398, p_norm: 2070.5692361413217, g_norm: 0.17363714410683526, lr:  0.000500, elapsed time:  122229
Step 249800, loss: 0.007562887594831409, acc: 99.75598974525928, p_norm: 2070.704552860601, g_norm: 0.20166723637541592, lr:  0.000500, elapsed time:  122276
Step 249900, loss: 0.008248521414880089, acc: 99.73870025575161, p_norm: 2070.8442326249033, g_norm: 0.2240196084254677, lr:  0.000500, elapsed time:  122324
Step 250000, loss: 0.008042563281287584, acc: 99.74726897478104, p_norm: 2070.979012611649, g_norm: 0.10154738706896087, lr:  0.000500, elapsed time:  122372
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 250000, eval loss: 0.019129802319766902, eval acc: 99.61267852783203
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c ( N 2 C C N ( C ( = O ) c 3 c c c c ( - c 4 c n c 5 c ( c 4 ) N ( C c 4 c c ( Cl ) c c c 4 C ( F ) ( F ) F ) C C N 5 ) c 3 ) C C 2 ) c 2 c c c c c 2 n 1 _EOS
Predicted text: C c 1 c c ( N 2 C C N ( C ( = O ) c 3 c c c c ( - c 4 c n c 5 c ( c 4 ) N ( C c 4 c c ( Cl ) c c c 4 C ( F ) ( F ) F ) C C N 5 ) c 3 ) C C 2 ) c 2 c c c c c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C = C C C = C C C C C C C C C O C ( C O C ( = O ) C C C ( = O ) O ) C N ( C ) C _EOS
Predicted text: C C C C C C = C C C = C C C C C C C C C O C ( C O C ( = O ) C C C ( = O ) O ) C N ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( O c 1 c c c c ( C ( F ) ( F ) F ) c 1 ) c 1 c c c ( O c 2 c c c ( C ( C ) ( C ) C ) c c 2 ) c c 1 _EOS
Predicted text: C O C ( = O ) C ( O c 1 c c c c ( C ( F ) ( F ) F ) c 1 ) c 1 c c c ( O c 2 c c c ( C ( C ) ( C ) C ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C S c 1 c n c ( N C ( = O ) N ( C C 2 C C C C 2 ) c 2 c c c ( F ) c ( C ( F ) ( F ) F ) c 2 ) s 1 _EOS
Predicted text: O = C ( O ) C S c 1 c n c ( N C ( = O ) N ( C C 2 C C C C 2 ) c 2 c c c ( F ) c ( C ( F ) ( F ) F ) c 2 ) s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C ( O ) c 1 c c c 2 c ( c 1 ) c ( C c 1 c c c ( C ( = O ) O C ) c c 1 O C ) c n 2 C C C _EOS
Predicted text: C = C C ( O ) c 1 c c c 2 c ( c 1 ) c ( C c 1 c c c ( C ( = O ) O C ) c c 1 O C ) c n 2 C C C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 250000, eval acc (token): 0.9422289748424997, eval acc (sequence): 0.8966350301984469
Saving at step 250000
Step 250100, loss: 0.007216352939976787, acc: 99.77525341510773, p_norm: 2071.124799885471, g_norm: 0.11641712662882207, lr:  0.000500, elapsed time:  122479
Step 250200, loss: 0.007572335746745012, acc: 99.75709043443203, p_norm: 2071.248643861148, g_norm: 0.18921955803200302, lr:  0.000500, elapsed time:  122527
Step 250300, loss: 0.007866324543283554, acc: 99.75212466716766, p_norm: 2071.378396693073, g_norm: 0.1325353374566127, lr:  0.000500, elapsed time:  122574
Step 250400, loss: 0.007709325584146427, acc: 99.7632417678833, p_norm: 2071.552687253771, g_norm: 0.26969550916557433, lr:  0.000499, elapsed time:  122622
Step 250500, loss: 0.007905066731909756, acc: 99.74819128215313, p_norm: 2071.6823952236914, g_norm: 0.2527934010054365, lr:  0.000499, elapsed time:  122670
Step 250600, loss: 0.008246103080364265, acc: 99.7337826937437, p_norm: 2071.8183115489583, g_norm: 0.16386802348969634, lr:  0.000499, elapsed time:  122724
Calling G2SDataset.batch()
Done, time:  0.68 s, total batches: 6822
Step 250700, loss: 0.007503367849327676, acc: 99.76149671722582, p_norm: 2071.957812306473, g_norm: 0.18553514155984638, lr:  0.000499, elapsed time:  122781
Step 250800, loss: 0.007478978094641206, acc: 99.7596043497324, p_norm: 2072.0892340660516, g_norm: 0.1608961925547988, lr:  0.000499, elapsed time:  122837
Step 250900, loss: 0.007203458212134137, acc: 99.76889863610268, p_norm: 2072.2244163832675, g_norm: 0.35546929196473587, lr:  0.000499, elapsed time:  122894
Step 251000, loss: 0.007467632298030367, acc: 99.76597689092159, p_norm: 2072.3665083586307, g_norm: 0.15041332881828817, lr:  0.000499, elapsed time:  122945
Step 251100, loss: 0.008253514759544486, acc: 99.74170286953449, p_norm: 2072.4964270814435, g_norm: 0.18554540232049713, lr:  0.000499, elapsed time:  122992
Step 251200, loss: 0.007697202487051981, acc: 99.76303009688854, p_norm: 2072.6385667301574, g_norm: 0.1398901888023133, lr:  0.000499, elapsed time:  123040
Step 251300, loss: 0.008270179961182294, acc: 99.73996412754059, p_norm: 2072.766551243413, g_norm: 0.20681955405686706, lr:  0.000499, elapsed time:  123087
Step 251400, loss: 0.00728115404919663, acc: 99.76606673002243, p_norm: 2072.886441534992, g_norm: 0.13745222389065634, lr:  0.000498, elapsed time:  123134
Step 251500, loss: 0.007839671134443052, acc: 99.74827466905117, p_norm: 2073.0187263436833, g_norm: 0.13853073816291583, lr:  0.000498, elapsed time:  123182
Step 251600, loss: 0.007881563275986991, acc: 99.7515218257904, p_norm: 2073.1640557559263, g_norm: 0.16071174098090588, lr:  0.000498, elapsed time:  123229
Step 251700, loss: 0.007643133955025405, acc: 99.76087212562561, p_norm: 2073.282250960386, g_norm: 0.1191972977777976, lr:  0.000498, elapsed time:  123276
Step 251800, loss: 0.007670859491408919, acc: 99.75449076294899, p_norm: 2073.4208512933424, g_norm: 0.10449562093756588, lr:  0.000498, elapsed time:  123324
Step 251900, loss: 0.007839550728995164, acc: 99.74750573933125, p_norm: 2073.5560730940915, g_norm: 0.19968607610549396, lr:  0.000498, elapsed time:  123372
Step 252000, loss: 0.007840518774719385, acc: 99.75367999076843, p_norm: 2073.7048076365054, g_norm: 0.2227891130587946, lr:  0.000498, elapsed time:  123420
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 252000, eval loss: 0.018372213098919024, eval acc: 99.61865997314453
Step 252100, loss: 0.0077241700601098275, acc: 99.75471316277981, p_norm: 2073.854961972131, g_norm: 0.23553577014849897, lr:  0.000498, elapsed time:  123474
Step 252200, loss: 0.007786921571132552, acc: 99.75918500125408, p_norm: 2073.989276540675, g_norm: 0.13856864852607476, lr:  0.000498, elapsed time:  123522
Step 252300, loss: 0.007571303227377939, acc: 99.75918470323086, p_norm: 2074.1128911816445, g_norm: 0.17935064780792426, lr:  0.000498, elapsed time:  123570
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 252400, loss: 0.008022904378247321, acc: 99.7461620699707, p_norm: 2074.25114330306, g_norm: 0.47127981144500874, lr:  0.000497, elapsed time:  123617
Step 252500, loss: 0.0072310254662897935, acc: 99.77264994382858, p_norm: 2074.391355995807, g_norm: 0.13177476060242285, lr:  0.000497, elapsed time:  123664
Step 252600, loss: 0.007439899550081464, acc: 99.76667203009129, p_norm: 2074.5135716359764, g_norm: 0.3073345840917346, lr:  0.000497, elapsed time:  123712
Step 252700, loss: 0.007800621700316697, acc: 99.75233362615108, p_norm: 2074.6507468566497, g_norm: 0.16788110681046442, lr:  0.000497, elapsed time:  123759
Step 252800, loss: 0.007466726868815385, acc: 99.76230253279209, p_norm: 2074.7889523177028, g_norm: 0.24427201468858062, lr:  0.000497, elapsed time:  123807
Step 252900, loss: 0.008095187531362171, acc: 99.74326539039612, p_norm: 2074.9214646826454, g_norm: 0.18341753444419617, lr:  0.000497, elapsed time:  123854
Step 253000, loss: 0.007239086068366305, acc: 99.7715570628643, p_norm: 2075.063990488386, g_norm: 0.1520549851509698, lr:  0.000497, elapsed time:  123902
Step 253100, loss: 0.0077213150385614425, acc: 99.75257579982281, p_norm: 2075.2012422681623, g_norm: 0.1075417346584088, lr:  0.000497, elapsed time:  123950
Step 253200, loss: 0.007413078612007667, acc: 99.76087874174118, p_norm: 2075.336872988445, g_norm: 0.22016703393827985, lr:  0.000497, elapsed time:  123998
Step 253300, loss: 0.007920812067677616, acc: 99.74928949773312, p_norm: 2075.4738115933333, g_norm: 0.11657043587974754, lr:  0.000497, elapsed time:  124045
Step 253400, loss: 0.008347816304012667, acc: 99.73749361932278, p_norm: 2075.623860666775, g_norm: 0.19549253500882346, lr:  0.000496, elapsed time:  124092
Step 253500, loss: 0.007714194030777435, acc: 99.7617086917162, p_norm: 2075.749755930734, g_norm: 0.2541440674558275, lr:  0.000496, elapsed time:  124140
Step 253600, loss: 0.007650114665329966, acc: 99.75949327647686, p_norm: 2075.89344075361, g_norm: 0.16008900540152624, lr:  0.000496, elapsed time:  124187
Step 253700, loss: 0.007903517396771349, acc: 99.75258359313011, p_norm: 2076.052869999084, g_norm: 0.26145700918779624, lr:  0.000496, elapsed time:  124235
Step 253800, loss: 0.007670907317697128, acc: 99.76015137135983, p_norm: 2076.176805287436, g_norm: 0.1520533348417857, lr:  0.000496, elapsed time:  124283
Step 253900, loss: 0.008222840269190783, acc: 99.74135234951973, p_norm: 2076.3107599665477, g_norm: 0.15393853906857133, lr:  0.000496, elapsed time:  124330
Step 254000, loss: 0.00804816920808662, acc: 99.74564927816391, p_norm: 2076.448430882961, g_norm: 0.19547592327323346, lr:  0.000496, elapsed time:  124377
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 254000, eval loss: 0.019065883177099757, eval acc: 99.614990234375
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 254100, loss: 0.00814252121351423, acc: 99.73758798630084, p_norm: 2076.5993356034905, g_norm: 0.20995606378913464, lr:  0.000496, elapsed time:  124433
Step 254200, loss: 0.007850071257562376, acc: 99.75043088197708, p_norm: 2076.7483639415636, g_norm: 0.22373670761300637, lr:  0.000496, elapsed time:  124481
Step 254300, loss: 0.007516668221587679, acc: 99.75970493257046, p_norm: 2076.889403670153, g_norm: 0.2568128810792114, lr:  0.000496, elapsed time:  124528
Step 254400, loss: 0.0074018266057464645, acc: 99.76291759312153, p_norm: 2077.014571654062, g_norm: 0.1467171752252007, lr:  0.000496, elapsed time:  124576
Step 254500, loss: 0.007636460539870314, acc: 99.75842227041721, p_norm: 2077.13933317568, g_norm: 0.14497506897538207, lr:  0.000495, elapsed time:  124623
Step 254600, loss: 0.008321712798442604, acc: 99.73822136223316, p_norm: 2077.269976445376, g_norm: 0.1671312409830784, lr:  0.000495, elapsed time:  124671
Step 254700, loss: 0.007739862328526215, acc: 99.75512427091599, p_norm: 2077.40072557129, g_norm: 0.17671375075801113, lr:  0.000495, elapsed time:  124718
Step 254800, loss: 0.008010491326149349, acc: 99.74362456798553, p_norm: 2077.5430298617684, g_norm: 0.1726422556838916, lr:  0.000495, elapsed time:  124766
Step 254900, loss: 0.007425644613613258, acc: 99.76443727314472, p_norm: 2077.670012255688, g_norm: 0.20464664170167432, lr:  0.000495, elapsed time:  124814
Step 255000, loss: 0.0077412572133653155, acc: 99.75365941226482, p_norm: 2077.7952809171975, g_norm: 0.23716571625531627, lr:  0.000495, elapsed time:  124861
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c c ( C O c 2 c c c n c 2 N C ( = S ) N c 2 c c c ( Cl ) c c 2 ) c ( F ) c 1 _EOS
Predicted text: C O c 1 c c c ( C O c 2 c c c n c 2 N C ( = S ) N c 2 c c c ( Cl ) c c 2 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c 2 c c ( C ( = O ) N C c 3 c c c ( Cl ) c ( O c 4 c c ( Cl ) c c ( C # N ) c 4 ) c 3 F ) [nH] c 1 2 _EOS
Predicted text: C c 1 c c c c 2 c c ( C ( = O ) N C c 3 c c c ( Cl ) c ( O c 4 c c ( Cl ) c c ( C # N ) c 4 ) c 3 F ) [nH] c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C n 1 c ( = O ) c 2 [nH] c ( - c 3 c n n ( C C ( = O ) N 4 C C N ( c 5 c c c c ( C ( F ) ( F ) F ) c 5 ) C C 4 ) c 3 ) n c 2 n ( C C C ) c 1 = O _EOS
Predicted text: C C C n 1 c ( = O ) c 2 [nH] c ( - c 3 c n n ( C C ( = O ) N 4 C C N ( c 5 c c c c ( C ( F ) ( F ) F ) c 5 ) C C 4 ) c 3 ) n c 2 n ( C C C ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c c ( C O ) c c ( C ( = O ) O C C ) c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c c ( C O ) c c ( C ( = O ) O C C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N 1 C ( = O ) C N C c 2 c c ( O C ) c ( N c 3 n c c ( Cl ) c ( N c 4 c c c c c 4 S ( = O ) ( = O ) C ( C ) C ) n 3 ) c c 2 1 _EOS
Predicted text: C C N 1 C ( = O ) C N C c 2 c c ( O C ) c ( N c 3 n c c ( Cl ) c ( N c 4 c c c c c 4 S ( = O ) ( = O ) C ( C ) C ) n 3 ) c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 255000, eval acc (token): 0.9413121095779725, eval acc (sequence): 0.8940149625935162
Saving at step 255000
Step 255100, loss: 0.007889859549122776, acc: 99.75582212209702, p_norm: 2077.9278980017148, g_norm: 0.13050638134841558, lr:  0.000495, elapsed time:  124963
Step 255200, loss: 0.007677776065465877, acc: 99.7491877824068, p_norm: 2078.050596589489, g_norm: 0.1552858405610824, lr:  0.000495, elapsed time:  125010
Step 255300, loss: 0.007668085266341222, acc: 99.75876864790916, p_norm: 2078.176232522085, g_norm: 0.24794808764399945, lr:  0.000495, elapsed time:  125057
Step 255400, loss: 0.007727414817727549, acc: 99.75557240843773, p_norm: 2078.3187966503256, g_norm: 0.1664232499267955, lr:  0.000495, elapsed time:  125105
Step 255500, loss: 0.00780003373612999, acc: 99.75659167766571, p_norm: 2078.4522697927523, g_norm: 0.32650044244018034, lr:  0.000494, elapsed time:  125153
Step 255600, loss: 0.007369416843575891, acc: 99.7617005854845, p_norm: 2078.5838724881964, g_norm: 0.1544717432912608, lr:  0.000494, elapsed time:  125200
Step 255700, loss: 0.007694079427310498, acc: 99.75071923434734, p_norm: 2078.7154678457464, g_norm: 0.21085414635354388, lr:  0.000494, elapsed time:  125248
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 255800, loss: 0.00722819220853297, acc: 99.76805627493941, p_norm: 2078.852581023536, g_norm: 0.2533847343447237, lr:  0.000494, elapsed time:  125297
Step 255900, loss: 0.007453847447263798, acc: 99.75801201164722, p_norm: 2078.987339960108, g_norm: 0.17602984854431394, lr:  0.000494, elapsed time:  125345
Step 256000, loss: 0.007374180123515543, acc: 99.75920097529888, p_norm: 2079.1264508053146, g_norm: 0.1972639967560465, lr:  0.000494, elapsed time:  125392
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 256000, eval loss: 0.01912406449206173, eval acc: 99.62268829345703
Step 256100, loss: 0.00738278510480086, acc: 99.76241567730904, p_norm: 2079.2485888812753, g_norm: 0.16841787402479808, lr:  0.000494, elapsed time:  125447
Step 256200, loss: 0.007368031613668791, acc: 99.76023778319359, p_norm: 2079.3949104748626, g_norm: 0.13043067614086695, lr:  0.000494, elapsed time:  125495
Step 256300, loss: 0.007884979065038352, acc: 99.74540022015572, p_norm: 2079.5522347390333, g_norm: 0.13708147157117245, lr:  0.000494, elapsed time:  125543
Step 256400, loss: 0.0075127330240047745, acc: 99.75838991999626, p_norm: 2079.677472671765, g_norm: 0.09740722062010203, lr:  0.000494, elapsed time:  125590
Step 256500, loss: 0.00788504241971168, acc: 99.74774044752121, p_norm: 2079.8087987365475, g_norm: 0.23858760442802954, lr:  0.000493, elapsed time:  125638
Step 256600, loss: 0.007673663144705642, acc: 99.75511002540588, p_norm: 2079.9487349589085, g_norm: 0.1858639193682522, lr:  0.000493, elapsed time:  125686
Step 256700, loss: 0.007511591985785344, acc: 99.76118610799313, p_norm: 2080.0688347759615, g_norm: 0.19892009359838111, lr:  0.000493, elapsed time:  125733
Step 256800, loss: 0.0076942885637072325, acc: 99.75856655836105, p_norm: 2080.2036401075397, g_norm: 0.2107600021459623, lr:  0.000493, elapsed time:  125781
Step 256900, loss: 0.007704178424392012, acc: 99.75947485864162, p_norm: 2080.346260892078, g_norm: 0.11057169823561512, lr:  0.000493, elapsed time:  125828
Step 257000, loss: 0.007708264637276443, acc: 99.75602927803993, p_norm: 2080.478614646169, g_norm: 0.15094897541233626, lr:  0.000493, elapsed time:  125876
Step 257100, loss: 0.007924069338860135, acc: 99.7474106401205, p_norm: 2080.6201150882603, g_norm: 0.14240185776869327, lr:  0.000493, elapsed time:  125924
Step 257200, loss: 0.00758031690329517, acc: 99.75468000769615, p_norm: 2080.757288737916, g_norm: 0.21642593327867116, lr:  0.000493, elapsed time:  125972
Step 257300, loss: 0.008054184913598874, acc: 99.74466714262962, p_norm: 2080.8891873544408, g_norm: 0.1377215092284631, lr:  0.000493, elapsed time:  126019
Step 257400, loss: 0.008422448211713346, acc: 99.73799741268158, p_norm: 2081.0337914748225, g_norm: 0.2088104494318139, lr:  0.000493, elapsed time:  126066
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6822
Step 257500, loss: 0.0072220350673608035, acc: 99.774666430045, p_norm: 2081.16843693172, g_norm: 0.15356990123279335, lr:  0.000493, elapsed time:  126115
Step 257600, loss: 0.006762542834185297, acc: 99.78491222858429, p_norm: 2081.286441537769, g_norm: 0.15165315559036693, lr:  0.000492, elapsed time:  126163
Step 257700, loss: 0.00730823432753823, acc: 99.7685976922512, p_norm: 2081.421420285099, g_norm: 0.16433475113632764, lr:  0.000492, elapsed time:  126211
Step 257800, loss: 0.007513880066762795, acc: 99.76196919381618, p_norm: 2081.5547488519737, g_norm: 0.23168704806299467, lr:  0.000492, elapsed time:  126258
Step 257900, loss: 0.00772049638810131, acc: 99.7572033405304, p_norm: 2081.6795081339956, g_norm: 0.25170745059300975, lr:  0.000492, elapsed time:  126306
Step 258000, loss: 0.007549924052800634, acc: 99.75953863561153, p_norm: 2081.80896736719, g_norm: 0.19393502841613014, lr:  0.000492, elapsed time:  126354
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 258000, eval loss: 0.01785815349059704, eval acc: 99.62823486328125
Step 258100, loss: 0.007447714991849352, acc: 99.7622993439436, p_norm: 2081.9448066593595, g_norm: 0.12899038858280187, lr:  0.000492, elapsed time:  126408
Step 258200, loss: 0.007431945877433463, acc: 99.76128770411015, p_norm: 2082.066862734713, g_norm: 0.24069738799055962, lr:  0.000492, elapsed time:  126455
Step 258300, loss: 0.0075007745480615996, acc: 99.76255102455616, p_norm: 2082.200322707522, g_norm: 0.1467289303244458, lr:  0.000492, elapsed time:  126503
Step 258400, loss: 0.007732564458128763, acc: 99.75670205056667, p_norm: 2082.3353417117664, g_norm: 0.18088695605060995, lr:  0.000492, elapsed time:  126551
Step 258500, loss: 0.007854963274166949, acc: 99.75705322623253, p_norm: 2082.474443507796, g_norm: 0.13448209405211217, lr:  0.000492, elapsed time:  126598
Step 258600, loss: 0.006925757447879733, acc: 99.78059659898281, p_norm: 2082.605927347592, g_norm: 0.15655892194010387, lr:  0.000491, elapsed time:  126646
Step 258700, loss: 0.00817011960061791, acc: 99.7382665425539, p_norm: 2082.738417079364, g_norm: 0.1833985683522104, lr:  0.000491, elapsed time:  126693
Step 258800, loss: 0.007606349867619429, acc: 99.75960396230221, p_norm: 2082.865277512456, g_norm: 0.16626607022351658, lr:  0.000491, elapsed time:  126741
Step 258900, loss: 0.007699517166711303, acc: 99.75916004180908, p_norm: 2083.0202237378107, g_norm: 0.21453064869488858, lr:  0.000491, elapsed time:  126789
Step 259000, loss: 0.008036465884142672, acc: 99.74130827188492, p_norm: 2083.1593182241704, g_norm: 0.12212409884930106, lr:  0.000491, elapsed time:  126837
Step 259100, loss: 0.007782712229054595, acc: 99.75217577815056, p_norm: 2083.283841390901, g_norm: 0.11968002750063976, lr:  0.000491, elapsed time:  126884
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 259200, loss: 0.007543169586150458, acc: 99.7601764415627, p_norm: 2083.4075468995766, g_norm: 0.2981811112094497, lr:  0.000491, elapsed time:  126932
Step 259300, loss: 0.00756661824279945, acc: 99.75859850645065, p_norm: 2083.557656295481, g_norm: 0.14422037471500773, lr:  0.000491, elapsed time:  126980
Step 259400, loss: 0.007255117833483382, acc: 99.76233603060246, p_norm: 2083.6800295080334, g_norm: 0.31443210019396284, lr:  0.000491, elapsed time:  127027
Step 259500, loss: 0.007527264778254903, acc: 99.7589885443449, p_norm: 2083.8125802732275, g_norm: 0.1929914473035549, lr:  0.000491, elapsed time:  127074
Step 259600, loss: 0.007644314558347105, acc: 99.75435429811478, p_norm: 2083.9398795695406, g_norm: 0.15573628181603097, lr:  0.000491, elapsed time:  127122
Step 259700, loss: 0.007277817988797324, acc: 99.76882773637772, p_norm: 2084.0654522728178, g_norm: 0.1534282071021194, lr:  0.000490, elapsed time:  127169
Step 259800, loss: 0.007937387318779656, acc: 99.74298159778118, p_norm: 2084.203034342766, g_norm: 0.21026170375881048, lr:  0.000490, elapsed time:  127216
Step 259900, loss: 0.007537249081160553, acc: 99.76190716028214, p_norm: 2084.335081149716, g_norm: 0.1731471335954246, lr:  0.000490, elapsed time:  127264
Step 260000, loss: 0.007929813406808534, acc: 99.74815967679024, p_norm: 2084.4698888547014, g_norm: 0.17827967845449313, lr:  0.000490, elapsed time:  127311
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 260000, eval loss: 0.01895831926693973, eval acc: 99.61858367919922
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C O C ( = O ) C C N C ( = O ) c 1 c c c ( C ( O c 2 c c ( C ) c ( - n 3 c c ( C ( F ) ( F ) F ) c n 3 ) c ( C ) c 2 ) C 2 C C ( C ) ( C ) C 2 ) c c 1 _EOS
Predicted text: C C O C ( = O ) C C N C ( = O ) c 1 c c c ( C ( O c 2 c c ( C ) c ( - n 3 c c ( C ( F ) ( F ) F ) c n 3 ) c ( C ) c 2 ) C 2 C C ( C ) ( C ) C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( C ) C c 2 c c ( C ( = O ) O ) c c c 2 N C 1 c 1 c c ( F ) c c ( N 2 C C N C C 2 ) c 1 _EOS
Predicted text: C C 1 ( C ) C c 2 c c ( C ( = O ) O ) c c c 2 N C 1 c 1 c c ( F ) c c ( N 2 C C N C C 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c ( C ( F ) ( F ) F ) c c c 1 C n 1 n c 2 c ( Br ) c ( - c 3 c c c ( Cl ) c c 3 ) c c n 2 c 1 = O _EOS
Predicted text: C c 1 n c ( C ( F ) ( F ) F ) c c c 1 C n 1 n c 2 c ( Br ) c ( - c 3 c c c ( Cl ) c c 3 ) c c n 2 c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 c ( = O ) c ( - c 2 c ( Cl ) c c c c 2 Cl ) c c 2 c n c ( N c 3 c c c c ( C O ) c 3 ) n c 2 1 _EOS
Predicted text: C n 1 c ( = O ) c ( - c 2 c ( Cl ) c c c c 2 Cl ) c c 2 c n c ( N c 3 c c c c ( C O ) c 3 ) n c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) c 1 c c c c ( - c 2 c c c c ( C ( = O ) c 3 c c c c n 3 ) c 2 ) c 1 O C c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c c c c ( - c 2 c c c c ( C ( = O ) c 3 c c c c n 3 ) c 2 ) c 1 O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 260000, eval acc (token): 0.9401768005684197, eval acc (sequence): 0.8922581738099271
Saving at step 260000
Step 260100, loss: 0.00736790907077193, acc: 99.77073292434216, p_norm: 2084.6104248457355, g_norm: 0.18181633408072118, lr:  0.000490, elapsed time:  127418
Step 260200, loss: 0.007580848636571318, acc: 99.75690822303295, p_norm: 2084.750409474657, g_norm: 0.24449171277788087, lr:  0.000490, elapsed time:  127465
Step 260300, loss: 0.007793481012486154, acc: 99.76024739444256, p_norm: 2084.8791390648744, g_norm: 0.16112096927421557, lr:  0.000490, elapsed time:  127513
Step 260400, loss: 0.007669321437588223, acc: 99.75999151170254, p_norm: 2085.0151366758378, g_norm: 0.1839155082177537, lr:  0.000490, elapsed time:  127561
Step 260500, loss: 0.007556229432320833, acc: 99.75667896866798, p_norm: 2085.138400513687, g_norm: 0.2220711735621133, lr:  0.000490, elapsed time:  127608
Step 260600, loss: 0.007949856972527414, acc: 99.74789729714394, p_norm: 2085.273746792548, g_norm: 0.1426224217143481, lr:  0.000490, elapsed time:  127655
Step 260700, loss: 0.0077972878405216765, acc: 99.74574993550777, p_norm: 2085.4059307849434, g_norm: 0.18586995916662802, lr:  0.000489, elapsed time:  127703
Step 260800, loss: 0.00741289439592947, acc: 99.76191671192646, p_norm: 2085.5369149573226, g_norm: 0.24337925647882966, lr:  0.000489, elapsed time:  127750
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 260900, loss: 0.008015296878212796, acc: 99.74487916154055, p_norm: 2085.687558193425, g_norm: 0.16711987973310272, lr:  0.000489, elapsed time:  127799
Step 261000, loss: 0.006944354984607343, acc: 99.77389079332352, p_norm: 2085.8155442072143, g_norm: 0.35812890650652474, lr:  0.000489, elapsed time:  127847
Step 261100, loss: 0.007615866390715383, acc: 99.75630013644695, p_norm: 2085.9375828266247, g_norm: 0.2157492275776702, lr:  0.000489, elapsed time:  127894
Step 261200, loss: 0.007260728619003203, acc: 99.76482637226582, p_norm: 2086.0547092380134, g_norm: 0.19310370233093194, lr:  0.000489, elapsed time:  127941
Step 261300, loss: 0.007320035574048233, acc: 99.76737865805626, p_norm: 2086.1767391447083, g_norm: 0.23842143978767863, lr:  0.000489, elapsed time:  127988
Step 261400, loss: 0.007024099341924739, acc: 99.77931487560272, p_norm: 2086.313373276265, g_norm: 0.17836917727798243, lr:  0.000489, elapsed time:  128037
Step 261500, loss: 0.007663119738444948, acc: 99.75194093585014, p_norm: 2086.443727568332, g_norm: 0.2495717664044284, lr:  0.000489, elapsed time:  128084
Step 261600, loss: 0.007445458912952745, acc: 99.75958259403706, p_norm: 2086.5776385491567, g_norm: 0.2673562419015643, lr:  0.000489, elapsed time:  128131
Step 261700, loss: 0.0074026712720524305, acc: 99.7586273252964, p_norm: 2086.706411977494, g_norm: 0.1535816772951886, lr:  0.000489, elapsed time:  128179
Step 261800, loss: 0.007113480479938516, acc: 99.77459682524204, p_norm: 2086.852711706511, g_norm: 0.11656899056271394, lr:  0.000488, elapsed time:  128227
Step 261900, loss: 0.007373345131454699, acc: 99.759447529912, p_norm: 2086.97359512719, g_norm: 0.16128775877018944, lr:  0.000488, elapsed time:  128275
Step 262000, loss: 0.007982261582710634, acc: 99.74225527048111, p_norm: 2087.117997321166, g_norm: 0.1754785460473946, lr:  0.000488, elapsed time:  128322
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 262000, eval loss: 0.019806317492038945, eval acc: 99.59644317626953
Step 262100, loss: 0.0074250362034217685, acc: 99.75661680102348, p_norm: 2087.2548636853194, g_norm: 0.133637139802584, lr:  0.000488, elapsed time:  128376
Step 262200, loss: 0.008199002361998282, acc: 99.73435078561306, p_norm: 2087.3894775577396, g_norm: 0.21011734538585577, lr:  0.000488, elapsed time:  128424
Step 262300, loss: 0.007694188729601592, acc: 99.75958469510078, p_norm: 2087.5208940576754, g_norm: 0.18671368306959424, lr:  0.000488, elapsed time:  128472
Step 262400, loss: 0.007677691552853503, acc: 99.75797973573208, p_norm: 2087.6628665640233, g_norm: 0.19242605330017268, lr:  0.000488, elapsed time:  128519
Step 262500, loss: 0.00790529001980758, acc: 99.74534231424332, p_norm: 2087.7920046961763, g_norm: 0.2521599841506888, lr:  0.000488, elapsed time:  128566
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 262600, loss: 0.007390203325485345, acc: 99.76950826039955, p_norm: 2087.914396992448, g_norm: 0.15742305850285734, lr:  0.000488, elapsed time:  128615
Step 262700, loss: 0.00668811962579639, acc: 99.7820646315813, p_norm: 2088.042922493637, g_norm: 0.18203773228679393, lr:  0.000488, elapsed time:  128663
Step 262800, loss: 0.007060009906135747, acc: 99.77333651483059, p_norm: 2088.163002469047, g_norm: 0.24848601450259403, lr:  0.000488, elapsed time:  128710
Step 262900, loss: 0.007486333496344742, acc: 99.76532976329327, p_norm: 2088.291715508312, g_norm: 0.19345205682944558, lr:  0.000487, elapsed time:  128758
Step 263000, loss: 0.008243658323408454, acc: 99.73665776848793, p_norm: 2088.431474555951, g_norm: 0.30436048929591125, lr:  0.000487, elapsed time:  128805
Step 263100, loss: 0.007386415548517107, acc: 99.76241961121559, p_norm: 2088.5662445545595, g_norm: 0.18864005187720864, lr:  0.000487, elapsed time:  128853
Step 263200, loss: 0.007147054734668927, acc: 99.77465987205505, p_norm: 2088.6890564774603, g_norm: 0.3302966150592994, lr:  0.000487, elapsed time:  128900
Step 263300, loss: 0.007412512023802264, acc: 99.76351208984852, p_norm: 2088.8212289276075, g_norm: 0.1431888211371714, lr:  0.000487, elapsed time:  128948
Step 263400, loss: 0.007589996052192873, acc: 99.76070062816143, p_norm: 2088.9476933922656, g_norm: 0.1641243229285839, lr:  0.000487, elapsed time:  128995
Step 263500, loss: 0.007314158590615989, acc: 99.76714134216309, p_norm: 2089.0799711101604, g_norm: 0.2459311324010025, lr:  0.000487, elapsed time:  129043
Step 263600, loss: 0.007454411735034227, acc: 99.76041893661022, p_norm: 2089.1996818018124, g_norm: 0.18744233122423265, lr:  0.000487, elapsed time:  129091
Step 263700, loss: 0.0071976237925355235, acc: 99.76796090602875, p_norm: 2089.336722673017, g_norm: 0.2228835879948814, lr:  0.000487, elapsed time:  129139
Step 263800, loss: 0.008146480529412657, acc: 99.74557775259018, p_norm: 2089.4772673555117, g_norm: 0.2046617422175451, lr:  0.000487, elapsed time:  129186
Step 263900, loss: 0.007603529417901882, acc: 99.75969234108925, p_norm: 2089.6033698447427, g_norm: 0.15392609234627544, lr:  0.000487, elapsed time:  129234
Step 264000, loss: 0.007761112300913737, acc: 99.75303509831429, p_norm: 2089.7379230276288, g_norm: 0.19520866816187354, lr:  0.000486, elapsed time:  129281
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 264000, eval loss: 0.018193474800209525, eval acc: 99.62232208251953
Step 264100, loss: 0.007277106696265036, acc: 99.76638670265675, p_norm: 2089.865301753296, g_norm: 0.17401910776600418, lr:  0.000486, elapsed time:  129336
Step 264200, loss: 0.007531255248641173, acc: 99.76329968869686, p_norm: 2089.990951479867, g_norm: 0.1809928394940949, lr:  0.000486, elapsed time:  129383
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 264300, loss: 0.007706939496084639, acc: 99.75440110225536, p_norm: 2090.108760798266, g_norm: 0.18907753249741605, lr:  0.000486, elapsed time:  129431
Step 264400, loss: 0.007479694224875857, acc: 99.76405775547028, p_norm: 2090.2310588397822, g_norm: 0.2364541961564732, lr:  0.000486, elapsed time:  129478
Step 264500, loss: 0.00728279244866826, acc: 99.76632767915726, p_norm: 2090.3718228559374, g_norm: 0.128298951211229, lr:  0.000486, elapsed time:  129525
Step 264600, loss: 0.007270437795214093, acc: 99.76635602116585, p_norm: 2090.5044129938747, g_norm: 0.1698295230797909, lr:  0.000486, elapsed time:  129573
Step 264700, loss: 0.007603705687633919, acc: 99.75912301242352, p_norm: 2090.6368892686687, g_norm: 0.24317138821828535, lr:  0.000486, elapsed time:  129620
Step 264800, loss: 0.007539152557710622, acc: 99.76106663048267, p_norm: 2090.7610697181995, g_norm: 0.10767188655046635, lr:  0.000486, elapsed time:  129668
Step 264900, loss: 0.0072373407567101825, acc: 99.76740942895412, p_norm: 2090.8883586092566, g_norm: 0.19669097671895344, lr:  0.000486, elapsed time:  129715
Step 265000, loss: 0.007858548084914218, acc: 99.7487410902977, p_norm: 2091.021280404478, g_norm: 0.37644130582977503, lr:  0.000486, elapsed time:  129763
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c ( C # N ) c 2 c ( c 1 O C ) C ( = O ) C C 2 _EOS
Predicted text: C O c 1 c c ( C # N ) c 2 c ( c 1 O C ) C ( = O ) C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) O C C N c 1 n o n c 1 - c 1 n o c ( = O ) n 1 C c 1 c c ( Br ) c o 1 _EOS
Predicted text: C S ( = O ) ( = O ) O C C N c 1 n o n c 1 - c 1 n o c ( = O ) n 1 C c 1 c c ( Br ) c o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C n 1 c ( C ) c ( C c 2 c c c ( S ( = O ) ( = O ) c 3 c c c ( F ) c c 3 ) c c 2 ) c 2 c c ( F ) c c c 2 1 _EOS
Predicted text: C O C ( = O ) C n 1 c ( C ) c ( C c 2 c c c ( S ( = O ) ( = O ) c 3 c c c ( F ) c c 3 ) c c 2 ) c 2 c c ( F ) c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C c 1 c c ( N c 2 n c n c 3 c c ( O C C C Cl ) c c c 2 3 ) n [nH] 1 ) N c 1 c c c c ( F ) c 1 _EOS
Predicted text: O = C ( C c 1 c c ( N c 2 n c n c 3 c c ( O C C C Cl ) c c c 2 3 ) n [nH] 1 ) N c 1 c c c c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) c 1 c c 2 c c c ( - c 3 c c c ( O C c 4 c ( - c 5 c ( Cl ) c n c c 5 Cl ) n o c 4 C 4 C C C 4 ) c c 3 ) c c 2 c n 1 _EOS
Predicted text: O = C ( O ) c 1 c c 2 c c c ( - c 3 c c c ( O C c 4 c ( - c 5 c ( Cl ) c n c c 5 Cl ) n o c 4 C 4 C C C 4 ) c c 3 ) c c 2 c n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 265000, eval acc (token): 0.94230115508978, eval acc (sequence): 0.8960882302257454
Saving at step 265000
Step 265100, loss: 0.0072387167177112135, acc: 99.77219924330711, p_norm: 2091.1487493401005, g_norm: 0.213631772001961, lr:  0.000485, elapsed time:  129863
Step 265200, loss: 0.007476997109879448, acc: 99.76241081953049, p_norm: 2091.2694556766087, g_norm: 0.19634189130771543, lr:  0.000485, elapsed time:  129910
Step 265300, loss: 0.00746862598331063, acc: 99.76616971194744, p_norm: 2091.4100788975775, g_norm: 0.12244412888938866, lr:  0.000485, elapsed time:  129958
Step 265400, loss: 0.00718270238504374, acc: 99.7733924984932, p_norm: 2091.5199367053856, g_norm: 0.25046087574162107, lr:  0.000485, elapsed time:  130006
Step 265500, loss: 0.008101492513196718, acc: 99.73615582287312, p_norm: 2091.663708741038, g_norm: 0.17519729549645466, lr:  0.000485, elapsed time:  130053
Step 265600, loss: 0.007920925567996165, acc: 99.7520567625761, p_norm: 2091.796144583937, g_norm: 0.12531173384185418, lr:  0.000485, elapsed time:  130100
Step 265700, loss: 0.007419359092855302, acc: 99.7647760361433, p_norm: 2091.912086920753, g_norm: 0.12501100203167304, lr:  0.000485, elapsed time:  130148
Step 265800, loss: 0.007495390759704606, acc: 99.76491285860538, p_norm: 2092.039068516117, g_norm: 0.2127013539494408, lr:  0.000485, elapsed time:  130195
Step 265900, loss: 0.0073874995893675076, acc: 99.76204389333725, p_norm: 2092.1570228375936, g_norm: 0.12846666982032254, lr:  0.000485, elapsed time:  130243
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 266000, loss: 0.007219596819773896, acc: 99.76583553602914, p_norm: 2092.2788435334287, g_norm: 0.21307972725463595, lr:  0.000485, elapsed time:  130292
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 266000, eval loss: 0.018071165083838416, eval acc: 99.63897705078125
Step 266100, loss: 0.006912700330103689, acc: 99.7760446369648, p_norm: 2092.4102156797258, g_norm: 0.16930857357516463, lr:  0.000484, elapsed time:  130346
Step 266200, loss: 0.007199378091063409, acc: 99.77001060545444, p_norm: 2092.543573135677, g_norm: 0.2535976534212601, lr:  0.000484, elapsed time:  130394
Step 266300, loss: 0.007241214596015197, acc: 99.77329583466053, p_norm: 2092.674892484541, g_norm: 0.11082833373350012, lr:  0.000484, elapsed time:  130441
Step 266400, loss: 0.0073847272849207005, acc: 99.76401779055595, p_norm: 2092.80265586709, g_norm: 0.16033861041695896, lr:  0.000484, elapsed time:  130489
Step 266500, loss: 0.007464568751020124, acc: 99.75921614468098, p_norm: 2092.9367567245745, g_norm: 0.14971663224343196, lr:  0.000484, elapsed time:  130537
Step 266600, loss: 0.007498443571585085, acc: 99.75926259160042, p_norm: 2093.065177143179, g_norm: 0.25199772185957076, lr:  0.000484, elapsed time:  130584
Step 266700, loss: 0.007137342077403446, acc: 99.76996746659279, p_norm: 2093.203848939116, g_norm: 0.22478393129079788, lr:  0.000484, elapsed time:  130632
Step 266800, loss: 0.0073844824063780835, acc: 99.7626253515482, p_norm: 2093.3296565864916, g_norm: 0.31203414167600285, lr:  0.000484, elapsed time:  130679
Step 266900, loss: 0.0076322245837218364, acc: 99.75303284823895, p_norm: 2093.477447839657, g_norm: 0.28962202852399, lr:  0.000484, elapsed time:  130727
Step 267000, loss: 0.007898929562688863, acc: 99.75046160817146, p_norm: 2093.610083321111, g_norm: 0.2047757677331855, lr:  0.000484, elapsed time:  130775
Step 267100, loss: 0.007459675303871336, acc: 99.76046742498875, p_norm: 2093.7558123109197, g_norm: 0.37329317135206463, lr:  0.000484, elapsed time:  130823
Step 267200, loss: 0.007482112480738578, acc: 99.75603564083576, p_norm: 2093.870941808655, g_norm: 0.18538344187300385, lr:  0.000483, elapsed time:  130870
Step 267300, loss: 0.007707744660310709, acc: 99.75687998533249, p_norm: 2093.9959614014037, g_norm: 0.22805813788177576, lr:  0.000483, elapsed time:  130917
Step 267400, loss: 0.007289022124823532, acc: 99.77061866223812, p_norm: 2094.122709597962, g_norm: 0.12220786367161433, lr:  0.000483, elapsed time:  130964
Step 267500, loss: 0.007347494738642126, acc: 99.77030470967293, p_norm: 2094.26370250481, g_norm: 0.11743134144583939, lr:  0.000483, elapsed time:  131012
Step 267600, loss: 0.007914407214557287, acc: 99.75251607596874, p_norm: 2094.38904037925, g_norm: 0.14776897296856895, lr:  0.000483, elapsed time:  131059
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 267700, loss: 0.00786472360159135, acc: 99.74966059573254, p_norm: 2094.5095002785342, g_norm: 0.20563294594536155, lr:  0.000483, elapsed time:  131107
Step 267800, loss: 0.007499829326370673, acc: 99.75908653438091, p_norm: 2094.637608434653, g_norm: 0.19326377282799412, lr:  0.000483, elapsed time:  131154
Step 267900, loss: 0.007130089759330076, acc: 99.7704605460167, p_norm: 2094.7595078749764, g_norm: 0.18752678559960412, lr:  0.000483, elapsed time:  131202
Step 268000, loss: 0.0071729919992321815, acc: 99.76841998100281, p_norm: 2094.8958269487503, g_norm: 0.141615013487442, lr:  0.000483, elapsed time:  131249
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 268000, eval loss: 0.02050508249099948, eval acc: 99.6129150390625
Step 268100, loss: 0.007317073967687975, acc: 99.77262000739574, p_norm: 2095.0181141553066, g_norm: 0.10706675142896423, lr:  0.000483, elapsed time:  131304
Step 268200, loss: 0.0073875189960926945, acc: 99.76409594714642, p_norm: 2095.1400294092427, g_norm: 0.17970655536956526, lr:  0.000483, elapsed time:  131351
Step 268300, loss: 0.007169847458662844, acc: 99.77663800120354, p_norm: 2095.2831062005625, g_norm: 0.18295252035101697, lr:  0.000483, elapsed time:  131399
Step 268400, loss: 0.007248234724975191, acc: 99.76960378885269, p_norm: 2095.401796031198, g_norm: 0.12750851524814805, lr:  0.000482, elapsed time:  131447
Step 268500, loss: 0.007339073570292385, acc: 99.76103645563126, p_norm: 2095.5240256309703, g_norm: 0.20892994014777697, lr:  0.000482, elapsed time:  131495
Step 268600, loss: 0.00757907195315056, acc: 99.7557723224163, p_norm: 2095.6435941097975, g_norm: 0.14774826383844344, lr:  0.000482, elapsed time:  131542
Step 268700, loss: 0.007291069363291171, acc: 99.76774655282497, p_norm: 2095.7737047674523, g_norm: 0.18543456311963394, lr:  0.000482, elapsed time:  131590
Step 268800, loss: 0.007421427433801, acc: 99.76470901072025, p_norm: 2095.907891043658, g_norm: 0.17662899539196592, lr:  0.000482, elapsed time:  131638
Step 268900, loss: 0.007451764386551076, acc: 99.77159930765629, p_norm: 2096.043227429419, g_norm: 0.1697735412982553, lr:  0.000482, elapsed time:  131686
Step 269000, loss: 0.007619495145636392, acc: 99.75604650378227, p_norm: 2096.1766670378993, g_norm: 0.19165160285892108, lr:  0.000482, elapsed time:  131734
Step 269100, loss: 0.007740061473014066, acc: 99.74949915707111, p_norm: 2096.304096776189, g_norm: 0.1942715701954355, lr:  0.000482, elapsed time:  131782
Step 269200, loss: 0.007352911632851828, acc: 99.76836040616035, p_norm: 2096.421931711204, g_norm: 0.19889188863701462, lr:  0.000482, elapsed time:  131829
Step 269300, loss: 0.007385404821652628, acc: 99.76271086931229, p_norm: 2096.539652587297, g_norm: 0.14476319958645478, lr:  0.000482, elapsed time:  131876
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 269400, loss: 0.007158706857817334, acc: 99.77014567425002, p_norm: 2096.6697445976333, g_norm: 0.215035589315654, lr:  0.000482, elapsed time:  131925
Step 269500, loss: 0.007261238333412621, acc: 99.76037818193436, p_norm: 2096.8035424670675, g_norm: 0.16761747687457357, lr:  0.000481, elapsed time:  131973
Step 269600, loss: 0.0067542525412955, acc: 99.78038749098778, p_norm: 2096.921367110775, g_norm: 0.16535789513884114, lr:  0.000481, elapsed time:  132021
Step 269700, loss: 0.007298812640656251, acc: 99.7691291719675, p_norm: 2097.0388080038488, g_norm: 0.1613021420675274, lr:  0.000481, elapsed time:  132068
Step 269800, loss: 0.0071306075188476824, acc: 99.76939210295677, p_norm: 2097.162577291408, g_norm: 0.23531031521897036, lr:  0.000481, elapsed time:  132116
Step 269900, loss: 0.0067706776261729825, acc: 99.78004233539104, p_norm: 2097.287245346548, g_norm: 0.17749672791499832, lr:  0.000481, elapsed time:  132164
Step 270000, loss: 0.0072440560669929255, acc: 99.76165229082108, p_norm: 2097.403000959603, g_norm: 0.1475373924516346, lr:  0.000481, elapsed time:  132211
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 270000, eval loss: 0.019008270940103093, eval acc: 99.60884094238281
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c 2 c ( c 3 c 1 O C ( C ) ( C ) C 3 ) C ( c 1 c c c ( N ( S ( C ) ( = O ) = O ) S ( C ) ( = O ) = O ) c c 1 ) = N C ( C ) ( C ) C 2 _EOS
Predicted text: C O c 1 c c 2 c ( c 3 c 1 O C ( C ) ( C ) C 3 ) C ( c 1 c c c ( N ( S ( C ) ( = O ) = O ) S ( C ) ( = O ) = O ) c c 1 ) = N C ( C ) ( C ) C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C ( N C ( = O ) C c 1 c c ( F ) c c ( F ) c 1 ) C ( = O ) N C 1 C ( = O ) N c 2 c c c c c 2 S C 1 c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) C ( N C ( = O ) C c 1 c c ( F ) c c ( F ) c 1 ) C ( = O ) N C 1 C ( = O ) N c 2 c c c c c 2 S C 1 c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C O C ( = O ) C 1 C C C ( C O S ( C ) ( = O ) = O ) C C 1 _EOS
Predicted text: C C C C O C ( = O ) C 1 C C C ( C O S ( C ) ( = O ) = O ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) n 1 c c ( N c 2 n c ( - c 3 c c c 4 c n [nH] c 4 c 3 ) c n 3 c c n c 2 3 ) c n 1 _EOS
Predicted text: C C ( C ) n 1 c c ( N c 2 n c ( - c 3 c c c 4 c n [nH] c 4 c 3 ) c n 3 c c n c 2 3 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) c 1 c c c ( C ( = O ) O ) o 1 _EOS
Predicted text: C S ( = O ) ( = O ) c 1 c c c ( C ( = O ) O ) o 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 270000, eval acc (token): 0.9424225074848466, eval acc (sequence): 0.8948509485094851
Saving at step 270000
Step 270100, loss: 0.0074956599074903355, acc: 99.76106891036034, p_norm: 2097.524832360812, g_norm: 0.16741020730980674, lr:  0.000481, elapsed time:  132318
Step 270200, loss: 0.007408928245922652, acc: 99.76033808290958, p_norm: 2097.659051741085, g_norm: 0.17306053518638545, lr:  0.000481, elapsed time:  132366
Step 270300, loss: 0.007510551468476479, acc: 99.75505919754505, p_norm: 2097.789169003204, g_norm: 0.21918556788570542, lr:  0.000481, elapsed time:  132414
Step 270400, loss: 0.007449412131472854, acc: 99.76513642072678, p_norm: 2097.9103578720865, g_norm: 0.173664454159088, lr:  0.000481, elapsed time:  132462
Step 270500, loss: 0.007004046971514981, acc: 99.77477511763573, p_norm: 2098.0514787827265, g_norm: 0.21059788664597548, lr:  0.000481, elapsed time:  132510
Step 270600, loss: 0.007429681725052433, acc: 99.76218079030514, p_norm: 2098.184550515423, g_norm: 0.2550749996959618, lr:  0.000480, elapsed time:  132558
Step 270700, loss: 0.0075112402547893, acc: 99.76292562484741, p_norm: 2098.3187587087664, g_norm: 0.22236717505571385, lr:  0.000480, elapsed time:  132605
Step 270800, loss: 0.007740761722852767, acc: 99.75159728527069, p_norm: 2098.4627962453433, g_norm: 0.1700844395867666, lr:  0.000480, elapsed time:  132653
Step 270900, loss: 0.00715701970651935, acc: 99.7670526355505, p_norm: 2098.591840421746, g_norm: 0.17769431964862595, lr:  0.000480, elapsed time:  132700
Step 271000, loss: 0.007178214694249618, acc: 99.77006945014, p_norm: 2098.7216115623996, g_norm: 0.18999903469829652, lr:  0.000480, elapsed time:  132749
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 271100, loss: 0.00775399994162225, acc: 99.75196001843247, p_norm: 2098.845739147871, g_norm: 0.3803287054656034, lr:  0.000480, elapsed time:  132797
Step 271200, loss: 0.007011126220731967, acc: 99.77531537413597, p_norm: 2098.9590977110056, g_norm: 0.18682949889441614, lr:  0.000480, elapsed time:  132844
Step 271300, loss: 0.0067691836650919865, acc: 99.78040573000908, p_norm: 2099.0727834636846, g_norm: 0.3641593280933928, lr:  0.000480, elapsed time:  132892
Step 271400, loss: 0.00693544379544619, acc: 99.7781515866518, p_norm: 2099.1936073724523, g_norm: 0.19497117199930605, lr:  0.000480, elapsed time:  132940
Step 271500, loss: 0.0067846321908564275, acc: 99.78632709383965, p_norm: 2099.319699847554, g_norm: 0.17576663495278008, lr:  0.000480, elapsed time:  132987
Step 271600, loss: 0.0076426071943933496, acc: 99.7580266147852, p_norm: 2099.449356796502, g_norm: 0.13313100691260135, lr:  0.000480, elapsed time:  133035
Step 271700, loss: 0.00714765524442555, acc: 99.7772993594408, p_norm: 2099.562379965889, g_norm: 0.18485742194712138, lr:  0.000479, elapsed time:  133082
Step 271800, loss: 0.007344272415939486, acc: 99.76684407889843, p_norm: 2099.678871432727, g_norm: 0.23971092324625867, lr:  0.000479, elapsed time:  133130
Step 271900, loss: 0.007121364357008133, acc: 99.77178746461868, p_norm: 2099.806427846112, g_norm: 0.1292355279408419, lr:  0.000479, elapsed time:  133177
Step 272000, loss: 0.007546112309373711, acc: 99.76674687862396, p_norm: 2099.937834429195, g_norm: 0.24274809716653167, lr:  0.000479, elapsed time:  133225
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 272000, eval loss: 0.019150377570349524, eval acc: 99.58734893798828
Step 272100, loss: 0.007368013223313028, acc: 99.76668883860111, p_norm: 2100.06542927828, g_norm: 0.10802588313662857, lr:  0.000479, elapsed time:  133279
Step 272200, loss: 0.007163939277561439, acc: 99.7747935205698, p_norm: 2100.1871903035853, g_norm: 0.13330445587985804, lr:  0.000479, elapsed time:  133327
Step 272300, loss: 0.007828763142806566, acc: 99.75118789076805, p_norm: 2100.311616547407, g_norm: 0.1618229645056676, lr:  0.000479, elapsed time:  133375
Step 272400, loss: 0.007233462352050992, acc: 99.76735267043114, p_norm: 2100.430740247122, g_norm: 0.23689166472406997, lr:  0.000479, elapsed time:  133422
Step 272500, loss: 0.007177526266068526, acc: 99.7682493776083, p_norm: 2100.5459908496287, g_norm: 0.20179526644376672, lr:  0.000479, elapsed time:  133470
Step 272600, loss: 0.007524463730223942, acc: 99.75730548799038, p_norm: 2100.675965799326, g_norm: 0.23778738577987926, lr:  0.000479, elapsed time:  133518
Step 272700, loss: 0.0074078869394179495, acc: 99.76587609946728, p_norm: 2100.7948094620733, g_norm: 0.19480430994926376, lr:  0.000479, elapsed time:  133565
Step 272800, loss: 0.007774318091505848, acc: 99.75384411215782, p_norm: 2100.9195434369144, g_norm: 0.1913620590737912, lr:  0.000479, elapsed time:  133612
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6822
Step 272900, loss: 0.007039971135822976, acc: 99.77077070753373, p_norm: 2101.0425705142593, g_norm: 0.18797914486749953, lr:  0.000478, elapsed time:  133663
Step 273000, loss: 0.006923812480554261, acc: 99.77557916939259, p_norm: 2101.1708160717612, g_norm: 0.1841983205969926, lr:  0.000478, elapsed time:  133711
Step 273100, loss: 0.006937204695186665, acc: 99.7858429402113, p_norm: 2101.289711484489, g_norm: 0.135354960679768, lr:  0.000478, elapsed time:  133759
Step 273200, loss: 0.00764649829749942, acc: 99.75546279549599, p_norm: 2101.4227843895874, g_norm: 0.21991234949199373, lr:  0.000478, elapsed time:  133807
Step 273300, loss: 0.007512423246553226, acc: 99.75496132671833, p_norm: 2101.5467518923374, g_norm: 0.2845978013361602, lr:  0.000478, elapsed time:  133866
Step 273400, loss: 0.006643225458810775, acc: 99.79129019379616, p_norm: 2101.669480351364, g_norm: 0.2876033349694339, lr:  0.000478, elapsed time:  133915
Step 273500, loss: 0.007353074893817393, acc: 99.76229512691498, p_norm: 2101.7912070063585, g_norm: 0.15624093564224234, lr:  0.000478, elapsed time:  133962
Step 273600, loss: 0.007379750496838824, acc: 99.76505683362484, p_norm: 2101.9178068495025, g_norm: 0.12841024505124335, lr:  0.000478, elapsed time:  134009
Step 273700, loss: 0.007090013915785676, acc: 99.7819419503212, p_norm: 2102.0521341912818, g_norm: 0.23064792369020656, lr:  0.000478, elapsed time:  134057
Step 273800, loss: 0.0074994541525484236, acc: 99.75882667303085, p_norm: 2102.176517036926, g_norm: 0.2977673819958733, lr:  0.000478, elapsed time:  134104
Step 273900, loss: 0.0074371888538371424, acc: 99.76216435432434, p_norm: 2102.3000776618837, g_norm: 0.22558749507155032, lr:  0.000478, elapsed time:  134152
Step 274000, loss: 0.007676168774505641, acc: 99.75805611908436, p_norm: 2102.4224642467702, g_norm: 0.18683291318743525, lr:  0.000477, elapsed time:  134199
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 274000, eval loss: 0.019043231807881967, eval acc: 99.60116577148438
Step 274100, loss: 0.0073769318842641955, acc: 99.76534296572208, p_norm: 2102.555241069675, g_norm: 0.24813547389020996, lr:  0.000477, elapsed time:  134253
Step 274200, loss: 0.007569148328684605, acc: 99.76265943050385, p_norm: 2102.6803922654967, g_norm: 0.21247655579292463, lr:  0.000477, elapsed time:  134301
Step 274300, loss: 0.00753381131153219, acc: 99.76165482401848, p_norm: 2102.800755624402, g_norm: 0.20267521923803244, lr:  0.000477, elapsed time:  134349
Step 274400, loss: 0.00770903255104713, acc: 99.75251497328281, p_norm: 2102.933196091403, g_norm: 0.18564989627351752, lr:  0.000477, elapsed time:  134396
Step 274500, loss: 0.007216923867053993, acc: 99.76469148695469, p_norm: 2103.0640575409366, g_norm: 0.190018323807512, lr:  0.000477, elapsed time:  134443
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 274600, loss: 0.007234633685855904, acc: 99.7663096408939, p_norm: 2103.1831676437832, g_norm: 0.1777222546379452, lr:  0.000477, elapsed time:  134492
Step 274700, loss: 0.007333864202655605, acc: 99.77339886128902, p_norm: 2103.3175425308937, g_norm: 0.18328955187308668, lr:  0.000477, elapsed time:  134540
Step 274800, loss: 0.006563402517604118, acc: 99.79091328382492, p_norm: 2103.4382397879376, g_norm: 0.11495590417357303, lr:  0.000477, elapsed time:  134587
Step 274900, loss: 0.0071117922483608705, acc: 99.77919375896454, p_norm: 2103.5435662667974, g_norm: 0.18620101049484733, lr:  0.000477, elapsed time:  134635
Step 275000, loss: 0.007348507073547807, acc: 99.76019638776779, p_norm: 2103.664899523965, g_norm: 0.1972354755583277, lr:  0.000477, elapsed time:  134682
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c n ( C 2 C C ( O P ( O C C C # N ) N ( C ( C ) C ) C ( C ) C ) C ( C S C c 3 c 4 c c c c c 4 c c 4 c c c c c 3 4 ) O 2 ) c ( = O ) [nH] c 1 = O _EOS
Predicted text: C c 1 c n ( C 2 C C ( O P ( O C C C # N ) N ( C ( C ) C ) C ( C ) C ) C ( C S C c 3 c 4 c c c c c 4 c c 4 c c c c c 3 4 ) O 2 ) c ( = O ) [nH] c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C c 1 c c c ( O C ) c ( - c 2 c c 3 c c c c c 3 n c 2 C N ( C C ) C ( = O ) C 2 C C 2 ) c 1 _EOS
Predicted text: C C O C ( = O ) C c 1 c c c ( O C ) c ( - c 2 c c 3 c c c c c 3 n c 2 C N ( C C ) C ( = O ) C 2 C C 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c ( Br ) s c 1 C O c 1 c c c ( C # N ) c ( Cl ) c 1 _EOS
Predicted text: C c 1 n c ( Br ) s c 1 C O c 1 c c c ( C # N ) c ( Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C [Si] ( C C ) ( C C ) O c 1 c c c 2 c ( c 1 ) C C C 1 C 2 C ( O C ) C C 2 ( C ) C = C C C 1 2 _EOS
Predicted text: C C [Si] ( C C ) ( C C ) O c 1 c c c 2 c ( c 1 ) C C C 1 C 2 C ( O C ) C C 2 ( C ) C = C C C 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( C N ( C C C C ( N ) = O ) C c 2 c c c ( C ) c c 2 ) c c 1 _EOS
Predicted text: C c 1 c c c ( C N ( C C C C ( N ) = O ) C c 2 c c c ( C ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 275000, eval acc (token): 0.9409164124964333, eval acc (sequence): 0.8930548116407784
Saving at step 275000
Step 275100, loss: 0.0069422796208891665, acc: 99.77567856013775, p_norm: 2103.792928378912, g_norm: 0.13867226707078903, lr:  0.000477, elapsed time:  134792
Step 275200, loss: 0.0069318259989449875, acc: 99.77561990916729, p_norm: 2103.919099380961, g_norm: 0.19200594426925796, lr:  0.000476, elapsed time:  134839
Step 275300, loss: 0.00713805959002002, acc: 99.77098944783211, p_norm: 2104.029835387364, g_norm: 0.16894758596805598, lr:  0.000476, elapsed time:  134885
Step 275400, loss: 0.007381149055654532, acc: 99.76402482390404, p_norm: 2104.161442657362, g_norm: 0.17813913429479805, lr:  0.000476, elapsed time:  134932
Step 275500, loss: 0.007268239966233523, acc: 99.76914876699448, p_norm: 2104.287667911502, g_norm: 0.17414017792019598, lr:  0.000476, elapsed time:  134978
Step 275600, loss: 0.007068266482165199, acc: 99.77722327411175, p_norm: 2104.404375916982, g_norm: 0.1404438517289539, lr:  0.000476, elapsed time:  135025
Step 275700, loss: 0.007629883740528385, acc: 99.75452311336994, p_norm: 2104.537202841592, g_norm: 0.1644580703436703, lr:  0.000476, elapsed time:  135071
Step 275800, loss: 0.007325516587407037, acc: 99.76652523875237, p_norm: 2104.6650455058357, g_norm: 0.23253731338978628, lr:  0.000476, elapsed time:  135118
Step 275900, loss: 0.007501421679708073, acc: 99.760024279356, p_norm: 2104.8063697105786, g_norm: 0.2013511019462595, lr:  0.000476, elapsed time:  135164
Step 276000, loss: 0.007771461395113874, acc: 99.74941939115524, p_norm: 2104.9427774816468, g_norm: 0.19847770434914347, lr:  0.000476, elapsed time:  135210
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 276000, eval loss: 0.019114007712960297, eval acc: 99.61314392089844
Step 276100, loss: 0.007113235292936224, acc: 99.77726909518242, p_norm: 2105.0707828615064, g_norm: 0.23108839355089023, lr:  0.000476, elapsed time:  135264
Step 276200, loss: 0.0072111946679069665, acc: 99.77185589075089, p_norm: 2105.1931569708418, g_norm: 0.17540717345556536, lr:  0.000476, elapsed time:  135310
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 276300, loss: 0.007170642253941738, acc: 99.7693687380843, p_norm: 2105.317309951316, g_norm: 0.24671223035830833, lr:  0.000475, elapsed time:  135358
Step 276400, loss: 0.006978871493884071, acc: 99.77741269767284, p_norm: 2105.432384573824, g_norm: 0.2119180980679611, lr:  0.000475, elapsed time:  135404
Step 276500, loss: 0.006943223548978495, acc: 99.77513983845711, p_norm: 2105.554968048629, g_norm: 0.14185568017670036, lr:  0.000475, elapsed time:  135450
Step 276600, loss: 0.006835801772540435, acc: 99.78109768033028, p_norm: 2105.678276260948, g_norm: 0.14826657711916977, lr:  0.000475, elapsed time:  135497
Step 276700, loss: 0.007482963306683814, acc: 99.75977921485901, p_norm: 2105.8240083934174, g_norm: 0.20472520408209727, lr:  0.000475, elapsed time:  135543
Step 276800, loss: 0.00708359223233856, acc: 99.77224345505238, p_norm: 2105.955522734151, g_norm: 0.14999512245802316, lr:  0.000475, elapsed time:  135590
Step 276900, loss: 0.00749933860958663, acc: 99.75957982242107, p_norm: 2106.077993950103, g_norm: 0.20507681255991703, lr:  0.000475, elapsed time:  135636
Step 277000, loss: 0.007306724617810687, acc: 99.76824207603931, p_norm: 2106.201190646083, g_norm: 0.23513135943392255, lr:  0.000475, elapsed time:  135684
Step 277100, loss: 0.00739140940218931, acc: 99.76785086095333, p_norm: 2106.323339911565, g_norm: 0.13658461982545717, lr:  0.000475, elapsed time:  135733
Step 277200, loss: 0.0073135318022104915, acc: 99.76350617408752, p_norm: 2106.436658873253, g_norm: 0.19509638307262722, lr:  0.000475, elapsed time:  135781
Step 277300, loss: 0.006974451275218598, acc: 99.7755022495985, p_norm: 2106.5605529224044, g_norm: 0.2282398748236851, lr:  0.000475, elapsed time:  135829
Step 277400, loss: 0.0068230942769605465, acc: 99.78432385623455, p_norm: 2106.678825857232, g_norm: 0.16041735140329688, lr:  0.000475, elapsed time:  135877
Step 277500, loss: 0.007436988642184588, acc: 99.76454542577267, p_norm: 2106.7970454002575, g_norm: 0.17807608576237602, lr:  0.000474, elapsed time:  135925
Step 277600, loss: 0.007123643686718424, acc: 99.76917088031769, p_norm: 2106.9259633442803, g_norm: 0.20357295385840657, lr:  0.000474, elapsed time:  135973
Step 277700, loss: 0.006891078703101811, acc: 99.77919025719166, p_norm: 2107.0394500865796, g_norm: 0.10213522707900698, lr:  0.000474, elapsed time:  136022
Step 277800, loss: 0.007350614337210573, acc: 99.76336245238781, p_norm: 2107.158304090613, g_norm: 0.1758495644619667, lr:  0.000474, elapsed time:  136070
Step 277900, loss: 0.007381767602819309, acc: 99.76028318703175, p_norm: 2107.2892617409716, g_norm: 0.1803936225043312, lr:  0.000474, elapsed time:  136118
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 278000, loss: 0.007104662222086935, acc: 99.77901147553702, p_norm: 2107.4241286738456, g_norm: 0.16785096448505285, lr:  0.000474, elapsed time:  136167
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 278000, eval loss: 0.019903919918215256, eval acc: 99.60057067871094
Step 278100, loss: 0.0068403979510731, acc: 99.78060549497604, p_norm: 2107.548595699803, g_norm: 0.148089534241559, lr:  0.000474, elapsed time:  136222
Step 278200, loss: 0.007382419849182043, acc: 99.76169721782207, p_norm: 2107.6749356653136, g_norm: 0.28322623234405847, lr:  0.000474, elapsed time:  136270
Step 278300, loss: 0.00696930268437427, acc: 99.77846071124077, p_norm: 2107.80038758178, g_norm: 0.23422568099371668, lr:  0.000474, elapsed time:  136319
Step 278400, loss: 0.006984798524790677, acc: 99.77344544231892, p_norm: 2107.9102365715166, g_norm: 0.17467670025695828, lr:  0.000474, elapsed time:  136366
Step 278500, loss: 0.007579686275885251, acc: 99.75375051796436, p_norm: 2108.0542013131494, g_norm: 0.2319855089485379, lr:  0.000474, elapsed time:  136414
Step 278600, loss: 0.007370424072614696, acc: 99.76328647136688, p_norm: 2108.183520768344, g_norm: 0.1670498173697202, lr:  0.000474, elapsed time:  136461
Step 278700, loss: 0.0072090214246418325, acc: 99.76581057906151, p_norm: 2108.329474061211, g_norm: 0.1685552123727827, lr:  0.000473, elapsed time:  136509
Step 278800, loss: 0.0075420046954423016, acc: 99.75696830451488, p_norm: 2108.446950741944, g_norm: 0.15979805715467207, lr:  0.000473, elapsed time:  136557
Step 278900, loss: 0.007019502042394379, acc: 99.7739352285862, p_norm: 2108.557565303897, g_norm: 0.17555237754591937, lr:  0.000473, elapsed time:  136604
Step 279000, loss: 0.006673267434798617, acc: 99.78506949543953, p_norm: 2108.6541379736395, g_norm: 0.16009180438311846, lr:  0.000473, elapsed time:  136651
Step 279100, loss: 0.007133358233686522, acc: 99.7650923281908, p_norm: 2108.787075993009, g_norm: 0.199329769408594, lr:  0.000473, elapsed time:  136699
Step 279200, loss: 0.007529127886045899, acc: 99.75581049919128, p_norm: 2108.9128720069225, g_norm: 0.16008265243510283, lr:  0.000473, elapsed time:  136747
Step 279300, loss: 0.006981265503454779, acc: 99.77748407423496, p_norm: 2109.0283696610604, g_norm: 0.20010250432058876, lr:  0.000473, elapsed time:  136794
Step 279400, loss: 0.0067867267253495815, acc: 99.7873567044735, p_norm: 2109.1533199374344, g_norm: 0.16338725037414234, lr:  0.000473, elapsed time:  136843
Step 279500, loss: 0.007207649046631559, acc: 99.77422851324081, p_norm: 2109.280723551973, g_norm: 0.17286106548517957, lr:  0.000473, elapsed time:  136890
Step 279600, loss: 0.007726696299232572, acc: 99.75596791505814, p_norm: 2109.408726611897, g_norm: 0.1591603200555973, lr:  0.000473, elapsed time:  136937
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 279700, loss: 0.007411887373785959, acc: 99.76581257967213, p_norm: 2109.515441144645, g_norm: 0.18938782061016357, lr:  0.000473, elapsed time:  136985
Step 279800, loss: 0.006981498041950545, acc: 99.77596831321716, p_norm: 2109.6237323900164, g_norm: 0.1538806027507454, lr:  0.000472, elapsed time:  137033
Step 279900, loss: 0.00649052101959569, acc: 99.79315358400345, p_norm: 2109.729462507979, g_norm: 0.14848518449286918, lr:  0.000472, elapsed time:  137081
Step 280000, loss: 0.006872767213963016, acc: 99.77985833585262, p_norm: 2109.8624509757246, g_norm: 0.18985134764828715, lr:  0.000472, elapsed time:  137129
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 280000, eval loss: 0.019063871423104506, eval acc: 99.61170196533203
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C C ( n 2 c c ( - c 3 c n c ( N ) c ( - c 4 n c 5 c c c c ( C ( = O ) O ) c 5 o 4 ) c 3 ) c n 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C C ( n 2 c c ( - c 3 c n c ( N ) c ( - c 4 n c 5 c c c c ( C ( = O ) O ) c 5 o 4 ) c 3 ) c n 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C C ( = O ) c 1 c c c 2 [nH] c ( = O ) [nH] c 2 c 1 _EOS
Predicted text: N C C ( = O ) c 1 c c c 2 [nH] c ( = O ) [nH] c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: F c 1 c c c ( C ( O C C N 2 C C N ( C C = C c 3 c c c o 3 ) C C 2 ) c 2 c c c s 2 ) c c 1 _EOS
Predicted text: F c 1 c c c ( C ( O C C N 2 C C N ( C C = C c 3 c c c o 3 ) C C 2 ) c 2 c c c s 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O c 1 c c c ( - c 2 n c ( C C C ( = O ) c 3 c c c c c 3 C ( = O ) O C ) c s 2 ) c c 1 O C C _EOS
Predicted text: C C O c 1 c c c ( - c 2 n c ( C C C ( = O ) c 3 c c c c c 3 C ( = O ) O C ) c s 2 ) c c 1 O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = c 1 c ( I ) c ( - c 2 c c c c c 2 ) o c 2 c ( O C ( F ) F ) n c c c 1 2 _EOS
Predicted text: O = c 1 c ( I ) c ( - c 2 c c c c c 2 ) o c 2 c ( = O ) n ( C ( F ) F ) c c c 1 2 _EOS
acc_token: 0.6410256410256411, acc_seq: False

Evaluation (without teacher) at step 280000, eval acc (token): 0.9450914771495227, eval acc (sequence): 0.9002267573696145
Saving at step 280000
Step 280100, loss: 0.007253747183885935, acc: 99.76641464233398, p_norm: 2109.9935522049864, g_norm: 0.18818038079833352, lr:  0.000472, elapsed time:  137236
Step 280200, loss: 0.0069745187781882125, acc: 99.76939690113068, p_norm: 2110.1146888263866, g_norm: 0.2051220318993951, lr:  0.000472, elapsed time:  137283
Step 280300, loss: 0.007199650217116869, acc: 99.76925909519196, p_norm: 2110.232754097997, g_norm: 0.20604414662563683, lr:  0.000472, elapsed time:  137330
Step 280400, loss: 0.007420637766208529, acc: 99.76654329895973, p_norm: 2110.3555154434207, g_norm: 0.15128347324607236, lr:  0.000472, elapsed time:  137377
Step 280500, loss: 0.007082298461591563, acc: 99.77866140007973, p_norm: 2110.4702329470256, g_norm: 0.17641264979602753, lr:  0.000472, elapsed time:  137425
Step 280600, loss: 0.007088708542605673, acc: 99.77492867410183, p_norm: 2110.5950622614346, g_norm: 0.17496759862738384, lr:  0.000472, elapsed time:  137473
Step 280700, loss: 0.00729977841489017, acc: 99.77120338380337, p_norm: 2110.7297805804455, g_norm: 0.17680796683489663, lr:  0.000472, elapsed time:  137520
Step 280800, loss: 0.007342284093901981, acc: 99.76605808734894, p_norm: 2110.863959480711, g_norm: 0.16814756439989437, lr:  0.000472, elapsed time:  137567
Step 280900, loss: 0.006993076215476322, acc: 99.77545304596424, p_norm: 2110.989997789971, g_norm: 0.16788116423799213, lr:  0.000472, elapsed time:  137615
Step 281000, loss: 0.007300739269694532, acc: 99.77049668133259, p_norm: 2111.112386094394, g_norm: 0.2071709354997789, lr:  0.000471, elapsed time:  137662
Step 281100, loss: 0.007394047480665904, acc: 99.7611780911684, p_norm: 2111.252192965491, g_norm: 0.1975512277192759, lr:  0.000471, elapsed time:  137710
Step 281200, loss: 0.0075517969588509, acc: 99.7532013207674, p_norm: 2111.369104620364, g_norm: 0.2528134696721996, lr:  0.000471, elapsed time:  137757
Step 281300, loss: 0.007036145654037682, acc: 99.78087970614433, p_norm: 2111.4834224459955, g_norm: 0.16653959428453924, lr:  0.000471, elapsed time:  137805
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 281400, loss: 0.006933606933897642, acc: 99.77360182437138, p_norm: 2111.603931976514, g_norm: 0.15714007378421826, lr:  0.000471, elapsed time:  137853
Step 281500, loss: 0.006931128132073354, acc: 99.77488096058369, p_norm: 2111.7096020703652, g_norm: 0.2074460157910077, lr:  0.000471, elapsed time:  137901
Step 281600, loss: 0.00720619473959232, acc: 99.77217175066471, p_norm: 2111.83708380523, g_norm: 0.1761050875300991, lr:  0.000471, elapsed time:  137948
Step 281700, loss: 0.007373465142500209, acc: 99.76241834461689, p_norm: 2111.963048192879, g_norm: 0.16782439864003587, lr:  0.000471, elapsed time:  137995
Step 281800, loss: 0.007034114633497666, acc: 99.77833247184753, p_norm: 2112.1007655639087, g_norm: 0.21694299867396905, lr:  0.000471, elapsed time:  138042
Step 281900, loss: 0.00724755849381836, acc: 99.76801159977913, p_norm: 2112.2271944836625, g_norm: 0.11338621609929504, lr:  0.000471, elapsed time:  138089
Step 282000, loss: 0.006825227244717098, acc: 99.7864546328783, p_norm: 2112.341028578771, g_norm: 0.1240882512253495, lr:  0.000471, elapsed time:  138137
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 282000, eval loss: 0.020851450967602433, eval acc: 99.58735656738281
Step 282100, loss: 0.0072939722287810585, acc: 99.76468504965305, p_norm: 2112.4517932371473, g_norm: 0.22695772122269084, lr:  0.000471, elapsed time:  138192
Step 282200, loss: 0.006891764495594544, acc: 99.77965158224106, p_norm: 2112.5721220138735, g_norm: 0.1753087302828688, lr:  0.000470, elapsed time:  138239
Step 282300, loss: 0.007206997512225826, acc: 99.76654462516308, p_norm: 2112.6976006879986, g_norm: 0.12958073651355492, lr:  0.000470, elapsed time:  138287
Step 282400, loss: 0.007230762396275168, acc: 99.76943777501583, p_norm: 2112.8210083711983, g_norm: 0.24161605828577776, lr:  0.000470, elapsed time:  138335
Step 282500, loss: 0.00747475642653626, acc: 99.75858622789383, p_norm: 2112.937746326889, g_norm: 0.16889551539688044, lr:  0.000470, elapsed time:  138383
Step 282600, loss: 0.007325326116661018, acc: 99.76675322651863, p_norm: 2113.0567503772054, g_norm: 0.2470503747883935, lr:  0.000470, elapsed time:  138430
Step 282700, loss: 0.007051734544111241, acc: 99.77807295322418, p_norm: 2113.1906612158746, g_norm: 0.1254963827386426, lr:  0.000470, elapsed time:  138478
Step 282800, loss: 0.006708292906687348, acc: 99.78548930585384, p_norm: 2113.2982969255513, g_norm: 0.18839548443969137, lr:  0.000470, elapsed time:  138526
Step 282900, loss: 0.0071339389058721284, acc: 99.77464483678341, p_norm: 2113.4077781902483, g_norm: 0.17757870406118068, lr:  0.000470, elapsed time:  138574
Step 283000, loss: 0.007078805661676597, acc: 99.77347922325134, p_norm: 2113.543302512479, g_norm: 0.1706602566219928, lr:  0.000470, elapsed time:  138621
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 283100, loss: 0.006911339623144456, acc: 99.77841186464276, p_norm: 2113.6449566933716, g_norm: 0.24144313268547732, lr:  0.000470, elapsed time:  138670
Step 283200, loss: 0.007375059208570746, acc: 99.76358035206795, p_norm: 2113.7723744401887, g_norm: 0.22565121697782886, lr:  0.000470, elapsed time:  138718
Step 283300, loss: 0.006981379681656108, acc: 99.77992908656597, p_norm: 2113.89609708376, g_norm: 0.2041165546079114, lr:  0.000470, elapsed time:  138765
Step 283400, loss: 0.006962657063413644, acc: 99.77766743302345, p_norm: 2114.0274383202336, g_norm: 0.24385545500069336, lr:  0.000469, elapsed time:  138812
Step 283500, loss: 0.00747793739896224, acc: 99.75970339775085, p_norm: 2114.1475088494917, g_norm: 0.11896096839183976, lr:  0.000469, elapsed time:  138857
Step 283600, loss: 0.006585807997698794, acc: 99.79303042590618, p_norm: 2114.264162486073, g_norm: 0.19016304326714173, lr:  0.000469, elapsed time:  138904
Step 283700, loss: 0.0073125657866512485, acc: 99.76828606426716, p_norm: 2114.3817534869436, g_norm: 0.24438720709819964, lr:  0.000469, elapsed time:  138950
Step 283800, loss: 0.007310196987164091, acc: 99.76599314808846, p_norm: 2114.5029765273694, g_norm: 0.3142342122591929, lr:  0.000469, elapsed time:  138996
Step 283900, loss: 0.006935651097210211, acc: 99.77573420107365, p_norm: 2114.6154355019435, g_norm: 0.13301759662793194, lr:  0.000469, elapsed time:  139042
Step 284000, loss: 0.007435436233590735, acc: 99.7610156238079, p_norm: 2114.737157872596, g_norm: 0.21357634386060562, lr:  0.000469, elapsed time:  139089
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 284000, eval loss: 0.0201944541686953, eval acc: 99.58712005615234
Step 284100, loss: 0.007211347517559261, acc: 99.76934210956097, p_norm: 2114.868029641643, g_norm: 0.25429352407628597, lr:  0.000469, elapsed time:  139145
Step 284200, loss: 0.007305002806515404, acc: 99.76879265904427, p_norm: 2114.99082419066, g_norm: 0.15883370001971625, lr:  0.000469, elapsed time:  139194
Step 284300, loss: 0.006878931321734854, acc: 99.7783122509718, p_norm: 2115.114239183645, g_norm: 0.16632116422209742, lr:  0.000469, elapsed time:  139241
Step 284400, loss: 0.007561051012307871, acc: 99.76315353810787, p_norm: 2115.2377518945036, g_norm: 0.19546793205030727, lr:  0.000469, elapsed time:  139289
Step 284500, loss: 0.007102777355776198, acc: 99.77465996146202, p_norm: 2115.3606387144814, g_norm: 0.20389841149796045, lr:  0.000469, elapsed time:  139336
Step 284600, loss: 0.006924591109418543, acc: 99.77600724995136, p_norm: 2115.469867955151, g_norm: 0.1634647498473079, lr:  0.000468, elapsed time:  139384
Step 284700, loss: 0.0071842652691520925, acc: 99.77148079872131, p_norm: 2115.5918506491575, g_norm: 0.16407871757815043, lr:  0.000468, elapsed time:  139431
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 284800, loss: 0.007288112845854624, acc: 99.7692054909453, p_norm: 2115.71411652837, g_norm: 0.12715567124534996, lr:  0.000468, elapsed time:  139480
Step 284900, loss: 0.006751035143133776, acc: 99.78148762881756, p_norm: 2115.832598905063, g_norm: 0.12091870378014632, lr:  0.000468, elapsed time:  139528
Step 285000, loss: 0.006886798169944086, acc: 99.7763836234808, p_norm: 2115.945155040155, g_norm: 0.21724971821725111, lr:  0.000468, elapsed time:  139575
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C O c 1 c c c ( C = O ) c ( F ) c 1 - c 1 c c 2 c ( c c 1 C ) C ( C ) ( C ) C C C 2 ( C ) C _EOS
Predicted text: C O c 1 c c c ( C = O ) c ( F ) c 1 - c 1 c c 2 c ( c c 1 C ) C ( C ) ( C ) C C C 2 ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( N C ( = O ) c 2 c c c ( Cl ) c c 2 ) c c 1 - c 1 c c c ( C ( = O ) N C C 2 C C 2 ) c c 1 _EOS
Predicted text: C c 1 c c c ( N C ( = O ) c 2 c c c ( Cl ) c c 2 ) c c 1 - c 1 c c c ( C ( = O ) N C C 2 C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = [N+] ( [O-] ) c 1 c c c ( O c 2 c c n c 3 c c ( - c 4 c c c ( C 5 O C C O 5 ) c n 4 ) s c 2 3 ) c ( F ) c 1 _EOS
Predicted text: O = [N+] ( [O-] ) c 1 c c c ( O c 2 c c n c 3 c c ( - c 4 c c c ( C 5 O C C O 5 ) c n 4 ) s c 2 3 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C 1 C N ( C ( = O ) O C ) C C 1 N c 1 n c ( C C ) c ( - c 2 c c c ( Cl ) c c 2 Cl ) n c 1 C C _EOS
Predicted text: C C O C 1 C N ( C ( = O ) O C ) C C 1 N c 1 n c ( C C ) c ( - c 2 c c c ( Cl ) c c 2 Cl ) n c 1 C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C 1 C C C ( O c 2 c c c 3 c c ( C ( C ) ( N ) C O ) c c c 3 c 2 ) C C 1 _EOS
Predicted text: C C C C C C 1 C C C ( O c 2 c c c 3 c c ( C 4 ( C ) C O C ( = O ) N 4 ) c c c 3 c 2 ) C C 1 _EOS
acc_token: 0.5476190476190477, acc_seq: False

Evaluation (without teacher) at step 285000, eval acc (token): 0.9412363912427381, eval acc (sequence): 0.893950306085704
Saving at step 285000
Step 285100, loss: 0.0066907222354166155, acc: 99.78990703821182, p_norm: 2116.0592819335548, g_norm: 0.14560550392226876, lr:  0.000468, elapsed time:  139672
Step 285200, loss: 0.007120628965949436, acc: 99.77121920883656, p_norm: 2116.1743954048634, g_norm: 0.14875496010714837, lr:  0.000468, elapsed time:  139719
Step 285300, loss: 0.006618355816681287, acc: 99.78705103695393, p_norm: 2116.2915951217487, g_norm: 0.16154712281759392, lr:  0.000468, elapsed time:  139766
Step 285400, loss: 0.006702134195575127, acc: 99.78701336681843, p_norm: 2116.4238947942013, g_norm: 0.20340020879719622, lr:  0.000468, elapsed time:  139812
Step 285500, loss: 0.007155823266020889, acc: 99.77516879141331, p_norm: 2116.543388832835, g_norm: 0.14819622242094094, lr:  0.000468, elapsed time:  139858
Step 285600, loss: 0.007102541658505288, acc: 99.76990480720997, p_norm: 2116.6673569385084, g_norm: 0.17665116087234617, lr:  0.000468, elapsed time:  139905
Step 285700, loss: 0.00734429831100897, acc: 99.76822665333748, p_norm: 2116.7793800913137, g_norm: 0.1115594177481893, lr:  0.000468, elapsed time:  139951
Step 285800, loss: 0.0073206724624833444, acc: 99.76514035463333, p_norm: 2116.904076780254, g_norm: 0.19273986185788083, lr:  0.000467, elapsed time:  139997
Step 285900, loss: 0.006819272888296837, acc: 99.78391940891743, p_norm: 2117.0290124068238, g_norm: 0.17385488766665053, lr:  0.000467, elapsed time:  140044
Step 286000, loss: 0.006974213327284815, acc: 99.77546982467175, p_norm: 2117.1428965376635, g_norm: 0.13578379747639227, lr:  0.000467, elapsed time:  140090
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 286000, eval loss: 0.021674485391522474, eval acc: 99.5743179321289
Step 286100, loss: 0.007128838825483399, acc: 99.77617257833481, p_norm: 2117.2732644368616, g_norm: 0.220468860341165, lr:  0.000467, elapsed time:  140144
Step 286200, loss: 0.007345800194734693, acc: 99.76857849955559, p_norm: 2117.3925853746105, g_norm: 0.1632612851596802, lr:  0.000467, elapsed time:  140190
Step 286300, loss: 0.007074817554857873, acc: 99.7729676514864, p_norm: 2117.5186093639654, g_norm: 0.19840403747578672, lr:  0.000467, elapsed time:  140237
Step 286400, loss: 0.007781496480456554, acc: 99.74821960926056, p_norm: 2117.6427387940175, g_norm: 0.27535924497891107, lr:  0.000467, elapsed time:  140283
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 286500, loss: 0.007036804477640761, acc: 99.77607027215151, p_norm: 2117.765422374573, g_norm: 0.13258306068313494, lr:  0.000467, elapsed time:  140330
Step 286600, loss: 0.007040443230544043, acc: 99.77445329725742, p_norm: 2117.870519436545, g_norm: 0.18074607242341903, lr:  0.000467, elapsed time:  140376
Step 286700, loss: 0.006986975431118481, acc: 99.77527336776257, p_norm: 2117.990809413053, g_norm: 0.22153989582045983, lr:  0.000467, elapsed time:  140422
Step 286800, loss: 0.006841537975560641, acc: 99.7780387699604, p_norm: 2118.107220211423, g_norm: 0.16644966054600135, lr:  0.000467, elapsed time:  140469
Step 286900, loss: 0.006915510811977583, acc: 99.77871389687061, p_norm: 2118.223908901271, g_norm: 0.1205224269547805, lr:  0.000467, elapsed time:  140515
Step 287000, loss: 0.0072216172959451794, acc: 99.77666065096855, p_norm: 2118.3490054596905, g_norm: 0.23796232253773214, lr:  0.000467, elapsed time:  140562
Step 287100, loss: 0.007012677211114351, acc: 99.77686639130116, p_norm: 2118.459907616398, g_norm: 0.19845544356025824, lr:  0.000466, elapsed time:  140608
Step 287200, loss: 0.007214031638013694, acc: 99.76597286760807, p_norm: 2118.579682304656, g_norm: 0.1733832304578758, lr:  0.000466, elapsed time:  140655
Step 287300, loss: 0.006894037914553337, acc: 99.77970290184021, p_norm: 2118.699266949447, g_norm: 0.22902712583222445, lr:  0.000466, elapsed time:  140702
Step 287400, loss: 0.006780229499145207, acc: 99.78241926431656, p_norm: 2118.8090563414294, g_norm: 0.4514921907295496, lr:  0.000466, elapsed time:  140748
Step 287500, loss: 0.00680464005752583, acc: 99.78361810743809, p_norm: 2118.9288324409727, g_norm: 0.26077898130628857, lr:  0.000466, elapsed time:  140795
Step 287600, loss: 0.0069720186703216315, acc: 99.77409160137177, p_norm: 2119.054900509919, g_norm: 0.2762143914929491, lr:  0.000466, elapsed time:  140841
Step 287700, loss: 0.0073278891069003295, acc: 99.75979240238667, p_norm: 2119.1749845528557, g_norm: 0.15335187758627433, lr:  0.000466, elapsed time:  140888
Step 287800, loss: 0.006802450991090154, acc: 99.78091840445995, p_norm: 2119.2947167458037, g_norm: 0.18480118796707437, lr:  0.000466, elapsed time:  140935
Step 287900, loss: 0.006922929198453858, acc: 99.77872121334076, p_norm: 2119.3993164638837, g_norm: 0.21353818984656758, lr:  0.000466, elapsed time:  140981
Step 288000, loss: 0.007089944726358226, acc: 99.76891639828682, p_norm: 2119.5133883528665, g_norm: 0.12910529452525094, lr:  0.000466, elapsed time:  141028
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 288000, eval loss: 0.020633545016230527, eval acc: 99.60572814941406
Step 288100, loss: 0.007679100934374219, acc: 99.75419275462627, p_norm: 2119.6454893153186, g_norm: 0.14150866042167926, lr:  0.000466, elapsed time:  141081
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 288200, loss: 0.006770746493207264, acc: 99.78413987100568, p_norm: 2119.7557714016034, g_norm: 0.16836828738133028, lr:  0.000466, elapsed time:  141128
Step 288300, loss: 0.006938156800188154, acc: 99.7746793627739, p_norm: 2119.8767494073954, g_norm: 0.14384081261028234, lr:  0.000465, elapsed time:  141175
Step 288400, loss: 0.0075557750596271945, acc: 99.76022082567215, p_norm: 2119.990044992718, g_norm: 0.2546680426266826, lr:  0.000465, elapsed time:  141221
Step 288500, loss: 0.00711089939060912, acc: 99.77079327404499, p_norm: 2120.1116433361412, g_norm: 0.1000823243631319, lr:  0.000465, elapsed time:  141267
Step 288600, loss: 0.006822379722889309, acc: 99.78926552832127, p_norm: 2120.2255675112237, g_norm: 0.37011644467364946, lr:  0.000465, elapsed time:  141314
Step 288700, loss: 0.006652306511732604, acc: 99.78990705311298, p_norm: 2120.3500846481065, g_norm: 0.2926925925005948, lr:  0.000465, elapsed time:  141361
Step 288800, loss: 0.00705652282023948, acc: 99.77365970611572, p_norm: 2120.464932467419, g_norm: 0.3274560257053739, lr:  0.000465, elapsed time:  141407
Step 288900, loss: 0.007091858237909037, acc: 99.76856531202793, p_norm: 2120.5925681949957, g_norm: 0.1549659629564562, lr:  0.000465, elapsed time:  141453
Step 289000, loss: 0.007040250273767015, acc: 99.77227374911308, p_norm: 2120.7124783108584, g_norm: 0.28665266621836655, lr:  0.000465, elapsed time:  141499
Step 289100, loss: 0.006965278549669165, acc: 99.77898003160954, p_norm: 2120.8278387741343, g_norm: 0.18455815834260894, lr:  0.000465, elapsed time:  141546
Step 289200, loss: 0.007273440890221536, acc: 99.76384019851685, p_norm: 2120.9576060466698, g_norm: 0.19748415917638118, lr:  0.000465, elapsed time:  141593
Step 289300, loss: 0.006471064691049832, acc: 99.79231302440166, p_norm: 2121.0613448258205, g_norm: 0.16345847509377587, lr:  0.000465, elapsed time:  141640
Step 289400, loss: 0.006758801485084405, acc: 99.78464171290398, p_norm: 2121.1853812167456, g_norm: 0.14838467265052765, lr:  0.000465, elapsed time:  141686
Step 289500, loss: 0.0075567199164106565, acc: 99.75862829387188, p_norm: 2121.305713196039, g_norm: 0.24696366727730498, lr:  0.000465, elapsed time:  141733
Step 289600, loss: 0.0063902565377065915, acc: 99.79398873448372, p_norm: 2121.4220224359296, g_norm: 0.14014509903528757, lr:  0.000464, elapsed time:  141779
Step 289700, loss: 0.007311163777685579, acc: 99.76354482769966, p_norm: 2121.53238533974, g_norm: 0.17490417625358173, lr:  0.000464, elapsed time:  141826
Step 289800, loss: 0.006923292597421095, acc: 99.77821171283722, p_norm: 2121.6520057708944, g_norm: 0.18057379130851334, lr:  0.000464, elapsed time:  141873
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 289900, loss: 0.007097653834059758, acc: 99.77752680505687, p_norm: 2121.7636726762007, g_norm: 0.14332489455286246, lr:  0.000464, elapsed time:  141920
Step 290000, loss: 0.006941157805340481, acc: 99.77493970096111, p_norm: 2121.8776882664074, g_norm: 0.11782636651008853, lr:  0.000464, elapsed time:  141967
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 290000, eval loss: 0.018957506992192067, eval acc: 99.6353759765625
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) C O c 1 c ( C # N ) c ( - c 2 c c c ( Cl ) c c 2 Cl ) c n 2 c ( Br ) c n c 1 2 _EOS
Predicted text: C C ( C ) C O c 1 c ( C # N ) c ( - c 2 c c c ( Cl ) c c 2 Cl ) c n 2 c ( Br ) c n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C O ) C N 1 C ( = O ) C 2 = C ( C 1 = O ) c 1 c c c c c 1 C C 2 _EOS
Predicted text: C C ( C ) ( C O ) C N = C ( O ) C 1 = C ( C ( = O ) O ) c 2 c c c c c 2 C C 1 _EOS
acc_token: 0.46153846153846156, acc_seq: False

Target text: O = C ( O ) c 1 c c 2 n c ( N c 3 c ( Cl ) c c c c 3 Cl ) [nH] c 2 c 2 n c ( C 3 C C 3 ) o c 1 2 _EOS
Predicted text: O = C ( O ) c 1 c c 2 n c ( N c 3 c ( Cl ) c c c c 3 Cl ) [nH] c 2 c 2 n c ( C 3 C C 3 ) o c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: O c 1 c c c ( S c 2 c c c ( C C N C C ( O ) c 3 c c c c ( Cl ) c 3 ) c c 2 ) c c 1 _EOS
Predicted text: O c 1 c c c ( S c 2 c c c ( C C N C C ( O ) c 3 c c c c ( Cl ) c 3 ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C 1 C C N ( C C C c 2 n [nH] c 3 c c ( O C ) c c c 2 3 ) C C 1 _EOS
Predicted text: C C C C C 1 C C N ( C C C c 2 n [nH] c 3 c c ( O C ) c c c 2 3 ) C C 1 . Cl _EOS
acc_token: 0.9714285714285714, acc_seq: False

Evaluation (without teacher) at step 290000, eval acc (token): 0.9403239580725038, eval acc (sequence): 0.890887889388639
Saving at step 290000
Step 290100, loss: 0.006701554320679861, acc: 99.7868481874466, p_norm: 2122.0018949535174, g_norm: 0.15148125419566844, lr:  0.000464, elapsed time:  142070
Step 290200, loss: 0.007000310814437399, acc: 99.77754127979279, p_norm: 2122.1213564271043, g_norm: 0.19045832620632314, lr:  0.000464, elapsed time:  142116
Step 290300, loss: 0.00662492863456464, acc: 99.78784027695656, p_norm: 2122.241988267345, g_norm: 0.1352227378898036, lr:  0.000464, elapsed time:  142162
Step 290400, loss: 0.006580518394962383, acc: 99.79059872031212, p_norm: 2122.361647936915, g_norm: 0.23131113628725594, lr:  0.000464, elapsed time:  142209
Step 290500, loss: 0.007252826628791809, acc: 99.76825287938118, p_norm: 2122.4917101194433, g_norm: 0.211171087787306, lr:  0.000464, elapsed time:  142256
Step 290600, loss: 0.006891547323812119, acc: 99.77675552666187, p_norm: 2122.619378500914, g_norm: 0.15482259199234008, lr:  0.000464, elapsed time:  142303
Step 290700, loss: 0.007084029300276597, acc: 99.77280052006245, p_norm: 2122.7484390966483, g_norm: 0.15421177992177038, lr:  0.000464, elapsed time:  142349
Step 290800, loss: 0.006965419683328946, acc: 99.77861014008522, p_norm: 2122.852836319943, g_norm: 0.12957130469232475, lr:  0.000463, elapsed time:  142395
Step 290900, loss: 0.007226659551124612, acc: 99.7740048468113, p_norm: 2122.987348371305, g_norm: 0.11102117554624, lr:  0.000463, elapsed time:  142441
Step 291000, loss: 0.007010289149593518, acc: 99.77617433667183, p_norm: 2123.1129947722275, g_norm: 0.1868347972351198, lr:  0.000463, elapsed time:  142488
Step 291100, loss: 0.007045744023798761, acc: 99.76841615140438, p_norm: 2123.228205961128, g_norm: 0.18978571236915784, lr:  0.000463, elapsed time:  142534
Step 291200, loss: 0.006905744144905839, acc: 99.77687038481236, p_norm: 2123.3395686986196, g_norm: 0.19810352263171538, lr:  0.000463, elapsed time:  142581
Step 291300, loss: 0.007102519351183219, acc: 99.76959328353405, p_norm: 2123.445727308315, g_norm: 0.13683296144900448, lr:  0.000463, elapsed time:  142627
Step 291400, loss: 0.006947893830624707, acc: 99.77475510537624, p_norm: 2123.569839817485, g_norm: 0.37199384374847105, lr:  0.000463, elapsed time:  142674
Step 291500, loss: 0.0076282209698274525, acc: 99.75121329724789, p_norm: 2123.682376465885, g_norm: 0.1840399634920998, lr:  0.000463, elapsed time:  142721
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 291600, loss: 0.006901753433222409, acc: 99.77891258802958, p_norm: 2123.790197990723, g_norm: 0.16836141673163965, lr:  0.000463, elapsed time:  142768
Step 291700, loss: 0.007071793471855017, acc: 99.77345845103264, p_norm: 2123.916248877635, g_norm: 0.16388682567617255, lr:  0.000463, elapsed time:  142814
Step 291800, loss: 0.006947386847314192, acc: 99.77732898294926, p_norm: 2124.0378972093304, g_norm: 0.1749019084590122, lr:  0.000463, elapsed time:  142860
Step 291900, loss: 0.00658231312472708, acc: 99.78932888805866, p_norm: 2124.1538689704685, g_norm: 0.42088649431335795, lr:  0.000463, elapsed time:  142907
Step 292000, loss: 0.007012996165144614, acc: 99.77362124621868, p_norm: 2124.2681863868597, g_norm: 0.3173606207516812, lr:  0.000463, elapsed time:  142953
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 292000, eval loss: 0.020993032768601556, eval acc: 99.59827423095703
Step 292100, loss: 0.00669695496737404, acc: 99.78955371677876, p_norm: 2124.3962943281963, g_norm: 0.1735433220995985, lr:  0.000462, elapsed time:  143007
Step 292200, loss: 0.0069360017037070065, acc: 99.77016444504261, p_norm: 2124.5121196830655, g_norm: 0.1760239876906959, lr:  0.000462, elapsed time:  143053
Step 292300, loss: 0.006692742058589829, acc: 99.7824587970972, p_norm: 2124.622387957798, g_norm: 0.25882589539273887, lr:  0.000462, elapsed time:  143100
Step 292400, loss: 0.006568730194512682, acc: 99.79052589833736, p_norm: 2124.729786726201, g_norm: 0.2206981109180287, lr:  0.000462, elapsed time:  143146
Step 292500, loss: 0.007171477022966428, acc: 99.76964329183102, p_norm: 2124.860263578052, g_norm: 0.19385155751343908, lr:  0.000462, elapsed time:  143193
Step 292600, loss: 0.007207977145517361, acc: 99.76727931201458, p_norm: 2124.981365757101, g_norm: 0.16308818806415287, lr:  0.000462, elapsed time:  143239
Step 292700, loss: 0.006958050773982904, acc: 99.7734817713499, p_norm: 2125.093766733519, g_norm: 0.1907803310604404, lr:  0.000462, elapsed time:  143286
Step 292800, loss: 0.007070007360653108, acc: 99.77044866979122, p_norm: 2125.2083250158926, g_norm: 0.17691299580633177, lr:  0.000462, elapsed time:  143332
Step 292900, loss: 0.006888787652787869, acc: 99.77932970225811, p_norm: 2125.342383523931, g_norm: 0.13287244088680294, lr:  0.000462, elapsed time:  143379
Step 293000, loss: 0.007380908891864237, acc: 99.75739352405071, p_norm: 2125.461769434495, g_norm: 0.18484341567859908, lr:  0.000462, elapsed time:  143426
Step 293100, loss: 0.007242786360429818, acc: 99.76725593209267, p_norm: 2125.590410071097, g_norm: 0.18880623935495436, lr:  0.000462, elapsed time:  143475
Step 293200, loss: 0.0069347365969224485, acc: 99.77855981886387, p_norm: 2125.7116576213175, g_norm: 0.2087499810841241, lr:  0.000462, elapsed time:  143524
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 293300, loss: 0.007157253092666524, acc: 99.77060634799986, p_norm: 2125.827750708706, g_norm: 0.26376787729941903, lr:  0.000461, elapsed time:  143576
Step 293400, loss: 0.0066486636251192974, acc: 99.78560200333595, p_norm: 2125.949513028011, g_norm: 0.2147486667886614, lr:  0.000461, elapsed time:  143623
Step 293500, loss: 0.006290023017645581, acc: 99.79873517155647, p_norm: 2126.047108455003, g_norm: 0.17699531609488917, lr:  0.000461, elapsed time:  143670
Step 293600, loss: 0.006643317044436116, acc: 99.78668807446957, p_norm: 2126.1650873309013, g_norm: 0.16205078628185002, lr:  0.000461, elapsed time:  143717
Step 293700, loss: 0.007198903902644815, acc: 99.7708117812872, p_norm: 2126.2760582996016, g_norm: 0.19422810499540313, lr:  0.000461, elapsed time:  143763
Step 293800, loss: 0.006919894203319927, acc: 99.78118447959423, p_norm: 2126.3925711594748, g_norm: 0.23323301047216718, lr:  0.000461, elapsed time:  143810
Step 293900, loss: 0.0065693472997736535, acc: 99.79117734730244, p_norm: 2126.5102824646874, g_norm: 0.19950135808022515, lr:  0.000461, elapsed time:  143856
Step 294000, loss: 0.007061608522435563, acc: 99.77475963532925, p_norm: 2126.622379046051, g_norm: 0.3893254095572897, lr:  0.000461, elapsed time:  143903
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 294000, eval loss: 0.018802500860765577, eval acc: 99.6266860961914
Step 294100, loss: 0.007122240621720266, acc: 99.77316398918629, p_norm: 2126.745908453892, g_norm: 0.20731940729274778, lr:  0.000461, elapsed time:  143956
Step 294200, loss: 0.007047876447268208, acc: 99.77291165292263, p_norm: 2126.867893383306, g_norm: 0.2978607646106043, lr:  0.000461, elapsed time:  144002
Step 294300, loss: 0.006961842343134777, acc: 99.7768125385046, p_norm: 2126.9916149543155, g_norm: 0.2050323187821799, lr:  0.000461, elapsed time:  144048
Step 294400, loss: 0.006876687896219664, acc: 99.77561412751675, p_norm: 2127.098468095864, g_norm: 0.227842130544448, lr:  0.000461, elapsed time:  144095
Step 294500, loss: 0.006877708188003453, acc: 99.77625082433224, p_norm: 2127.226083795243, g_norm: 0.19278223662504407, lr:  0.000461, elapsed time:  144141
Step 294600, loss: 0.00710458208593991, acc: 99.77581112086773, p_norm: 2127.3383804541604, g_norm: 0.2234672694512575, lr:  0.000460, elapsed time:  144188
Step 294700, loss: 0.007117070569729549, acc: 99.77069960534573, p_norm: 2127.472566824828, g_norm: 0.15400221627723926, lr:  0.000460, elapsed time:  144234
Step 294800, loss: 0.007112940487713786, acc: 99.7738314718008, p_norm: 2127.5942266693314, g_norm: 0.14028109577518633, lr:  0.000460, elapsed time:  144281
Step 294900, loss: 0.007056444635236403, acc: 99.77759559452534, p_norm: 2127.6997461522965, g_norm: 0.15454372027949242, lr:  0.000460, elapsed time:  144327
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 295000, loss: 0.006722551125872889, acc: 99.78697626821456, p_norm: 2127.815452432027, g_norm: 0.15646811030909413, lr:  0.000460, elapsed time:  144374
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C c 1 c c s c 1 C O _EOS
Predicted text: O = C c 1 c c s c 1 C O _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C S ( = O ) ( = O ) c 1 c c ( C # N ) c c c 1 C 1 C ( C # N ) = C ( C ) N ( c 2 c c c c ( C ( F ) ( F ) F ) c 2 ) C ( = O ) N 1 C _EOS
Predicted text: C O C C S ( = O ) ( = O ) c 1 c c ( C # N ) c c c 1 C 1 C ( C # N ) = C ( C ) N ( c 2 c c c c ( C ( F ) ( F ) F ) c 2 ) C ( = O ) N 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C C C O c 1 c c ( C ( = O ) N C ( C c 2 c c c c c 2 ) C ( O ) C C ( C ) C ( = O ) N C 2 C C 3 C C C 2 C 3 ) c c ( N 2 C C C C 2 = O ) c 1 _EOS
Predicted text: C O C C C C O c 1 c c ( C ( = O ) N C ( C c 2 c c c c c 2 ) C ( O ) C C ( C ) C ( = O ) N C 2 C C 3 C C C 2 C 3 ) c c ( N 2 C C C C 2 = O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) N c 1 n c ( C ( = O ) O ) c n 2 c ( = O ) [nH] n c 1 2 _EOS
Predicted text: C C ( C ) N c 1 n c ( C ( = O ) O ) c n 2 c ( = O ) [nH] n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C C O C C O C C O C C O C ( C ( = O ) O ) C ( = O ) C ( C c 1 c c c c c 1 ) N C ( = O ) C ( C C ( = O ) O C c 1 c c c c c 1 ) N C ( = O ) C C N C ( = O ) c 1 c c c ( - c 2 n c ( = O ) o [nH] 2 ) c c 1 _EOS
Predicted text: N C C O C C O C C O C C O C ( C ( = O ) O ) C ( = O ) C ( C c 1 c c c c c 1 ) N C ( = O ) C ( C C ( = O ) O C c 1 c c c c c 1 ) N C ( = O ) C C N C ( = O ) c 1 c c c ( - c 2 n c ( = O ) o [nH] 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 295000, eval acc (token): 0.9408911189066026, eval acc (sequence): 0.8897651006711409
Saving at step 295000
Step 295100, loss: 0.006745198854578121, acc: 99.78109040856361, p_norm: 2127.9185629284966, g_norm: 0.12434435835428523, lr:  0.000460, elapsed time:  144470
Step 295200, loss: 0.006421661728713843, acc: 99.78823433816433, p_norm: 2128.026250286079, g_norm: 0.4408793200839708, lr:  0.000460, elapsed time:  144516
Step 295300, loss: 0.006981129436117044, acc: 99.77263270318508, p_norm: 2128.142922173712, g_norm: 0.17024808924764417, lr:  0.000460, elapsed time:  144563
Step 295400, loss: 0.006985538751705462, acc: 99.7718434035778, p_norm: 2128.259225855911, g_norm: 0.1730704350348418, lr:  0.000460, elapsed time:  144609
Step 295500, loss: 0.00677114275709755, acc: 99.78256653249264, p_norm: 2128.368696855529, g_norm: 0.14709784246710692, lr:  0.000460, elapsed time:  144655
Step 295600, loss: 0.007102201658381091, acc: 99.77428461611271, p_norm: 2128.4942097000944, g_norm: 0.2093789681795983, lr:  0.000460, elapsed time:  144701
Step 295700, loss: 0.006704531260834301, acc: 99.78712859749794, p_norm: 2128.613474536928, g_norm: 0.24770708392927168, lr:  0.000460, elapsed time:  144748
Step 295800, loss: 0.0070361633629545395, acc: 99.77813646197319, p_norm: 2128.717703121593, g_norm: 0.1522765070577177, lr:  0.000460, elapsed time:  144794
Step 295900, loss: 0.0068628499340775305, acc: 99.77546468377113, p_norm: 2128.824029762683, g_norm: 0.1910656131844983, lr:  0.000459, elapsed time:  144840
Step 296000, loss: 0.007181626891824635, acc: 99.76618646085262, p_norm: 2128.945955910641, g_norm: 0.1830412919188902, lr:  0.000459, elapsed time:  144887
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 296000, eval loss: 0.021073491270763033, eval acc: 99.59005737304688
Step 296100, loss: 0.0066950687782446035, acc: 99.78311298787594, p_norm: 2129.0615879562124, g_norm: 0.22585078871605332, lr:  0.000459, elapsed time:  144940
Step 296200, loss: 0.006844723780486675, acc: 99.78188709914684, p_norm: 2129.176893239426, g_norm: 0.1621073927830973, lr:  0.000459, elapsed time:  144987
Step 296300, loss: 0.007156787505027751, acc: 99.76750640571117, p_norm: 2129.2950591990048, g_norm: 0.1400555708796458, lr:  0.000459, elapsed time:  145033
Step 296400, loss: 0.006969238653900902, acc: 99.77363428473473, p_norm: 2129.406574109454, g_norm: 0.2002796004962793, lr:  0.000459, elapsed time:  145080
Step 296500, loss: 0.006412349966776674, acc: 99.79331387579441, p_norm: 2129.516589212153, g_norm: 0.14501005376874904, lr:  0.000459, elapsed time:  145127
Step 296600, loss: 0.006991569400179287, acc: 99.77794446051121, p_norm: 2129.647404874748, g_norm: 0.18373255703089553, lr:  0.000459, elapsed time:  145173
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 296700, loss: 0.007122969432778295, acc: 99.7695101845649, p_norm: 2129.774909046007, g_norm: 0.23021273190650265, lr:  0.000459, elapsed time:  145221
Step 296800, loss: 0.006532841883035871, acc: 99.79213742911816, p_norm: 2129.8736264870986, g_norm: 0.1740203048537133, lr:  0.000459, elapsed time:  145267
Step 296900, loss: 0.007313155606898363, acc: 99.76159647107124, p_norm: 2129.984435757415, g_norm: 0.2352179910412328, lr:  0.000459, elapsed time:  145313
Step 297000, loss: 0.0066913281819688565, acc: 99.78556743264198, p_norm: 2130.099360649115, g_norm: 0.20786138640187649, lr:  0.000459, elapsed time:  145364
Step 297100, loss: 0.0065634062126537175, acc: 99.79513648152351, p_norm: 2130.2263443108436, g_norm: 0.1794683180081698, lr:  0.000459, elapsed time:  145423
Step 297200, loss: 0.007119145595133887, acc: 99.76768055558205, p_norm: 2130.3458439022847, g_norm: 0.16012357649003164, lr:  0.000458, elapsed time:  145472
Step 297300, loss: 0.006765871118059295, acc: 99.78703337907791, p_norm: 2130.4664690786126, g_norm: 0.18966171948797192, lr:  0.000458, elapsed time:  145519
Step 297400, loss: 0.007034672898807912, acc: 99.77362042665482, p_norm: 2130.578861893563, g_norm: 0.15822900286685218, lr:  0.000458, elapsed time:  145566
Step 297500, loss: 0.0073422287700987, acc: 99.76369653642178, p_norm: 2130.6962710514936, g_norm: 0.2768481144960035, lr:  0.000458, elapsed time:  145614
Step 297600, loss: 0.00701249060122791, acc: 99.77633230388165, p_norm: 2130.8238757181516, g_norm: 0.11788418922295096, lr:  0.000458, elapsed time:  145662
Step 297700, loss: 0.0066195146915924855, acc: 99.78894723951817, p_norm: 2130.9277867585424, g_norm: 0.22406541891369733, lr:  0.000458, elapsed time:  145710
Step 297800, loss: 0.0066902417720575615, acc: 99.78183615207672, p_norm: 2131.0301175530944, g_norm: 0.2450675373216198, lr:  0.000458, elapsed time:  145758
Step 297900, loss: 0.006981060899233853, acc: 99.77594491839409, p_norm: 2131.153337499665, g_norm: 0.1675773734259017, lr:  0.000458, elapsed time:  145805
Step 298000, loss: 0.006736912553315051, acc: 99.78440794348717, p_norm: 2131.271200650455, g_norm: 0.1240217800500444, lr:  0.000458, elapsed time:  145852
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 298000, eval loss: 0.02058335693787739, eval acc: 99.61544036865234
Step 298100, loss: 0.0068882327330084085, acc: 99.78185579180717, p_norm: 2131.397735853322, g_norm: 0.15892233519825347, lr:  0.000458, elapsed time:  145907
Step 298200, loss: 0.006698532365508072, acc: 99.78824351727962, p_norm: 2131.512003701456, g_norm: 0.18992458443770296, lr:  0.000458, elapsed time:  145955
Step 298300, loss: 0.00665856663114937, acc: 99.78933393955231, p_norm: 2131.614770728867, g_norm: 0.14355904344088818, lr:  0.000458, elapsed time:  146003
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 298400, loss: 0.007119884083227187, acc: 99.77351171207191, p_norm: 2131.7237161042594, g_norm: 0.1668524041899016, lr:  0.000458, elapsed time:  146051
Step 298500, loss: 0.006241172224126785, acc: 99.80045321583748, p_norm: 2131.8372632871024, g_norm: 0.1547381814538652, lr:  0.000457, elapsed time:  146100
Step 298600, loss: 0.006589573140372522, acc: 99.79098205268383, p_norm: 2131.963809994002, g_norm: 0.2783474686381943, lr:  0.000457, elapsed time:  146147
Step 298700, loss: 0.006513625324041641, acc: 99.7908816486597, p_norm: 2132.0799528757793, g_norm: 0.15643916163080954, lr:  0.000457, elapsed time:  146194
Step 298800, loss: 0.00716280521734916, acc: 99.7673341780901, p_norm: 2132.1997385080745, g_norm: 0.19515864956413204, lr:  0.000457, elapsed time:  146242
Step 298900, loss: 0.006779109439194144, acc: 99.78069449961185, p_norm: 2132.3139541630057, g_norm: 0.23968063510106571, lr:  0.000457, elapsed time:  146290
Step 299000, loss: 0.00700891645576121, acc: 99.77177128195763, p_norm: 2132.4394116976664, g_norm: 0.13336886619515181, lr:  0.000457, elapsed time:  146337
Step 299100, loss: 0.0068874285391939336, acc: 99.77552202343941, p_norm: 2132.5524857834857, g_norm: 0.2180396608541348, lr:  0.000457, elapsed time:  146385
Step 299200, loss: 0.006924574286817915, acc: 99.77632862329483, p_norm: 2132.6685205675517, g_norm: 0.20750540243876195, lr:  0.000457, elapsed time:  146433
Step 299300, loss: 0.006784218778848299, acc: 99.77709735929966, p_norm: 2132.7860477955714, g_norm: 0.25131355799864474, lr:  0.000457, elapsed time:  146481
Step 299400, loss: 0.007092943673542323, acc: 99.77120390534401, p_norm: 2132.903560286154, g_norm: 0.23026165139030916, lr:  0.000457, elapsed time:  146528
Step 299500, loss: 0.006725363408058911, acc: 99.78616479039192, p_norm: 2133.01755391373, g_norm: 0.22581420343998143, lr:  0.000457, elapsed time:  146576
Step 299600, loss: 0.006339738846581895, acc: 99.79551653563976, p_norm: 2133.1242012951934, g_norm: 0.18222662422780914, lr:  0.000457, elapsed time:  146624
Step 299700, loss: 0.006906771121011843, acc: 99.78211714327335, p_norm: 2133.2304595882492, g_norm: 0.14451327868481562, lr:  0.000457, elapsed time:  146671
Step 299800, loss: 0.006725582011640654, acc: 99.78439827263355, p_norm: 2133.346720301383, g_norm: 0.2229283105520153, lr:  0.000456, elapsed time:  146719
Step 299900, loss: 0.006850113955042616, acc: 99.78776454925537, p_norm: 2133.4603655877345, g_norm: 0.291004860714067, lr:  0.000456, elapsed time:  146767
Step 300000, loss: 0.007219846134867112, acc: 99.76944518089294, p_norm: 2133.573895483122, g_norm: 0.19083383191606146, lr:  0.000456, elapsed time:  146814
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 300000, eval loss: 0.020807460703526893, eval acc: 99.56580352783203
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c c ( Cl ) c ( C ( C ) C ( O ) c 2 c c n c ( Cl ) c 2 ) c 1 _EOS
Predicted text: C O c 1 c c c ( Cl ) c ( C ( C ) C ( O ) c 2 c c n c ( Cl ) c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C C C N c 1 n c c c n 1 _EOS
Predicted text: N C C C N c 1 n c c c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C c 1 c ( O ) c c c c 1 F _EOS
Predicted text: C C C c 1 c ( O ) c c c c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 c c c ( C c 2 c c ( Br ) c ( O C C O C C ( F ) ( F ) F ) c c 2 Cl ) c c 1 _EOS
Predicted text: C C c 1 c c c ( C c 2 c c ( Br ) c ( O C C = O ) c c 2 Cl ) c c 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.5121951219512195, acc_seq: False

Target text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N O C C 2 C C 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 _EOS
Predicted text: C C ( C ) ( C ) C C 1 N C ( C ( = O ) N O C C 2 C C 2 ) C ( c 2 c c c c ( Cl ) c 2 F ) C 1 ( C # N ) c 1 c c c ( Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 300000, eval acc (token): 0.9481402650746303, eval acc (sequence): 0.9022283641388841
Saving at step 300000
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 300100, loss: 0.007157853633634206, acc: 99.7752586407448, p_norm: 2133.686628216344, g_norm: 0.24117543634371147, lr:  0.000456, elapsed time:  146923
Step 300200, loss: 0.006690017368746339, acc: 99.78136652708054, p_norm: 2133.797835526731, g_norm: 0.2542926208138104, lr:  0.000456, elapsed time:  146969
Step 300300, loss: 0.0065334475644704074, acc: 99.78453087806702, p_norm: 2133.904712787224, g_norm: 0.17673252411045798, lr:  0.000456, elapsed time:  147017
Step 300400, loss: 0.00659062126279423, acc: 99.78557404875755, p_norm: 2134.023777739541, g_norm: 0.20853017439470747, lr:  0.000456, elapsed time:  147064
Step 300500, loss: 0.0067807426858962575, acc: 99.77982845902443, p_norm: 2134.139156732515, g_norm: 0.25231344542447853, lr:  0.000456, elapsed time:  147112
Step 300600, loss: 0.006876196522825922, acc: 99.77657690644264, p_norm: 2134.2560738731036, g_norm: 0.15752133465945645, lr:  0.000456, elapsed time:  147159
Step 300700, loss: 0.007107254511779502, acc: 99.7707003057003, p_norm: 2134.3717695559676, g_norm: 0.4018249580635746, lr:  0.000456, elapsed time:  147206
Step 300800, loss: 0.007109887359392815, acc: 99.76737575232983, p_norm: 2134.4908408623937, g_norm: 0.2522448603576469, lr:  0.000456, elapsed time:  147253
Step 300900, loss: 0.006459966668426204, acc: 99.79484015703201, p_norm: 2134.603147404239, g_norm: 0.1044172848200735, lr:  0.000456, elapsed time:  147301
Step 301000, loss: 0.006652290577840177, acc: 99.7875834107399, p_norm: 2134.721693314605, g_norm: 0.17490627247390172, lr:  0.000456, elapsed time:  147349
Step 301100, loss: 0.00713398278800014, acc: 99.77829575538635, p_norm: 2134.83327224654, g_norm: 0.183598364163397, lr:  0.000455, elapsed time:  147396
Step 301200, loss: 0.006670334449736402, acc: 99.78816616535187, p_norm: 2134.9448765696775, g_norm: 0.1662504139116596, lr:  0.000455, elapsed time:  147443
Step 301300, loss: 0.006718154352302008, acc: 99.78491492569447, p_norm: 2135.050539924089, g_norm: 0.1814632625070847, lr:  0.000455, elapsed time:  147492
Step 301400, loss: 0.006642702506815113, acc: 99.78928130865097, p_norm: 2135.1595773320773, g_norm: 0.13289278664336782, lr:  0.000455, elapsed time:  147539
Step 301500, loss: 0.006921643088262499, acc: 99.77181948721409, p_norm: 2135.2832344176027, g_norm: 0.20457163389466387, lr:  0.000455, elapsed time:  147587
Step 301600, loss: 0.00667168470586148, acc: 99.78671444952488, p_norm: 2135.398399053196, g_norm: 0.15494239712997973, lr:  0.000455, elapsed time:  147634
Step 301700, loss: 0.006711084662747453, acc: 99.7850733101368, p_norm: 2135.517247340755, g_norm: 0.14281030102126882, lr:  0.000455, elapsed time:  147683
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 301800, loss: 0.0069334080004292125, acc: 99.77568441362523, p_norm: 2135.630713165265, g_norm: 0.19218064270048513, lr:  0.000455, elapsed time:  147731
Step 301900, loss: 0.0063866819695067535, acc: 99.7900890558958, p_norm: 2135.737707688254, g_norm: 0.16911693014022314, lr:  0.000455, elapsed time:  147779
Step 302000, loss: 0.006531634389793908, acc: 99.79607158899307, p_norm: 2135.8540831772193, g_norm: 0.1372000326115099, lr:  0.000455, elapsed time:  147827
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 302000, eval loss: 0.02053364072344265, eval acc: 99.6025619506836
Step 302100, loss: 0.006346416012656846, acc: 99.80160982906818, p_norm: 2135.9643545443582, g_norm: 0.27881551784507247, lr:  0.000455, elapsed time:  147882
Step 302200, loss: 0.006748832543289609, acc: 99.78185503184795, p_norm: 2136.0762302129783, g_norm: 0.17135816808488222, lr:  0.000455, elapsed time:  147930
Step 302300, loss: 0.006581048049092715, acc: 99.78967055678368, p_norm: 2136.185066348484, g_norm: 0.20961522858175508, lr:  0.000455, elapsed time:  147978
Step 302400, loss: 0.007024775939698884, acc: 99.77379436790943, p_norm: 2136.299259971675, g_norm: 0.18977104128073588, lr:  0.000454, elapsed time:  148025
Step 302500, loss: 0.006444282586380723, acc: 99.79095184803009, p_norm: 2136.408091046367, g_norm: 0.29166742579206023, lr:  0.000454, elapsed time:  148073
Step 302600, loss: 0.006682355163075044, acc: 99.78713503479958, p_norm: 2136.5223996569885, g_norm: 0.1117281742533685, lr:  0.000454, elapsed time:  148120
Step 302700, loss: 0.006956232375032414, acc: 99.77816393971443, p_norm: 2136.642062416074, g_norm: 0.27777619037329365, lr:  0.000454, elapsed time:  148168
Step 302800, loss: 0.007067587094697955, acc: 99.77651512622833, p_norm: 2136.7556942793217, g_norm: 0.23971942550532116, lr:  0.000454, elapsed time:  148215
Step 302900, loss: 0.0071065033234481234, acc: 99.77146089076996, p_norm: 2136.8739487503617, g_norm: 0.15966053992955173, lr:  0.000454, elapsed time:  148262
Step 303000, loss: 0.006686860179670475, acc: 99.78056740760803, p_norm: 2136.995157120127, g_norm: 0.17389270226781406, lr:  0.000454, elapsed time:  148309
Step 303100, loss: 0.006918881464621336, acc: 99.77378775179386, p_norm: 2137.098286881878, g_norm: 0.17988728397718168, lr:  0.000454, elapsed time:  148356
Step 303200, loss: 0.006567540014348196, acc: 99.78881800174713, p_norm: 2137.2124082685145, g_norm: 0.19711166572636538, lr:  0.000454, elapsed time:  148404
Step 303300, loss: 0.007086189562769505, acc: 99.76977400481701, p_norm: 2137.33427792788, g_norm: 0.21285837011134426, lr:  0.000454, elapsed time:  148451
Step 303400, loss: 0.006853987529557344, acc: 99.78216949105263, p_norm: 2137.4532205955056, g_norm: 0.1270278989406752, lr:  0.000454, elapsed time:  148499
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 303500, loss: 0.006863882721355676, acc: 99.77696869272748, p_norm: 2137.563749191435, g_norm: 0.17109510867488475, lr:  0.000454, elapsed time:  148548
Step 303600, loss: 0.006365688060723187, acc: 99.79772627353668, p_norm: 2137.6836073337195, g_norm: 0.17501516091400124, lr:  0.000454, elapsed time:  148595
Step 303700, loss: 0.006264486436939478, acc: 99.80154237151146, p_norm: 2137.7734325533766, g_norm: 0.12844564609431983, lr:  0.000454, elapsed time:  148643
Step 303800, loss: 0.006241069949855955, acc: 99.7966795116663, p_norm: 2137.876107114319, g_norm: 0.19369303869034946, lr:  0.000453, elapsed time:  148691
Step 303900, loss: 0.006489477541163069, acc: 99.79396516084671, p_norm: 2137.987870120807, g_norm: 0.22440163809496827, lr:  0.000453, elapsed time:  148738
Step 304000, loss: 0.006535080099370134, acc: 99.79176838696003, p_norm: 2138.090452254695, g_norm: 0.24492159864222923, lr:  0.000453, elapsed time:  148786
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 304000, eval loss: 0.018642848559466074, eval acc: 99.63414764404297
Step 304100, loss: 0.006943225294016884, acc: 99.77784359455109, p_norm: 2138.2033813526705, g_norm: 0.14323751715310482, lr:  0.000453, elapsed time:  148841
Step 304200, loss: 0.006405788662659688, acc: 99.79504650831223, p_norm: 2138.3215759809045, g_norm: 0.3172047679877802, lr:  0.000453, elapsed time:  148889
Step 304300, loss: 0.006872330573351064, acc: 99.77575072646141, p_norm: 2138.4476008010565, g_norm: 0.19300718640130077, lr:  0.000453, elapsed time:  148936
Step 304400, loss: 0.0065640931020607245, acc: 99.79008829593658, p_norm: 2138.5636796393483, g_norm: 0.17896629933954822, lr:  0.000453, elapsed time:  148984
Step 304500, loss: 0.006749147953983083, acc: 99.78577946126461, p_norm: 2138.6851454047764, g_norm: 0.17569402084639593, lr:  0.000453, elapsed time:  149031
Step 304600, loss: 0.0068487159306096146, acc: 99.77859143912792, p_norm: 2138.7967496410956, g_norm: 0.13609353661345042, lr:  0.000453, elapsed time:  149078
Step 304700, loss: 0.007535362796133995, acc: 99.75442472100258, p_norm: 2138.913633589148, g_norm: 0.21603772712533198, lr:  0.000453, elapsed time:  149125
Step 304800, loss: 0.006863550602465693, acc: 99.78046895563602, p_norm: 2139.022952348282, g_norm: 0.181729361256451, lr:  0.000453, elapsed time:  149173
Step 304900, loss: 0.006778611226545763, acc: 99.78524552285671, p_norm: 2139.1357478023433, g_norm: 0.12115883986689677, lr:  0.000453, elapsed time:  149221
Step 305000, loss: 0.006964901295314121, acc: 99.77849942445755, p_norm: 2139.254008590551, g_norm: 0.3246620058145615, lr:  0.000453, elapsed time:  149269
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C c 1 c c 2 n c c c c 2 c c 1 S c 1 n n c 2 c c c ( - c 3 c n n ( C ) c 3 ) n n 1 2 _EOS
Predicted text: C c 1 c c 2 n c c c c 2 c c 1 S c 1 n n c 2 c c c ( - c 3 c n n ( C ) c 3 ) n n 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( N C ( = O ) c 2 c o c 3 c 2 C ( = O ) C C ( C ) ( C ) C 3 ) c ( F ) c 1 _EOS
Predicted text: C O c 1 c c c ( N C ( = O ) c 2 c o c 3 c 2 C ( = O ) C C ( C ) ( C ) C 3 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( O c 2 c c c c ( O C c 3 c c c c c 3 ) c 2 ) c c 2 c 1 C ( C C ( = O ) O ) O B 2 O _EOS
Predicted text: C c 1 c c ( O c 2 c c c c ( O C c 3 c c c c c 3 ) c 2 ) c c 2 c 1 C ( C C ( = O ) O ) O B 2 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C C C C C C C C C C C C C C C O c 1 c c c 2 c ( c 1 ) C ( O ) ( c 1 c c c ( Cl ) c c 1 ) c 1 c c c c c 1 - 2 _EOS
Predicted text: C C C C C C C C C C C C C C C C C C C C C O c 1 c c c 2 c ( c 1 ) C ( O ) ( c 1 c c c ( Cl ) c c 1 ) c 1 c c c c c 1 - 2 _EOS _PAD
acc_token: 0.4838709677419355, acc_seq: False

Target text: C O C ( = O ) c 1 c c ( [N+] ( = O ) [O-] ) c ( O C ) c ( [N+] ( = O ) [O-] ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c ( [N+] ( = O ) [O-] ) c ( O C ) c ( [N+] ( = O ) [O-] ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 305000, eval acc (token): 0.9419267961875634, eval acc (sequence): 0.8951347160302384
Saving at step 305000
Step 305100, loss: 0.006896215232263785, acc: 99.77740381658077, p_norm: 2139.3747193450645, g_norm: 0.17307492243980296, lr:  0.000452, elapsed time:  149371
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 305200, loss: 0.006806931984286597, acc: 99.77744853230327, p_norm: 2139.484950099907, g_norm: 0.18025802718015996, lr:  0.000452, elapsed time:  149420
Step 305300, loss: 0.006790048178118013, acc: 99.7809836268425, p_norm: 2139.599489764983, g_norm: 0.18675083001678502, lr:  0.000452, elapsed time:  149470
Step 305400, loss: 0.006630816506112751, acc: 99.78784936666489, p_norm: 2139.7052219914167, g_norm: 0.351433073775405, lr:  0.000452, elapsed time:  149518
Step 305500, loss: 0.0065204748188261875, acc: 99.79236872494221, p_norm: 2139.8183935323027, g_norm: 0.26855785842145125, lr:  0.000452, elapsed time:  149566
Step 305600, loss: 0.0066631631006339375, acc: 99.78590713441372, p_norm: 2139.9253737375966, g_norm: 0.1827763997265565, lr:  0.000452, elapsed time:  149614
Step 305700, loss: 0.006521830463170773, acc: 99.79513791203499, p_norm: 2140.0339303087835, g_norm: 0.22864427431483955, lr:  0.000452, elapsed time:  149661
Step 305800, loss: 0.006565089570922282, acc: 99.79164627194405, p_norm: 2140.1475437540134, g_norm: 0.24207125103741464, lr:  0.000452, elapsed time:  149710
Step 305900, loss: 0.006743896861844405, acc: 99.78264556825161, p_norm: 2140.255924882138, g_norm: 0.1863598555499034, lr:  0.000452, elapsed time:  149757
Step 306000, loss: 0.0066844209454029625, acc: 99.78326171636581, p_norm: 2140.36306978096, g_norm: 0.1783234436564974, lr:  0.000452, elapsed time:  149805
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 306000, eval loss: 0.01954193596087862, eval acc: 99.6064224243164
Step 306100, loss: 0.006775421663405723, acc: 99.78476786613464, p_norm: 2140.4843031445707, g_norm: 0.27559345735144225, lr:  0.000452, elapsed time:  149860
Step 306200, loss: 0.006465667813426989, acc: 99.79050770401955, p_norm: 2140.607989697268, g_norm: 0.17877362901339716, lr:  0.000452, elapsed time:  149909
Step 306300, loss: 0.006858378724973591, acc: 99.77993001043797, p_norm: 2140.716802607195, g_norm: 0.1525338791746956, lr:  0.000452, elapsed time:  149956
Step 306400, loss: 0.006577982390044781, acc: 99.78418566286564, p_norm: 2140.8258750538826, g_norm: 0.18660721472340894, lr:  0.000452, elapsed time:  150004
Step 306500, loss: 0.007224932312992678, acc: 99.76918740570545, p_norm: 2140.943495757202, g_norm: 0.15088186219906718, lr:  0.000451, elapsed time:  150051
Step 306600, loss: 0.00663167584486473, acc: 99.78380753099918, p_norm: 2141.054623754286, g_norm: 0.20342391447086383, lr:  0.000451, elapsed time:  150098
Step 306700, loss: 0.006802250310784075, acc: 99.78332749009132, p_norm: 2141.152627512454, g_norm: 0.12471840576505049, lr:  0.000451, elapsed time:  150146
Step 306800, loss: 0.006511649527155896, acc: 99.78608874976635, p_norm: 2141.264849028885, g_norm: 0.19025053320335936, lr:  0.000451, elapsed time:  150194
Step 306900, loss: 0.006626366121872706, acc: 99.78203761577606, p_norm: 2141.378738043425, g_norm: 0.21691405798876734, lr:  0.000451, elapsed time:  150241
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 307000, loss: 0.006197117070927286, acc: 99.7963716463179, p_norm: 2141.473436773508, g_norm: 0.20042464129847565, lr:  0.000451, elapsed time:  150289
Step 307100, loss: 0.006322012362779787, acc: 99.79648464918137, p_norm: 2141.584476914698, g_norm: 0.194048711283122, lr:  0.000451, elapsed time:  150338
Step 307200, loss: 0.006348057465584134, acc: 99.79696533083916, p_norm: 2141.702102333036, g_norm: 0.328025272624347, lr:  0.000451, elapsed time:  150387
Step 307300, loss: 0.006739922347660468, acc: 99.77835024893284, p_norm: 2141.810541114228, g_norm: 0.38569431289585693, lr:  0.000451, elapsed time:  150435
Step 307400, loss: 0.006710758128338057, acc: 99.78101620078087, p_norm: 2141.9211004056538, g_norm: 0.24071482694460367, lr:  0.000451, elapsed time:  150482
Step 307500, loss: 0.006790931245559477, acc: 99.7821795642376, p_norm: 2142.0292462367215, g_norm: 0.1791999733540378, lr:  0.000451, elapsed time:  150530
Step 307600, loss: 0.006873191997146933, acc: 99.7782169431448, p_norm: 2142.15833974981, g_norm: 0.1519508356357008, lr:  0.000451, elapsed time:  150577
Step 307700, loss: 0.006672965088982892, acc: 99.77850699424744, p_norm: 2142.26790605898, g_norm: 0.20244181995497748, lr:  0.000451, elapsed time:  150625
Step 307800, loss: 0.006993053431124281, acc: 99.77631412446499, p_norm: 2142.391433409284, g_norm: 0.1592972476330334, lr:  0.000450, elapsed time:  150672
Step 307900, loss: 0.006654375221696682, acc: 99.78742095828056, p_norm: 2142.4911497203752, g_norm: 0.19447745698292657, lr:  0.000450, elapsed time:  150720
Step 308000, loss: 0.00638109454044752, acc: 99.80054685473442, p_norm: 2142.597237505011, g_norm: 0.20247822213389718, lr:  0.000450, elapsed time:  150768
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 308000, eval loss: 0.02008709870398888, eval acc: 99.61946868896484
Step 308100, loss: 0.006785150831719875, acc: 99.78117255866528, p_norm: 2142.7167222118032, g_norm: 0.1682483039029652, lr:  0.000450, elapsed time:  150823
Step 308200, loss: 0.006648193784058094, acc: 99.78960590064526, p_norm: 2142.8337474123214, g_norm: 0.20557207884333528, lr:  0.000450, elapsed time:  150870
Step 308300, loss: 0.006645006182370707, acc: 99.7889139354229, p_norm: 2142.9412202009917, g_norm: 0.16735929670475, lr:  0.000450, elapsed time:  150917
Step 308400, loss: 0.007280771331215874, acc: 99.76636646687984, p_norm: 2143.06209502104, g_norm: 0.21796832623941736, lr:  0.000450, elapsed time:  150964
Step 308500, loss: 0.006284638531560631, acc: 99.79470385611057, p_norm: 2143.1772733823445, g_norm: 0.18478103797530282, lr:  0.000450, elapsed time:  151013
Step 308600, loss: 0.006820878374965105, acc: 99.78176644444466, p_norm: 2143.2952562523633, g_norm: 0.21906681885075888, lr:  0.000450, elapsed time:  151060
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 308700, loss: 0.006457253582285233, acc: 99.79393213025985, p_norm: 2143.4066554406104, g_norm: 0.13614726021639934, lr:  0.000450, elapsed time:  151109
Step 308800, loss: 0.006647473530547359, acc: 99.78097067773342, p_norm: 2143.5052443701684, g_norm: 0.27682603356089036, lr:  0.000450, elapsed time:  151156
Step 308900, loss: 0.0065941557369660585, acc: 99.7873046696186, p_norm: 2143.6273653844746, g_norm: 0.17976934028362807, lr:  0.000450, elapsed time:  151203
Step 309000, loss: 0.006824510534206638, acc: 99.78014220297337, p_norm: 2143.7350855047353, g_norm: 0.15203991804731926, lr:  0.000450, elapsed time:  151251
Step 309100, loss: 0.006652443488037534, acc: 99.7867831736803, p_norm: 2143.847362619651, g_norm: 0.3030585714521581, lr:  0.000450, elapsed time:  151299
Step 309200, loss: 0.006760752910959127, acc: 99.7845998853445, p_norm: 2143.9704020835475, g_norm: 0.19588320910435691, lr:  0.000449, elapsed time:  151347
Step 309300, loss: 0.00636075171412358, acc: 99.79499851167202, p_norm: 2144.066606277841, g_norm: 0.16823903729004663, lr:  0.000449, elapsed time:  151395
Step 309400, loss: 0.006821739567822078, acc: 99.78053414821625, p_norm: 2144.1712169782527, g_norm: 0.22018363042951938, lr:  0.000449, elapsed time:  151442
Step 309500, loss: 0.006666257420274633, acc: 99.78211589157581, p_norm: 2144.289610964343, g_norm: 0.1480129213023533, lr:  0.000449, elapsed time:  151491
Step 309600, loss: 0.006412626689457284, acc: 99.79513841867447, p_norm: 2144.402712654887, g_norm: 0.14575680851342507, lr:  0.000449, elapsed time:  151539
Step 309700, loss: 0.006659906417735328, acc: 99.78825840353966, p_norm: 2144.5108364798466, g_norm: 0.19279825331289635, lr:  0.000449, elapsed time:  151588
Step 309800, loss: 0.0068330175344090095, acc: 99.7772523611784, p_norm: 2144.611098615309, g_norm: 0.16636559726263628, lr:  0.000449, elapsed time:  151635
Step 309900, loss: 0.006592083209779958, acc: 99.78559255599976, p_norm: 2144.716955355071, g_norm: 0.19544877362585858, lr:  0.000449, elapsed time:  151683
Step 310000, loss: 0.006824529006880766, acc: 99.77825763821602, p_norm: 2144.8271581993927, g_norm: 0.13392602927205044, lr:  0.000449, elapsed time:  151731
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 310000, eval loss: 0.019494734716561195, eval acc: 99.61936950683594
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C C C C C C C C C C C C C C C C C N ( C C C C C C C C C C C C C C C C C C ) C ( = O ) C C C ( C ) C 1 C C C 2 C 3 C C C 4 C C ( O ) C C C 4 ( C ) C 3 C C C 1 2 C _EOS
Predicted text: C C C C C C C C C C C C C C C C C C N ( C C C C C C C C C C C C C C C C C C ) C ( = O ) C C C ( C ) C 1 C C C 2 C 3 C C C 4 C C ( O ) C C C 4 ( C ) C 3 C C C 1 2 C _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C c 1 c c c 2 c c c c c 2 c 1 ) C 1 = C ( C ( = O ) N c 2 c c ( O C 3 C C C C 3 ) c ( Cl ) c c 2 F ) C C C C 1 _EOS
Predicted text: O = C ( N C c 1 c c c 2 c c c c c 2 c 1 ) C 1 = C ( C ( = O ) N c 2 c c ( O C 3 C C C C 3 ) c ( Cl ) c c 2 F ) C C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c c c ( C O c 2 c c c 3 c ( c 2 ) C ( C ) ( C ) C C C 3 ( C ) C ) c c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c c c ( C O c 2 c c c 3 c ( c 2 ) C ( C ) ( C ) C C C 3 ( C ) C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c ( Cl ) c c ( Cl ) n c 1 C ( = O ) O _EOS
Predicted text: N C ( = O ) c 1 n c ( Cl ) c c ( Cl ) c 1 N _EOS
acc_token: 0.13636363636363635, acc_seq: False

Target text: C O C ( = O ) c 1 c ( - c 2 c c c c c 2 ) c 2 c c ( C ( N ) = O ) c c c 2 c ( = O ) n 1 C c 1 c c c ( C ( = O ) O C ( C ) ( C ) C ) c c 1 _EOS
Predicted text: C O C ( = O ) c 1 c ( - c 2 c c c c c 2 ) c 2 c c ( C ( N ) = O ) c c c 2 c ( = O ) n 1 C c 1 c c c ( C ( = O ) O C ( C ) ( C ) C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 310000, eval acc (token): 0.9389009316264804, eval acc (sequence): 0.8915015737826328
Saving at step 310000
Step 310100, loss: 0.007130760175205069, acc: 99.76992392539978, p_norm: 2144.9468266212652, g_norm: 0.14849526054866571, lr:  0.000449, elapsed time:  151840
Step 310200, loss: 0.006703430790566927, acc: 99.7900783419609, p_norm: 2145.060920092843, g_norm: 0.11238040650097607, lr:  0.000449, elapsed time:  151888
Step 310300, loss: 0.006390953300915499, acc: 99.79144901037216, p_norm: 2145.1720840362564, g_norm: 0.15516428462228807, lr:  0.000449, elapsed time:  151935
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 310400, loss: 0.006315969027746088, acc: 99.79298237535558, p_norm: 2145.2929846376633, g_norm: 0.2596055891964937, lr:  0.000449, elapsed time:  151984
Step 310500, loss: 0.006139105807560555, acc: 99.80350910127163, p_norm: 2145.3929653427913, g_norm: 0.11278285431034106, lr:  0.000449, elapsed time:  152032
Step 310600, loss: 0.006695854461131603, acc: 99.78763042390347, p_norm: 2145.4993252379213, g_norm: 0.17589739707957674, lr:  0.000448, elapsed time:  152079
Step 310700, loss: 0.006662417354491481, acc: 99.78745159506798, p_norm: 2145.5970814904854, g_norm: 0.2439832485168665, lr:  0.000448, elapsed time:  152126
Step 310800, loss: 0.006724271771927306, acc: 99.78315369784832, p_norm: 2145.7177045471253, g_norm: 0.2449622564129668, lr:  0.000448, elapsed time:  152174
Step 310900, loss: 0.006581502040662599, acc: 99.79283517599106, p_norm: 2145.8420958190127, g_norm: 0.21010517243800494, lr:  0.000448, elapsed time:  152221
Step 311000, loss: 0.00652874725552465, acc: 99.7928577363491, p_norm: 2145.9487249559397, g_norm: 0.14626714887019743, lr:  0.000448, elapsed time:  152269
Step 311100, loss: 0.006772616030048084, acc: 99.77652005851269, p_norm: 2146.0548600577513, g_norm: 0.22484104804268568, lr:  0.000448, elapsed time:  152316
Step 311200, loss: 0.006387555836317916, acc: 99.79429212212563, p_norm: 2146.1673989599194, g_norm: 0.12987910603063552, lr:  0.000448, elapsed time:  152364
Step 311300, loss: 0.006902999100821035, acc: 99.7807205170393, p_norm: 2146.2676024846005, g_norm: 0.2657647952583192, lr:  0.000448, elapsed time:  152412
Step 311400, loss: 0.006641384589729568, acc: 99.78449711203575, p_norm: 2146.3781035964357, g_norm: 0.23095386561972284, lr:  0.000448, elapsed time:  152459
Step 311500, loss: 0.0067880662670177115, acc: 99.77768030762672, p_norm: 2146.5000870039125, g_norm: 0.19083403249204356, lr:  0.000448, elapsed time:  152507
Step 311600, loss: 0.0065410673600217704, acc: 99.78789940476418, p_norm: 2146.612906541528, g_norm: 0.24932657564495123, lr:  0.000448, elapsed time:  152554
Step 311700, loss: 0.006553313974200137, acc: 99.79125054180622, p_norm: 2146.723066441134, g_norm: 0.13430271133266147, lr:  0.000448, elapsed time:  152602
Step 311800, loss: 0.007080893468973955, acc: 99.77197232842445, p_norm: 2146.8478363419217, g_norm: 0.26640098499285575, lr:  0.000448, elapsed time:  152649
Step 311900, loss: 0.006904488485433831, acc: 99.77924159169197, p_norm: 2146.95148859397, g_norm: 0.22214722417526936, lr:  0.000448, elapsed time:  152697
Step 312000, loss: 0.006655161044086526, acc: 99.78139908611774, p_norm: 2147.0551859054417, g_norm: 0.11560445320396072, lr:  0.000447, elapsed time:  152745
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 312000, eval loss: 0.02132435934296153, eval acc: 99.62042999267578
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 312100, loss: 0.006175477515501538, acc: 99.79905830093877, p_norm: 2147.158855112952, g_norm: 0.10846904028076904, lr:  0.000447, elapsed time:  152800
Step 312200, loss: 0.0064027098411861515, acc: 99.79429645836353, p_norm: 2147.266449848139, g_norm: 0.14534883023255085, lr:  0.000447, elapsed time:  152848
Step 312300, loss: 0.006653351023951473, acc: 99.78637860715389, p_norm: 2147.374071777926, g_norm: 0.1575246781494894, lr:  0.000447, elapsed time:  152896
Step 312400, loss: 0.00708055020430038, acc: 99.76775155961514, p_norm: 2147.4891908278355, g_norm: 0.19331469476703503, lr:  0.000447, elapsed time:  152943
Step 312500, loss: 0.006612027266701261, acc: 99.78877973556519, p_norm: 2147.5964433545487, g_norm: 0.16343613419069108, lr:  0.000447, elapsed time:  152990
Step 312600, loss: 0.0066645910355236995, acc: 99.78748281300068, p_norm: 2147.7043198039323, g_norm: 0.16556192975386702, lr:  0.000447, elapsed time:  153038
Step 312700, loss: 0.006376354722960969, acc: 99.79150193929672, p_norm: 2147.811829177508, g_norm: 0.17567136968037608, lr:  0.000447, elapsed time:  153085
Step 312800, loss: 0.0071351446711742025, acc: 99.77070751786232, p_norm: 2147.930261116613, g_norm: 0.1933783046788253, lr:  0.000447, elapsed time:  153132
Step 312900, loss: 0.006324563332736943, acc: 99.79082836210728, p_norm: 2148.0399135837292, g_norm: 0.13835625439277477, lr:  0.000447, elapsed time:  153180
Step 313000, loss: 0.00677551906871031, acc: 99.77838581800461, p_norm: 2148.151386781616, g_norm: 0.24649118097619677, lr:  0.000447, elapsed time:  153227
Step 313100, loss: 0.006361605607544334, acc: 99.79421369731426, p_norm: 2148.246317740592, g_norm: 0.19241108285435873, lr:  0.000447, elapsed time:  153275
Step 313200, loss: 0.006453124853014742, acc: 99.79500526189804, p_norm: 2148.355905277203, g_norm: 0.1847703620012883, lr:  0.000447, elapsed time:  153323
Step 313300, loss: 0.007003923669080905, acc: 99.7749192416668, p_norm: 2148.4560529688824, g_norm: 0.21383722452233794, lr:  0.000447, elapsed time:  153370
Step 313400, loss: 0.006803159688015512, acc: 99.78252083063126, p_norm: 2148.568605686946, g_norm: 0.18221035507858094, lr:  0.000446, elapsed time:  153417
Step 313500, loss: 0.006972684021930036, acc: 99.7765653282404, p_norm: 2148.6754672133234, g_norm: 0.4385134293246743, lr:  0.000446, elapsed time:  153465
Step 313600, loss: 0.006591563975543977, acc: 99.78926217556, p_norm: 2148.789659853244, g_norm: 0.12854912805463947, lr:  0.000446, elapsed time:  153513
Step 313700, loss: 0.006399253036142909, acc: 99.79202492535114, p_norm: 2148.8945254816963, g_norm: 0.14771791342130577, lr:  0.000446, elapsed time:  153561
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 313800, loss: 0.006217694446094543, acc: 99.80166631360208, p_norm: 2149.0100876569986, g_norm: 0.168229916396472, lr:  0.000446, elapsed time:  153610
Step 313900, loss: 0.006252763276734186, acc: 99.79612417519093, p_norm: 2149.1140006895425, g_norm: 0.18104184840566034, lr:  0.000446, elapsed time:  153657
Step 314000, loss: 0.006504387020213471, acc: 99.78736783564091, p_norm: 2149.222432712379, g_norm: 0.14031621479324777, lr:  0.000446, elapsed time:  153705
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 314000, eval loss: 0.02213141220582428, eval acc: 99.59607696533203
Step 314100, loss: 0.006493873218569206, acc: 99.79267962276936, p_norm: 2149.3211696025387, g_norm: 0.25963090729209987, lr:  0.000446, elapsed time:  153760
Step 314200, loss: 0.006827498876791651, acc: 99.77739268541336, p_norm: 2149.426894730772, g_norm: 0.14908977524392583, lr:  0.000446, elapsed time:  153807
Step 314300, loss: 0.006230648445125553, acc: 99.79524753987789, p_norm: 2149.535148124171, g_norm: 0.16343344080233244, lr:  0.000446, elapsed time:  153855
Step 314400, loss: 0.006789610320192878, acc: 99.78393118083477, p_norm: 2149.653842275342, g_norm: 0.1910870778176861, lr:  0.000446, elapsed time:  153902
Step 314500, loss: 0.006466466734937057, acc: 99.79028791189194, p_norm: 2149.7619851206623, g_norm: 0.3593483380573549, lr:  0.000446, elapsed time:  153949
Step 314600, loss: 0.006703378073325439, acc: 99.78752738237381, p_norm: 2149.8782091245207, g_norm: 0.1274224804103195, lr:  0.000446, elapsed time:  153996
Step 314700, loss: 0.006588086322890377, acc: 99.78724190592766, p_norm: 2149.9856030058827, g_norm: 0.183074678341129, lr:  0.000446, elapsed time:  154044
Step 314800, loss: 0.006898529482100457, acc: 99.78107053041458, p_norm: 2150.098749888224, g_norm: 0.22927574350104957, lr:  0.000445, elapsed time:  154092
Step 314900, loss: 0.006564884414310654, acc: 99.7853137999773, p_norm: 2150.204801309492, g_norm: 0.16765439669921522, lr:  0.000445, elapsed time:  154139
Step 315000, loss: 0.006801401542215899, acc: 99.78017923235893, p_norm: 2150.3106254732293, g_norm: 0.1244940277594479, lr:  0.000445, elapsed time:  154186
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: O = C 1 C C C c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 N 1 _EOS
Predicted text: O = C 1 C C C c 2 c c c ( [N+] ( = O ) [O-] ) c c 2 N 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C ( C ) O C ( = O ) c 1 c c c ( - c 2 c c c ( C 3 C C C ( O C ( = O ) C ( F ) C C C C ) C C 3 ) c c 2 ) c c 1 _EOS
Predicted text: C C C C C C C ( C ) O C ( = O ) c 1 c c c ( - c 2 c c c ( C 3 C C C ( O C ( = O ) C ( F ) C C C C ) C C 3 ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C ( = O ) N C C N 1 c 1 n n c c 2 c c ( Br ) c c c 1 2 _EOS
Predicted text: C C 1 C ( = O ) N C C N 1 c 1 n n c c 2 c c ( Br ) c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C C C O ) c 1 c c 2 c c c c c 2 [nH] 1 _EOS
Predicted text: O = C ( N C C C O ) c 1 c c 2 c c c c c 2 [nH] 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C C ( C ) ( C ) C = C C ( Cl ) ( Cl ) Cl _EOS
Predicted text: C C O C ( = O ) C 1 C ( C C ( Cl ) ( Cl ) Cl ) C 1 ( C ) C _EOS
acc_token: 0.32142857142857145, acc_seq: False

Evaluation (without teacher) at step 315000, eval acc (token): 0.9366729456062131, eval acc (sequence): 0.8874958207957205
Saving at step 315000
Step 315100, loss: 0.006841126349136175, acc: 99.78359319269657, p_norm: 2150.4172163449402, g_norm: 0.18988496917834427, lr:  0.000445, elapsed time:  154302
Step 315200, loss: 0.006736203484233556, acc: 99.78768900036812, p_norm: 2150.529885424653, g_norm: 0.17281219376120777, lr:  0.000445, elapsed time:  154358
Step 315300, loss: 0.006079290869674878, acc: 99.80420787632465, p_norm: 2150.629532483131, g_norm: 0.09569929875912139, lr:  0.000445, elapsed time:  154406
Step 315400, loss: 0.006775789711700782, acc: 99.7826790958643, p_norm: 2150.749887815682, g_norm: 0.2733856900702973, lr:  0.000445, elapsed time:  154454
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 315500, loss: 0.006660140109698449, acc: 99.78411477197784, p_norm: 2150.8645214126086, g_norm: 0.1865196761060911, lr:  0.000445, elapsed time:  154503
Step 315600, loss: 0.0061472669604290785, acc: 99.80214920639992, p_norm: 2150.9592521229806, g_norm: 0.1547499695753214, lr:  0.000445, elapsed time:  154551
Step 315700, loss: 0.006318637507674794, acc: 99.80328291654587, p_norm: 2151.0649043353797, g_norm: 0.1699690459039789, lr:  0.000445, elapsed time:  154599
Step 315800, loss: 0.006620974226771068, acc: 99.78812286257744, p_norm: 2151.1727430343644, g_norm: 0.146425930488205, lr:  0.000445, elapsed time:  154646
Step 315900, loss: 0.006293653062884914, acc: 99.79778595268726, p_norm: 2151.2871764887964, g_norm: 0.20720244934162174, lr:  0.000445, elapsed time:  154694
Step 316000, loss: 0.0064775550743797795, acc: 99.8000175356865, p_norm: 2151.3848653393384, g_norm: 0.22848721959158763, lr:  0.000445, elapsed time:  154741
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 316000, eval loss: 0.01949363621533849, eval acc: 99.61146545410156
Step 316100, loss: 0.006247790321722278, acc: 99.79495571553707, p_norm: 2151.484313524974, g_norm: 0.1600858553603512, lr:  0.000445, elapsed time:  154796
Step 316200, loss: 0.006363050644285977, acc: 99.79911625385284, p_norm: 2151.5974115638483, g_norm: 0.0798390522421954, lr:  0.000444, elapsed time:  154844
Step 316300, loss: 0.0068438792349297724, acc: 99.78209547698498, p_norm: 2151.7159949395523, g_norm: 0.3367114203521525, lr:  0.000444, elapsed time:  154891
Step 316400, loss: 0.006416107295663096, acc: 99.79357051849365, p_norm: 2151.8415438942416, g_norm: 0.14202423548932952, lr:  0.000444, elapsed time:  154938
Step 316500, loss: 0.00638898089662689, acc: 99.79222562909126, p_norm: 2151.9504798153043, g_norm: 0.1940164391819764, lr:  0.000444, elapsed time:  154986
Step 316600, loss: 0.0069708136123153965, acc: 99.7723421305418, p_norm: 2152.0565600372083, g_norm: 0.17517049560959172, lr:  0.000444, elapsed time:  155033
Step 316700, loss: 0.006877291755099577, acc: 99.78121431171894, p_norm: 2152.177512861475, g_norm: 0.1944562662919207, lr:  0.000444, elapsed time:  155080
Step 316800, loss: 0.006451926607878704, acc: 99.79330955445766, p_norm: 2152.277754289378, g_norm: 0.14449926703353777, lr:  0.000444, elapsed time:  155128
Step 316900, loss: 0.006413474907603813, acc: 99.79142513871193, p_norm: 2152.391672132236, g_norm: 0.2498917896488302, lr:  0.000444, elapsed time:  155176
Step 317000, loss: 0.006771545099236391, acc: 99.78245335817337, p_norm: 2152.50048611996, g_norm: 0.15990975192672935, lr:  0.000444, elapsed time:  155223
Step 317100, loss: 0.007007165297072788, acc: 99.77149973809719, p_norm: 2152.618282391918, g_norm: 0.13239469747556729, lr:  0.000444, elapsed time:  155271
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 317200, loss: 0.006827795581255026, acc: 99.77940353507144, p_norm: 2152.7351174298474, g_norm: 0.1865154365964, lr:  0.000444, elapsed time:  155319
Step 317300, loss: 0.006173997900878021, acc: 99.79890136420727, p_norm: 2152.8271053903554, g_norm: 0.1733576069016547, lr:  0.000444, elapsed time:  155368
Step 317400, loss: 0.006411809994606301, acc: 99.79050110280514, p_norm: 2152.931321896624, g_norm: 0.17459853876929277, lr:  0.000444, elapsed time:  155415
Step 317500, loss: 0.006541786411680732, acc: 99.79176115989685, p_norm: 2153.0491352946465, g_norm: 0.18835361212016355, lr:  0.000444, elapsed time:  155462
Step 317600, loss: 0.0064684460917487745, acc: 99.78941813111305, p_norm: 2153.153627343995, g_norm: 0.1626754945242452, lr:  0.000443, elapsed time:  155510
Step 317700, loss: 0.006725322015163329, acc: 99.78455859422684, p_norm: 2153.2558921807495, g_norm: 0.2336046762740398, lr:  0.000443, elapsed time:  155557
Step 317800, loss: 0.00642681140608147, acc: 99.78765241801739, p_norm: 2153.366657139175, g_norm: 0.16596084247222812, lr:  0.000443, elapsed time:  155604
Step 317900, loss: 0.006618638794943763, acc: 99.77933086454868, p_norm: 2153.474333272668, g_norm: 0.21729486301373144, lr:  0.000443, elapsed time:  155652
Step 318000, loss: 0.006217685003211955, acc: 99.80115479230881, p_norm: 2153.577348931293, g_norm: 0.22576179576252856, lr:  0.000443, elapsed time:  155700
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 318000, eval loss: 0.020594517984855825, eval acc: 99.61602783203125
Step 318100, loss: 0.006464786013602861, acc: 99.79525423049927, p_norm: 2153.700519762821, g_norm: 0.19895452139002506, lr:  0.000443, elapsed time:  155755
Step 318200, loss: 0.006604305928831309, acc: 99.78272813558578, p_norm: 2153.8045331531825, g_norm: 0.20662140321987396, lr:  0.000443, elapsed time:  155802
Step 318300, loss: 0.0066580145048646955, acc: 99.78413493931293, p_norm: 2153.9119858319805, g_norm: 0.18131611167623302, lr:  0.000443, elapsed time:  155849
Step 318400, loss: 0.006179977216452244, acc: 99.80371160805225, p_norm: 2154.017176219489, g_norm: 0.14898050045960606, lr:  0.000443, elapsed time:  155897
Step 318500, loss: 0.0064971973419233105, acc: 99.79531897604465, p_norm: 2154.1387018310243, g_norm: 0.16131731927796494, lr:  0.000443, elapsed time:  155945
Step 318600, loss: 0.006412405328419481, acc: 99.79437074065208, p_norm: 2154.2432933386576, g_norm: 0.2294964426304556, lr:  0.000443, elapsed time:  155993
Step 318700, loss: 0.0069417223378604835, acc: 99.77587120234966, p_norm: 2154.3392766329016, g_norm: 0.21221345103101621, lr:  0.000443, elapsed time:  156040
Step 318800, loss: 0.006761725302658306, acc: 99.79096420109272, p_norm: 2154.4416717256404, g_norm: 0.11698262579542658, lr:  0.000443, elapsed time:  156088
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 318900, loss: 0.006542493640925964, acc: 99.7931562493516, p_norm: 2154.549754844478, g_norm: 0.20766590163748316, lr:  0.000443, elapsed time:  156137
Step 319000, loss: 0.006177086161460466, acc: 99.8009192943573, p_norm: 2154.646946324183, g_norm: 0.21970353378219035, lr:  0.000443, elapsed time:  156184
Step 319100, loss: 0.00650214604467692, acc: 99.78779630362988, p_norm: 2154.756590355412, g_norm: 0.14761494118718246, lr:  0.000442, elapsed time:  156232
Step 319200, loss: 0.006813514020414004, acc: 99.78265661001205, p_norm: 2154.8678435088746, g_norm: 0.17487604060973244, lr:  0.000442, elapsed time:  156279
Step 319300, loss: 0.006191969694136787, acc: 99.79989935457706, p_norm: 2154.990655254346, g_norm: 0.16058273489932015, lr:  0.000442, elapsed time:  156327
Step 319400, loss: 0.006484229962243262, acc: 99.78991617262363, p_norm: 2155.0937098778513, g_norm: 0.1993901362050679, lr:  0.000442, elapsed time:  156375
Step 319500, loss: 0.006570348951609049, acc: 99.78631043434143, p_norm: 2155.2078925533665, g_norm: 0.18686440560223508, lr:  0.000442, elapsed time:  156421
Step 319600, loss: 0.006304441927291009, acc: 99.79670679569244, p_norm: 2155.3226523232547, g_norm: 0.14857258058301565, lr:  0.000442, elapsed time:  156469
Step 319700, loss: 0.006301778724237011, acc: 99.79907475411892, p_norm: 2155.42483820851, g_norm: 0.19084682793726276, lr:  0.000442, elapsed time:  156517
Step 319800, loss: 0.006841711235783805, acc: 99.78481012582779, p_norm: 2155.526037569236, g_norm: 0.18082081229876565, lr:  0.000442, elapsed time:  156564
Step 319900, loss: 0.006982158004575467, acc: 99.77044363319874, p_norm: 2155.6404721618746, g_norm: 0.17275500769195176, lr:  0.000442, elapsed time:  156612
Step 320000, loss: 0.006727197841664747, acc: 99.78814865648746, p_norm: 2155.755585965456, g_norm: 0.352283855766625, lr:  0.000442, elapsed time:  156659
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 320000, eval loss: 0.0184404759917652, eval acc: 99.63343811035156
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C S ( = O ) ( = O ) c 1 c c c ( C ( = C C 2 C C C C 2 ) C ( = O ) N c 2 c c c c n 2 ) c c 1 Cl _EOS
Predicted text: C S ( = O ) ( = O ) c 1 c c c ( C ( = C C 2 C C C C 2 ) C ( = O ) N c 2 c c c c n 2 ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: [Cl-] _EOS
Predicted text: O = C 1 O C ( = O ) C 2 C C C C C 1 2 _EOS
acc_token: 0.0, acc_seq: False

Target text: O = C ( C C C C C ( = O ) N c 1 c c c ( Cl ) c c 1 C ( = O ) O ) N c 1 c c c ( Cl ) c c 1 _EOS
Predicted text: O = C ( C C C C C ( = O ) N c 1 c c c ( Cl ) c c 1 C ( = O ) O ) N c 1 c c c ( Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) N c 1 n c c ( Br ) c c 1 - c 1 n n n n 1 - c 1 c c c ( C 2 C C 2 ) c ( F ) c 1 F _EOS
Predicted text: C C ( C ) ( C ) N c 1 n c c ( Br ) c c 1 - c 1 n n n n 1 - c 1 c c c ( C 2 C C 2 ) c ( F ) c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c ( [N+] ( = O ) [O-] ) c 1 N c 1 c c c ( O C ( F ) ( F ) F ) c c 1 _EOS
Predicted text: C c 1 c c c c ( [N+] ( = O ) [O-] ) c 1 N c 1 c c c ( O C ( F ) ( F ) F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 320000, eval acc (token): 0.9396576159629975, eval acc (sequence): 0.8904310907903331
Saving at step 320000
Step 320100, loss: 0.006292284270311938, acc: 99.80042105913162, p_norm: 2155.862738344375, g_norm: 0.29915758864381825, lr:  0.000442, elapsed time:  156765
Step 320200, loss: 0.006140887147648755, acc: 99.80393575131893, p_norm: 2155.9597689301595, g_norm: 0.13785464425952715, lr:  0.000442, elapsed time:  156813
Step 320300, loss: 0.0067568266413218225, acc: 99.78409542143345, p_norm: 2156.0686165592983, g_norm: 0.15434991036621235, lr:  0.000442, elapsed time:  156861
Step 320400, loss: 0.0066552182174928025, acc: 99.78842011094093, p_norm: 2156.171324760272, g_norm: 0.3366439882703864, lr:  0.000442, elapsed time:  156908
Step 320500, loss: 0.006430075224070606, acc: 99.79123932123184, p_norm: 2156.274538892765, g_norm: 0.10919599607907034, lr:  0.000441, elapsed time:  156955
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 320600, loss: 0.006363872264955717, acc: 99.79150079320145, p_norm: 2156.3742529240744, g_norm: 0.19502757338553384, lr:  0.000441, elapsed time:  157004
Step 320700, loss: 0.005923727699992014, acc: 99.80796599388123, p_norm: 2156.472988524802, g_norm: 0.17623417221263682, lr:  0.000441, elapsed time:  157051
Step 320800, loss: 0.006227699029677751, acc: 99.7963045835495, p_norm: 2156.57876174275, g_norm: 0.2233030057866729, lr:  0.000441, elapsed time:  157099
Step 320900, loss: 0.006348592726799325, acc: 99.79539276659489, p_norm: 2156.6960753199983, g_norm: 0.17763632205665755, lr:  0.000441, elapsed time:  157146
Step 321000, loss: 0.0059636705293996785, acc: 99.80892804265022, p_norm: 2156.7941765899054, g_norm: 0.1638733296737124, lr:  0.000441, elapsed time:  157194
Step 321100, loss: 0.006450118807406397, acc: 99.7882626503706, p_norm: 2156.9000061927986, g_norm: 0.18261964617096127, lr:  0.000441, elapsed time:  157241
Step 321200, loss: 0.006308293949605286, acc: 99.79810105264187, p_norm: 2156.9999120028433, g_norm: 0.15034470008370893, lr:  0.000441, elapsed time:  157289
Step 321300, loss: 0.0061932695016412255, acc: 99.79726062715054, p_norm: 2157.1083931342346, g_norm: 0.20386777562755612, lr:  0.000441, elapsed time:  157337
Step 321400, loss: 0.006351614611194236, acc: 99.79393589496613, p_norm: 2157.2159241491004, g_norm: 0.2691309128063486, lr:  0.000441, elapsed time:  157385
Step 321500, loss: 0.007025754721098565, acc: 99.77982603013515, p_norm: 2157.336347045713, g_norm: 0.26752964623173864, lr:  0.000441, elapsed time:  157433
Step 321600, loss: 0.006530859992572005, acc: 99.79239562153816, p_norm: 2157.447648900369, g_norm: 0.129129500214667, lr:  0.000441, elapsed time:  157480
Step 321700, loss: 0.0070264397589699, acc: 99.7794154137373, p_norm: 2157.5562068128193, g_norm: 0.1561381322162633, lr:  0.000441, elapsed time:  157528
Step 321800, loss: 0.006848629528321908, acc: 99.77644847333431, p_norm: 2157.6677994042984, g_norm: 0.15937618218504587, lr:  0.000441, elapsed time:  157576
Step 321900, loss: 0.006526421286725963, acc: 99.78817491233349, p_norm: 2157.7807014065224, g_norm: 0.15597458888196486, lr:  0.000441, elapsed time:  157623
Step 322000, loss: 0.0065315834755438115, acc: 99.79246205091476, p_norm: 2157.8844815336706, g_norm: 0.1912712205071721, lr:  0.000440, elapsed time:  157671
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 322000, eval loss: 0.02188009073372996, eval acc: 99.51820373535156
Step 322100, loss: 0.006499807281070389, acc: 99.79273027181625, p_norm: 2157.991631918755, g_norm: 0.17138554985095583, lr:  0.000440, elapsed time:  157725
Step 322200, loss: 0.0065900514322493105, acc: 99.79057286679745, p_norm: 2158.0993498255825, g_norm: 0.2957462615936762, lr:  0.000440, elapsed time:  157772
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 322300, loss: 0.0065187697744061935, acc: 99.78238364898833, p_norm: 2158.208448743979, g_norm: 0.5317393253886488, lr:  0.000440, elapsed time:  157820
Step 322400, loss: 0.00641685409913407, acc: 99.79508636891842, p_norm: 2158.310853742429, g_norm: 0.2361385232150377, lr:  0.000440, elapsed time:  157867
Step 322500, loss: 0.006165420955194349, acc: 99.79978473484516, p_norm: 2158.411894992185, g_norm: 0.20261471715038873, lr:  0.000440, elapsed time:  157915
Step 322600, loss: 0.006224671760301135, acc: 99.7944293320179, p_norm: 2158.5228274737324, g_norm: 0.281644005410274, lr:  0.000440, elapsed time:  157963
Step 322700, loss: 0.006542855251568653, acc: 99.78486709296703, p_norm: 2158.6314886643654, g_norm: 0.142380438499373, lr:  0.000440, elapsed time:  158010
Step 322800, loss: 0.006339658543911355, acc: 99.79318229854107, p_norm: 2158.743784884866, g_norm: 0.18198210144732277, lr:  0.000440, elapsed time:  158058
Step 322900, loss: 0.006595715550802197, acc: 99.78610117733479, p_norm: 2158.8525075765606, g_norm: 0.18282988097728206, lr:  0.000440, elapsed time:  158105
Step 323000, loss: 0.006360105814856069, acc: 99.795121088624, p_norm: 2158.94618281185, g_norm: 0.2241978133896989, lr:  0.000440, elapsed time:  158152
Step 323100, loss: 0.006281388962270285, acc: 99.79217198491096, p_norm: 2159.0587551882977, g_norm: 0.23467766426422618, lr:  0.000440, elapsed time:  158200
Step 323200, loss: 0.006425693059172772, acc: 99.79076087474823, p_norm: 2159.160244536419, g_norm: 0.15343795763648335, lr:  0.000440, elapsed time:  158247
Step 323300, loss: 0.006829955497287301, acc: 99.78206896781921, p_norm: 2159.2748293478708, g_norm: 0.1993846917670477, lr:  0.000440, elapsed time:  158295
Step 323400, loss: 0.006752674864201253, acc: 99.77841700613499, p_norm: 2159.3909798050586, g_norm: 0.15198516566106043, lr:  0.000439, elapsed time:  158342
Step 323500, loss: 0.0067762617268454055, acc: 99.7807656377554, p_norm: 2159.4975221989066, g_norm: 0.2736604081695877, lr:  0.000439, elapsed time:  158390
Step 323600, loss: 0.006272541719249602, acc: 99.79365342855453, p_norm: 2159.595464969926, g_norm: 0.17450901998390286, lr:  0.000439, elapsed time:  158437
Step 323700, loss: 0.00632125439891297, acc: 99.80341802537441, p_norm: 2159.696146631564, g_norm: 0.14503517370236826, lr:  0.000439, elapsed time:  158485
Step 323800, loss: 0.006444418933315319, acc: 99.78934115171432, p_norm: 2159.808367949909, g_norm: 0.22036983010295438, lr:  0.000439, elapsed time:  158533
Step 323900, loss: 0.0067144457119457, acc: 99.7910490334034, p_norm: 2159.9150241023426, g_norm: 0.12160168724696614, lr:  0.000439, elapsed time:  158581
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 324000, loss: 0.006593584765729943, acc: 99.79301053493177, p_norm: 2160.0236394014796, g_norm: 0.1674898717641469, lr:  0.000439, elapsed time:  158629
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 324000, eval loss: 0.02096478429120907, eval acc: 99.61234283447266
Step 324100, loss: 0.006148711651821941, acc: 99.80531729757786, p_norm: 2160.1222384103885, g_norm: 0.16178332426759182, lr:  0.000439, elapsed time:  158684
Step 324200, loss: 0.006353320019725288, acc: 99.79373127222061, p_norm: 2160.220388788074, g_norm: 0.24925502383025275, lr:  0.000439, elapsed time:  158731
Step 324300, loss: 0.006339605984085211, acc: 99.79669803380966, p_norm: 2160.323629074753, g_norm: 0.18570824279354178, lr:  0.000439, elapsed time:  158778
Step 324400, loss: 0.005909321829512919, acc: 99.80615578591824, p_norm: 2160.4230446025763, g_norm: 0.1617057483400378, lr:  0.000439, elapsed time:  158826
Step 324500, loss: 0.0064018532811360275, acc: 99.79538735747337, p_norm: 2160.5306564558173, g_norm: 0.17714337000513095, lr:  0.000439, elapsed time:  158874
Step 324600, loss: 0.00621373142930679, acc: 99.80190473794937, p_norm: 2160.631507815487, g_norm: 0.1559867466005026, lr:  0.000439, elapsed time:  158921
Step 324700, loss: 0.006751525764912003, acc: 99.78883618116379, p_norm: 2160.7460095648858, g_norm: 0.14230401795871112, lr:  0.000439, elapsed time:  158969
Step 324800, loss: 0.006340059715748794, acc: 99.7919837385416, p_norm: 2160.866135967564, g_norm: 0.30604138466039715, lr:  0.000439, elapsed time:  159017
Step 324900, loss: 0.0068202260614998525, acc: 99.78095427155495, p_norm: 2160.9735058185443, g_norm: 0.20418544093313126, lr:  0.000438, elapsed time:  159064
Step 325000, loss: 0.006514776264248212, acc: 99.78901132941246, p_norm: 2161.0853611465695, g_norm: 0.13524889526526257, lr:  0.000438, elapsed time:  159111
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C c 1 c ( C c 2 c c c n c 2 ) s c 2 c c ( Br ) c c c 1 2 _EOS
Predicted text: C c 1 c ( C c 2 c c c n c 2 ) s c 2 c c ( Br ) c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c 2 c ( c 1 ) c 1 c ( n 2 C C ( = O ) N 2 C c 3 c c c c c 3 C 2 ) C C N ( C ) C 1 _EOS
Predicted text: C c 1 c c c 2 c ( c 1 ) c 1 c ( n 2 C C ( = O ) N 2 C c 3 c c c c c 3 C 2 ) C C N ( C ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N C 1 ( C 2 C C ( = O ) N ( C c 3 c c c c c 3 ) C 2 ) C C ( = O ) C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C 1 ( C 2 C C ( = O ) N ( C c 3 c c c c c 3 ) C 2 ) C C ( = O ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C 1 C C C ( N 2 C C C ( = N c 3 c c c c c 3 ) C C 2 ) C C 1 _EOS
Predicted text: C C ( C ) C 1 C C C ( N 2 C C C ( = N c 3 c c c c c 3 ) C C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N 1 C C N ( C 2 C C C ( n 3 n c ( - c 4 c c c ( N c 5 n c 6 c c c c c 6 s 5 ) c ( F ) c 4 ) c 4 c ( N ) n c n c 4 3 ) C C 2 ) C C 1 _EOS
Predicted text: C N 1 C C N ( C 2 C C C ( n 3 n c ( - c 4 c c c ( N c 5 n c 6 c c c c c 6 s 5 ) c ( F ) c 4 ) c 4 c ( N ) n c n c 4 3 ) C C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 325000, eval acc (token): 0.9425195070070849, eval acc (sequence): 0.8956289027653881
Saving at step 325000
Step 325100, loss: 0.006523951201434102, acc: 99.78783467411995, p_norm: 2161.201556321947, g_norm: 0.19028894278309497, lr:  0.000438, elapsed time:  159211
Step 325200, loss: 0.006201441466600954, acc: 99.79773938655853, p_norm: 2161.305772474993, g_norm: 0.16700961412040757, lr:  0.000438, elapsed time:  159259
Step 325300, loss: 0.006767406376966391, acc: 99.78436030447483, p_norm: 2161.420489156877, g_norm: 0.19263446527488026, lr:  0.000438, elapsed time:  159306
Step 325400, loss: 0.006710560552483003, acc: 99.78016090393066, p_norm: 2161.5293281143663, g_norm: 0.18641666069023274, lr:  0.000438, elapsed time:  159354
Step 325500, loss: 0.006632124417283194, acc: 99.78658048808575, p_norm: 2161.6382551524052, g_norm: 0.26559886568167573, lr:  0.000438, elapsed time:  159401
Step 325600, loss: 0.006284850298015954, acc: 99.79401625692844, p_norm: 2161.7428183186885, g_norm: 0.22204406685126551, lr:  0.000438, elapsed time:  159449
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 325700, loss: 0.0064763344712231875, acc: 99.78606765974249, p_norm: 2161.841267814103, g_norm: 0.16778011659241063, lr:  0.000438, elapsed time:  159498
Step 325800, loss: 0.006346663894773883, acc: 99.79441867768764, p_norm: 2161.941971495754, g_norm: 0.15315199072289146, lr:  0.000438, elapsed time:  159545
Step 325900, loss: 0.006328428849901684, acc: 99.79605142772198, p_norm: 2162.042229670665, g_norm: 0.20239726225402363, lr:  0.000438, elapsed time:  159593
Step 326000, loss: 0.006477951885899529, acc: 99.78947077691555, p_norm: 2162.1447925942807, g_norm: 0.2876107491599927, lr:  0.000438, elapsed time:  159640
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 326000, eval loss: 0.02001687905198197, eval acc: 99.607666015625
Step 326100, loss: 0.0070735959598459885, acc: 99.76651804149151, p_norm: 2162.257747139463, g_norm: 0.1329477560318173, lr:  0.000438, elapsed time:  159695
Step 326200, loss: 0.0062629836554879146, acc: 99.79906131327152, p_norm: 2162.357358131427, g_norm: 0.23279064356329, lr:  0.000438, elapsed time:  159742
Step 326300, loss: 0.006175988227359994, acc: 99.80322071909904, p_norm: 2162.461904543041, g_norm: 0.1801669955344646, lr:  0.000438, elapsed time:  159790
Step 326400, loss: 0.006635425747344925, acc: 99.78415895998478, p_norm: 2162.5733545588682, g_norm: 0.2516940991638245, lr:  0.000437, elapsed time:  159837
Step 326500, loss: 0.005892332220109892, acc: 99.81354193389416, p_norm: 2162.680018025212, g_norm: 0.14055995407730362, lr:  0.000437, elapsed time:  159885
Step 326600, loss: 0.00670495420638872, acc: 99.78168551623821, p_norm: 2162.7906912144417, g_norm: 0.24838474463348692, lr:  0.000437, elapsed time:  159933
Step 326700, loss: 0.006364659650416798, acc: 99.79340456426144, p_norm: 2162.9008384842778, g_norm: 0.19943840364909105, lr:  0.000437, elapsed time:  159980
Step 326800, loss: 0.006468367293100527, acc: 99.79484102129936, p_norm: 2162.990224039231, g_norm: 0.23543401275770812, lr:  0.000437, elapsed time:  160027
Step 326900, loss: 0.006373656195496551, acc: 99.79506580531597, p_norm: 2163.0973367046204, g_norm: 0.18031476790029724, lr:  0.000437, elapsed time:  160075
Step 327000, loss: 0.006563086033147556, acc: 99.79217222332954, p_norm: 2163.1968984368345, g_norm: 0.22112381133542885, lr:  0.000437, elapsed time:  160122
Step 327100, loss: 0.006540705513616558, acc: 99.78865624964237, p_norm: 2163.30131459732, g_norm: 0.12630689685072544, lr:  0.000437, elapsed time:  160169
Step 327200, loss: 0.00606245995095378, acc: 99.80787935853004, p_norm: 2163.392043826059, g_norm: 0.1629923617051192, lr:  0.000437, elapsed time:  160217
Step 327300, loss: 0.006603182929147806, acc: 99.78610894083977, p_norm: 2163.4941959070516, g_norm: 0.15731325283505362, lr:  0.000437, elapsed time:  160265
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 327400, loss: 0.006001861424931492, acc: 99.80451924629305, p_norm: 2163.5998202557403, g_norm: 0.1786435549762556, lr:  0.000437, elapsed time:  160313
Step 327500, loss: 0.005898931430911034, acc: 99.8122369647026, p_norm: 2163.7000976072018, g_norm: 0.16704134876731005, lr:  0.000437, elapsed time:  160361
Step 327600, loss: 0.006131246772742998, acc: 99.79918639361858, p_norm: 2163.7875549434066, g_norm: 0.17006802000342228, lr:  0.000437, elapsed time:  160409
Step 327700, loss: 0.00625848401211897, acc: 99.79781202971935, p_norm: 2163.904914266524, g_norm: 0.15947131818305474, lr:  0.000437, elapsed time:  160456
Step 327800, loss: 0.006185747216986784, acc: 99.79793806374073, p_norm: 2163.9971423117927, g_norm: 0.16834556605276865, lr:  0.000437, elapsed time:  160504
Step 327900, loss: 0.0063589580777988885, acc: 99.79477350413799, p_norm: 2164.1014388526924, g_norm: 0.18329852127777704, lr:  0.000436, elapsed time:  160551
Step 328000, loss: 0.006571080917055951, acc: 99.78747613728046, p_norm: 2164.2023743784575, g_norm: 0.14794105252309062, lr:  0.000436, elapsed time:  160598
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 328000, eval loss: 0.020110377344572054, eval acc: 99.61994934082031
Step 328100, loss: 0.006546112290825476, acc: 99.78824318945408, p_norm: 2164.301674911679, g_norm: 0.2046122268595725, lr:  0.000436, elapsed time:  160653
Step 328200, loss: 0.006391174380546545, acc: 99.78890407085419, p_norm: 2164.4185507657344, g_norm: 0.11651890341474037, lr:  0.000436, elapsed time:  160701
Step 328300, loss: 0.006307192163039872, acc: 99.79532626271248, p_norm: 2164.5280761816953, g_norm: 0.16789048738757878, lr:  0.000436, elapsed time:  160749
Step 328400, loss: 0.006560189173405888, acc: 99.78755849599838, p_norm: 2164.6303707241113, g_norm: 0.1686060435690405, lr:  0.000436, elapsed time:  160796
Step 328500, loss: 0.006458194681717941, acc: 99.78879629075527, p_norm: 2164.7272661894763, g_norm: 0.20639392351039504, lr:  0.000436, elapsed time:  160843
Step 328600, loss: 0.006570923322142335, acc: 99.7960014641285, p_norm: 2164.831384512087, g_norm: 0.20330707247874166, lr:  0.000436, elapsed time:  160891
Step 328700, loss: 0.006509824779786868, acc: 99.79772709310055, p_norm: 2164.9302765401817, g_norm: 0.13143315554348603, lr:  0.000436, elapsed time:  160939
Step 328800, loss: 0.006763449294121529, acc: 99.78604307770729, p_norm: 2165.0468572122986, g_norm: 0.14644708719576324, lr:  0.000436, elapsed time:  160986
Step 328900, loss: 0.007004222329669574, acc: 99.77561664581299, p_norm: 2165.16251247991, g_norm: 0.25117406637221523, lr:  0.000436, elapsed time:  161033
Step 329000, loss: 0.006650975063566875, acc: 99.78923578560352, p_norm: 2165.2613211030816, g_norm: 0.20820917373391, lr:  0.000436, elapsed time:  161084
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 329100, loss: 0.006668151942793349, acc: 99.78488938092593, p_norm: 2165.3706197951637, g_norm: 0.18996292759758865, lr:  0.000436, elapsed time:  161133
Step 329200, loss: 0.005803399044398247, acc: 99.81294353306293, p_norm: 2165.454657455492, g_norm: 0.1483195365738081, lr:  0.000436, elapsed time:  161181
Step 329300, loss: 0.005977167894398008, acc: 99.81155556440353, p_norm: 2165.5567972713675, g_norm: 0.11636022565658662, lr:  0.000436, elapsed time:  161228
Step 329400, loss: 0.006247229342397987, acc: 99.79644030332565, p_norm: 2165.660621529193, g_norm: 0.22171055175223545, lr:  0.000435, elapsed time:  161276
Step 329500, loss: 0.006438179355809552, acc: 99.78983595967293, p_norm: 2165.754748786455, g_norm: 0.15495212287878862, lr:  0.000435, elapsed time:  161324
Step 329600, loss: 0.006255431227200461, acc: 99.80409277975559, p_norm: 2165.8559120424006, g_norm: 0.15969802192043542, lr:  0.000435, elapsed time:  161370
Step 329700, loss: 0.0062086961975910526, acc: 99.79891757667065, p_norm: 2165.9572147053677, g_norm: 0.23577362145249153, lr:  0.000435, elapsed time:  161418
Step 329800, loss: 0.006338735043145789, acc: 99.79038381576538, p_norm: 2166.0726464658183, g_norm: 0.29180810695141635, lr:  0.000435, elapsed time:  161465
Step 329900, loss: 0.006343509981034004, acc: 99.79733514785767, p_norm: 2166.1734760906243, g_norm: 0.20060032512526565, lr:  0.000435, elapsed time:  161512
Step 330000, loss: 0.0065748381519370016, acc: 99.7817867398262, p_norm: 2166.277478950045, g_norm: 0.17999068324247722, lr:  0.000435, elapsed time:  161559
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 330000, eval loss: 0.02211914433468338, eval acc: 99.57970428466797
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: F C ( F ) ( F ) C O c 1 c c c c c 1 S c 1 n c [nH] n 1 _EOS
Predicted text: F C ( F ) ( F ) C O c 1 c c c c c 1 S c 1 n c [nH] n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N C C C 1 ( c 2 c c c c c 2 ) C C N ( c 2 c c c c ( - c 3 c c c ( F ) c c 3 F ) c 2 ) C ( = O ) O 1 _EOS
Predicted text: C C ( = O ) N C C C 1 ( c 2 c c c c c 2 ) C C N ( c 2 c c c c ( - c 3 c c c ( F ) c c 3 F ) c 2 ) C ( = O ) O 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( - c 2 c c ( F ) c c c 2 O C ) c c c 1 C N S ( = O ) ( = O ) c 1 c c c ( F ) c c 1 _EOS
Predicted text: C O c 1 c c c ( F ) c c 1 - c 1 c c c ( C N S ( = O ) ( = O ) c 2 c c c ( F ) c c 2 ) c ( O C ) c 1 _EOS
acc_token: 0.2653061224489796, acc_seq: False

Target text: C O C ( = O ) C ( C C ( = C C C c 1 c c c 2 c ( c 1 ) C ( C ) ( C ) C C C 2 ( C ) C ) c 1 c c c c ( C ( F ) ( F ) F ) c 1 ) C ( = O ) O C _EOS
Predicted text: C C 1 ( C ) C C C ( C ) ( C ) c 2 c c ( C C C = C ( C O ) c 3 c c c c ( C ( F ) ( F ) F ) c 3 ) c c c 2 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.14285714285714285, acc_seq: False

Target text: C C C C O C C O c 1 c c c ( - c 2 c c c 3 c ( c 2 ) C = C ( C ( = O ) N c 2 c c c ( S ( = O ) C c 4 n n c n 4 C C C ) c c 2 ) C C C N 3 C C ( C ) C ) c c 1 _EOS
Predicted text: C C C C O C C O c 1 c c c ( - c 2 c c c 3 c ( c 2 ) C = C ( C ( = O ) N c 2 c c c ( S ( = O ) C c 4 n n c n 4 C C C ) c c 2 ) C C C N 3 C C ( C ) C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 330000, eval acc (token): 0.9421036911809795, eval acc (sequence): 0.8945666235446313
Saving at step 330000
Step 330100, loss: 0.0064854943162936255, acc: 99.7935369759798, p_norm: 2166.3860593633653, g_norm: 0.23026952579944265, lr:  0.000435, elapsed time:  161663
Step 330200, loss: 0.006802174297063175, acc: 99.78360845148563, p_norm: 2166.4908473201626, g_norm: 0.13293296072791627, lr:  0.000435, elapsed time:  161709
Step 330300, loss: 0.006333972759885001, acc: 99.79621717333794, p_norm: 2166.5985108682735, g_norm: 0.16954387588062947, lr:  0.000435, elapsed time:  161758
Step 330400, loss: 0.006699939127029211, acc: 99.7800280302763, p_norm: 2166.7165553838513, g_norm: 0.2715371617809493, lr:  0.000435, elapsed time:  161805
Step 330500, loss: 0.0063685275436000666, acc: 99.79596462845802, p_norm: 2166.8202510422875, g_norm: 0.1299350146821532, lr:  0.000435, elapsed time:  161853
Step 330600, loss: 0.006335981869833631, acc: 99.79891803860664, p_norm: 2166.9177646394996, g_norm: 0.18743869089157555, lr:  0.000435, elapsed time:  161901
Step 330700, loss: 0.006871708331773334, acc: 99.77505174279213, p_norm: 2167.027129648922, g_norm: 0.1384639916089796, lr:  0.000435, elapsed time:  161948
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 330800, loss: 0.00629559994266321, acc: 99.7957130519687, p_norm: 2167.1363442298994, g_norm: 0.18094305792475537, lr:  0.000435, elapsed time:  161997
Step 330900, loss: 0.005825600455136737, acc: 99.81179635226727, p_norm: 2167.2327123648015, g_norm: 0.15477852572601028, lr:  0.000434, elapsed time:  162045
Step 331000, loss: 0.00624147697510125, acc: 99.79542560875416, p_norm: 2167.3356650959977, g_norm: 0.23213151066934118, lr:  0.000434, elapsed time:  162093
Step 331100, loss: 0.006492894217735738, acc: 99.7920813113451, p_norm: 2167.422708520049, g_norm: 0.21223218424510404, lr:  0.000434, elapsed time:  162139
Step 331200, loss: 0.006243459674378755, acc: 99.79974333941936, p_norm: 2167.5209324936222, g_norm: 0.25203998633163244, lr:  0.000434, elapsed time:  162187
Step 331300, loss: 0.006249834186592125, acc: 99.79872606694698, p_norm: 2167.628275830386, g_norm: 0.2214035796129625, lr:  0.000434, elapsed time:  162234
Step 331400, loss: 0.006276926653536066, acc: 99.79948887228966, p_norm: 2167.737106752234, g_norm: 0.2166290075465908, lr:  0.000434, elapsed time:  162282
Step 331500, loss: 0.006107817644706301, acc: 99.79890604317188, p_norm: 2167.8340522134413, g_norm: 0.1865769040876549, lr:  0.000434, elapsed time:  162330
Step 331600, loss: 0.0067184485908364875, acc: 99.78621055185795, p_norm: 2167.9441352257013, g_norm: 0.3103038402257426, lr:  0.000434, elapsed time:  162377
Step 331700, loss: 0.006035455976470985, acc: 99.80260939896107, p_norm: 2168.0451638873033, g_norm: 0.21282767617852685, lr:  0.000434, elapsed time:  162424
Step 331800, loss: 0.0064812533436270315, acc: 99.7929847240448, p_norm: 2168.1426128199187, g_norm: 0.12936551364653293, lr:  0.000434, elapsed time:  162472
Step 331900, loss: 0.00635061995992146, acc: 99.79765297472477, p_norm: 2168.24861681358, g_norm: 0.1520073356465252, lr:  0.000434, elapsed time:  162519
Step 332000, loss: 0.006324022752069141, acc: 99.79469874501228, p_norm: 2168.346331112846, g_norm: 0.2411277396585571, lr:  0.000434, elapsed time:  162567
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 332000, eval loss: 0.021802398359031947, eval acc: 99.57233428955078
Step 332100, loss: 0.006325562394958979, acc: 99.79305920004845, p_norm: 2168.4538221953926, g_norm: 0.12764230677182367, lr:  0.000434, elapsed time:  162621
Step 332200, loss: 0.005930900475595991, acc: 99.80769358575344, p_norm: 2168.560108999847, g_norm: 0.2668062445204837, lr:  0.000434, elapsed time:  162669
Step 332300, loss: 0.006466161546004514, acc: 99.78898106515408, p_norm: 2168.659932796425, g_norm: 0.20702506914258748, lr:  0.000434, elapsed time:  162717
Step 332400, loss: 0.006729247279345145, acc: 99.78289254009724, p_norm: 2168.7714159382263, g_norm: 0.21394780866667526, lr:  0.000433, elapsed time:  162765
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 332500, loss: 0.006536700070454917, acc: 99.7922318744896, p_norm: 2168.8798045150115, g_norm: 0.22475669039428497, lr:  0.000433, elapsed time:  162813
Step 332600, loss: 0.006263188568063924, acc: 99.79670071601868, p_norm: 2168.982303921272, g_norm: 0.19769683456258547, lr:  0.000433, elapsed time:  162860
Step 332700, loss: 0.0062028035994990205, acc: 99.80011360347271, p_norm: 2169.0780560956646, g_norm: 0.19222309051488834, lr:  0.000433, elapsed time:  162907
Step 332800, loss: 0.00642699000731227, acc: 99.7928901463747, p_norm: 2169.2025738457296, g_norm: 0.18573223799741548, lr:  0.000433, elapsed time:  162954
Step 332900, loss: 0.006258142618335114, acc: 99.79717990756035, p_norm: 2169.3040364027606, g_norm: 0.1025040860151633, lr:  0.000433, elapsed time:  163001
Step 333000, loss: 0.006399715658772038, acc: 99.79668141901493, p_norm: 2169.4134681047326, g_norm: 0.16405401888507942, lr:  0.000433, elapsed time:  163048
Step 333100, loss: 0.006427268992756581, acc: 99.79605993628502, p_norm: 2169.5044304311136, g_norm: 0.14427705535379956, lr:  0.000433, elapsed time:  163095
Step 333200, loss: 0.0064442230494023535, acc: 99.79312424361706, p_norm: 2169.5997804082263, g_norm: 0.1970246868609243, lr:  0.000433, elapsed time:  163142
Step 333300, loss: 0.00649788300948785, acc: 99.79121522605419, p_norm: 2169.700403340979, g_norm: 0.26179324655081826, lr:  0.000433, elapsed time:  163190
Step 333400, loss: 0.006166145033416797, acc: 99.79746194183826, p_norm: 2169.8054793584415, g_norm: 0.23507306273820286, lr:  0.000433, elapsed time:  163237
Step 333500, loss: 0.006415710659239266, acc: 99.78888855874538, p_norm: 2169.8999113115883, g_norm: 0.2074291152670654, lr:  0.000433, elapsed time:  163285
Step 333600, loss: 0.006118060729495483, acc: 99.79891994595528, p_norm: 2169.99076711632, g_norm: 0.1852262258820949, lr:  0.000433, elapsed time:  163333
Step 333700, loss: 0.006906389375853905, acc: 99.77822948992252, p_norm: 2170.0986999219904, g_norm: 0.1517031038225826, lr:  0.000433, elapsed time:  163380
Step 333800, loss: 0.006192369523287198, acc: 99.80322313308716, p_norm: 2170.1935312542482, g_norm: 0.16418768941070222, lr:  0.000433, elapsed time:  163428
Step 333900, loss: 0.006406882096293884, acc: 99.79128189384937, p_norm: 2170.2967006413996, g_norm: 0.16225830676490594, lr:  0.000433, elapsed time:  163475
Step 334000, loss: 0.006353950048978731, acc: 99.79264429211617, p_norm: 2170.395872358031, g_norm: 0.2127111370444283, lr:  0.000432, elapsed time:  163522
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 334000, eval loss: 0.01947641333512366, eval acc: 99.6168212890625
Step 334100, loss: 0.006361655688451719, acc: 99.79543486237526, p_norm: 2170.5021471004, g_norm: 0.1450942944511514, lr:  0.000432, elapsed time:  163576
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 334200, loss: 0.006195922887076702, acc: 99.79870085099444, p_norm: 2170.60118367052, g_norm: 0.14961078269649725, lr:  0.000432, elapsed time:  163625
Step 334300, loss: 0.006248448319538511, acc: 99.79824677109718, p_norm: 2170.701558872634, g_norm: 0.15560220775873557, lr:  0.000432, elapsed time:  163672
Step 334400, loss: 0.005779406417350402, acc: 99.81269969046116, p_norm: 2170.7966876410064, g_norm: 0.14585926620540263, lr:  0.000432, elapsed time:  163720
Step 334500, loss: 0.00611622319343951, acc: 99.80727308988571, p_norm: 2170.8979978686293, g_norm: 0.08884090046982718, lr:  0.000432, elapsed time:  163767
Step 334600, loss: 0.005969872170489907, acc: 99.80580334365368, p_norm: 2171.0081057471207, g_norm: 0.26031257161237986, lr:  0.000432, elapsed time:  163815
Step 334700, loss: 0.006188036536477739, acc: 99.80052208900452, p_norm: 2171.1236187139534, g_norm: 0.24470884912349622, lr:  0.000432, elapsed time:  163862
Step 334800, loss: 0.005948100072127999, acc: 99.8077290803194, p_norm: 2171.224802111113, g_norm: 0.22589429094924743, lr:  0.000432, elapsed time:  163910
Step 334900, loss: 0.006338745704852045, acc: 99.79325664043427, p_norm: 2171.320280574591, g_norm: 0.1686210707970192, lr:  0.000432, elapsed time:  163957
Step 335000, loss: 0.006209672776039951, acc: 99.79415535926819, p_norm: 2171.4307455931803, g_norm: 0.14591341085194318, lr:  0.000432, elapsed time:  164005
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( N C c 1 c c c ( F ) c c 1 ) N 1 C C C ( O c 2 c c c ( C C N C C ( O ) C O c 3 c c c ( O ) c c 3 ) c c 2 ) C C 1 _EOS
Predicted text: O = C ( N C c 1 c c c ( F ) c c 1 ) N 1 C C C ( O c 2 c c c ( C C N C C ( O ) C O c 3 c c c ( O ) c c 3 ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( - c 2 c c s c 2 ) c c 1 C = O _EOS
Predicted text: C O c 1 c c c ( - c 2 c c s c 2 ) c c 1 C = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( C C 2 C O C ( C ) ( C ) O 2 ) c c c 1 O C C N c 1 n c n c ( C ) c 1 Cl _EOS
Predicted text: C c 1 c c ( C C 2 C O C ( C ) ( C ) O 2 ) c c c 1 O C C N c 1 n c n c ( C ) c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C 1 = C ( C O C C N S ( = O ) ( = O ) N 2 C C N ( C ) C C 2 ) N C ( C ) = C ( C ( = O ) O C ) C 1 c 1 c c c c c 1 Cl _EOS
Predicted text: C C O C ( = O ) C 1 = C ( C O C C N S ( = O ) ( = O ) N 2 C C N ( C ) C C 2 ) N C ( C ) = C ( C ( = O ) O C ) C 1 c 1 c c c c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: N # C C c 1 c c c c ( N C ( = O ) c 2 c c c c ( - c 3 c c c c c 3 ) n 2 ) c 1 _EOS
Predicted text: N # C C c 1 c c c c ( N C ( = O ) c 2 c c c c ( - c 3 c c c c c 3 ) n 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 335000, eval acc (token): 0.9451941350524286, eval acc (sequence): 0.9019706922688226
Saving at step 335000
Step 335100, loss: 0.006333046008912788, acc: 99.79420126974583, p_norm: 2171.547774941357, g_norm: 0.20264223076022636, lr:  0.000432, elapsed time:  164104
Step 335200, loss: 0.006725955753245217, acc: 99.78600138425827, p_norm: 2171.6604792563917, g_norm: 0.16196711852996695, lr:  0.000432, elapsed time:  164151
Step 335300, loss: 0.006303796778556716, acc: 99.79526983201504, p_norm: 2171.7497846338406, g_norm: 0.24181892557884738, lr:  0.000432, elapsed time:  164198
Step 335400, loss: 0.006621172565719462, acc: 99.78069719672203, p_norm: 2171.861042180179, g_norm: 0.2096322591251209, lr:  0.000432, elapsed time:  164246
Step 335500, loss: 0.006547940340333298, acc: 99.78927530348301, p_norm: 2171.957509645197, g_norm: 0.2018186338823995, lr:  0.000431, elapsed time:  164293
Step 335600, loss: 0.006012623154592802, acc: 99.8073151409626, p_norm: 2172.0629419145835, g_norm: 0.3620090558253511, lr:  0.000431, elapsed time:  164341
Step 335700, loss: 0.006141147149901371, acc: 99.79810385406017, p_norm: 2172.1538296877216, g_norm: 0.2000651312557144, lr:  0.000431, elapsed time:  164388
Step 335800, loss: 0.006675377513656713, acc: 99.78449168801308, p_norm: 2172.26962900904, g_norm: 0.23479089818682744, lr:  0.000431, elapsed time:  164436
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 335900, loss: 0.006469729399383235, acc: 99.79101571788267, p_norm: 2172.366546825089, g_norm: 0.11219349209537843, lr:  0.000431, elapsed time:  164484
Step 336000, loss: 0.006054101821755467, acc: 99.80814428627491, p_norm: 2172.4543792206914, g_norm: 0.18387668249076358, lr:  0.000431, elapsed time:  164531
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 336000, eval loss: 0.02015912953218504, eval acc: 99.63024139404297
Step 336100, loss: 0.005917930562391121, acc: 99.80809509754181, p_norm: 2172.5564366228164, g_norm: 0.11789601898401697, lr:  0.000431, elapsed time:  164587
Step 336200, loss: 0.006114288462395052, acc: 99.80260846018791, p_norm: 2172.657271627988, g_norm: 0.10488601390687445, lr:  0.000431, elapsed time:  164634
Step 336300, loss: 0.0060152170441870115, acc: 99.80181175470352, p_norm: 2172.758338721485, g_norm: 0.20345578829775018, lr:  0.000431, elapsed time:  164682
Step 336400, loss: 0.005992355999514984, acc: 99.81002512574196, p_norm: 2172.8603174716804, g_norm: 0.19727945725803808, lr:  0.000431, elapsed time:  164729
Step 336500, loss: 0.0064608823206162925, acc: 99.79433597624302, p_norm: 2172.9668296210793, g_norm: 0.15991570543338027, lr:  0.000431, elapsed time:  164777
Step 336600, loss: 0.006032479359655554, acc: 99.80379688739777, p_norm: 2173.0649857443696, g_norm: 0.23320596186975834, lr:  0.000431, elapsed time:  164824
Step 336700, loss: 0.006386609364262767, acc: 99.7921327650547, p_norm: 2173.1578981241805, g_norm: 0.1743055288419675, lr:  0.000431, elapsed time:  164871
Step 336800, loss: 0.00638151275433529, acc: 99.79123212397099, p_norm: 2173.2463834012506, g_norm: 0.19548442941716196, lr:  0.000431, elapsed time:  164919
Step 336900, loss: 0.005842941509799857, acc: 99.81701566278934, p_norm: 2173.3401917860297, g_norm: 0.23526543127572752, lr:  0.000431, elapsed time:  164967
Step 337000, loss: 0.006186903162924864, acc: 99.80073828995228, p_norm: 2173.434448490689, g_norm: 0.20579850586141396, lr:  0.000431, elapsed time:  165014
Step 337100, loss: 0.006117635424557193, acc: 99.80648985505104, p_norm: 2173.5363876891715, g_norm: 0.1599662170669499, lr:  0.000430, elapsed time:  165062
Step 337200, loss: 0.006094254932304466, acc: 99.7956213504076, p_norm: 2173.63933733864, g_norm: 0.1545686599586788, lr:  0.000430, elapsed time:  165110
Step 337300, loss: 0.00669441064748753, acc: 99.78289243578911, p_norm: 2173.7511675667765, g_norm: 0.3127369520090267, lr:  0.000430, elapsed time:  165157
Step 337400, loss: 0.006747033526853557, acc: 99.77882392704487, p_norm: 2173.850222870843, g_norm: 0.4897849100652205, lr:  0.000430, elapsed time:  165204
Step 337500, loss: 0.006469212462616269, acc: 99.78948824107647, p_norm: 2173.956443128191, g_norm: 0.23251243259773866, lr:  0.000430, elapsed time:  165252
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 337600, loss: 0.006299491653904539, acc: 99.79743087853747, p_norm: 2174.0634332420814, g_norm: 0.1992150918724141, lr:  0.000430, elapsed time:  165300
Step 337700, loss: 0.005998608547342883, acc: 99.80596640706062, p_norm: 2174.164806349437, g_norm: 0.17180930112216364, lr:  0.000430, elapsed time:  165348
Step 337800, loss: 0.006240255833799893, acc: 99.79797154664993, p_norm: 2174.2715079580657, g_norm: 0.18185003349114381, lr:  0.000430, elapsed time:  165395
Step 337900, loss: 0.006119928342441199, acc: 99.80465407669544, p_norm: 2174.367877145403, g_norm: 0.1826398142871125, lr:  0.000430, elapsed time:  165443
Step 338000, loss: 0.006116421758106299, acc: 99.79994635283947, p_norm: 2174.4693999734145, g_norm: 0.19967368141312863, lr:  0.000430, elapsed time:  165490
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 338000, eval loss: 0.022788832046838944, eval acc: 99.58500671386719
Step 338100, loss: 0.0064651255957414834, acc: 99.7921344190836, p_norm: 2174.571764957058, g_norm: 0.15082760988200894, lr:  0.000430, elapsed time:  165544
Step 338200, loss: 0.006049374551403162, acc: 99.8098116517067, p_norm: 2174.659930599094, g_norm: 0.17124621793101136, lr:  0.000430, elapsed time:  165592
Step 338300, loss: 0.006136272716830717, acc: 99.8030947893858, p_norm: 2174.7538798407213, g_norm: 0.14618514127449372, lr:  0.000430, elapsed time:  165639
Step 338400, loss: 0.006344270453664649, acc: 99.79216627776623, p_norm: 2174.8651531295914, g_norm: 0.16815076758859687, lr:  0.000430, elapsed time:  165686
Step 338500, loss: 0.006337246143648372, acc: 99.79402068257332, p_norm: 2174.9636800402577, g_norm: 0.1449499671072547, lr:  0.000430, elapsed time:  165734
Step 338600, loss: 0.006420460545296009, acc: 99.79308797419071, p_norm: 2175.0648868926964, g_norm: 0.1779764686445956, lr:  0.000430, elapsed time:  165782
Step 338700, loss: 0.005953933701512142, acc: 99.80980655550957, p_norm: 2175.158752000001, g_norm: 0.1283393444023911, lr:  0.000429, elapsed time:  165829
Step 338800, loss: 0.006380490551327967, acc: 99.79408676922321, p_norm: 2175.255264230693, g_norm: 0.11878049076455437, lr:  0.000429, elapsed time:  165877
Step 338900, loss: 0.0062837849094285044, acc: 99.7982013374567, p_norm: 2175.353726937049, g_norm: 0.14794743588166223, lr:  0.000429, elapsed time:  165925
Step 339000, loss: 0.006247325832082424, acc: 99.79932467639446, p_norm: 2175.4720904024293, g_norm: 0.23656131020049553, lr:  0.000429, elapsed time:  165973
Step 339100, loss: 0.006719498551046854, acc: 99.78537754714489, p_norm: 2175.57502424417, g_norm: 0.2586103479119755, lr:  0.000429, elapsed time:  166020
Step 339200, loss: 0.006235242571383423, acc: 99.79744951426983, p_norm: 2175.6838181624025, g_norm: 0.1910078344450102, lr:  0.000429, elapsed time:  166068
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 339300, loss: 0.006414971710946431, acc: 99.79038300644375, p_norm: 2175.804386704211, g_norm: 0.1495330601356663, lr:  0.000429, elapsed time:  166117
Step 339400, loss: 0.006819818050207687, acc: 99.77873679995537, p_norm: 2175.905343701409, g_norm: 0.23607122491675003, lr:  0.000429, elapsed time:  166164
Step 339500, loss: 0.00673006970424467, acc: 99.78173425793648, p_norm: 2176.0135451788738, g_norm: 0.11330967529661408, lr:  0.000429, elapsed time:  166211
Step 339600, loss: 0.0061293744101931225, acc: 99.8073369115591, p_norm: 2176.1087188833085, g_norm: 0.20705179291197862, lr:  0.000429, elapsed time:  166258
Step 339700, loss: 0.0059454338544492205, acc: 99.80716700851917, p_norm: 2176.2035641590614, g_norm: 0.8439856570433283, lr:  0.000429, elapsed time:  166305
Step 339800, loss: 0.006467799377687698, acc: 99.79359638690948, p_norm: 2176.3062873118565, g_norm: 0.1431753130876949, lr:  0.000429, elapsed time:  166353
Step 339900, loss: 0.0060667240556358595, acc: 99.80372615158558, p_norm: 2176.4034696216036, g_norm: 0.19301859251930245, lr:  0.000429, elapsed time:  166401
Step 340000, loss: 0.006043564696647082, acc: 99.80431091785431, p_norm: 2176.5053671415158, g_norm: 0.11194181756850195, lr:  0.000429, elapsed time:  166449
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 340000, eval loss: 0.02029136647268388, eval acc: 99.60569763183594
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C c 1 c ( N c 2 c c c ( I ) c c 2 F ) c ( N S ( = O ) ( = O ) C 2 ( C C = O ) C C 2 ) c 2 n ( c 1 = O ) C C O 2 _EOS
Predicted text: C c 1 c ( N c 2 c c c ( I ) c c 2 F ) c ( N S ( = O ) ( = O ) C 2 ( C C = O ) C C 2 ) c 2 n ( c 1 = O ) C C O 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( N c 2 n c ( N c 3 c c [nH] n 3 ) c c 3 c c c c c 2 3 ) c c 1 O C _EOS
Predicted text: C O c 1 c c c ( N c 2 n c ( N c 3 c c [nH] n 3 ) c c 3 c c c c c 2 3 ) c c 1 O C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n c ( - c 2 c ( C ( C ) C ) c c c 3 [nH] n c c 2 3 ) c 2 c c c ( O ) c c 2 c 1 C = O _EOS
Predicted text: C c 1 n c ( - c 2 c ( C ( C ) C ) c c c 3 [nH] n c c 2 3 ) c 2 c c c ( O ) c c 2 c 1 C = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N c 1 c c ( C ( F ) ( F ) F ) c c c 1 N 1 C C O C C 1 ) c 1 c c n c c 1 _EOS
Predicted text: O = C ( N c 1 c c ( C ( F ) ( F ) F ) c c c 1 N 1 C C O C C 1 ) c 1 c c n c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c c ( C n 2 n c ( N ( C O C C [Si] ( C ) ( C ) C ) S ( = O ) ( = O ) c 3 c c c ( Cl ) s 3 ) c 3 c ( O C ) c c c c 3 2 ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c c ( C n 2 n c ( N ( C O C C [Si] ( C ) ( C ) C ) S ( = O ) ( = O ) c 3 c c c ( Cl ) s 3 ) c 3 c ( O C ) c c c c 3 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 340000, eval acc (token): 0.9424521828316736, eval acc (sequence): 0.8926233858128427
Saving at step 340000
Step 340100, loss: 0.005984838093108919, acc: 99.80692447721958, p_norm: 2176.6038158767583, g_norm: 0.16433657813163585, lr:  0.000429, elapsed time:  166556
Step 340200, loss: 0.006318583895026677, acc: 99.79379424452782, p_norm: 2176.705553242607, g_norm: 0.1835666709826609, lr:  0.000428, elapsed time:  166604
Step 340300, loss: 0.006004731182019896, acc: 99.80577826499939, p_norm: 2176.8090354200235, g_norm: 0.21137667715137015, lr:  0.000428, elapsed time:  166652
Step 340400, loss: 0.006585781803405553, acc: 99.78874211013317, p_norm: 2176.9106162990242, g_norm: 0.18573331410265595, lr:  0.000428, elapsed time:  166699
Step 340500, loss: 0.0061426713802848094, acc: 99.80103206634521, p_norm: 2177.0167823922498, g_norm: 0.22364220250772227, lr:  0.000428, elapsed time:  166746
Step 340600, loss: 0.006681290160136086, acc: 99.78497403860092, p_norm: 2177.117291334048, g_norm: 0.19108173424579414, lr:  0.000428, elapsed time:  166794
Step 340700, loss: 0.006069357364376629, acc: 99.80568012595177, p_norm: 2177.206705929635, g_norm: 0.16094123209027075, lr:  0.000428, elapsed time:  166842
Step 340800, loss: 0.006244481591365912, acc: 99.7973190844059, p_norm: 2177.309445942475, g_norm: 0.14800114421928956, lr:  0.000428, elapsed time:  166889
Step 340900, loss: 0.0060727285869234034, acc: 99.80616188049316, p_norm: 2177.3913741788406, g_norm: 0.22484153546324856, lr:  0.000428, elapsed time:  166937
Step 341000, loss: 0.006018963642995914, acc: 99.80105802416801, p_norm: 2177.485671491744, g_norm: 0.14621529672453862, lr:  0.000428, elapsed time:  166984
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 341100, loss: 0.006056363425858973, acc: 99.80284311339518, p_norm: 2177.5872129955815, g_norm: 0.1634300215065382, lr:  0.000428, elapsed time:  167033
Step 341200, loss: 0.005571130140749574, acc: 99.8242750018835, p_norm: 2177.6863201316487, g_norm: 0.14975791963423785, lr:  0.000428, elapsed time:  167081
Step 341300, loss: 0.00569858847240539, acc: 99.81531329452991, p_norm: 2177.779382332987, g_norm: 0.10047433218687982, lr:  0.000428, elapsed time:  167128
Step 341400, loss: 0.005943985803678515, acc: 99.80692076683044, p_norm: 2177.869206213481, g_norm: 0.1329147889462038, lr:  0.000428, elapsed time:  167175
Step 341500, loss: 0.0061969727770883765, acc: 99.80175450444221, p_norm: 2177.9616145472146, g_norm: 0.18870536714049244, lr:  0.000428, elapsed time:  167222
Step 341600, loss: 0.006118477709442231, acc: 99.80013880133629, p_norm: 2178.066841981065, g_norm: 0.14532774371449972, lr:  0.000428, elapsed time:  167270
Step 341700, loss: 0.005749911568254901, acc: 99.81257575750351, p_norm: 2178.1729697826386, g_norm: 0.16918326513247414, lr:  0.000428, elapsed time:  167318
Step 341800, loss: 0.006205627265408111, acc: 99.79958906769753, p_norm: 2178.2811773844837, g_norm: 0.17717917329632968, lr:  0.000427, elapsed time:  167366
Step 341900, loss: 0.0067133136969641785, acc: 99.78537833690643, p_norm: 2178.3971670562373, g_norm: 0.27232396286550614, lr:  0.000427, elapsed time:  167413
Step 342000, loss: 0.00614032553625293, acc: 99.7968942373991, p_norm: 2178.4976329798524, g_norm: 0.20893335148335512, lr:  0.000427, elapsed time:  167460
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 342000, eval loss: 0.02158609513520786, eval acc: 99.5877914428711
Step 342100, loss: 0.0063457535451289, acc: 99.794273391366, p_norm: 2178.602684201542, g_norm: 0.31768828280290684, lr:  0.000427, elapsed time:  167514
Step 342200, loss: 0.006184098741523485, acc: 99.79690234363079, p_norm: 2178.7194395664856, g_norm: 0.17455056185050585, lr:  0.000427, elapsed time:  167563
Step 342300, loss: 0.0060628662560975495, acc: 99.80278530716896, p_norm: 2178.8130881362445, g_norm: 0.1430326834618099, lr:  0.000427, elapsed time:  167610
Step 342400, loss: 0.006576664562089718, acc: 99.78417460620403, p_norm: 2178.91959690799, g_norm: 0.22184575881895838, lr:  0.000427, elapsed time:  167658
Step 342500, loss: 0.0068712014936318155, acc: 99.78573034703732, p_norm: 2179.014325726445, g_norm: 0.19797444198412228, lr:  0.000427, elapsed time:  167705
Step 342600, loss: 0.006343688141423626, acc: 99.79737804830074, p_norm: 2179.105566946785, g_norm: 0.17774877870255668, lr:  0.000427, elapsed time:  167752
Step 342700, loss: 0.006529884119536291, acc: 99.79212765395641, p_norm: 2179.218459022611, g_norm: 0.23407023786015563, lr:  0.000427, elapsed time:  167800
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 342800, loss: 0.005864455756080187, acc: 99.81157705558473, p_norm: 2179.3195143609255, g_norm: 0.15681778915117398, lr:  0.000427, elapsed time:  167848
Step 342900, loss: 0.0059819995146608565, acc: 99.80769987404346, p_norm: 2179.422075819626, g_norm: 0.16088011012410963, lr:  0.000427, elapsed time:  167896
Step 343000, loss: 0.006027818374168419, acc: 99.80647327005863, p_norm: 2179.505463274603, g_norm: 0.25027662286169133, lr:  0.000427, elapsed time:  167943
Step 343100, loss: 0.005977940846514684, acc: 99.80660319328308, p_norm: 2179.5976608036226, g_norm: 0.22938888281664663, lr:  0.000427, elapsed time:  167990
Step 343200, loss: 0.006360296550346902, acc: 99.798499122262, p_norm: 2179.7023423332926, g_norm: 0.18287732515911337, lr:  0.000427, elapsed time:  168038
Step 343300, loss: 0.005965111794121185, acc: 99.80298157036304, p_norm: 2179.787958313401, g_norm: 0.20063953177556246, lr:  0.000427, elapsed time:  168086
Step 343400, loss: 0.006327286516925597, acc: 99.7969226539135, p_norm: 2179.8937591138374, g_norm: 0.1621567919454533, lr:  0.000426, elapsed time:  168132
Step 343500, loss: 0.0064279187446754805, acc: 99.79128316044807, p_norm: 2179.9951028545606, g_norm: 0.12118934095616396, lr:  0.000426, elapsed time:  168180
Step 343600, loss: 0.006426025446107815, acc: 99.79122671484947, p_norm: 2180.103136882755, g_norm: 0.18218437652663125, lr:  0.000426, elapsed time:  168227
Step 343700, loss: 0.006162455435623997, acc: 99.79883164167404, p_norm: 2180.202841784755, g_norm: 0.12940315504067484, lr:  0.000426, elapsed time:  168275
Step 343800, loss: 0.006219418864966428, acc: 99.8053290694952, p_norm: 2180.3010663042924, g_norm: 0.17873105757470462, lr:  0.000426, elapsed time:  168322
Step 343900, loss: 0.006030283490908914, acc: 99.80826470255852, p_norm: 2180.395275808169, g_norm: 0.1684004039907698, lr:  0.000426, elapsed time:  168370
Step 344000, loss: 0.00623613472782381, acc: 99.79857385158539, p_norm: 2180.487881042328, g_norm: 0.20920382331893692, lr:  0.000426, elapsed time:  168417
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 344000, eval loss: 0.02122793294664006, eval acc: 99.60236358642578
Step 344100, loss: 0.006236764355035121, acc: 99.80198067426682, p_norm: 2180.583104168363, g_norm: 0.21673504111120315, lr:  0.000426, elapsed time:  168472
Step 344200, loss: 0.006271492883497558, acc: 99.794618755579, p_norm: 2180.6894699616073, g_norm: 0.26302014716491384, lr:  0.000426, elapsed time:  168520
Step 344300, loss: 0.0061605816700466675, acc: 99.80081778764725, p_norm: 2180.793052216601, g_norm: 0.2115368412885681, lr:  0.000426, elapsed time:  168567
Step 344400, loss: 0.005829589054374082, acc: 99.81028240919113, p_norm: 2180.8901476107767, g_norm: 0.1733443162914187, lr:  0.000426, elapsed time:  168616
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 344500, loss: 0.005923453955055361, acc: 99.81419501909569, p_norm: 2180.9955666598503, g_norm: 0.19868730504135135, lr:  0.000426, elapsed time:  168664
Step 344600, loss: 0.005782090619059091, acc: 99.80846363306046, p_norm: 2181.0972297592402, g_norm: 0.18520698649945194, lr:  0.000426, elapsed time:  168712
Step 344700, loss: 0.006020655742486269, acc: 99.80894908308983, p_norm: 2181.202924083476, g_norm: 0.1438515677659071, lr:  0.000426, elapsed time:  168760
Step 344800, loss: 0.006262136468403696, acc: 99.79883432388306, p_norm: 2181.317022952549, g_norm: 0.19708231584394426, lr:  0.000426, elapsed time:  168807
Step 344900, loss: 0.006638016909610087, acc: 99.78639444708824, p_norm: 2181.4189016485984, g_norm: 0.14788496090895475, lr:  0.000426, elapsed time:  168855
Step 345000, loss: 0.006049480924293676, acc: 99.8040885925293, p_norm: 2181.5167101812667, g_norm: 0.17689607935002605, lr:  0.000426, elapsed time:  168902
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: O = C 1 c 2 n n ( - c 3 c c c c c 3 Cl ) c ( - c 3 c c c ( Cl ) c c 3 ) c 2 O C C N 1 C C ( F ) ( F ) F _EOS
Predicted text: O = C 1 c 2 n n ( - c 3 c c c c c 3 Cl ) c ( - c 3 c c c ( Cl ) c c 3 ) c 2 O C C N 1 C C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c ( C ) c 1 N C ( = O ) c 1 c c c ( [N+] ( = O ) [O-] ) c c 1 _EOS
Predicted text: C c 1 c c c c ( C ) c 1 N C ( = O ) c 1 c c c ( [N+] ( = O ) [O-] ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c c c ( - c 2 n c 3 c c c c c 3 s 2 ) c c 1 _EOS
Predicted text: C C O C ( = O ) c 1 c c c ( - c 2 n c 3 c c c c c 3 s 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C ( = O ) c 1 c ( N C ( = O ) N c 2 c c c ( Cl ) c c 2 ) s c 2 c 1 C C N C 2 _EOS
Predicted text: N C ( = O ) c 1 c ( N C ( = O ) N c 2 c c c ( Cl ) c c 2 ) s c 2 c 1 C C N C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C c 1 c c ( C ( = O ) O ) c c c 1 O C ( C ) C _EOS
Predicted text: C O C c 1 c c ( C ( = O ) O ) c c c 1 O C ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 345000, eval acc (token): 0.9407299619300145, eval acc (sequence): 0.8907494716306291
Saving at step 345000
Step 345100, loss: 0.006287163669494476, acc: 99.79306636750698, p_norm: 2181.618358416229, g_norm: 0.14630947145969453, lr:  0.000425, elapsed time:  169000
Step 345200, loss: 0.006506146550664198, acc: 99.78983801603317, p_norm: 2181.717574638484, g_norm: 0.31541178701525635, lr:  0.000425, elapsed time:  169047
Step 345300, loss: 0.005761925408305615, acc: 99.81098146736622, p_norm: 2181.8141004446134, g_norm: 0.13832187313789138, lr:  0.000425, elapsed time:  169095
Step 345400, loss: 0.006043630921485601, acc: 99.80794389545918, p_norm: 2181.925994623307, g_norm: 0.1768011963795877, lr:  0.000425, elapsed time:  169143
Step 345500, loss: 0.0064645545541861795, acc: 99.78883290290833, p_norm: 2182.0198915766937, g_norm: 0.20842151584649227, lr:  0.000425, elapsed time:  169190
Step 345600, loss: 0.006156770925590535, acc: 99.79510036110878, p_norm: 2182.1317824810308, g_norm: 0.18095976160580055, lr:  0.000425, elapsed time:  169238
Step 345700, loss: 0.006264749450710951, acc: 99.79470093548298, p_norm: 2182.233657756132, g_norm: 0.20180175229560982, lr:  0.000425, elapsed time:  169285
Step 345800, loss: 0.006539353892026156, acc: 99.79290616512299, p_norm: 2182.329692401505, g_norm: 0.17446107563974772, lr:  0.000425, elapsed time:  169333
Step 345900, loss: 0.006352448500820174, acc: 99.79234963655472, p_norm: 2182.4389998495894, g_norm: 0.1752508367868145, lr:  0.000425, elapsed time:  169381
Step 346000, loss: 0.006271415285264084, acc: 99.79638983309269, p_norm: 2182.5335678867064, g_norm: 0.22773039579923535, lr:  0.000425, elapsed time:  169428
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 346000, eval loss: 0.021648744295798675, eval acc: 99.60127258300781
Step 346100, loss: 0.006421681266710948, acc: 99.79668942093849, p_norm: 2182.6237679260607, g_norm: 0.19957136009497972, lr:  0.000425, elapsed time:  169483
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6822
Step 346200, loss: 0.00630846274378981, acc: 99.79790049806127, p_norm: 2182.7164884826843, g_norm: 0.16496504429023345, lr:  0.000425, elapsed time:  169531
Step 346300, loss: 0.006187783933619358, acc: 99.79763032495975, p_norm: 2182.815740208497, g_norm: 0.28098727989577654, lr:  0.000425, elapsed time:  169579
Step 346400, loss: 0.005759327296036645, acc: 99.815588504076, p_norm: 2182.904219510125, g_norm: 0.2653527135956173, lr:  0.000425, elapsed time:  169626
Step 346500, loss: 0.00590542991060829, acc: 99.80697329342365, p_norm: 2183.0028501666284, g_norm: 0.14342356238018256, lr:  0.000425, elapsed time:  169675
Step 346600, loss: 0.005881388263223926, acc: 99.80620734393597, p_norm: 2183.086563908547, g_norm: 0.15365505410021274, lr:  0.000425, elapsed time:  169722
Step 346700, loss: 0.006082408355632651, acc: 99.79740376770496, p_norm: 2183.1791744906427, g_norm: 0.18606867464551974, lr:  0.000424, elapsed time:  169769
Step 346800, loss: 0.0061163880660751605, acc: 99.80416943132877, p_norm: 2183.2822643044374, g_norm: 0.16051321697974524, lr:  0.000424, elapsed time:  169817
Step 346900, loss: 0.0063569705802319736, acc: 99.79179149866104, p_norm: 2183.383032464798, g_norm: 0.4122757407123207, lr:  0.000424, elapsed time:  169865
Step 347000, loss: 0.005847926054148047, acc: 99.81330162286758, p_norm: 2183.4855928184365, g_norm: 0.13694471384995274, lr:  0.000424, elapsed time:  169913
Step 347100, loss: 0.006022620625353739, acc: 99.802648589015, p_norm: 2183.585402863243, g_norm: 0.21801648541025395, lr:  0.000424, elapsed time:  169960
Step 347200, loss: 0.006351625635002165, acc: 99.78874881565571, p_norm: 2183.6856884435538, g_norm: 0.16592623341037707, lr:  0.000424, elapsed time:  170008
Step 347300, loss: 0.006379334442262916, acc: 99.79255357384682, p_norm: 2183.796222902953, g_norm: 0.1958552875325119, lr:  0.000424, elapsed time:  170056
Step 347400, loss: 0.006476085876129218, acc: 99.79194197058678, p_norm: 2183.896367346675, g_norm: 0.14741579978217556, lr:  0.000424, elapsed time:  170103
Step 347500, loss: 0.006060664028327664, acc: 99.80301190912724, p_norm: 2183.994094703444, g_norm: 0.1359405777409344, lr:  0.000424, elapsed time:  170150
Step 347600, loss: 0.006157767255244835, acc: 99.80529733002186, p_norm: 2184.0857150605298, g_norm: 0.2879372533800831, lr:  0.000424, elapsed time:  170198
Step 347700, loss: 0.006355061699282487, acc: 99.79671986401081, p_norm: 2184.178476476892, g_norm: 0.15304757576557546, lr:  0.000424, elapsed time:  170246
Step 347800, loss: 0.006236441207993266, acc: 99.79320968687534, p_norm: 2184.270065213234, g_norm: 0.1406931364702324, lr:  0.000424, elapsed time:  170293
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 347900, loss: 0.006193882281053927, acc: 99.79547449012301, p_norm: 2184.370627140851, g_norm: 0.15080622966785362, lr:  0.000424, elapsed time:  170341
Step 348000, loss: 0.005961289207953087, acc: 99.80949737131596, p_norm: 2184.4626224535714, g_norm: 0.2753880183910414, lr:  0.000424, elapsed time:  170388
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 348000, eval loss: 0.02014553592307492, eval acc: 99.61661529541016
Step 348100, loss: 0.00566262740881939, acc: 99.81208783388138, p_norm: 2184.5655687007315, g_norm: 0.1957977838458864, lr:  0.000424, elapsed time:  170443
Step 348200, loss: 0.006305746277521393, acc: 99.79927784204483, p_norm: 2184.6555624977586, g_norm: 0.1612130994164416, lr:  0.000424, elapsed time:  170490
Step 348300, loss: 0.006156395324323966, acc: 99.80174715816975, p_norm: 2184.752889460199, g_norm: 0.16365754799806717, lr:  0.000423, elapsed time:  170538
Step 348400, loss: 0.006184458590878421, acc: 99.79885718226433, p_norm: 2184.8597272267148, g_norm: 0.18291238010341568, lr:  0.000423, elapsed time:  170585
Step 348500, loss: 0.006139703601620567, acc: 99.80391290783882, p_norm: 2184.9532493758456, g_norm: 0.1506770022671375, lr:  0.000423, elapsed time:  170632
Step 348600, loss: 0.006052557681923645, acc: 99.80139628052711, p_norm: 2185.0464863627035, g_norm: 0.17737093836545767, lr:  0.000423, elapsed time:  170680
Step 348700, loss: 0.0062678687354309655, acc: 99.79656924307346, p_norm: 2185.153898763129, g_norm: 0.18729376672654574, lr:  0.000423, elapsed time:  170728
Step 348800, loss: 0.00620413468717743, acc: 99.79363903403282, p_norm: 2185.2507870386735, g_norm: 0.2358369440349975, lr:  0.000423, elapsed time:  170776
Step 348900, loss: 0.006078499707818992, acc: 99.80419188737869, p_norm: 2185.3581261909753, g_norm: 0.3484908694328397, lr:  0.000423, elapsed time:  170824
Step 349000, loss: 0.006182690865834957, acc: 99.79665529727936, p_norm: 2185.4510245211454, g_norm: 0.08719544687352561, lr:  0.000423, elapsed time:  170871
Step 349100, loss: 0.00623903534225974, acc: 99.79678235948086, p_norm: 2185.5568948379027, g_norm: 0.22624415412322324, lr:  0.000423, elapsed time:  170918
Step 349200, loss: 0.005787875047590205, acc: 99.81464120745659, p_norm: 2185.648563491209, g_norm: 0.15740631409865807, lr:  0.000423, elapsed time:  170966
Step 349300, loss: 0.006313031458948899, acc: 99.79583153128624, p_norm: 2185.752194697609, g_norm: 0.18422566571167026, lr:  0.000423, elapsed time:  171013
Step 349400, loss: 0.006484276768405834, acc: 99.79246398806572, p_norm: 2185.852686836122, g_norm: 0.20575043367642828, lr:  0.000423, elapsed time:  171061
Step 349500, loss: 0.0064109940163416465, acc: 99.79492084681988, p_norm: 2185.9533510176866, g_norm: 0.15988181249775543, lr:  0.000423, elapsed time:  171108
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 349600, loss: 0.006180313964799077, acc: 99.8021971055355, p_norm: 2186.054357443473, g_norm: 0.23678240890662314, lr:  0.000423, elapsed time:  171157
Step 349700, loss: 0.005743011011954877, acc: 99.80987042188644, p_norm: 2186.1582560759434, g_norm: 0.15932846833011285, lr:  0.000423, elapsed time:  171204
Step 349800, loss: 0.0060579873651386154, acc: 99.80115731060505, p_norm: 2186.2506857377834, g_norm: 0.22310332124681823, lr:  0.000423, elapsed time:  171252
Step 349900, loss: 0.005877927453284428, acc: 99.81676530838013, p_norm: 2186.354319779756, g_norm: 0.1628205714934878, lr:  0.000423, elapsed time:  171300
Step 350000, loss: 0.005871856918101912, acc: 99.81103879213333, p_norm: 2186.458058511569, g_norm: 0.17448848191563662, lr:  0.000422, elapsed time:  171347
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 350000, eval loss: 0.021090481601022483, eval acc: 99.61178588867188
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) C N C 1 = C ( C ( = O ) c 2 c c c n c 2 Cl ) C C C 1 _EOS
Predicted text: C C O C ( = O ) C N c 1 n c c c c 1 C ( = O ) C 1 = C ( N 2 C C C C 2 ) C C C 1 _EOS
acc_token: 0.4, acc_seq: False

Target text: N C 1 C N ( C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) C 1 _EOS
Predicted text: N C 1 C N ( C ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: c 1 c c c ( - c 2 n n c ( - c 3 c c c c c 3 ) n 2 - c 2 c c c ( - c 3 c c c n c 3 ) c c 2 ) c c 1 _EOS
Predicted text: c 1 c c c ( - c 2 n n c ( - c 3 c c c c c 3 ) n 2 - c 2 c c c ( - c 3 c c c n c 3 ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c c 2 c ( c 1 ) N ( C ) S ( = O ) ( = O ) C C 2 N C ( = O ) C C ( N S ( = O ) ( = O ) c 1 c c c 2 c c c c c 2 c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c c 2 c ( c 1 ) N ( C ) S ( = O ) ( = O ) C C 2 N C ( = O ) C C ( N S ( = O ) ( = O ) c 1 c c c 2 c c c c c 2 c 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 C N C C N 1 C ( = O ) c 1 c c c ( N C ( = O ) N C 2 C C C 2 ) c c 1 _EOS
Predicted text: C C 1 C N C C N 1 C ( = O ) c 1 c c c ( N C ( = O ) N C 2 C C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 350000, eval acc (token): 0.9435518101838565, eval acc (sequence): 0.8976897689768977
Saving at step 350000
Step 350100, loss: 0.005854944116781553, acc: 99.81119225919247, p_norm: 2186.542441584669, g_norm: 0.2268764495165615, lr:  0.000422, elapsed time:  171456
Step 350200, loss: 0.0060722640237327145, acc: 99.80503207445145, p_norm: 2186.6363464992414, g_norm: 0.2159043898628688, lr:  0.000422, elapsed time:  171504
Step 350300, loss: 0.006280483869104501, acc: 99.79731342196465, p_norm: 2186.735401550896, g_norm: 0.15818276196509284, lr:  0.000422, elapsed time:  171551
Step 350400, loss: 0.006092881016920728, acc: 99.80563622713089, p_norm: 2186.83979478802, g_norm: 0.10970777881601072, lr:  0.000422, elapsed time:  171599
Step 350500, loss: 0.005951583826135903, acc: 99.80487883090973, p_norm: 2186.937835843225, g_norm: 0.20134052002316666, lr:  0.000422, elapsed time:  171646
Step 350600, loss: 0.00606243168374931, acc: 99.80664186179638, p_norm: 2187.0368542434303, g_norm: 0.3015093115631475, lr:  0.000422, elapsed time:  171694
Step 350700, loss: 0.006031585396967785, acc: 99.8047841489315, p_norm: 2187.131717443364, g_norm: 0.33181009482129104, lr:  0.000422, elapsed time:  171742
Step 350800, loss: 0.006301134864534106, acc: 99.79346491396427, p_norm: 2187.2252610162595, g_norm: 0.1571973974187666, lr:  0.000422, elapsed time:  171789
Step 350900, loss: 0.006411133227229584, acc: 99.79489912092686, p_norm: 2187.3302907129223, g_norm: 0.34850825500718274, lr:  0.000422, elapsed time:  171837
Step 351000, loss: 0.006552408439893043, acc: 99.79117698967457, p_norm: 2187.431289712355, g_norm: 0.19104275160641154, lr:  0.000422, elapsed time:  171884
Step 351100, loss: 0.006266510937475687, acc: 99.79115928709507, p_norm: 2187.5231859523606, g_norm: 0.2189863898488132, lr:  0.000422, elapsed time:  171932
Step 351200, loss: 0.0059890494773389945, acc: 99.80933685600758, p_norm: 2187.628896230719, g_norm: 0.1837427393761252, lr:  0.000422, elapsed time:  171980
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 351300, loss: 0.005927867414244184, acc: 99.80791682936713, p_norm: 2187.7208736331386, g_norm: 0.18486681608218014, lr:  0.000422, elapsed time:  172029
Step 351400, loss: 0.005943973030789493, acc: 99.80650222301483, p_norm: 2187.804737608084, g_norm: 0.170717853706702, lr:  0.000422, elapsed time:  172076
Step 351500, loss: 0.0056242310789957626, acc: 99.81426951289177, p_norm: 2187.9106102235883, g_norm: 0.15013486015714653, lr:  0.000422, elapsed time:  172124
Step 351600, loss: 0.005845929798360885, acc: 99.807792365551, p_norm: 2188.000745448264, g_norm: 0.25290890081269923, lr:  0.000421, elapsed time:  172172
Step 351700, loss: 0.005832825233301264, acc: 99.81142143905163, p_norm: 2188.1044142530704, g_norm: 0.12640834471212167, lr:  0.000421, elapsed time:  172220
Step 351800, loss: 0.005840919092011063, acc: 99.80950506031513, p_norm: 2188.185728025761, g_norm: 0.24547002736342652, lr:  0.000421, elapsed time:  172268
Step 351900, loss: 0.006005212414584094, acc: 99.80984035134315, p_norm: 2188.289731236075, g_norm: 0.1730715419348141, lr:  0.000421, elapsed time:  172316
Step 352000, loss: 0.00605662056545043, acc: 99.80212932825089, p_norm: 2188.394912933975, g_norm: 0.1868446233339697, lr:  0.000421, elapsed time:  172363
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 352000, eval loss: 0.020435041494275767, eval acc: 99.62659454345703
Step 352100, loss: 0.006679367355168324, acc: 99.78311198949814, p_norm: 2188.4861030495763, g_norm: 0.17436857189156088, lr:  0.000421, elapsed time:  172417
Step 352200, loss: 0.006397531341453941, acc: 99.79264888167381, p_norm: 2188.586140087609, g_norm: 0.22099636405413084, lr:  0.000421, elapsed time:  172465
Step 352300, loss: 0.006015358633339929, acc: 99.80869998037815, p_norm: 2188.6763231176024, g_norm: 0.17830247674275843, lr:  0.000421, elapsed time:  172513
Step 352400, loss: 0.0061508981213637525, acc: 99.79821167886257, p_norm: 2188.7822258737824, g_norm: 0.133926027267893, lr:  0.000421, elapsed time:  172560
Step 352500, loss: 0.006323533599488656, acc: 99.79827447235584, p_norm: 2188.875284909223, g_norm: 0.16300320860195502, lr:  0.000421, elapsed time:  172608
Step 352600, loss: 0.006319259564052117, acc: 99.80044636130333, p_norm: 2188.983031589914, g_norm: 0.21323248381928545, lr:  0.000421, elapsed time:  172656
Step 352700, loss: 0.006330071471347764, acc: 99.79391466081142, p_norm: 2189.084640774957, g_norm: 0.1398403302722819, lr:  0.000421, elapsed time:  172703
Step 352800, loss: 0.006384045097711351, acc: 99.79363901913166, p_norm: 2189.188175616378, g_norm: 0.2095672614571956, lr:  0.000421, elapsed time:  172751
Step 352900, loss: 0.0063827986670003155, acc: 99.7957080155611, p_norm: 2189.295001467081, g_norm: 0.20449079361579225, lr:  0.000421, elapsed time:  172798
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 353000, loss: 0.006184332857325596, acc: 99.79701862109835, p_norm: 2189.388811831574, g_norm: 0.17524417514882734, lr:  0.000421, elapsed time:  172847
Step 353100, loss: 0.006009584411767719, acc: 99.80498623847961, p_norm: 2189.4815463041455, g_norm: 0.15012210541169851, lr:  0.000421, elapsed time:  172894
Step 353200, loss: 0.0057683721239300215, acc: 99.81511022150517, p_norm: 2189.570606023306, g_norm: 0.18970639011796073, lr:  0.000421, elapsed time:  172942
Step 353300, loss: 0.005846231237628671, acc: 99.80710139870644, p_norm: 2189.662418688076, g_norm: 0.14208442183963357, lr:  0.000420, elapsed time:  172990
Step 353400, loss: 0.006212825545298983, acc: 99.80021677911282, p_norm: 2189.751825426775, g_norm: 0.17154366614068664, lr:  0.000420, elapsed time:  173037
Step 353500, loss: 0.005830555089305562, acc: 99.8119674474001, p_norm: 2189.8364208494067, g_norm: 0.1674329362435891, lr:  0.000420, elapsed time:  173085
Step 353600, loss: 0.005822445787980541, acc: 99.81309317052364, p_norm: 2189.9430043408615, g_norm: 0.08860904720927665, lr:  0.000420, elapsed time:  173132
Step 353700, loss: 0.0061297197975545715, acc: 99.79649230837822, p_norm: 2190.0461109749854, g_norm: 0.13238234387465994, lr:  0.000420, elapsed time:  173181
Step 353800, loss: 0.0059985150691863965, acc: 99.80378124117851, p_norm: 2190.143502248925, g_norm: 0.178070863719885, lr:  0.000420, elapsed time:  173228
Step 353900, loss: 0.006081536377478187, acc: 99.80186629295349, p_norm: 2190.2386886529193, g_norm: 0.22189579817586022, lr:  0.000420, elapsed time:  173276
Step 354000, loss: 0.006317608311310324, acc: 99.79310877621174, p_norm: 2190.333571698051, g_norm: 0.19561764302405416, lr:  0.000420, elapsed time:  173324
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 354000, eval loss: 0.01868015815805847, eval acc: 99.64958953857422
Step 354100, loss: 0.006179748915023993, acc: 99.7999828606844, p_norm: 2190.4412308856286, g_norm: 0.18082495964725148, lr:  0.000420, elapsed time:  173378
Step 354200, loss: 0.005793212202970608, acc: 99.81374782323837, p_norm: 2190.53584785646, g_norm: 0.19377571191748774, lr:  0.000420, elapsed time:  173426
Step 354300, loss: 0.005907547531378441, acc: 99.80749157071114, p_norm: 2190.6250778603935, g_norm: 0.17361489070899072, lr:  0.000420, elapsed time:  173474
Step 354400, loss: 0.0060660779965292025, acc: 99.79959097504616, p_norm: 2190.7276863415696, g_norm: 0.19786828366797962, lr:  0.000420, elapsed time:  173521
Step 354500, loss: 0.006284159021724918, acc: 99.79304677248001, p_norm: 2190.8369082104978, g_norm: 0.2296128310887711, lr:  0.000420, elapsed time:  173569
Step 354600, loss: 0.006333536015390564, acc: 99.79474653303623, p_norm: 2190.9336180662253, g_norm: 0.17546022516619744, lr:  0.000420, elapsed time:  173617
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 354700, loss: 0.006361764136834486, acc: 99.79482205866584, p_norm: 2191.0264631750124, g_norm: 0.16295921535115188, lr:  0.000420, elapsed time:  173665
Step 354800, loss: 0.006005481808178956, acc: 99.80343455076218, p_norm: 2191.106900047971, g_norm: 0.14944180800874407, lr:  0.000420, elapsed time:  173713
Step 354900, loss: 0.005960598355104593, acc: 99.80691957473755, p_norm: 2191.1997318124886, g_norm: 0.2083208063220663, lr:  0.000420, elapsed time:  173761
Step 355000, loss: 0.006078584704928289, acc: 99.80750983953476, p_norm: 2191.294001431796, g_norm: 0.18873250984640663, lr:  0.000419, elapsed time:  173808
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O C ( = O ) C O C 1 C c 2 c c c c c 2 C 1 2 C C N ( C C C 1 ( c 3 c c c ( F ) c ( Br ) c 3 ) C N ( C ( = O ) c 3 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 3 ) C O 1 ) C C 2 _EOS
Predicted text: C C O C ( = O ) C O C 1 C c 2 c c c c c 2 C 1 2 C C N ( C C C 1 ( c 3 c c c ( F ) c ( Br ) c 3 ) C N ( C ( = O ) c 3 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 3 ) C O 1 ) C C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 s c ( - c 2 c c c ( C ( = O ) O ) c c 2 C ) n c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1 C N 1 C ( = O ) O C ( c 2 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 2 ) C 1 C _EOS
Predicted text: C C c 1 s c ( - c 2 c c c ( C ( = O ) O ) c c 2 C ) n c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1 C N 1 C ( = O ) O C ( c 2 c c ( C ( F ) ( F ) F ) c c ( C ( F ) ( F ) F ) c 2 ) C 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) c 1 c c ( C ( = O ) N 2 C c 3 c c c ( C N 4 C C N ( C ) C C 4 ) c c 3 C 2 ) c ( O C c 2 c c c c c 2 ) c c 1 O C c 1 c c c c c 1 _EOS
Predicted text: C C ( C ) c 1 c c ( C ( = O ) N 2 C c 3 c c c ( C N 4 C C N ( C ) C C 4 ) c c 3 C 2 ) c ( O C c 2 c c c c c 2 ) c c 1 O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) C 1 C C C C ( N 2 C ( = O ) C ( = C c 3 c c c ( - c 4 c c c ( C 5 C C C C C 5 ) c c 4 ) o 3 ) S C 2 = S ) C 1 _EOS
Predicted text: O = C ( O ) C 1 C C C C ( N 2 C ( = O ) C ( = C c 3 c c c ( - c 4 c c c ( C 5 C C C C C 5 ) c c 4 ) o 3 ) S C 2 = S ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) c 1 c c c c ( Cl ) c 1 _EOS
Predicted text: C C ( O C ( = O ) O N 1 C ( = O ) C C C 1 = O ) O C ( = O ) C ( C ) C _EOS
acc_token: 0.0, acc_seq: False

Evaluation (without teacher) at step 355000, eval acc (token): 0.9442034726994665, eval acc (sequence): 0.8968720379146919
Saving at step 355000
Step 355100, loss: 0.006355804974191415, acc: 99.79516758024693, p_norm: 2191.402230126659, g_norm: 0.12660450852040125, lr:  0.000419, elapsed time:  173909
Step 355200, loss: 0.0062099163755056, acc: 99.79798936843872, p_norm: 2191.492735022268, g_norm: 0.1576069476112907, lr:  0.000419, elapsed time:  173956
Step 355300, loss: 0.006367842053066397, acc: 99.79068537056446, p_norm: 2191.601141044825, g_norm: 0.16084957638458955, lr:  0.000419, elapsed time:  174004
Step 355400, loss: 0.006221311451672591, acc: 99.79964627325535, p_norm: 2191.7037276715596, g_norm: 0.14702339428909314, lr:  0.000419, elapsed time:  174052
Step 355500, loss: 0.005859533206548803, acc: 99.81126590073109, p_norm: 2191.807159176219, g_norm: 0.15240920611900924, lr:  0.000419, elapsed time:  174100
Step 355600, loss: 0.006081475137489178, acc: 99.80267131328583, p_norm: 2191.902346313471, g_norm: 0.10743725447028955, lr:  0.000419, elapsed time:  174147
Step 355700, loss: 0.006355862782284021, acc: 99.79816438257694, p_norm: 2191.992072382737, g_norm: 0.1885012393538583, lr:  0.000419, elapsed time:  174194
Step 355800, loss: 0.0058544678374528305, acc: 99.8105530589819, p_norm: 2192.0852355666516, g_norm: 0.17704795289266137, lr:  0.000419, elapsed time:  174241
Step 355900, loss: 0.006129080860741851, acc: 99.79965829849243, p_norm: 2192.184481922804, g_norm: 0.17895319802365262, lr:  0.000419, elapsed time:  174289
Step 356000, loss: 0.005815665858053762, acc: 99.8117223829031, p_norm: 2192.2846419555412, g_norm: 0.16144339781344313, lr:  0.000419, elapsed time:  174337
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 356000, eval loss: 0.02112106078744546, eval acc: 99.59793090820312
Step 356100, loss: 0.0058867888264057915, acc: 99.81110644340515, p_norm: 2192.389053562688, g_norm: 0.1562732530290451, lr:  0.000419, elapsed time:  174393
Step 356200, loss: 0.006270564507476592, acc: 99.79982000589371, p_norm: 2192.476091207845, g_norm: 0.2018348084091677, lr:  0.000419, elapsed time:  174440
Step 356300, loss: 0.006212540172655281, acc: 99.79591615498066, p_norm: 2192.570532315025, g_norm: 0.17873159455813997, lr:  0.000419, elapsed time:  174488
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 356400, loss: 0.00562050436212673, acc: 99.81726384340385, p_norm: 2192.6551616111165, g_norm: 0.18145871999654248, lr:  0.000419, elapsed time:  174536
Step 356500, loss: 0.005937781074026134, acc: 99.8030813485384, p_norm: 2192.7492206890865, g_norm: 0.22292203970534213, lr:  0.000419, elapsed time:  174583
Step 356600, loss: 0.005969053779626848, acc: 99.80634941160679, p_norm: 2192.8467499744274, g_norm: 0.20501778277898722, lr:  0.000419, elapsed time:  174631
Step 356700, loss: 0.005947201612625577, acc: 99.8054760247469, p_norm: 2192.949982912721, g_norm: 0.15500929935618482, lr:  0.000418, elapsed time:  174678
Step 356800, loss: 0.006026061169241075, acc: 99.80484572052956, p_norm: 2193.0534619914847, g_norm: 0.16652578983768163, lr:  0.000418, elapsed time:  174726
Step 356900, loss: 0.005997657263324072, acc: 99.80503870546818, p_norm: 2193.1477572019157, g_norm: 0.1577345762561441, lr:  0.000418, elapsed time:  174774
Step 357000, loss: 0.005579064470693993, acc: 99.81843738257885, p_norm: 2193.241678371555, g_norm: 0.10361873892549368, lr:  0.000418, elapsed time:  174822
Step 357100, loss: 0.00638046322759692, acc: 99.79725514352322, p_norm: 2193.3420613478465, g_norm: 0.14972030264497344, lr:  0.000418, elapsed time:  174869
Step 357200, loss: 0.00589646699237619, acc: 99.81095597147942, p_norm: 2193.432919260842, g_norm: 0.15915308715333057, lr:  0.000418, elapsed time:  174916
Step 357300, loss: 0.00581264302029922, acc: 99.80796828866005, p_norm: 2193.5210626770263, g_norm: 0.18501384971862314, lr:  0.000418, elapsed time:  174963
Step 357400, loss: 0.00586206285111075, acc: 99.81293581426144, p_norm: 2193.6168937232055, g_norm: 0.18774282293809663, lr:  0.000418, elapsed time:  175012
Step 357500, loss: 0.006182436675953795, acc: 99.7986414283514, p_norm: 2193.726199217945, g_norm: 0.2133695883897975, lr:  0.000418, elapsed time:  175059
Step 357600, loss: 0.0060436815755520006, acc: 99.80484728515148, p_norm: 2193.819581081615, g_norm: 0.24826223096667183, lr:  0.000418, elapsed time:  175107
Step 357700, loss: 0.006288295265585475, acc: 99.79235401749611, p_norm: 2193.9326211479297, g_norm: 0.18394931266714284, lr:  0.000418, elapsed time:  175154
Step 357800, loss: 0.006054529615657884, acc: 99.80469781160355, p_norm: 2194.032137187183, g_norm: 0.2862966904320302, lr:  0.000418, elapsed time:  175202
Step 357900, loss: 0.006263588593501481, acc: 99.79884378612041, p_norm: 2194.1295588423764, g_norm: 0.1735856320558206, lr:  0.000418, elapsed time:  175249
Step 358000, loss: 0.006073869281080988, acc: 99.8027771115303, p_norm: 2194.2223492772273, g_norm: 0.17228767608470563, lr:  0.000418, elapsed time:  175297
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 358000, eval loss: 0.01981610105946856, eval acc: 99.62434387207031
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 358100, loss: 0.005813378257949293, acc: 99.8143208529754, p_norm: 2194.327846958993, g_norm: 0.1295067262243318, lr:  0.000418, elapsed time:  175353
Step 358200, loss: 0.005966632504405425, acc: 99.80503895878792, p_norm: 2194.431049792384, g_norm: 0.13538241463897208, lr:  0.000418, elapsed time:  175400
Step 358300, loss: 0.005875434265708464, acc: 99.81645934283733, p_norm: 2194.5189962927057, g_norm: 0.16702736760862438, lr:  0.000418, elapsed time:  175448
Step 358400, loss: 0.0059435413369283195, acc: 99.81116050481796, p_norm: 2194.6156941247086, g_norm: 0.17496986272221451, lr:  0.000417, elapsed time:  175496
Step 358500, loss: 0.0061054585355850574, acc: 99.80194517970085, p_norm: 2194.7221625411253, g_norm: 0.24752542889968768, lr:  0.000417, elapsed time:  175543
Step 358600, loss: 0.006067662425602975, acc: 99.80285988748074, p_norm: 2194.8121123862616, g_norm: 0.14086378499911614, lr:  0.000417, elapsed time:  175590
Step 358700, loss: 0.006237733276448125, acc: 99.7984172552824, p_norm: 2194.916679360051, g_norm: 0.14930433047626457, lr:  0.000417, elapsed time:  175637
Step 358800, loss: 0.006004671490645705, acc: 99.80206720530987, p_norm: 2195.0033548653823, g_norm: 0.13875169520220587, lr:  0.000417, elapsed time:  175684
Step 358900, loss: 0.006022338586390106, acc: 99.80705337226391, p_norm: 2195.1181898149935, g_norm: 0.15256657161267825, lr:  0.000417, elapsed time:  175732
Step 359000, loss: 0.006033886896857439, acc: 99.80734115839005, p_norm: 2195.214482331328, g_norm: 0.13028397256283625, lr:  0.000417, elapsed time:  175780
Step 359100, loss: 0.00594088399834618, acc: 99.80370944738388, p_norm: 2195.311210864977, g_norm: 0.2016619657566097, lr:  0.000417, elapsed time:  175827
Step 359200, loss: 0.005613672407130252, acc: 99.81670488417149, p_norm: 2195.400004762582, g_norm: 0.23426527000577763, lr:  0.000417, elapsed time:  175875
Step 359300, loss: 0.006051876785222703, acc: 99.80268724262714, p_norm: 2195.498276573532, g_norm: 0.2407446815420559, lr:  0.000417, elapsed time:  175923
Step 359400, loss: 0.005963318135695772, acc: 99.80721844732761, p_norm: 2195.591502365414, g_norm: 0.17424956878469658, lr:  0.000417, elapsed time:  175971
Step 359500, loss: 0.006124042305264084, acc: 99.79908645153046, p_norm: 2195.6905393753973, g_norm: 0.11168506470416674, lr:  0.000417, elapsed time:  176018
Step 359600, loss: 0.005799482816428281, acc: 99.81425181031227, p_norm: 2195.7799278944403, g_norm: 0.18143733737410156, lr:  0.000417, elapsed time:  176066
Step 359700, loss: 0.005994843607709299, acc: 99.80883574485779, p_norm: 2195.8769360217834, g_norm: 0.14776135641965918, lr:  0.000417, elapsed time:  176113
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 359800, loss: 0.0058291283942078454, acc: 99.8111362936479, p_norm: 2195.988542826599, g_norm: 0.1798379201713731, lr:  0.000417, elapsed time:  176162
Step 359900, loss: 0.005588125670792579, acc: 99.81670959293842, p_norm: 2196.0756912525485, g_norm: 0.16925696689556652, lr:  0.000417, elapsed time:  176209
Step 360000, loss: 0.006067520865562983, acc: 99.80052937567234, p_norm: 2196.1933340352302, g_norm: 0.21061139231051176, lr:  0.000417, elapsed time:  176257
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 360000, eval loss: 0.022016486928478116, eval acc: 99.58203125
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C S ( = O ) ( = O ) c 1 c c c 2 o c ( N 3 C C N ( C ( = O ) c 4 c c ( S ( C ) ( = O ) = O ) c c c 4 O C C ( C ) C ) C C 3 ) n c 2 c 1 _EOS
Predicted text: C C S ( = O ) ( = O ) c 1 c c c 2 o c ( N 3 C C N ( C ( = O ) c 4 c c ( S ( C ) ( = O ) = O ) c c c 4 O C C ( C ) C ) C C 3 ) n c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C ( = O ) c 1 c c 2 c 3 c c c c c 3 n ( C C ( N ) C O ) c 2 n c 1 N _EOS
Predicted text: N C ( = O ) c 1 c c 2 c 3 c c c c c 3 n ( C C ( N ) C O ) c 2 n c 1 N _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( F ) c ( O C C ( C 2 C C C C C 2 ) n 2 c ( - c 3 c c c ( Cl ) c c 3 ) n c 3 c c ( F ) c ( F ) c c 3 2 ) c ( F ) c 1 _EOS
Predicted text: C O C ( = O ) c 1 c c ( F ) c ( O C C ( C 2 C C C C C 2 ) n 2 c ( - c 3 c c c ( Cl ) c c 3 ) n c 3 c c ( F ) c ( F ) c c 3 2 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C ) c ( O S ( C ) ( = O ) = O ) c c 1 N _EOS
Predicted text: C O c 1 c c ( C ) c ( O S ( C ) ( = O ) = O ) c c 1 N _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C ( = O ) O C c 1 n c c c ( Cl ) n 1 _EOS
Predicted text: C N C ( = O ) O C c 1 n c c c ( Cl ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 360000, eval acc (token): 0.9412240055923947, eval acc (sequence): 0.8911087113030958
Saving at step 360000
Step 360100, loss: 0.005803728539922304, acc: 99.80967225134373, p_norm: 2196.2805803575584, g_norm: 0.11677397120974901, lr:  0.000416, elapsed time:  176364
Step 360200, loss: 0.006025343656647237, acc: 99.81090705096722, p_norm: 2196.3755833996443, g_norm: 0.17652474321780975, lr:  0.000416, elapsed time:  176412
Step 360300, loss: 0.005864434903746769, acc: 99.80891318619251, p_norm: 2196.468789910202, g_norm: 0.3034589575680889, lr:  0.000416, elapsed time:  176460
Step 360400, loss: 0.005955623071458831, acc: 99.80523712933064, p_norm: 2196.5480022544475, g_norm: 0.09293743139846543, lr:  0.000416, elapsed time:  176507
Step 360500, loss: 0.006105267674365677, acc: 99.80747577548027, p_norm: 2196.646611638896, g_norm: 0.19653701355908676, lr:  0.000416, elapsed time:  176554
Step 360600, loss: 0.005720406569075749, acc: 99.81572392582893, p_norm: 2196.7370399240704, g_norm: 0.19409424321735624, lr:  0.000416, elapsed time:  176601
Step 360700, loss: 0.0057142863054286865, acc: 99.81949724256992, p_norm: 2196.826912960177, g_norm: 0.19633975056616804, lr:  0.000416, elapsed time:  176649
Step 360800, loss: 0.005961200025558356, acc: 99.80792982876301, p_norm: 2196.9134189107945, g_norm: 0.19618811004699022, lr:  0.000416, elapsed time:  176697
Step 360900, loss: 0.0062661095848125115, acc: 99.80024854838848, p_norm: 2197.0121708946954, g_norm: 0.24615287199484176, lr:  0.000416, elapsed time:  176744
Step 361000, loss: 0.005819313490383138, acc: 99.81401075422764, p_norm: 2197.1078090903343, g_norm: 0.1844734563740458, lr:  0.000416, elapsed time:  176792
Step 361100, loss: 0.006209450169599222, acc: 99.80083744227886, p_norm: 2197.2114964274183, g_norm: 0.18083949012100364, lr:  0.000416, elapsed time:  176839
Step 361200, loss: 0.005981346383168784, acc: 99.8064478635788, p_norm: 2197.3089890796105, g_norm: 0.19180212216008102, lr:  0.000416, elapsed time:  176887
Step 361300, loss: 0.006089791448739561, acc: 99.79840007424355, p_norm: 2197.3981066891174, g_norm: 0.20611802571326232, lr:  0.000416, elapsed time:  176935
Step 361400, loss: 0.006249175282491705, acc: 99.7965931892395, p_norm: 2197.507801601798, g_norm: 0.20711122822040032, lr:  0.000416, elapsed time:  176982
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 361500, loss: 0.006147501387657721, acc: 99.79648735032188, p_norm: 2197.6017196567996, g_norm: 0.2517226296952396, lr:  0.000416, elapsed time:  177030
Step 361600, loss: 0.0055913086433065475, acc: 99.8164618909359, p_norm: 2197.685411880874, g_norm: 0.09192698185816303, lr:  0.000416, elapsed time:  177078
Step 361700, loss: 0.0056463905427744975, acc: 99.81797125935555, p_norm: 2197.7786887463844, g_norm: 0.16179040782256565, lr:  0.000416, elapsed time:  177126
Step 361800, loss: 0.005742808169097771, acc: 99.81594340503216, p_norm: 2197.8859378711604, g_norm: 0.14916148779072577, lr:  0.000416, elapsed time:  177174
Step 361900, loss: 0.005801393756109973, acc: 99.80826152861118, p_norm: 2197.983082553317, g_norm: 0.17963347958480533, lr:  0.000415, elapsed time:  177221
Step 362000, loss: 0.006153440328516808, acc: 99.79740230739117, p_norm: 2198.087348347316, g_norm: 0.21114012460027923, lr:  0.000415, elapsed time:  177269
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 362000, eval loss: 0.01733345234141324, eval acc: 99.6725845336914
Step 362100, loss: 0.006168420599897218, acc: 99.79927285015583, p_norm: 2198.1697380985893, g_norm: 0.1572602430691404, lr:  0.000415, elapsed time:  177323
Step 362200, loss: 0.005698970579742308, acc: 99.80941016972065, p_norm: 2198.262028478763, g_norm: 0.1565229647130557, lr:  0.000415, elapsed time:  177371
Step 362300, loss: 0.0059599144306776, acc: 99.80435417592525, p_norm: 2198.3604545402663, g_norm: 0.12753235986149414, lr:  0.000415, elapsed time:  177419
Step 362400, loss: 0.0057541344403944095, acc: 99.80638568103313, p_norm: 2198.458521269925, g_norm: 0.2819164036011045, lr:  0.000415, elapsed time:  177467
Step 362500, loss: 0.006157233606718365, acc: 99.799963504076, p_norm: 2198.5650426710295, g_norm: 0.20330340023922447, lr:  0.000415, elapsed time:  177514
Step 362600, loss: 0.005869962353244773, acc: 99.80397126078606, p_norm: 2198.6637290055937, g_norm: 0.21118814271804662, lr:  0.000415, elapsed time:  177562
Step 362700, loss: 0.006339654955281731, acc: 99.7948796004057, p_norm: 2198.7532450570984, g_norm: 0.13511948249535247, lr:  0.000415, elapsed time:  177609
Step 362800, loss: 0.005953764878649963, acc: 99.80637477338314, p_norm: 2198.8512571330602, g_norm: 0.15126918568818087, lr:  0.000415, elapsed time:  177656
Step 362900, loss: 0.006340240662393626, acc: 99.79670548439026, p_norm: 2198.946042231957, g_norm: 0.17743638763756217, lr:  0.000415, elapsed time:  177703
Step 363000, loss: 0.005963109249260015, acc: 99.80346444249153, p_norm: 2199.043566264661, g_norm: 0.20501190966312788, lr:  0.000415, elapsed time:  177751
Step 363100, loss: 0.006016159488508492, acc: 99.80562523007393, p_norm: 2199.138232907482, g_norm: 0.20807428130456912, lr:  0.000415, elapsed time:  177798
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 363200, loss: 0.006053235252444545, acc: 99.80012319277768, p_norm: 2199.2310885072416, g_norm: 0.16946633153254528, lr:  0.000415, elapsed time:  177846
Step 363300, loss: 0.0057774960373353675, acc: 99.80972108244896, p_norm: 2199.3236342740797, g_norm: 0.21631592151234671, lr:  0.000415, elapsed time:  177894
Step 363400, loss: 0.005706623306923575, acc: 99.81585775315762, p_norm: 2199.4041665457353, g_norm: 0.24029912475811455, lr:  0.000415, elapsed time:  177941
Step 363500, loss: 0.006014574649470888, acc: 99.80358225107193, p_norm: 2199.4991211932693, g_norm: 0.1274721340724059, lr:  0.000415, elapsed time:  177989
Step 363600, loss: 0.006201995198744044, acc: 99.80117711424828, p_norm: 2199.604924336083, g_norm: 0.16229919939312953, lr:  0.000414, elapsed time:  178036
Step 363700, loss: 0.005794823812466348, acc: 99.81353241205215, p_norm: 2199.689046454097, g_norm: 0.19571076150989974, lr:  0.000414, elapsed time:  178083
Step 363800, loss: 0.005187928985151302, acc: 99.83248434960842, p_norm: 2199.7829933316293, g_norm: 0.33517795060561434, lr:  0.000414, elapsed time:  178131
Step 363900, loss: 0.0054031090913622395, acc: 99.81897556781769, p_norm: 2199.874080022634, g_norm: 0.19218130157537025, lr:  0.000414, elapsed time:  178180
Step 364000, loss: 0.006088240264598426, acc: 99.8017779737711, p_norm: 2199.9699954938433, g_norm: 0.1707178698952151, lr:  0.000414, elapsed time:  178227
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 364000, eval loss: 0.019282142159599978, eval acc: 99.6451416015625
Step 364100, loss: 0.006218798039299145, acc: 99.79898856580257, p_norm: 2200.068346630327, g_norm: 0.26054364616399867, lr:  0.000414, elapsed time:  178281
Step 364200, loss: 0.005940559599648623, acc: 99.81020024418831, p_norm: 2200.155211950244, g_norm: 0.14006302673092758, lr:  0.000414, elapsed time:  178328
Step 364300, loss: 0.00620646394857431, acc: 99.79935844242573, p_norm: 2200.2436373480814, g_norm: 0.1742460618471708, lr:  0.000414, elapsed time:  178375
Step 364400, loss: 0.005607209362351568, acc: 99.81313991546631, p_norm: 2200.338529811443, g_norm: 0.2560805749863252, lr:  0.000414, elapsed time:  178423
Step 364500, loss: 0.0058900066048954616, acc: 99.8097268640995, p_norm: 2200.4400268890063, g_norm: 0.2027646712154747, lr:  0.000414, elapsed time:  178470
Step 364600, loss: 0.005678487451023102, acc: 99.81723383069038, p_norm: 2200.5386724514706, g_norm: 0.18040294495432713, lr:  0.000414, elapsed time:  178518
Step 364700, loss: 0.006445672645545528, acc: 99.79300794005394, p_norm: 2200.6372815535624, g_norm: 0.19411782859478255, lr:  0.000414, elapsed time:  178566
Step 364800, loss: 0.005824004688311107, acc: 99.80827023088932, p_norm: 2200.7373734528355, g_norm: 0.17078001398611986, lr:  0.000414, elapsed time:  178614
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 364900, loss: 0.005824398621710438, acc: 99.80823304226149, p_norm: 2200.829088579281, g_norm: 0.21864164886423726, lr:  0.000414, elapsed time:  178662
Step 365000, loss: 0.00586459182289218, acc: 99.80895990133286, p_norm: 2200.927208974984, g_norm: 0.16935296800129354, lr:  0.000414, elapsed time:  178709
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( N C C c 1 c [nH] c 2 c c c ( Cl ) c c 1 2 ) c 1 n o c ( C c 2 c c c c c 2 ) n 1 _EOS
Predicted text: O = C ( N C C c 1 c [nH] c 2 c c c ( Cl ) c c 1 2 ) c 1 n o c ( C c 2 c c c c c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( c 1 c c c c ( C ( F ) ( F ) F ) c 1 Cl ) N 1 C C n 2 c ( n c ( Cl ) c 2 Cl ) C 1 _EOS
Predicted text: O = C ( c 1 c c c c ( C ( F ) ( F ) F ) c 1 Cl ) N 1 C C n 2 c ( n c ( Cl ) c 2 Cl ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 O C C N 1 C C 1 C C C ( N c 2 n c 3 c ( s 2 ) C C C c 2 c c c ( F ) c c 2 - 3 ) C C 1 _EOS
Predicted text: O = C 1 O C C N 1 C C 1 C C C ( N c 2 n c 3 c ( s 2 ) C C C c 2 c c c ( F ) c c 2 - 3 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c c c ( C c 2 c c n c ( N ) c 2 ) c ( F ) c 1 _EOS
Predicted text: N c 1 c c c ( C c 2 c c n c ( N ) c 2 ) c ( F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C C ( C ( = O ) N 4 C C C C 4 ) C 3 ) n ( C ) c 2 n 1 _EOS
Predicted text: C C c 1 n c 2 c c c c c 2 n 1 - c 1 n c ( N 2 C C O C C 2 ) c 2 n c ( C N 3 C C C ( C ( = O ) N 4 C C C C 4 ) C 3 ) n ( C ) c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 365000, eval acc (token): 0.9452943347350269, eval acc (sequence): 0.8982514880952381
Saving at step 365000
Step 365100, loss: 0.005792926591520881, acc: 99.81029416620731, p_norm: 2201.0135171419574, g_norm: 0.14447245742974804, lr:  0.000414, elapsed time:  178812
Step 365200, loss: 0.005804027510112064, acc: 99.81592983007431, p_norm: 2201.1277474543035, g_norm: 0.25069878679917124, lr:  0.000414, elapsed time:  178860
Step 365300, loss: 0.006135955938189, acc: 99.80393587052822, p_norm: 2201.2217576192265, g_norm: 0.18186898898940174, lr:  0.000414, elapsed time:  178908
Step 365400, loss: 0.0058590569636817235, acc: 99.80603896081448, p_norm: 2201.31630927183, g_norm: 0.20351309799065717, lr:  0.000413, elapsed time:  178956
Step 365500, loss: 0.005896683875289454, acc: 99.81010647118092, p_norm: 2201.4179345838625, g_norm: 0.21846936828925034, lr:  0.000413, elapsed time:  179003
Step 365600, loss: 0.005795049028856738, acc: 99.81469257175922, p_norm: 2201.5041440767927, g_norm: 0.1549188133625131, lr:  0.000413, elapsed time:  179050
Step 365700, loss: 0.005659104223068426, acc: 99.810740634799, p_norm: 2201.6084962545406, g_norm: 0.19475679207466395, lr:  0.000413, elapsed time:  179098
Step 365800, loss: 0.005696736699992471, acc: 99.81581488251686, p_norm: 2201.6976763640155, g_norm: 0.20187212154575676, lr:  0.000413, elapsed time:  179146
Step 365900, loss: 0.0058868895769956, acc: 99.80955058336258, p_norm: 2201.7874999484193, g_norm: 0.19850342435788382, lr:  0.000413, elapsed time:  179193
Step 366000, loss: 0.005649947801957751, acc: 99.81541270017624, p_norm: 2201.880448242515, g_norm: 0.4437925003560804, lr:  0.000413, elapsed time:  179241
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 366000, eval loss: 0.018208940174326928, eval acc: 99.6660385131836
Step 366100, loss: 0.0062224723130839266, acc: 99.7945366948843, p_norm: 2201.9787384245296, g_norm: 0.2336947573095107, lr:  0.000413, elapsed time:  179296
Step 366200, loss: 0.00620320158346658, acc: 99.79738910496235, p_norm: 2202.0704110403167, g_norm: 0.21152189072724023, lr:  0.000413, elapsed time:  179343
Step 366300, loss: 0.006427620579906943, acc: 99.793163433671, p_norm: 2202.1672074720154, g_norm: 0.24674745337342435, lr:  0.000413, elapsed time:  179390
Step 366400, loss: 0.0058908437665331805, acc: 99.80866239964962, p_norm: 2202.263307363776, g_norm: 0.1359442075135664, lr:  0.000413, elapsed time:  179438
Step 366500, loss: 0.005925063604317984, acc: 99.80609408020973, p_norm: 2202.3638828785397, g_norm: 0.22817415321564427, lr:  0.000413, elapsed time:  179485
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 366600, loss: 0.005884491876880586, acc: 99.80363070816911, p_norm: 2202.458473238813, g_norm: 0.2430892145303681, lr:  0.000413, elapsed time:  179533
Step 366700, loss: 0.005764386354630915, acc: 99.81409272551537, p_norm: 2202.554553042438, g_norm: 0.20043576617323086, lr:  0.000413, elapsed time:  179581
Step 366800, loss: 0.005687995247226354, acc: 99.81109899282455, p_norm: 2202.6386501359043, g_norm: 0.19580258488153784, lr:  0.000413, elapsed time:  179628
Step 366900, loss: 0.005693148800032759, acc: 99.81231415271759, p_norm: 2202.717762608018, g_norm: 0.17342377251985933, lr:  0.000413, elapsed time:  179675
Step 367000, loss: 0.005859504377212943, acc: 99.80653305351734, p_norm: 2202.806227903282, g_norm: 0.24344041590171844, lr:  0.000413, elapsed time:  179723
Step 367100, loss: 0.005567196618767411, acc: 99.81597462296486, p_norm: 2202.8918548182896, g_norm: 0.23910023552558202, lr:  0.000412, elapsed time:  179771
Step 367200, loss: 0.005692610762107506, acc: 99.81534351408482, p_norm: 2202.982571653427, g_norm: 0.15353752061120687, lr:  0.000412, elapsed time:  179819
Step 367300, loss: 0.00589827914785019, acc: 99.8017239421606, p_norm: 2203.077741441807, g_norm: 0.198532544634521, lr:  0.000412, elapsed time:  179866
Step 367400, loss: 0.005736845927767718, acc: 99.81707888841629, p_norm: 2203.1815313328543, g_norm: 0.16088991817197193, lr:  0.000412, elapsed time:  179914
Step 367500, loss: 0.00606022662101168, acc: 99.80524332821369, p_norm: 2203.2681361219256, g_norm: 0.17287717054932375, lr:  0.000412, elapsed time:  179961
Step 367600, loss: 0.005961421520646581, acc: 99.80393821001053, p_norm: 2203.3772588985944, g_norm: 0.21729612870316514, lr:  0.000412, elapsed time:  180008
Step 367700, loss: 0.006158479749551589, acc: 99.80352488160133, p_norm: 2203.467440856365, g_norm: 0.441686161357217, lr:  0.000412, elapsed time:  180056
Step 367800, loss: 0.006272733129490007, acc: 99.7981221228838, p_norm: 2203.563725839539, g_norm: 0.14805540683009022, lr:  0.000412, elapsed time:  180102
Step 367900, loss: 0.005722934121604339, acc: 99.81497555971146, p_norm: 2203.6478825631907, g_norm: 0.13528013067655778, lr:  0.000412, elapsed time:  180150
Step 368000, loss: 0.0059138284485561595, acc: 99.81068082153797, p_norm: 2203.7418402993226, g_norm: 0.18600801818822674, lr:  0.000412, elapsed time:  180198
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 368000, eval loss: 0.018515041062619267, eval acc: 99.65312957763672
Step 368100, loss: 0.005991327722540518, acc: 99.80211645364761, p_norm: 2203.831462916346, g_norm: 0.2243707660797775, lr:  0.000412, elapsed time:  180253
Step 368200, loss: 0.005986856989065928, acc: 99.81102706491947, p_norm: 2203.928192094717, g_norm: 0.24589488933450457, lr:  0.000412, elapsed time:  180301
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 368300, loss: 0.006270212671834246, acc: 99.79792019865353, p_norm: 2204.0281353423607, g_norm: 0.1964721170881478, lr:  0.000412, elapsed time:  180348
Step 368400, loss: 0.005406523565552561, acc: 99.82182393968105, p_norm: 2204.1182548376364, g_norm: 0.19578251651570588, lr:  0.000412, elapsed time:  180396
Step 368500, loss: 0.005723970171520705, acc: 99.80948880314827, p_norm: 2204.2117495600087, g_norm: 0.24067037724834123, lr:  0.000412, elapsed time:  180443
Step 368600, loss: 0.005684366321484049, acc: 99.81105977296829, p_norm: 2204.3021804843374, g_norm: 0.40106193857277694, lr:  0.000412, elapsed time:  180491
Step 368700, loss: 0.006027489739108205, acc: 99.8018894046545, p_norm: 2204.3874961829674, g_norm: 0.19680256282983782, lr:  0.000412, elapsed time:  180538
Step 368800, loss: 0.005792867010213741, acc: 99.80956834554672, p_norm: 2204.486174382074, g_norm: 0.1366137587448252, lr:  0.000412, elapsed time:  180586
Step 368900, loss: 0.006223850803980895, acc: 99.79805724322796, p_norm: 2204.5702315536037, g_norm: 0.20903410922376633, lr:  0.000411, elapsed time:  180632
Step 369000, loss: 0.005649568026583438, acc: 99.81819957494736, p_norm: 2204.658224549786, g_norm: 0.28404923347250954, lr:  0.000411, elapsed time:  180680
Step 369100, loss: 0.005990583166280885, acc: 99.80696350336075, p_norm: 2204.756152584808, g_norm: 0.19384696286251404, lr:  0.000411, elapsed time:  180728
Step 369200, loss: 0.0057689419735288535, acc: 99.8094337284565, p_norm: 2204.8544788636846, g_norm: 0.14328450530377218, lr:  0.000411, elapsed time:  180775
Step 369300, loss: 0.0057003003294357766, acc: 99.81401753425598, p_norm: 2204.9457655820593, g_norm: 0.12991866511491507, lr:  0.000411, elapsed time:  180823
Step 369400, loss: 0.005817838435523299, acc: 99.81367120146751, p_norm: 2205.0446199344346, g_norm: 0.1867992501555669, lr:  0.000411, elapsed time:  180871
Step 369500, loss: 0.0059446555887916475, acc: 99.8063538223505, p_norm: 2205.1361614032494, g_norm: 0.20334463011496015, lr:  0.000411, elapsed time:  180918
Step 369600, loss: 0.005668406185836829, acc: 99.81809045374393, p_norm: 2205.2226060800344, g_norm: 0.14218860892318064, lr:  0.000411, elapsed time:  180965
Step 369700, loss: 0.0059781410648975, acc: 99.80606253445148, p_norm: 2205.320894902989, g_norm: 0.11888285613032805, lr:  0.000411, elapsed time:  181013
Step 369800, loss: 0.006045282352160939, acc: 99.80234552919865, p_norm: 2205.421356901147, g_norm: 0.20067131241847358, lr:  0.000411, elapsed time:  181061
Step 369900, loss: 0.006048490028006199, acc: 99.80437237024307, p_norm: 2205.5163836886427, g_norm: 0.19983929036358417, lr:  0.000411, elapsed time:  181108
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 370000, loss: 0.006407739241821494, acc: 99.7960298215572, p_norm: 2205.611772107846, g_norm: 0.15540643839704407, lr:  0.000411, elapsed time:  181156
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 370000, eval loss: 0.020641933301708378, eval acc: 99.58900451660156
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( C Br ) c 1 c n c ( - c 2 c c c c c 2 ) n c 1 _EOS
Predicted text: O = C ( C Br ) c 1 c n c ( - c 2 c c c c c 2 ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N C ( = O ) c 1 c c c ( - c 2 n c 3 c c c c c 3 s 2 ) c n 1 _EOS
Predicted text: N C ( = O ) c 1 c c c ( - c 2 n c 3 c c c c c 3 s 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C n 1 c ( = O ) n ( - c 2 c n n ( C c 3 c ( C ) n o c 3 C ) c 2 ) c ( = O ) n 1 C c 1 c c c c c 1 _EOS
Predicted text: C C C n 1 c ( = O ) n ( - c 2 c n n ( C c 3 c ( C ) n o c 3 C ) c 2 ) c ( = O ) n 1 C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( F ) c c c 1 O c 1 c c c c c 1 [N+] ( = O ) [O-] _EOS
Predicted text: C O C ( = O ) c 1 c c ( F ) c c c 1 O c 1 c c c c c 1 [N+] ( = O ) [O-] _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) C ( = O ) C N 1 C ( = O ) C ( N ) C N ( C 2 C C C C C 2 ) c 2 c c c c c 2 1 _EOS
Predicted text: C C ( C ) ( C ) C ( = O ) C N 1 C ( = O ) C ( N ) C N ( C 2 C C C C C 2 ) c 2 c c c c c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 370000, eval acc (token): 0.9383870517711537, eval acc (sequence): 0.8877887788778878
Saving at step 370000
Step 370100, loss: 0.005414815850390369, acc: 99.82535497844219, p_norm: 2205.6947248352644, g_norm: 0.20664709060158826, lr:  0.000411, elapsed time:  181262
Step 370200, loss: 0.005521331612162612, acc: 99.82042755186558, p_norm: 2205.7810493250095, g_norm: 0.2958131055573177, lr:  0.000411, elapsed time:  181309
Step 370300, loss: 0.005635774591446534, acc: 99.81649546325207, p_norm: 2205.8669469958886, g_norm: 0.15565850300010572, lr:  0.000411, elapsed time:  181357
Step 370400, loss: 0.005768120450325114, acc: 99.81706616282463, p_norm: 2205.9664991653885, g_norm: 0.17828667707268162, lr:  0.000411, elapsed time:  181405
Step 370500, loss: 0.005529565409096904, acc: 99.81973461806774, p_norm: 2206.058057963462, g_norm: 0.19041966635221935, lr:  0.000411, elapsed time:  181452
Step 370600, loss: 0.0057485976153247974, acc: 99.81551957130432, p_norm: 2206.1522187026403, g_norm: 0.11594951686732269, lr:  0.000411, elapsed time:  181500
Step 370700, loss: 0.006008633577916953, acc: 99.80120082199574, p_norm: 2206.2516076792053, g_norm: 0.19375458120128258, lr:  0.000410, elapsed time:  181547
Step 370800, loss: 0.005435091452418419, acc: 99.8215909153223, p_norm: 2206.3390420803603, g_norm: 0.25943361852509117, lr:  0.000410, elapsed time:  181596
Step 370900, loss: 0.005957504288071505, acc: 99.80399198830128, p_norm: 2206.4295355724103, g_norm: 0.12467267164759802, lr:  0.000410, elapsed time:  181643
Step 371000, loss: 0.006280007560717422, acc: 99.79111531376839, p_norm: 2206.53558910524, g_norm: 0.12561771000124336, lr:  0.000410, elapsed time:  181690
Step 371100, loss: 0.005809412432240606, acc: 99.81588591635227, p_norm: 2206.6280394633955, g_norm: 0.23638487415089876, lr:  0.000410, elapsed time:  181738
Step 371200, loss: 0.0057691881792925415, acc: 99.8144270926714, p_norm: 2206.723885507243, g_norm: 0.1334665983511413, lr:  0.000410, elapsed time:  181786
Step 371300, loss: 0.0059973468726184365, acc: 99.80161345005035, p_norm: 2206.8119226280296, g_norm: 0.22427909808840044, lr:  0.000410, elapsed time:  181833
Step 371400, loss: 0.005913427333289292, acc: 99.8095248490572, p_norm: 2206.9178550163624, g_norm: 0.17473279124509117, lr:  0.000410, elapsed time:  181880
Step 371500, loss: 0.005994288552246871, acc: 99.79998518526554, p_norm: 2207.009650624236, g_norm: 0.18170328062414257, lr:  0.000410, elapsed time:  181927
Step 371600, loss: 0.0063940350692610086, acc: 99.79428689181805, p_norm: 2207.112876835987, g_norm: 0.19753562482413803, lr:  0.000410, elapsed time:  181975
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 371700, loss: 0.0058397418616950025, acc: 99.80868450169528, p_norm: 2207.219393519091, g_norm: 0.13619090946182139, lr:  0.000410, elapsed time:  182023
Step 371800, loss: 0.0053587197827528145, acc: 99.82571728527546, p_norm: 2207.3065845589863, g_norm: 0.13559307718999505, lr:  0.000410, elapsed time:  182071
Step 371900, loss: 0.005676408470981187, acc: 99.81246043741703, p_norm: 2207.392231605628, g_norm: 0.24766599642188888, lr:  0.000410, elapsed time:  182119
Step 372000, loss: 0.005694554414039885, acc: 99.81615167856216, p_norm: 2207.479644353325, g_norm: 0.11690743443377795, lr:  0.000410, elapsed time:  182167
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 372000, eval loss: 0.022601118674538154, eval acc: 99.5981674194336
Step 372100, loss: 0.00574525607200485, acc: 99.81665469706059, p_norm: 2207.569128360005, g_norm: 0.1303822664773943, lr:  0.000410, elapsed time:  182221
Step 372200, loss: 0.006031768474422279, acc: 99.79715292155743, p_norm: 2207.6689996332693, g_norm: 0.1730940183204713, lr:  0.000410, elapsed time:  182268
Step 372300, loss: 0.005632566712265543, acc: 99.81806276738644, p_norm: 2207.7500333668872, g_norm: 0.18055286198176615, lr:  0.000410, elapsed time:  182316
Step 372400, loss: 0.005720198647468351, acc: 99.8135939091444, p_norm: 2207.8449286428763, g_norm: 0.201659361016016, lr:  0.000410, elapsed time:  182364
Step 372500, loss: 0.005638523440784411, acc: 99.8153014332056, p_norm: 2207.937942056974, g_norm: 0.1777626581969995, lr:  0.000409, elapsed time:  182411
Step 372600, loss: 0.006076478280410811, acc: 99.80382606387138, p_norm: 2208.024114629386, g_norm: 0.21728121659928176, lr:  0.000409, elapsed time:  182458
Step 372700, loss: 0.0058985818976998415, acc: 99.80616401135921, p_norm: 2208.106679296196, g_norm: 0.16044103928542092, lr:  0.000409, elapsed time:  182505
Step 372800, loss: 0.00598874904915192, acc: 99.80796970427036, p_norm: 2208.20499443374, g_norm: 0.15211136679715875, lr:  0.000409, elapsed time:  182553
Step 372900, loss: 0.005910603477509539, acc: 99.80839118361473, p_norm: 2208.302116532135, g_norm: 0.14550205948207523, lr:  0.000409, elapsed time:  182601
Step 373000, loss: 0.005763510326814867, acc: 99.81264765560627, p_norm: 2208.3900801619147, g_norm: 0.19594584174910523, lr:  0.000409, elapsed time:  182649
Step 373100, loss: 0.00581239325725619, acc: 99.80833013355732, p_norm: 2208.4722974865426, g_norm: 0.20207635211960878, lr:  0.000409, elapsed time:  182697
Step 373200, loss: 0.006351309044066511, acc: 99.79383596777916, p_norm: 2208.569858660729, g_norm: 0.17990004259212194, lr:  0.000409, elapsed time:  182743
Step 373300, loss: 0.006190328582115399, acc: 99.80360825359821, p_norm: 2208.6626523779364, g_norm: 0.22990000589106432, lr:  0.000409, elapsed time:  182790
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 373400, loss: 0.005748445257308654, acc: 99.80959803531543, p_norm: 2208.7458705168992, g_norm: 0.1264294616038317, lr:  0.000409, elapsed time:  182839
Step 373500, loss: 0.005332726936849212, acc: 99.82535430788994, p_norm: 2208.8310630273504, g_norm: 0.23563839327343372, lr:  0.000409, elapsed time:  182887
Step 373600, loss: 0.005898543764087663, acc: 99.80735535919666, p_norm: 2208.920759573942, g_norm: 0.20049729920387244, lr:  0.000409, elapsed time:  182934
Step 373700, loss: 0.006040257221843604, acc: 99.8001020848751, p_norm: 2209.0099240804166, g_norm: 0.16658820914070652, lr:  0.000409, elapsed time:  182982
Step 373800, loss: 0.005729353599499518, acc: 99.81367626786232, p_norm: 2209.0957418036583, g_norm: 0.2891022152959191, lr:  0.000409, elapsed time:  183029
Step 373900, loss: 0.005798970591154102, acc: 99.81168183684349, p_norm: 2209.1940207681378, g_norm: 0.09608662846760505, lr:  0.000409, elapsed time:  183076
Step 374000, loss: 0.005841254297197338, acc: 99.81145639717579, p_norm: 2209.2782032679265, g_norm: 0.22992080054139427, lr:  0.000409, elapsed time:  183124
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 374000, eval loss: 0.022651567870304923, eval acc: 99.5907211303711
Step 374100, loss: 0.005931415712857415, acc: 99.81008417904377, p_norm: 2209.366104637744, g_norm: 0.17078289401212995, lr:  0.000409, elapsed time:  183178
Step 374200, loss: 0.005710732483712491, acc: 99.81668098270893, p_norm: 2209.4488054358008, g_norm: 0.21355867715141982, lr:  0.000409, elapsed time:  183226
Step 374300, loss: 0.00554493137145073, acc: 99.81792739033699, p_norm: 2209.5389025466166, g_norm: 0.18201314111330366, lr:  0.000409, elapsed time:  183273
Step 374400, loss: 0.005980804465134497, acc: 99.80022236704826, p_norm: 2209.6388804757958, g_norm: 0.15119361559293487, lr:  0.000408, elapsed time:  183321
Step 374500, loss: 0.005710753776038473, acc: 99.8221794217825, p_norm: 2209.7272841649938, g_norm: 0.17983516067543726, lr:  0.000408, elapsed time:  183369
Step 374600, loss: 0.005940864916074134, acc: 99.80861595273018, p_norm: 2209.81270458268, g_norm: 0.1266990748543579, lr:  0.000408, elapsed time:  183416
Step 374700, loss: 0.005747447797220957, acc: 99.80707481503487, p_norm: 2209.908667110763, g_norm: 0.21318569254748274, lr:  0.000408, elapsed time:  183463
Step 374800, loss: 0.0057248598819023755, acc: 99.81495527923107, p_norm: 2210.0091571844005, g_norm: 0.18023161296000367, lr:  0.000408, elapsed time:  183511
Step 374900, loss: 0.005906688928548647, acc: 99.80580852925777, p_norm: 2210.093379923782, g_norm: 0.2737195646439536, lr:  0.000408, elapsed time:  183559
Step 375000, loss: 0.005670699894931203, acc: 99.81283465027809, p_norm: 2210.1855921539536, g_norm: 0.16583289612446284, lr:  0.000408, elapsed time:  183606
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) ( C ) O C ( = O ) N C 1 ( C 2 C C ( = O ) N ( C c 3 c c c c c 3 ) C 2 ) C C ( = O ) C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N C 1 ( C 2 C C ( = O ) N ( C c 3 c c c c c 3 ) C 2 ) C C ( = O ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C N ( C C C ) C 1 C c 2 c c c c 3 c 2 C ( C N 3 ) C 1 _EOS
Predicted text: C C C N C 1 C c 2 c c c c 3 c 2 C ( C 1 ) C N 3 C ( = O ) c 1 c c c c c 1 _EOS
acc_token: 0.26666666666666666, acc_seq: False

Target text: C C O C = C ( C ( = O ) C C ) C ( = O ) c 1 c c c ( S ( C ) ( = O ) = O ) c c 1 Cl _EOS
Predicted text: C C O C = C ( C ( = O ) C C ) C ( = O ) c 1 c c c ( S ( C ) ( = O ) = O ) c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C n 1 c ( - c 2 n o n c 2 N ) n c 2 c n c c ( N c 3 c c c c c 3 ) c 2 1 _EOS
Predicted text: C C n 1 c ( - c 2 n o n c 2 N ) n c 2 c n c c ( N c 3 c c c c c 3 ) c 2 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C O c 2 c ( c c c c 2 C 2 ( O ) C C C 2 ) C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C O c 2 c ( c c c c 2 C 2 ( O ) C C C 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 375000, eval acc (token): 0.9441763349840121, eval acc (sequence): 0.9004629629629629
Saving at step 375000
Step 375100, loss: 0.00597633092009346, acc: 99.80874222517014, p_norm: 2210.292881978645, g_norm: 0.1370329018717464, lr:  0.000408, elapsed time:  183706
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 375200, loss: 0.005774685249020572, acc: 99.80992347963395, p_norm: 2210.388768957056, g_norm: 0.17172805860883877, lr:  0.000408, elapsed time:  183757
Step 375300, loss: 0.005265280511607671, acc: 99.82298618555069, p_norm: 2210.477080300108, g_norm: 0.12361542543281463, lr:  0.000408, elapsed time:  183805
Step 375400, loss: 0.00592561403079344, acc: 99.80781699717045, p_norm: 2210.5616216773037, g_norm: 0.19946084014269178, lr:  0.000408, elapsed time:  183852
Step 375500, loss: 0.005835104600914747, acc: 99.80863980948925, p_norm: 2210.67041045578, g_norm: 0.20894750089205105, lr:  0.000408, elapsed time:  183900
Step 375600, loss: 0.005619478640305715, acc: 99.82053369283676, p_norm: 2210.7611633025954, g_norm: 0.16208535672759158, lr:  0.000408, elapsed time:  183948
Step 375700, loss: 0.005605393280402496, acc: 99.8247672021389, p_norm: 2210.854354586103, g_norm: 0.13820464257960066, lr:  0.000408, elapsed time:  183995
Step 375800, loss: 0.005861276325713333, acc: 99.81339912116528, p_norm: 2210.9449811518384, g_norm: 0.2028820596259284, lr:  0.000408, elapsed time:  184042
Step 375900, loss: 0.005991972604647344, acc: 99.80567640066147, p_norm: 2211.0438755426876, g_norm: 0.21274095079840147, lr:  0.000408, elapsed time:  184090
Step 376000, loss: 0.00576671003892443, acc: 99.80979296565056, p_norm: 2211.1273038251456, g_norm: 0.18518933606263455, lr:  0.000408, elapsed time:  184137
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 376000, eval loss: 0.021620641996205458, eval acc: 99.60414123535156
Step 376100, loss: 0.005407130128496647, acc: 99.82322552800179, p_norm: 2211.2185721838114, g_norm: 0.1441894020505685, lr:  0.000408, elapsed time:  184191
Step 376200, loss: 0.005500844854486786, acc: 99.82118599116802, p_norm: 2211.3148773395906, g_norm: 0.23162793119063396, lr:  0.000407, elapsed time:  184239
Step 376300, loss: 0.005986957722980151, acc: 99.80177953839302, p_norm: 2211.4097952407633, g_norm: 0.23178429249727292, lr:  0.000407, elapsed time:  184286
Step 376400, loss: 0.005908856930213915, acc: 99.80615037679672, p_norm: 2211.50198681228, g_norm: 0.24658667672241852, lr:  0.000407, elapsed time:  184333
Step 376500, loss: 0.005685421278412832, acc: 99.81027175486088, p_norm: 2211.6028927506395, g_norm: 0.23844925959488045, lr:  0.000407, elapsed time:  184381
Step 376600, loss: 0.00613371377325393, acc: 99.8002283424139, p_norm: 2211.7045869897793, g_norm: 0.20731805378024434, lr:  0.000407, elapsed time:  184428
Step 376700, loss: 0.005705117117104237, acc: 99.81401365995407, p_norm: 2211.7987318377936, g_norm: 0.1581792141564689, lr:  0.000407, elapsed time:  184475
Step 376800, loss: 0.0060900291064263, acc: 99.80377814173698, p_norm: 2211.89362364698, g_norm: 0.21176824841304506, lr:  0.000407, elapsed time:  184522
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 376900, loss: 0.005607333988226321, acc: 99.81716392058001, p_norm: 2211.982328116318, g_norm: 0.20245271913482174, lr:  0.000407, elapsed time:  184571
Step 377000, loss: 0.00624626532817274, acc: 99.79690556228161, p_norm: 2212.0783228748055, g_norm: 0.19432418541938537, lr:  0.000407, elapsed time:  184618
Step 377100, loss: 0.005803606782410498, acc: 99.81236118078232, p_norm: 2212.163791911187, g_norm: 0.16388577819678984, lr:  0.000407, elapsed time:  184665
Step 377200, loss: 0.005484626093948464, acc: 99.82099379599094, p_norm: 2212.2524174764485, g_norm: 0.17241284268370816, lr:  0.000407, elapsed time:  184712
Step 377300, loss: 0.0059279368841271204, acc: 99.80860863626003, p_norm: 2212.3320381121343, g_norm: 0.12378569645765611, lr:  0.000407, elapsed time:  184759
Step 377400, loss: 0.0058152713724985, acc: 99.80878831446171, p_norm: 2212.421047853069, g_norm: 0.23481017734637316, lr:  0.000407, elapsed time:  184807
Step 377500, loss: 0.005969123983354621, acc: 99.8084153085947, p_norm: 2212.5204017433734, g_norm: 0.2180043453725545, lr:  0.000407, elapsed time:  184855
Step 377600, loss: 0.005697221363097924, acc: 99.81849558651447, p_norm: 2212.60887835872, g_norm: 0.2257057900269082, lr:  0.000407, elapsed time:  184902
Step 377700, loss: 0.00592556886109378, acc: 99.80615006387234, p_norm: 2212.7132595771677, g_norm: 0.2126112716168643, lr:  0.000407, elapsed time:  184950
Step 377800, loss: 0.0055494279555909996, acc: 99.82283526659012, p_norm: 2212.7980577968456, g_norm: 0.13517725899832064, lr:  0.000407, elapsed time:  184997
Step 377900, loss: 0.005171241664784248, acc: 99.82766604423523, p_norm: 2212.884604320018, g_norm: 0.1857168334318565, lr:  0.000407, elapsed time:  185045
Step 378000, loss: 0.005500664619557938, acc: 99.82082051038742, p_norm: 2212.974295272536, g_norm: 0.1245307540721214, lr:  0.000407, elapsed time:  185093
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 378000, eval loss: 0.021919718440622092, eval acc: 99.60115051269531
Step 378100, loss: 0.005267258721603412, acc: 99.82792729139328, p_norm: 2213.0669075997466, g_norm: 0.24496035635584162, lr:  0.000406, elapsed time:  185148
Step 378200, loss: 0.005598357558974385, acc: 99.81418001651764, p_norm: 2213.155161744089, g_norm: 0.1553920507834, lr:  0.000406, elapsed time:  185195
Step 378300, loss: 0.005955060102451171, acc: 99.80483902990818, p_norm: 2213.263847427732, g_norm: 0.2178308339023279, lr:  0.000406, elapsed time:  185243
Step 378400, loss: 0.0059188531529071045, acc: 99.8088663071394, p_norm: 2213.3568549446786, g_norm: 0.1986998072517473, lr:  0.000406, elapsed time:  185291
Step 378500, loss: 0.006014489754661554, acc: 99.80719204246998, p_norm: 2213.454235200358, g_norm: 0.168993478284184, lr:  0.000406, elapsed time:  185338
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 378600, loss: 0.006021282897455055, acc: 99.80186106850259, p_norm: 2213.552030228201, g_norm: 0.17314707807991944, lr:  0.000406, elapsed time:  185386
Step 378700, loss: 0.005792259989420927, acc: 99.81034241616726, p_norm: 2213.644272337763, g_norm: 0.18936076542390723, lr:  0.000406, elapsed time:  185434
Step 378800, loss: 0.005583324454637478, acc: 99.81513103842735, p_norm: 2213.73900738698, g_norm: 0.15470473991708186, lr:  0.000406, elapsed time:  185481
Step 378900, loss: 0.0053902641667446, acc: 99.82666796445847, p_norm: 2213.82260401879, g_norm: 0.17469283246768239, lr:  0.000406, elapsed time:  185529
Step 379000, loss: 0.0056994884918731255, acc: 99.81843683123589, p_norm: 2213.913659413569, g_norm: 0.18782135037169476, lr:  0.000406, elapsed time:  185576
Step 379100, loss: 0.005639331237161969, acc: 99.81479865312576, p_norm: 2214.004038668497, g_norm: 0.1744940606701116, lr:  0.000406, elapsed time:  185624
Step 379200, loss: 0.005706455137683406, acc: 99.81545534729958, p_norm: 2214.087755740872, g_norm: 0.2300539437767189, lr:  0.000406, elapsed time:  185671
Step 379300, loss: 0.0056852696108762755, acc: 99.81578093767166, p_norm: 2214.175526549339, g_norm: 0.11431559630351447, lr:  0.000406, elapsed time:  185719
Step 379400, loss: 0.00578951801252515, acc: 99.81128410995007, p_norm: 2214.2576678285145, g_norm: 0.18263560650900876, lr:  0.000406, elapsed time:  185766
Step 379500, loss: 0.005625281066140814, acc: 99.81554719805717, p_norm: 2214.3478483127806, g_norm: 0.2998576375351586, lr:  0.000406, elapsed time:  185814
Step 379600, loss: 0.005622986183097965, acc: 99.81843174993992, p_norm: 2214.443209058248, g_norm: 0.11263400819991705, lr:  0.000406, elapsed time:  185861
Step 379700, loss: 0.005823387266191276, acc: 99.80641597509384, p_norm: 2214.532065084187, g_norm: 0.19451876783426042, lr:  0.000406, elapsed time:  185908
Step 379800, loss: 0.005924220083779801, acc: 99.81145027279854, p_norm: 2214.631658553901, g_norm: 0.2381693299104369, lr:  0.000406, elapsed time:  185956
Step 379900, loss: 0.005996309026122617, acc: 99.80555218458176, p_norm: 2214.725310772342, g_norm: 0.14567501309041714, lr:  0.000405, elapsed time:  186004
Step 380000, loss: 0.005740001795702483, acc: 99.81271371245384, p_norm: 2214.8153526316632, g_norm: 0.15439773215156236, lr:  0.000405, elapsed time:  186051
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 380000, eval loss: 0.021365080297691755, eval acc: 99.61369323730469
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c c ( C = C C ( = O ) c 2 c ( O ) c c ( C ) o c 2 = O ) c ( O C ) c 1 _EOS
Predicted text: C O c 1 c c c ( C = C C ( = O ) c 2 c ( O ) c c ( C ) o c 2 = O ) c ( O C ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C O ) N C ( = O ) C 1 C C C N 1 C ( = O ) O C c 1 c c c c c 1 _EOS
Predicted text: C O C ( = O ) C ( C O ) N C ( = O ) C 1 C C C N 1 C ( = O ) O C c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N c 1 c c c ( Cl ) c n 1 ) c 1 o c 2 c c c ( C ( = O ) N 3 C C O C C 3 ) n c 2 c 1 N C ( = O ) C 1 C C C ( N 2 C C O C C 2 = O ) C C 1 _EOS
Predicted text: O = C ( N c 1 c c c ( Cl ) c n 1 ) c 1 o c 2 c c c ( C ( = O ) N 3 C C O C C 3 ) n c 2 c 1 N C ( = O ) C 1 C C C ( N 2 C C O C C 2 = O ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C O c 1 c c c ( - c 2 c c c ( C = O ) c c 2 ) c c 1 C 1 2 C C 3 C C ( C C ( C 3 ) C 1 ) C 2 _EOS
Predicted text: C O C O c 1 c c c ( - c 2 c c c ( C = O ) c c 2 ) c c 1 C 1 2 C C 3 C C ( C C ( C 3 ) C 1 ) C 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 s c ( - c 2 c c c ( O C ) c c 2 ) n c 1 C Br _EOS
Predicted text: C C O C ( = O ) c 1 s c ( - c 2 c c c ( O C ) c c 2 ) n c 1 C Br _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 380000, eval acc (token): 0.9424806198093763, eval acc (sequence): 0.8962974835710851
Saving at step 380000
Step 380100, loss: 0.006017982186517656, acc: 99.80446143448353, p_norm: 2214.90233076332, g_norm: 0.10368187483735518, lr:  0.000405, elapsed time:  186156
Step 380200, loss: 0.0060032193963706956, acc: 99.80568903684616, p_norm: 2214.990582145598, g_norm: 0.1937513179093326, lr:  0.000405, elapsed time:  186203
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 380300, loss: 0.005499407878160489, acc: 99.81891291948101, p_norm: 2215.0863086107674, g_norm: 0.14841475712714933, lr:  0.000405, elapsed time:  186252
Step 380400, loss: 0.0059414222547729875, acc: 99.8035069257021, p_norm: 2215.175383501687, g_norm: 0.1823865367238852, lr:  0.000405, elapsed time:  186299
Step 380500, loss: 0.005669252327447793, acc: 99.81643009185791, p_norm: 2215.265006076517, g_norm: 0.21042767406434146, lr:  0.000405, elapsed time:  186347
Step 380600, loss: 0.00537446983054906, acc: 99.82160837948322, p_norm: 2215.355775185897, g_norm: 0.16829865988607173, lr:  0.000405, elapsed time:  186395
Step 380700, loss: 0.005716326052470322, acc: 99.81441642343998, p_norm: 2215.4516663681625, g_norm: 0.19341801169399303, lr:  0.000405, elapsed time:  186442
Step 380800, loss: 0.005558726458584715, acc: 99.81806889176369, p_norm: 2215.5349351409877, g_norm: 0.17201214224831532, lr:  0.000405, elapsed time:  186490
Step 380900, loss: 0.005638003317717449, acc: 99.81814520061016, p_norm: 2215.622270474173, g_norm: 0.1443201436488967, lr:  0.000405, elapsed time:  186537
Step 381000, loss: 0.005693152520075273, acc: 99.81539291143417, p_norm: 2215.7043756245816, g_norm: 0.12136507857410415, lr:  0.000405, elapsed time:  186585
Step 381100, loss: 0.005795076803988195, acc: 99.81344896554947, p_norm: 2215.7951758423255, g_norm: 0.1761119803143786, lr:  0.000405, elapsed time:  186639
Step 381200, loss: 0.005616037156537459, acc: 99.81978122889996, p_norm: 2215.8876958639557, g_norm: 0.17571805899251833, lr:  0.000405, elapsed time:  186691
Step 381300, loss: 0.005694262402312233, acc: 99.81461481750011, p_norm: 2215.9808237498983, g_norm: 0.19387912596687612, lr:  0.000405, elapsed time:  186738
Step 381400, loss: 0.005758604258644482, acc: 99.81128111481667, p_norm: 2216.078335860326, g_norm: 0.17763744344121205, lr:  0.000405, elapsed time:  186786
Step 381500, loss: 0.006023753918507282, acc: 99.80127727985382, p_norm: 2216.173896466941, g_norm: 0.3802518619756235, lr:  0.000405, elapsed time:  186834
Step 381600, loss: 0.005796920539460189, acc: 99.81247235834599, p_norm: 2216.2668352781666, g_norm: 0.14326734037532265, lr:  0.000405, elapsed time:  186881
Step 381700, loss: 0.005552418317865886, acc: 99.81589265167713, p_norm: 2216.3488533978248, g_norm: 0.20975374450715706, lr:  0.000405, elapsed time:  186929
Step 381800, loss: 0.005888713185959205, acc: 99.8045224249363, p_norm: 2216.4378903326324, g_norm: 0.16158984883056404, lr:  0.000404, elapsed time:  186976
Step 381900, loss: 0.0060228530378662985, acc: 99.80420616269112, p_norm: 2216.5354598986537, g_norm: 0.223978162897385, lr:  0.000404, elapsed time:  187024
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 382000, loss: 0.005537684085398515, acc: 99.81870207917038, p_norm: 2216.615214059168, g_norm: 0.2622381573830946, lr:  0.000404, elapsed time:  187081
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 382000, eval loss: 0.021407253236284302, eval acc: 99.62065887451172
Step 382100, loss: 0.0054859535772357046, acc: 99.82443189620972, p_norm: 2216.699737935327, g_norm: 0.15610712809659794, lr:  0.000404, elapsed time:  187136
Step 382200, loss: 0.005269646385577289, acc: 99.82935783267021, p_norm: 2216.7822583693423, g_norm: 0.2997093755470815, lr:  0.000404, elapsed time:  187184
Step 382300, loss: 0.005353816805491078, acc: 99.82960818707943, p_norm: 2216.8700238038873, g_norm: 0.22380100887464152, lr:  0.000404, elapsed time:  187232
Step 382400, loss: 0.005731532131749191, acc: 99.8136775046587, p_norm: 2216.9558028188185, g_norm: 0.21904206555077488, lr:  0.000404, elapsed time:  187279
Step 382500, loss: 0.006364411044869484, acc: 99.79074281454086, p_norm: 2217.049047179297, g_norm: 0.1735913277564309, lr:  0.000404, elapsed time:  187326
Step 382600, loss: 0.005404468759552401, acc: 99.82265466451645, p_norm: 2217.135943465322, g_norm: 0.21411406282220638, lr:  0.000404, elapsed time:  187374
Step 382700, loss: 0.005823905489378376, acc: 99.81088896095753, p_norm: 2217.228444227614, g_norm: 0.2064135344273203, lr:  0.000404, elapsed time:  187421
Step 382800, loss: 0.005771446917151479, acc: 99.81086580455303, p_norm: 2217.3157347030406, g_norm: 0.13707319437773302, lr:  0.000404, elapsed time:  187468
Step 382900, loss: 0.005487105329193582, acc: 99.82116203010082, p_norm: 2217.415287381764, g_norm: 0.1936965797287985, lr:  0.000404, elapsed time:  187515
Step 383000, loss: 0.005661369866929817, acc: 99.81779256463051, p_norm: 2217.498926271272, g_norm: 0.29840123107229033, lr:  0.000404, elapsed time:  187563
Step 383100, loss: 0.006055426199491194, acc: 99.80033747851849, p_norm: 2217.5854425152934, g_norm: 0.22544291251463355, lr:  0.000404, elapsed time:  187610
Step 383200, loss: 0.0057850358444375164, acc: 99.81407880783081, p_norm: 2217.6812028113495, g_norm: 0.21211593551362615, lr:  0.000404, elapsed time:  187657
Step 383300, loss: 0.005696988352353855, acc: 99.81128393113613, p_norm: 2217.773193119072, g_norm: 0.1317658130257167, lr:  0.000404, elapsed time:  187705
Step 383400, loss: 0.005806377043918474, acc: 99.81675115227699, p_norm: 2217.8770541730933, g_norm: 0.17085897784620385, lr:  0.000404, elapsed time:  187753
Step 383500, loss: 0.005945125608704984, acc: 99.808896869421, p_norm: 2217.967555423736, g_norm: 0.1449354999082146, lr:  0.000404, elapsed time:  187800
Step 383600, loss: 0.005938359958886395, acc: 99.80666016042233, p_norm: 2218.0587499073595, g_norm: 0.199143356474073, lr:  0.000404, elapsed time:  187848
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 383700, loss: 0.005439506994937555, acc: 99.82633024232263, p_norm: 2218.1458895410983, g_norm: 0.24372298633231193, lr:  0.000403, elapsed time:  187896
Step 383800, loss: 0.005506233499295377, acc: 99.81792578101158, p_norm: 2218.234979183345, g_norm: 0.1202059821159943, lr:  0.000403, elapsed time:  187943
Step 383900, loss: 0.005417531131333817, acc: 99.81951230764389, p_norm: 2218.3192383415385, g_norm: 0.21586272209381283, lr:  0.000403, elapsed time:  187991
Step 384000, loss: 0.005736792689031062, acc: 99.81023025512695, p_norm: 2218.416995840417, g_norm: 0.265282634848865, lr:  0.000403, elapsed time:  188039
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 384000, eval loss: 0.019175789407454433, eval acc: 99.663818359375
Step 384100, loss: 0.005599862695657975, acc: 99.81709091365337, p_norm: 2218.5113751774093, g_norm: 0.2083970636321171, lr:  0.000403, elapsed time:  188094
Step 384200, loss: 0.005808025028973134, acc: 99.80919697880745, p_norm: 2218.6139614566196, g_norm: 0.18865369911501542, lr:  0.000403, elapsed time:  188142
Step 384300, loss: 0.005903938446963366, acc: 99.80623319745064, p_norm: 2218.6906092029667, g_norm: 0.18084743522197208, lr:  0.000403, elapsed time:  188189
Step 384400, loss: 0.005838646477350266, acc: 99.81280817091465, p_norm: 2218.7778227527997, g_norm: 0.15713721170268127, lr:  0.000403, elapsed time:  188236
Step 384500, loss: 0.005619846394311025, acc: 99.81489084661007, p_norm: 2218.8630281249225, g_norm: 0.20589884245686477, lr:  0.000403, elapsed time:  188283
Step 384600, loss: 0.00547446898652197, acc: 99.82151325047016, p_norm: 2218.9484844091485, g_norm: 0.22564826294961965, lr:  0.000403, elapsed time:  188330
Step 384700, loss: 0.005635030064286184, acc: 99.81800472736359, p_norm: 2219.0375678653077, g_norm: 0.16179958685812482, lr:  0.000403, elapsed time:  188377
Step 384800, loss: 0.005798069429047246, acc: 99.81249549984932, p_norm: 2219.1323286229403, g_norm: 0.2952656461890657, lr:  0.000403, elapsed time:  188425
Step 384900, loss: 0.005759992957937356, acc: 99.81420247256756, p_norm: 2219.2142211588025, g_norm: 0.1713293507026639, lr:  0.000403, elapsed time:  188472
Step 385000, loss: 0.005802027696799997, acc: 99.80865494906902, p_norm: 2219.30641994377, g_norm: 0.16122988293354024, lr:  0.000403, elapsed time:  188519
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C C C C C C C c 1 n o c ( - c 2 c c c ( C N C C c 3 c c c ( - c 4 c c c c c 4 ) c c 3 ) c c 2 ) n 1 _EOS
Predicted text: C C C C C C C C c 1 n o c ( - c 2 c c c ( C N C C c 3 c c c ( - c 4 c c c c c 4 ) c c 3 ) c c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c c 2 c 1 C ( = O ) C ( = O ) N 2 C c 1 c c c ( C ( F ) ( F ) F ) o 1 _EOS
Predicted text: C O c 1 c c c c 2 c 1 C ( = O ) C ( = O ) N 2 C c 1 c c c ( C ( F ) ( F ) F ) o 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: Cl c 1 c c c ( - c 2 c c c ( C # C c 3 c c c 4 n n ( C C N 5 C C C C 5 ) c c 4 c 3 ) n c 2 ) c c 1 _EOS
Predicted text: Cl c 1 c c c ( - c 2 c c c ( C # C c 3 c c c 4 n n ( C C N 5 C C C C 5 ) c c 4 c 3 ) n c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O C c 1 c ( - c 2 c c ( N c 3 c c c 4 c ( c 3 ) C C N ( C 3 C O C 3 ) C 4 ) c ( = O ) n ( C ) c 2 ) c c ( F ) c c 1 N 1 C C n 2 c ( c c 3 c 2 C C C C 3 ) C 1 = O _EOS
Predicted text: C C ( = O ) O C c 1 c ( - c 2 c c ( N c 3 c c c 4 c ( c 3 ) C C N ( C 3 C O C 3 ) C 4 ) c ( = O ) n ( C ) c 2 ) c c ( F ) c c 1 N 1 C C n 2 c ( c c 3 c 2 C C C C 3 ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( C n 1 c n c 2 c c c c c 2 1 ) N 1 C C N ( c 2 c c c ( Cl ) c c 2 ) C C 1 _EOS
Predicted text: O = C ( C n 1 c n c 2 c c c c c 2 1 ) N 1 C C N ( c 2 c c c ( Cl ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 385000, eval acc (token): 0.9391057899238776, eval acc (sequence): 0.8897278314310799
Saving at step 385000
Step 385100, loss: 0.005903803547371353, acc: 99.80863665044308, p_norm: 2219.4003710532365, g_norm: 0.31003451023522693, lr:  0.000403, elapsed time:  188621
Step 385200, loss: 0.0056959090505097265, acc: 99.81800848245621, p_norm: 2219.497141562643, g_norm: 0.271078384772891, lr:  0.000403, elapsed time:  188669
Step 385300, loss: 0.005455256170907887, acc: 99.81709371507168, p_norm: 2219.587249029, g_norm: 0.19911630519725196, lr:  0.000403, elapsed time:  188716
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 385400, loss: 0.005681136496950469, acc: 99.81645465488765, p_norm: 2219.6779340681346, g_norm: 0.1652043535629032, lr:  0.000403, elapsed time:  188765
Step 385500, loss: 0.00555484114094952, acc: 99.81977407634258, p_norm: 2219.7631404869535, g_norm: 0.14869346011102322, lr:  0.000403, elapsed time:  188813
Step 385600, loss: 0.005271219843771178, acc: 99.82747642695904, p_norm: 2219.8493512808013, g_norm: 0.18424111338694313, lr:  0.000402, elapsed time:  188860
Step 385700, loss: 0.005206209061016125, acc: 99.82549102604389, p_norm: 2219.9358162031817, g_norm: 0.2468590505125736, lr:  0.000402, elapsed time:  188908
Step 385800, loss: 0.005833174176459579, acc: 99.8091806769371, p_norm: 2220.0245160994345, g_norm: 0.24905330306853088, lr:  0.000402, elapsed time:  188955
Step 385900, loss: 0.005600589833261438, acc: 99.8154915124178, p_norm: 2220.123216022551, g_norm: 0.11355554393909445, lr:  0.000402, elapsed time:  189004
Step 386000, loss: 0.005763362621037231, acc: 99.81043611466885, p_norm: 2220.2115206688945, g_norm: 0.3196785584410763, lr:  0.000402, elapsed time:  189051
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 386000, eval loss: 0.020808039964067576, eval acc: 99.60831451416016
Step 386100, loss: 0.00545617231743563, acc: 99.82165491580963, p_norm: 2220.2999615298413, g_norm: 0.24904028124695993, lr:  0.000402, elapsed time:  189106
Step 386200, loss: 0.005680129508582468, acc: 99.8096167743206, p_norm: 2220.395468993798, g_norm: 0.07353127525574249, lr:  0.000402, elapsed time:  189154
Step 386300, loss: 0.005805318458660622, acc: 99.80854900181293, p_norm: 2220.488507023271, g_norm: 0.2046552209552878, lr:  0.000402, elapsed time:  189201
Step 386400, loss: 0.0058391126509923195, acc: 99.81678773462772, p_norm: 2220.5762676420327, g_norm: 0.26475855699452644, lr:  0.000402, elapsed time:  189249
Step 386500, loss: 0.005920024726801785, acc: 99.806691467762, p_norm: 2220.668924517554, g_norm: 0.10273041065941552, lr:  0.000402, elapsed time:  189296
Step 386600, loss: 0.006143749316829599, acc: 99.80065356194973, p_norm: 2220.771836967265, g_norm: 0.25888551875043453, lr:  0.000402, elapsed time:  189343
Step 386700, loss: 0.005590725358933924, acc: 99.8152367323637, p_norm: 2220.8636389950902, g_norm: 0.18875262819329156, lr:  0.000402, elapsed time:  189390
Step 386800, loss: 0.005777862290874509, acc: 99.81121231615543, p_norm: 2220.9483474667213, g_norm: 0.14763973939887423, lr:  0.000402, elapsed time:  189437
Step 386900, loss: 0.0056513864261978596, acc: 99.81996221840382, p_norm: 2221.0211067858795, g_norm: 0.13560410384840177, lr:  0.000402, elapsed time:  189485
Step 387000, loss: 0.0058789834123308534, acc: 99.80803033709526, p_norm: 2221.112040181802, g_norm: 0.26464295323513864, lr:  0.000402, elapsed time:  189532
Calling G2SDataset.batch()
Done, time:  0.67 s, total batches: 6823
Step 387100, loss: 0.005342976994550337, acc: 99.82596876016304, p_norm: 2221.1955672872464, g_norm: 0.1422666088685478, lr:  0.000402, elapsed time:  189581
Step 387200, loss: 0.0054209177651137, acc: 99.82472738623619, p_norm: 2221.28193771894, g_norm: 0.24145059457078927, lr:  0.000402, elapsed time:  189629
Step 387300, loss: 0.005624606085057167, acc: 99.81648521125317, p_norm: 2221.3773048826147, g_norm: 0.17015641206494486, lr:  0.000402, elapsed time:  189676
Step 387400, loss: 0.005401689380578318, acc: 99.82178623974323, p_norm: 2221.4556111185157, g_norm: 0.3748920039276187, lr:  0.000402, elapsed time:  189724
Step 387500, loss: 0.0059375707512140255, acc: 99.80414272844791, p_norm: 2221.5471274383294, g_norm: 0.1778171010038428, lr:  0.000401, elapsed time:  189771
Step 387600, loss: 0.005652538157150957, acc: 99.81628699600697, p_norm: 2221.6354065595824, g_norm: 0.22158402405631414, lr:  0.000401, elapsed time:  189818
Step 387700, loss: 0.00566896854884817, acc: 99.81651221215725, p_norm: 2221.7275718140895, g_norm: 0.130176908961386, lr:  0.000401, elapsed time:  189866
Step 387800, loss: 0.005834410903989919, acc: 99.80683103203773, p_norm: 2221.807504684273, g_norm: 0.19143921149353132, lr:  0.000401, elapsed time:  189914
Step 387900, loss: 0.006260364557347202, acc: 99.79568101465702, p_norm: 2221.9012693138466, g_norm: 0.17745748475162018, lr:  0.000401, elapsed time:  189961
Step 388000, loss: 0.005870560470848432, acc: 99.80854618549347, p_norm: 2221.9887523826796, g_norm: 0.1314254181410936, lr:  0.000401, elapsed time:  190008
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 388000, eval loss: 0.023443543645262254, eval acc: 99.55592346191406
Step 388100, loss: 0.00565263482626051, acc: 99.81363995373249, p_norm: 2222.0801287711906, g_norm: 0.2100785898753109, lr:  0.000401, elapsed time:  190062
Step 388200, loss: 0.005790095140305311, acc: 99.8097817748785, p_norm: 2222.166276133631, g_norm: 0.23080471017052717, lr:  0.000401, elapsed time:  190110
Step 388300, loss: 0.005552642318807557, acc: 99.8229252398014, p_norm: 2222.2464579352873, g_norm: 0.17049477588770656, lr:  0.000401, elapsed time:  190158
Step 388400, loss: 0.005295438045204719, acc: 99.82481826841831, p_norm: 2222.3275550188832, g_norm: 0.15318881683014343, lr:  0.000401, elapsed time:  190205
Step 388500, loss: 0.00528362487861159, acc: 99.82599064707756, p_norm: 2222.4009724074594, g_norm: 0.17964443727375146, lr:  0.000401, elapsed time:  190253
Step 388600, loss: 0.005378066851853873, acc: 99.82546643912792, p_norm: 2222.4842562643908, g_norm: 0.16455040179457694, lr:  0.000401, elapsed time:  190301
Step 388700, loss: 0.005566589442760232, acc: 99.81791035830975, p_norm: 2222.5807980285817, g_norm: 0.13020212447543844, lr:  0.000401, elapsed time:  190348
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 388800, loss: 0.005631848153629215, acc: 99.81892210969853, p_norm: 2222.680351541551, g_norm: 0.3262657739127631, lr:  0.000401, elapsed time:  190397
Step 388900, loss: 0.005437704875012059, acc: 99.82221241295338, p_norm: 2222.7632785735373, g_norm: 0.14841339074263984, lr:  0.000401, elapsed time:  190444
Step 389000, loss: 0.005728327629230989, acc: 99.81605871021748, p_norm: 2222.8437628270963, g_norm: 0.20802047866776802, lr:  0.000401, elapsed time:  190491
Step 389100, loss: 0.005649498880047759, acc: 99.81616628170013, p_norm: 2222.9294662210773, g_norm: 0.29662706807199024, lr:  0.000401, elapsed time:  190539
Step 389200, loss: 0.005765195943049548, acc: 99.81407192349434, p_norm: 2223.017744703016, g_norm: 0.1988808733464005, lr:  0.000401, elapsed time:  190587
Step 389300, loss: 0.005882039915722999, acc: 99.80913025140762, p_norm: 2223.1144191098165, g_norm: 0.2389132951740957, lr:  0.000401, elapsed time:  190634
Step 389400, loss: 0.0055769298794984936, acc: 99.8205883949995, p_norm: 2223.1950028308192, g_norm: 0.15565076045729032, lr:  0.000401, elapsed time:  190681
Step 389500, loss: 0.005639962486275181, acc: 99.81367653608322, p_norm: 2223.279164214692, g_norm: 0.16829241815479107, lr:  0.000400, elapsed time:  190728
Step 389600, loss: 0.005888281970328535, acc: 99.81285567581654, p_norm: 2223.369667501321, g_norm: 0.17695745721997247, lr:  0.000400, elapsed time:  190776
Step 389700, loss: 0.005634927370183504, acc: 99.8146484196186, p_norm: 2223.4707331324516, g_norm: 0.31351921843500075, lr:  0.000400, elapsed time:  190823
Step 389800, loss: 0.00542762389724885, acc: 99.82559649646282, p_norm: 2223.554951259396, g_norm: 0.18946703298927103, lr:  0.000400, elapsed time:  190871
Step 389900, loss: 0.005596050895642293, acc: 99.82072550058365, p_norm: 2223.642307941565, g_norm: 0.1749513747450388, lr:  0.000400, elapsed time:  190919
Step 390000, loss: 0.005631213742462933, acc: 99.81755286455154, p_norm: 2223.730027488905, g_norm: 0.39600175220681344, lr:  0.000400, elapsed time:  190967
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 390000, eval loss: 0.02069984268808185, eval acc: 99.630859375
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( O ) C C 1 ( c 2 c c c c c 2 ) C C 1 c 1 c c c ( O C C c 2 c c c 3 c ( n 2 ) N C C C 3 ) c c 1 _EOS
Predicted text: O = C ( O ) C C 1 ( c 2 c c c c c 2 ) C C 1 c 1 c c c ( O C C c 2 c c c 3 c ( n 2 ) N C C C 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: N c 1 c c c 2 n c n ( C ( C C ( = O ) O ) c 3 c c c c c 3 ) c 2 c 1 _EOS
Predicted text: N c 1 c c c 2 n c n ( C ( C C ( = O ) O ) c 3 c c c c c 3 ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 s c 2 c ( c 1 C ) C ( c 1 c c c ( Cl ) c c 1 ) = N C ( C C ( = O ) N C c 1 c c c n c 1 ) c 1 n n c ( C ) n 1 - 2 _EOS
Predicted text: C c 1 s c 2 c ( c 1 C ) C ( c 1 c c c ( Cl ) c c 1 ) = N C ( C C ( = O ) N C c 1 c c c n c 1 ) c 1 n n c ( C ) n 1 - 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N ( C c 1 c c c ( C ) c c 1 ) C ( = O ) c 1 c c c ( - c 2 c c ( - c 3 n n c ( C ) o 3 ) c c c 2 C ) c c 1 _EOS
Predicted text: C C N ( C c 1 c c c ( C ) c c 1 ) C ( = O ) c 1 c c c ( - c 2 c c ( - c 3 n n c ( C ) o 3 ) c c c 2 C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 c c ( Br ) n c ( N c 2 c c c ( C 3 C C N C C 3 ) c c 2 ) c 1 = O _EOS
Predicted text: C n 1 c c ( Br ) n c ( N c 2 c c c ( C 3 C C N C C 3 ) c c 2 ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 390000, eval acc (token): 0.9438983603901463, eval acc (sequence): 0.9001049685094472
Saving at step 390000
Step 390100, loss: 0.005668499138228072, acc: 99.81783053278923, p_norm: 2223.8131989430626, g_norm: 0.162825586379354, lr:  0.000400, elapsed time:  191074
Step 390200, loss: 0.0056544937413855224, acc: 99.81936573982239, p_norm: 2223.907664385872, g_norm: 0.22687682258594058, lr:  0.000400, elapsed time:  191122
Step 390300, loss: 0.005440602590151684, acc: 99.82197390496731, p_norm: 2223.9925570336127, g_norm: 0.15622996923982757, lr:  0.000400, elapsed time:  191169
Step 390400, loss: 0.005695772278718323, acc: 99.81591109931469, p_norm: 2224.086439495278, g_norm: 0.16818647127393796, lr:  0.000400, elapsed time:  191217
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 390500, loss: 0.005243965124039731, acc: 99.82956602023198, p_norm: 2224.1788556364354, g_norm: 0.17027333043294984, lr:  0.000400, elapsed time:  191266
Step 390600, loss: 0.005490238393958862, acc: 99.82082931697369, p_norm: 2224.2700624541494, g_norm: 0.14553738415158465, lr:  0.000400, elapsed time:  191313
Step 390700, loss: 0.00546165791045496, acc: 99.82256717979908, p_norm: 2224.3581925620433, g_norm: 0.1949257252112583, lr:  0.000400, elapsed time:  191360
Step 390800, loss: 0.0051488379441343565, acc: 99.83152242004871, p_norm: 2224.4385500668586, g_norm: 0.190550633777105, lr:  0.000400, elapsed time:  191408
Step 390900, loss: 0.005753804507212408, acc: 99.81602737307549, p_norm: 2224.5195832580075, g_norm: 0.6308329893343742, lr:  0.000400, elapsed time:  191456
Step 391000, loss: 0.005617154358878907, acc: 99.81684464216232, p_norm: 2224.608100506346, g_norm: 0.16348980314453326, lr:  0.000400, elapsed time:  191503
Step 391100, loss: 0.005678657401199416, acc: 99.81336717307568, p_norm: 2224.7022082889093, g_norm: 0.21069691540986218, lr:  0.000400, elapsed time:  191551
Step 391200, loss: 0.005804415406937551, acc: 99.81080041825771, p_norm: 2224.7808002545557, g_norm: 0.1469796882874944, lr:  0.000400, elapsed time:  191598
Step 391300, loss: 0.0053190895907619055, acc: 99.8240588158369, p_norm: 2224.867714570975, g_norm: 0.14354466284346143, lr:  0.000400, elapsed time:  191645
Step 391400, loss: 0.00541269508023106, acc: 99.83076034486294, p_norm: 2224.948127569356, g_norm: 0.24696763423515505, lr:  0.000399, elapsed time:  191693
Step 391500, loss: 0.005615474618152803, acc: 99.81886440515518, p_norm: 2225.0379829078333, g_norm: 0.1307572913166896, lr:  0.000399, elapsed time:  191740
Step 391600, loss: 0.005914106859527237, acc: 99.80557684600353, p_norm: 2225.1293238087355, g_norm: 0.15102082069039474, lr:  0.000399, elapsed time:  191788
Step 391700, loss: 0.005392282844859438, acc: 99.82280865311623, p_norm: 2225.2266685477857, g_norm: 0.15656783526074225, lr:  0.000399, elapsed time:  191835
Step 391800, loss: 0.00604799911407099, acc: 99.8064832687378, p_norm: 2225.3178162311315, g_norm: 0.12039794216643213, lr:  0.000399, elapsed time:  191882
Step 391900, loss: 0.005503056962061237, acc: 99.82390066981316, p_norm: 2225.4008739694887, g_norm: 0.11425971353350307, lr:  0.000399, elapsed time:  191930
Step 392000, loss: 0.005762932426741827, acc: 99.80601876974106, p_norm: 2225.4926401194484, g_norm: 0.19283267246704827, lr:  0.000399, elapsed time:  191978
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 392000, eval loss: 0.021882612604968012, eval acc: 99.61031341552734
Step 392100, loss: 0.005742002316655999, acc: 99.81549678742886, p_norm: 2225.5834131872634, g_norm: 0.18733459904628685, lr:  0.000399, elapsed time:  192033
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 392200, loss: 0.005572131542640157, acc: 99.82222076089447, p_norm: 2225.6853522792326, g_norm: 0.26508192745354986, lr:  0.000399, elapsed time:  192081
Step 392300, loss: 0.005334081583091574, acc: 99.82421889901161, p_norm: 2225.7706048780765, g_norm: 0.19272685046109614, lr:  0.000399, elapsed time:  192129
Step 392400, loss: 0.005437994905823871, acc: 99.82316613197327, p_norm: 2225.8646048946953, g_norm: 0.1431759258191766, lr:  0.000399, elapsed time:  192176
Step 392500, loss: 0.005343638545646172, acc: 99.83232825994492, p_norm: 2225.957465936314, g_norm: 0.13353165576856152, lr:  0.000399, elapsed time:  192224
Step 392600, loss: 0.005724053532521794, acc: 99.81515538692474, p_norm: 2226.0395902822956, g_norm: 0.13226198006739892, lr:  0.000399, elapsed time:  192271
Step 392700, loss: 0.005593182362749758, acc: 99.82058311998844, p_norm: 2226.127336753734, g_norm: 0.1257087505509269, lr:  0.000399, elapsed time:  192319
Step 392800, loss: 0.005306302391672944, acc: 99.82604086399078, p_norm: 2226.2140425674493, g_norm: 0.16738700534160525, lr:  0.000399, elapsed time:  192367
Step 392900, loss: 0.005302243786932195, acc: 99.82513378560543, p_norm: 2226.291696878667, g_norm: 0.11099437069923754, lr:  0.000399, elapsed time:  192414
Step 393000, loss: 0.005699728646650328, acc: 99.81541536748409, p_norm: 2226.384754624354, g_norm: 0.10143612631127182, lr:  0.000399, elapsed time:  192462
Step 393100, loss: 0.00570906731463765, acc: 99.81281735002995, p_norm: 2226.4782763697717, g_norm: 0.12305651947072857, lr:  0.000399, elapsed time:  192509
Step 393200, loss: 0.0054240128748642745, acc: 99.82908833026886, p_norm: 2226.571933408579, g_norm: 0.26365294894077757, lr:  0.000399, elapsed time:  192556
Step 393300, loss: 0.005867974688835602, acc: 99.8081268966198, p_norm: 2226.6551726385965, g_norm: 0.13679762193842024, lr:  0.000399, elapsed time:  192604
Step 393400, loss: 0.00576183924851648, acc: 99.8110366910696, p_norm: 2226.7432283608687, g_norm: 0.2039515805813158, lr:  0.000398, elapsed time:  192651
Step 393500, loss: 0.0053808797232932195, acc: 99.82348798215389, p_norm: 2226.8230413790875, g_norm: 0.17545968503995155, lr:  0.000398, elapsed time:  192699
Step 393600, loss: 0.00576650674778648, acc: 99.81058168411255, p_norm: 2226.9038854190503, g_norm: 0.16155366462451706, lr:  0.000398, elapsed time:  192747
Step 393700, loss: 0.005658556868993401, acc: 99.8127987831831, p_norm: 2227.001995196538, g_norm: 0.2103838772569334, lr:  0.000398, elapsed time:  192794
Step 393800, loss: 0.005908741366092727, acc: 99.80734597146511, p_norm: 2227.0949179161285, g_norm: 0.20907134731990562, lr:  0.000398, elapsed time:  192842
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 393900, loss: 0.005773987208244332, acc: 99.80772446044048, p_norm: 2227.1849464278152, g_norm: 0.21798459972344073, lr:  0.000398, elapsed time:  192890
Step 394000, loss: 0.005439014495241281, acc: 99.82086758315563, p_norm: 2227.277159397657, g_norm: 0.14370997200460317, lr:  0.000398, elapsed time:  192938
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 394000, eval loss: 0.022603274711428898, eval acc: 99.61542510986328
Step 394100, loss: 0.00549105217820852, acc: 99.82148812711239, p_norm: 2227.371514047396, g_norm: 0.23498447971371672, lr:  0.000398, elapsed time:  192992
Step 394200, loss: 0.005573619528995551, acc: 99.81492732465267, p_norm: 2227.4568379260204, g_norm: 0.1594700942903708, lr:  0.000398, elapsed time:  193040
Step 394300, loss: 0.005582747447720067, acc: 99.82062815129757, p_norm: 2227.5359091880314, g_norm: 0.24107572920163997, lr:  0.000398, elapsed time:  193087
Step 394400, loss: 0.005334810643130367, acc: 99.82717490196228, p_norm: 2227.618129510109, g_norm: 0.15273484566934406, lr:  0.000398, elapsed time:  193135
Step 394500, loss: 0.005187053064837528, acc: 99.82853254675865, p_norm: 2227.7008858730087, g_norm: 0.21171037483010244, lr:  0.000398, elapsed time:  193183
Step 394600, loss: 0.005728337091468348, acc: 99.81300869584084, p_norm: 2227.7910349612084, g_norm: 0.19012365278523077, lr:  0.000398, elapsed time:  193230
Step 394700, loss: 0.005621060518042214, acc: 99.81508477032185, p_norm: 2227.8863541860846, g_norm: 0.20005304315257963, lr:  0.000398, elapsed time:  193277
Step 394800, loss: 0.005713293903831982, acc: 99.80969506502151, p_norm: 2227.97774068564, g_norm: 0.16429919208212695, lr:  0.000398, elapsed time:  193324
Step 394900, loss: 0.005677605461810345, acc: 99.81700326502323, p_norm: 2228.067739244329, g_norm: 0.18136022234092034, lr:  0.000398, elapsed time:  193372
Step 395000, loss: 0.005908718927494192, acc: 99.81269155442715, p_norm: 2228.16196827386, g_norm: 0.1763653254360902, lr:  0.000398, elapsed time:  193419
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O N = C ( C ( = O ) N C 1 C ( = O ) N 2 C ( C ( = O ) O C ( c 3 c c c c c 3 ) c 3 c c c c c 3 ) = C ( C = C ( C ) S c 3 n n c ( C ) s 3 ) C S C 1 2 ) c 1 c s c ( N C ( c 2 c c c c c 2 ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) n 1 _EOS
Predicted text: C O N = C ( C ( = O ) N C 1 C ( = O ) N 2 C ( C ( = O ) O C ( c 3 c c c c c 3 ) c 3 c c c c c 3 ) = C ( C = C ( C ) S c 3 n n c ( C ) s 3 ) C S C 1 2 ) c 1 c s c ( N C ( c 2 c c c c c 2 ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C C C C = C C C C C C C C C O C C ( O ) C O C C C C C C C C C = C C C C C C C C C _EOS
Predicted text: C C C C C C C C C = C C C C C C C C C O C C ( O ) C O C C C C C C C C C = C C C C C C C C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O c 1 c c c c c 1 C ( = O ) N c 1 c c c 2 c ( c 1 ) C ( C ) ( c 1 c c c c c 1 ) C C ( C ) ( C ) N 2 C ( C ) = O _EOS
Predicted text: C C ( = O ) O c 1 c c c c c 1 C ( = O ) N c 1 c c c 2 c ( c 1 ) C ( C ) ( c 1 c c c c c 1 ) C C ( C ) ( C ) N 2 C ( C ) = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C 1 C ( I ) C C C 2 C C C C ( c 3 c c c c c 3 F ) N 1 2 _EOS
Predicted text: O = C 1 C ( I ) C C C 2 C C C C ( c 3 c c c c c 3 F ) N 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O c 1 c c c 2 c c c c ( N ) c 2 c 1 _EOS
Predicted text: C C O c 1 c c c 2 c c c c ( N ) c 2 c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 395000, eval acc (token): 0.9435447721877801, eval acc (sequence): 0.8946415640839971
Saving at step 395000
Step 395100, loss: 0.005682690715857462, acc: 99.8128769993782, p_norm: 2228.2437519780437, g_norm: 0.12627603105754773, lr:  0.000398, elapsed time:  193535
Step 395200, loss: 0.005802611901767705, acc: 99.80842344462872, p_norm: 2228.336861453344, g_norm: 0.17826687730924995, lr:  0.000398, elapsed time:  193589
Step 395300, loss: 0.005550252021066626, acc: 99.82258316874504, p_norm: 2228.4226682360227, g_norm: 0.1771794721074967, lr:  0.000398, elapsed time:  193637
Step 395400, loss: 0.005406318991936132, acc: 99.82409492135048, p_norm: 2228.506776142647, g_norm: 0.17264733203844676, lr:  0.000397, elapsed time:  193684
Step 395500, loss: 0.005775342271194858, acc: 99.809977799654, p_norm: 2228.602738874787, g_norm: 0.1929278732815904, lr:  0.000397, elapsed time:  193732
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 395600, loss: 0.0053689869827152955, acc: 99.82228187414316, p_norm: 2228.6938267073238, g_norm: 0.16828873710054854, lr:  0.000397, elapsed time:  193780
Step 395700, loss: 0.005288457715737422, acc: 99.82536843419075, p_norm: 2228.773011479801, g_norm: 0.19265629890418492, lr:  0.000397, elapsed time:  193827
Step 395800, loss: 0.005455388191294332, acc: 99.8173436820507, p_norm: 2228.856569143184, g_norm: 0.1455523512942929, lr:  0.000397, elapsed time:  193874
Step 395900, loss: 0.005614536635275727, acc: 99.81758676469326, p_norm: 2228.953580540163, g_norm: 0.12877899469444412, lr:  0.000397, elapsed time:  193922
Step 396000, loss: 0.005295133303079637, acc: 99.82621830701828, p_norm: 2229.048231170688, g_norm: 0.18880586682085965, lr:  0.000397, elapsed time:  193970
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 396000, eval loss: 0.01909691699809628, eval acc: 99.65118408203125
Step 396100, loss: 0.0059681602990622196, acc: 99.80711537599564, p_norm: 2229.133238806253, g_norm: 0.21767299898250883, lr:  0.000397, elapsed time:  194025
Step 396200, loss: 0.005661393900991243, acc: 99.81794452667236, p_norm: 2229.209361428492, g_norm: 0.20477059629621303, lr:  0.000397, elapsed time:  194072
Step 396300, loss: 0.005949989656719481, acc: 99.8053133636713, p_norm: 2229.295355314009, g_norm: 0.18870603880257253, lr:  0.000397, elapsed time:  194120
Step 396400, loss: 0.00537199982411039, acc: 99.82556796073914, p_norm: 2229.3852321259037, g_norm: 0.21008581004972862, lr:  0.000397, elapsed time:  194167
Step 396500, loss: 0.005735327669135586, acc: 99.81599472463131, p_norm: 2229.4619401764694, g_norm: 0.19238669324632965, lr:  0.000397, elapsed time:  194214
Step 396600, loss: 0.006056670191765079, acc: 99.80657489597797, p_norm: 2229.551774311947, g_norm: 0.16527410299150289, lr:  0.000397, elapsed time:  194261
Step 396700, loss: 0.005503939138943679, acc: 99.81851014494896, p_norm: 2229.6418461527587, g_norm: 0.1965532487084786, lr:  0.000397, elapsed time:  194309
Step 396800, loss: 0.005397022335673682, acc: 99.82765530049801, p_norm: 2229.733797543883, g_norm: 0.18505438085984652, lr:  0.000397, elapsed time:  194356
Step 396900, loss: 0.005892693428486382, acc: 99.80362091958523, p_norm: 2229.823173537553, g_norm: 0.11095515056666011, lr:  0.000397, elapsed time:  194404
Step 397000, loss: 0.005693035458034501, acc: 99.81858813762665, p_norm: 2229.9051354385097, g_norm: 0.17136424799841435, lr:  0.000397, elapsed time:  194451
Step 397100, loss: 0.0052596367819251096, acc: 99.82947379350662, p_norm: 2229.9962790242616, g_norm: 0.2007313361975693, lr:  0.000397, elapsed time:  194499
Step 397200, loss: 0.005593840789679234, acc: 99.8177634626627, p_norm: 2230.0847357566295, g_norm: 0.152094573308803, lr:  0.000397, elapsed time:  194546
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 397300, loss: 0.0054589340207029415, acc: 99.82406763888117, p_norm: 2230.176680632731, g_norm: 0.2978493027338147, lr:  0.000397, elapsed time:  194595
Step 397400, loss: 0.005326076792002823, acc: 99.82750655710697, p_norm: 2230.2559218496394, g_norm: 0.18659961355095112, lr:  0.000396, elapsed time:  194642
Step 397500, loss: 0.005311017989115498, acc: 99.8283684104681, p_norm: 2230.335136393172, g_norm: 0.1560026274962937, lr:  0.000396, elapsed time:  194689
Step 397600, loss: 0.005485441277687642, acc: 99.8179268091917, p_norm: 2230.4366394270983, g_norm: 0.15339140555314565, lr:  0.000396, elapsed time:  194737
Step 397700, loss: 0.005440911096839045, acc: 99.82216683030128, p_norm: 2230.5353990779404, g_norm: 0.15576227822830863, lr:  0.000396, elapsed time:  194784
Step 397800, loss: 0.005563730510680216, acc: 99.81708976626396, p_norm: 2230.6235557142795, g_norm: 0.16631096550681645, lr:  0.000396, elapsed time:  194831
Step 397900, loss: 0.005763117576661898, acc: 99.81320941448212, p_norm: 2230.7036846540136, g_norm: 0.169194587226243, lr:  0.000396, elapsed time:  194878
Step 398000, loss: 0.005729519054311822, acc: 99.81291209161282, p_norm: 2230.795629886802, g_norm: 0.16915986446061934, lr:  0.000396, elapsed time:  194926
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 398000, eval loss: 0.021695047667653854, eval acc: 99.60604095458984
Step 398100, loss: 0.0058546971425130325, acc: 99.80546072125435, p_norm: 2230.8714382493986, g_norm: 0.30053994576777426, lr:  0.000396, elapsed time:  194980
Step 398200, loss: 0.005522381947371286, acc: 99.82027573883533, p_norm: 2230.956620017364, g_norm: 0.1641707101284803, lr:  0.000396, elapsed time:  195028
Step 398300, loss: 0.005186312994610489, acc: 99.8299237638712, p_norm: 2231.0394387006268, g_norm: 0.16229509326438804, lr:  0.000396, elapsed time:  195076
Step 398400, loss: 0.005764830637126579, acc: 99.8172096312046, p_norm: 2231.1197854701427, g_norm: 0.18123129130618135, lr:  0.000396, elapsed time:  195123
Step 398500, loss: 0.005731951331472374, acc: 99.8096154332161, p_norm: 2231.2065836155807, g_norm: 0.1418368145258288, lr:  0.000396, elapsed time:  195171
Step 398600, loss: 0.005538873132982189, acc: 99.81914107501507, p_norm: 2231.2855389234055, g_norm: 0.15911227747031134, lr:  0.000396, elapsed time:  195219
Step 398700, loss: 0.005524418961740594, acc: 99.82384911179543, p_norm: 2231.380838874578, g_norm: 0.17081863685621676, lr:  0.000396, elapsed time:  195266
Step 398800, loss: 0.005834940181448474, acc: 99.80687519907951, p_norm: 2231.477135957807, g_norm: 0.20456796714438602, lr:  0.000396, elapsed time:  195313
Step 398900, loss: 0.005581100414055982, acc: 99.81605352461338, p_norm: 2231.572124966325, g_norm: 0.1874983342020612, lr:  0.000396, elapsed time:  195361
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6822
Step 399000, loss: 0.005639613284304779, acc: 99.8123896329042, p_norm: 2231.6611219910724, g_norm: 0.1381983542936753, lr:  0.000396, elapsed time:  195410
Step 399100, loss: 0.005349138869360104, acc: 99.8253215700388, p_norm: 2231.7431424700676, g_norm: 0.11249515451666123, lr:  0.000396, elapsed time:  195457
Step 399200, loss: 0.005409260602409632, acc: 99.81975704431534, p_norm: 2231.827646237191, g_norm: 0.13861437077361805, lr:  0.000396, elapsed time:  195504
Step 399300, loss: 0.005439186414314463, acc: 99.81880567967892, p_norm: 2231.904219889301, g_norm: 0.17304415527779474, lr:  0.000396, elapsed time:  195551
Step 399400, loss: 0.005211380801356426, acc: 99.82645350694656, p_norm: 2231.9954321692117, g_norm: 0.11914502301572177, lr:  0.000395, elapsed time:  195599
Step 399500, loss: 0.005649969693861294, acc: 99.81963954865932, p_norm: 2232.084960443969, g_norm: 0.17495855651554335, lr:  0.000395, elapsed time:  195647
Step 399600, loss: 0.005226751805689673, acc: 99.83095712959766, p_norm: 2232.1610337262227, g_norm: 0.16282337099129485, lr:  0.000395, elapsed time:  195694
Step 399700, loss: 0.005669750951719834, acc: 99.81427295506, p_norm: 2232.2325108454484, g_norm: 0.19727330618957936, lr:  0.000395, elapsed time:  195741
Step 399800, loss: 0.005251905739460199, acc: 99.8271419852972, p_norm: 2232.321577304145, g_norm: 0.2277347722303283, lr:  0.000395, elapsed time:  195788
Step 399900, loss: 0.005677529680642692, acc: 99.81226089596748, p_norm: 2232.40300417488, g_norm: 0.27508818437508925, lr:  0.000395, elapsed time:  195836
Step 400000, loss: 0.005454192240604243, acc: 99.81833036243916, p_norm: 2232.486673158222, g_norm: 0.15537131247888125, lr:  0.000395, elapsed time:  195884
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 400000, eval loss: 0.019665620093583133, eval acc: 99.61278533935547
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O c 1 c c c c c 1 - c 1 c [nH] c 2 n c c ( - c 3 c c c c ( C ( = O ) N 4 C C N ( C C N ( C ) C ) C C 4 ) c 3 ) n c 1 2 _EOS
Predicted text: C O c 1 c c c c c 1 - c 1 c [nH] c 2 n c c ( - c 3 c c c c ( C ( = O ) N 4 C C N ( C C N ( C ) C ) C C 4 ) c 3 ) n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c 2 c ( C C N C ( = O ) c 3 c c ( C c 4 c c ( F ) c c c 4 F ) o n 3 ) c [nH] c 2 c c 1 Cl _EOS
Predicted text: C c 1 c c 2 c ( C C N C ( = O ) c 3 c c ( C c 4 c c ( F ) c c c 4 F ) o n 3 ) c [nH] c 2 c c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C N c 1 n c ( N C C = C ( C ) C ) c 2 s c c ( C ) c 2 n 1 _EOS
Predicted text: C = C C N c 1 n c ( N C C = C ( C ) C ) c 2 s c c ( C ) c 2 n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 n o c ( N S ( = O ) ( = O ) c 2 s c c c 2 C c 2 c c c c c 2 ) c 1 Br _EOS
Predicted text: C c 1 n o c ( N S ( = O ) ( = O ) c 2 s c c c 2 C c 2 c c c c c 2 ) c 1 Br _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c c ( [N+] ( = O ) [O-] ) n n 1 C C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C O C ( = O ) c 1 c c ( [N+] ( = O ) [O-] ) n n 1 C C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 400000, eval acc (token): 0.9380790662244917, eval acc (sequence): 0.8897939626257786
Saving at step 400000
Step 400100, loss: 0.005610273251259059, acc: 99.81985296308994, p_norm: 2232.5771568495047, g_norm: 0.15360500228555746, lr:  0.000395, elapsed time:  196002
Step 400200, loss: 0.005802990064530604, acc: 99.81122812628746, p_norm: 2232.6687728639818, g_norm: 0.19939534898902503, lr:  0.000395, elapsed time:  196050
Step 400300, loss: 0.005972926344202279, acc: 99.80499139428139, p_norm: 2232.766166961195, g_norm: 0.20683513785908766, lr:  0.000395, elapsed time:  196097
Step 400400, loss: 0.00567605903686399, acc: 99.81572948396206, p_norm: 2232.8469653604157, g_norm: 0.1742710369058408, lr:  0.000395, elapsed time:  196144
Step 400500, loss: 0.0055766791793575975, acc: 99.82032890617847, p_norm: 2232.932843573167, g_norm: 0.22758808462643493, lr:  0.000395, elapsed time:  196192
Step 400600, loss: 0.0056243112703668885, acc: 99.82022197544575, p_norm: 2233.0259677185068, g_norm: 0.1607068669663455, lr:  0.000395, elapsed time:  196252
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 400700, loss: 0.005583184382880995, acc: 99.81710793663613, p_norm: 2233.113596432602, g_norm: 0.12324490415767948, lr:  0.000395, elapsed time:  196300
Step 400800, loss: 0.005514633294005762, acc: 99.82062704861164, p_norm: 2233.197664333122, g_norm: 0.2991061616039774, lr:  0.000395, elapsed time:  196350
Step 400900, loss: 0.0051832593108247236, acc: 99.82955887913704, p_norm: 2233.278648402806, g_norm: 0.14654578014012948, lr:  0.000395, elapsed time:  196398
Step 401000, loss: 0.0056602981229661965, acc: 99.81886851787567, p_norm: 2233.3656559892033, g_norm: 0.15789962356871282, lr:  0.000395, elapsed time:  196445
Step 401100, loss: 0.00553291882517442, acc: 99.81796365976334, p_norm: 2233.450898572428, g_norm: 0.17226390494920996, lr:  0.000395, elapsed time:  196492
Step 401200, loss: 0.005449076562872506, acc: 99.81969726085663, p_norm: 2233.5414645595492, g_norm: 0.17608706559188356, lr:  0.000395, elapsed time:  196540
Step 401300, loss: 0.005547026315489347, acc: 99.81781224906445, p_norm: 2233.622142905654, g_norm: 0.17773321628268504, lr:  0.000395, elapsed time:  196587
Step 401400, loss: 0.0048058936986853954, acc: 99.84110344946384, p_norm: 2233.6936920371227, g_norm: 0.1990906478298369, lr:  0.000394, elapsed time:  196636
Step 401500, loss: 0.005336654621060006, acc: 99.82473921775818, p_norm: 2233.779955390493, g_norm: 0.1754884207190972, lr:  0.000394, elapsed time:  196684
Step 401600, loss: 0.005439542444564722, acc: 99.82432340085506, p_norm: 2233.867169929824, g_norm: 0.17905124943958634, lr:  0.000394, elapsed time:  196731
Step 401700, loss: 0.005998540042655804, acc: 99.80840699374676, p_norm: 2233.9583368518165, g_norm: 0.22946301041494088, lr:  0.000394, elapsed time:  196779
Step 401800, loss: 0.0058461675911985365, acc: 99.81080104410648, p_norm: 2234.042933547649, g_norm: 0.19047099779404703, lr:  0.000394, elapsed time:  196827
Step 401900, loss: 0.00601134328824628, acc: 99.80450186133385, p_norm: 2234.131111108277, g_norm: 0.31349305755652596, lr:  0.000394, elapsed time:  196875
Step 402000, loss: 0.005471199493345011, acc: 99.81887477636337, p_norm: 2234.217888836381, g_norm: 0.18744387600017892, lr:  0.000394, elapsed time:  196923
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 402000, eval loss: 0.020892982664554437, eval acc: 99.62879943847656
Step 402100, loss: 0.005449982695154176, acc: 99.82391773164272, p_norm: 2234.304571502676, g_norm: 0.09469939837957608, lr:  0.000394, elapsed time:  196978
Step 402200, loss: 0.005478723468959288, acc: 99.82187142968178, p_norm: 2234.3992715368986, g_norm: 0.14724829316064977, lr:  0.000394, elapsed time:  197026
Step 402300, loss: 0.005778660780315477, acc: 99.80901357531548, p_norm: 2234.4898749515373, g_norm: 0.16586176460463942, lr:  0.000394, elapsed time:  197074
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 402400, loss: 0.005486557035305117, acc: 99.81816016119112, p_norm: 2234.569149154679, g_norm: 0.1284544385758442, lr:  0.000394, elapsed time:  197126
Step 402500, loss: 0.005050462591389078, acc: 99.83300903439522, p_norm: 2234.6506505859293, g_norm: 0.12597011491985233, lr:  0.000394, elapsed time:  197175
Step 402600, loss: 0.005274554567049563, acc: 99.82639148831367, p_norm: 2234.7279783618987, g_norm: 0.29675693202333, lr:  0.000394, elapsed time:  197221
Step 402700, loss: 0.005193102373023066, acc: 99.83003735542297, p_norm: 2234.806645710547, g_norm: 0.1606899761049642, lr:  0.000394, elapsed time:  197268
Step 402800, loss: 0.00571372215127667, acc: 99.81226518750191, p_norm: 2234.8952289290482, g_norm: 0.16977231291095077, lr:  0.000394, elapsed time:  197315
Step 402900, loss: 0.005400291671612649, acc: 99.82271875441074, p_norm: 2234.976925262032, g_norm: 0.2377839589469052, lr:  0.000394, elapsed time:  197361
Step 403000, loss: 0.005071091377853918, acc: 99.83038271963596, p_norm: 2235.0604999842326, g_norm: 0.169655874845165, lr:  0.000394, elapsed time:  197407
Step 403100, loss: 0.005146521888336792, acc: 99.82848393917084, p_norm: 2235.1489277764654, g_norm: 0.20929763010662306, lr:  0.000394, elapsed time:  197454
Step 403200, loss: 0.005411203600315276, acc: 99.82345849275589, p_norm: 2235.23935325605, g_norm: 0.11631039373180094, lr:  0.000394, elapsed time:  197501
Step 403300, loss: 0.005554298995048157, acc: 99.8146241903305, p_norm: 2235.322163604477, g_norm: 0.16677764003751397, lr:  0.000394, elapsed time:  197547
Step 403400, loss: 0.005503143735622871, acc: 99.81794111430645, p_norm: 2235.4120910656757, g_norm: 0.25333456085864153, lr:  0.000393, elapsed time:  197594
Step 403500, loss: 0.00605623387164087, acc: 99.79943563044071, p_norm: 2235.507634177043, g_norm: 0.31156932845396945, lr:  0.000393, elapsed time:  197640
Step 403600, loss: 0.0057982614502361685, acc: 99.81214570999146, p_norm: 2235.5858762815424, g_norm: 0.12155230185421205, lr:  0.000393, elapsed time:  197686
Step 403700, loss: 0.005386676306579829, acc: 99.8254841119051, p_norm: 2235.6705121902346, g_norm: 0.6266484514986311, lr:  0.000393, elapsed time:  197733
Step 403800, loss: 0.006040489702209015, acc: 99.80262441933155, p_norm: 2235.770695535256, g_norm: 0.20082110630404837, lr:  0.000393, elapsed time:  197779
Step 403900, loss: 0.005704493750108668, acc: 99.8141905516386, p_norm: 2235.856595980737, g_norm: 0.182728615341758, lr:  0.000393, elapsed time:  197825
Step 404000, loss: 0.005319687689543571, acc: 99.82366923987865, p_norm: 2235.9414995094885, g_norm: 0.18148382057941798, lr:  0.000393, elapsed time:  197872
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 404000, eval loss: 0.021759658431246855, eval acc: 99.61737823486328
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 404100, loss: 0.005653835757037096, acc: 99.81751508677183, p_norm: 2236.025812969898, g_norm: 0.21864633454506613, lr:  0.000393, elapsed time:  197926
Step 404200, loss: 0.0047875815791030615, acc: 99.83585880696774, p_norm: 2236.1050531389187, g_norm: 0.2158367571224828, lr:  0.000393, elapsed time:  197973
Step 404300, loss: 0.005693131635853206, acc: 99.8112376332283, p_norm: 2236.1902920465295, g_norm: 0.19990495990046364, lr:  0.000393, elapsed time:  198019
Step 404400, loss: 0.00531942494062605, acc: 99.82458141446114, p_norm: 2236.2772865153015, g_norm: 0.13150556896260404, lr:  0.000393, elapsed time:  198066
Step 404500, loss: 0.0053063523318769516, acc: 99.82600817084312, p_norm: 2236.352342393886, g_norm: 0.21498233722343615, lr:  0.000393, elapsed time:  198112
Step 404600, loss: 0.00535184617449886, acc: 99.8242262750864, p_norm: 2236.4362963903745, g_norm: 0.10484253132173567, lr:  0.000393, elapsed time:  198159
Step 404700, loss: 0.0055012187657121105, acc: 99.82184110581875, p_norm: 2236.515566649117, g_norm: 0.21856453326328754, lr:  0.000393, elapsed time:  198205
Step 404800, loss: 0.005550720148585242, acc: 99.82006999850273, p_norm: 2236.6015810970653, g_norm: 0.225709400179063, lr:  0.000393, elapsed time:  198252
Step 404900, loss: 0.005660767120016317, acc: 99.81722897291183, p_norm: 2236.6852505157935, g_norm: 0.2512512144999482, lr:  0.000393, elapsed time:  198298
Step 405000, loss: 0.005283583993168577, acc: 99.8284986615181, p_norm: 2236.774894461726, g_norm: 0.22680293964692627, lr:  0.000393, elapsed time:  198345
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C O C ( = O ) c 1 c c c ( O C c 2 c c c ( F ) c c 2 ) n c 1 C ( = O ) O C C _EOS
Predicted text: C C O C ( = O ) c 1 c c c ( O C c 2 c c c ( F ) c c 2 ) n c 1 C ( = O ) O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) c 1 c c 2 c ( c ( C ( C ) ( C ) C ) c 1 ) N C ( = O ) C 2 = O _EOS
Predicted text: C C ( C ) ( C ) c 1 c c 2 c ( c ( C ( C ) ( C ) C ) c 1 ) N C ( = O ) C 2 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: O c 1 c c ( O ) n c ( C 2 C C 2 ) c 1 _EOS
Predicted text: N C ( = O ) c 1 c ( O ) c c ( C 2 C C 2 ) n c 1 O _EOS
acc_token: 0.0, acc_seq: False

Target text: C C O C C ( = O ) c 1 c c 2 [nH] c n c 2 c ( F ) c 1 N c 1 c c c ( Br ) c c 1 Cl _EOS
Predicted text: C C O C C ( O ) c 1 c c 2 [nH] c n c 2 c ( F ) c 1 N c 1 c c c ( Br ) c c 1 Cl _EOS _PAD
acc_token: 0.2564102564102564, acc_seq: False

Target text: C N ( C c 1 c c c ( C ( F ) ( F ) F ) c c 1 ) c 1 c c c ( O c 2 c c c ( C ( = O ) N 3 C C N ( C c 4 c c c c c 4 ) C C 3 ) c c 2 ) n c 1 _EOS
Predicted text: C N ( C c 1 c c c ( C ( F ) ( F ) F ) c c 1 ) c 1 c c c ( O c 2 c c c ( C ( = O ) N 3 C C N ( C c 4 c c c c c 4 ) C C 3 ) c c 2 ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 405000, eval acc (token): 0.9415736577552887, eval acc (sequence): 0.8946199829205806
Saving at step 405000
Step 405100, loss: 0.005540148806339858, acc: 99.81958997249603, p_norm: 2236.852115851293, g_norm: 0.16103278012677513, lr:  0.000393, elapsed time:  198441
Step 405200, loss: 0.005845319264080899, acc: 99.80213117599487, p_norm: 2236.9509607244663, g_norm: 0.2771920948212163, lr:  0.000393, elapsed time:  198487
Step 405300, loss: 0.006089535223327403, acc: 99.80357563495636, p_norm: 2237.0457387178203, g_norm: 0.12939655261092609, lr:  0.000393, elapsed time:  198533
Step 405400, loss: 0.005325982366512108, acc: 99.83047917485237, p_norm: 2237.1207614691302, g_norm: 0.1192801336099607, lr:  0.000393, elapsed time:  198580
Step 405500, loss: 0.00566837712238339, acc: 99.81739614903927, p_norm: 2237.201705275507, g_norm: 0.15000165194678172, lr:  0.000392, elapsed time:  198626
Step 405600, loss: 0.005248849111533218, acc: 99.82600209116936, p_norm: 2237.287862553229, g_norm: 0.17251354952744136, lr:  0.000392, elapsed time:  198673
Step 405700, loss: 0.005471621689403037, acc: 99.81889183819294, p_norm: 2237.377428342029, g_norm: 0.18333217584027775, lr:  0.000392, elapsed time:  198720
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 405800, loss: 0.005691077639063558, acc: 99.81382170423346, p_norm: 2237.4664295453995, g_norm: 0.19807690382556714, lr:  0.000392, elapsed time:  198767
Step 405900, loss: 0.005160125499387504, acc: 99.8293269276619, p_norm: 2237.5417551175296, g_norm: 0.1860001860192027, lr:  0.000392, elapsed time:  198813
Step 406000, loss: 0.005152061318594861, acc: 99.82785823941231, p_norm: 2237.625667628582, g_norm: 0.23326294125717048, lr:  0.000392, elapsed time:  198860
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 406000, eval loss: 0.02333440393733327, eval acc: 99.58161163330078
Step 406100, loss: 0.005478229929331065, acc: 99.8233020156622, p_norm: 2237.7062257768825, g_norm: 0.1732042481034856, lr:  0.000392, elapsed time:  198913
Step 406200, loss: 0.005460854906223176, acc: 99.82213643193245, p_norm: 2237.7814643789825, g_norm: 0.13748424983278454, lr:  0.000392, elapsed time:  198960
Step 406300, loss: 0.005338029685835863, acc: 99.8261411935091, p_norm: 2237.8640148562868, g_norm: 0.276905534418831, lr:  0.000392, elapsed time:  199006
Step 406400, loss: 0.005712991507361948, acc: 99.81544217467308, p_norm: 2237.952816709162, g_norm: 0.12346914391113256, lr:  0.000392, elapsed time:  199053
Step 406500, loss: 0.005541859642371492, acc: 99.81739436089993, p_norm: 2238.0473970208236, g_norm: 0.20815779291405884, lr:  0.000392, elapsed time:  199099
Step 406600, loss: 0.005286724422062434, acc: 99.82598376274109, p_norm: 2238.12437827236, g_norm: 0.11654576108399124, lr:  0.000392, elapsed time:  199146
Step 406700, loss: 0.0058306878280836826, acc: 99.80903911590576, p_norm: 2238.2133801935965, g_norm: 0.18358176615558566, lr:  0.000392, elapsed time:  199192
Step 406800, loss: 0.005466101535539565, acc: 99.82183350622654, p_norm: 2238.290341117677, g_norm: 0.20423998217864375, lr:  0.000392, elapsed time:  199239
Step 406900, loss: 0.005815754529003243, acc: 99.81018255650997, p_norm: 2238.3705626284923, g_norm: 0.18739102580019215, lr:  0.000392, elapsed time:  199285
Step 407000, loss: 0.005036713335894092, acc: 99.83510410785675, p_norm: 2238.4528722128425, g_norm: 0.23976383206249807, lr:  0.000392, elapsed time:  199332
Step 407100, loss: 0.005561437300621037, acc: 99.8166142553091, p_norm: 2238.5498621681386, g_norm: 0.18584830743211664, lr:  0.000392, elapsed time:  199379
Step 407200, loss: 0.005297155687258055, acc: 99.82975493371487, p_norm: 2238.6266735664344, g_norm: 0.3263049875797717, lr:  0.000392, elapsed time:  199425
Step 407300, loss: 0.005506072118951124, acc: 99.82755640149117, p_norm: 2238.7199812584477, g_norm: 0.18011048248625858, lr:  0.000392, elapsed time:  199472
Step 407400, loss: 0.005541603402598412, acc: 99.82448269426823, p_norm: 2238.8077560123184, g_norm: 0.19123703871718725, lr:  0.000392, elapsed time:  199519
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 407500, loss: 0.00571229957616199, acc: 99.81103406354748, p_norm: 2238.909068916665, g_norm: 0.19336367240329078, lr:  0.000392, elapsed time:  199566
Step 407600, loss: 0.005427823071458988, acc: 99.82107119262218, p_norm: 2238.987157394483, g_norm: 0.20000077123714155, lr:  0.000391, elapsed time:  199613
Step 407700, loss: 0.005719536443211837, acc: 99.81698589026928, p_norm: 2239.0619137033204, g_norm: 0.2923283114587322, lr:  0.000391, elapsed time:  199659
Step 407800, loss: 0.00510311115353943, acc: 99.83471482992172, p_norm: 2239.147441581023, g_norm: 0.13160886577912814, lr:  0.000391, elapsed time:  199706
Step 407900, loss: 0.005630816232551297, acc: 99.81871236860752, p_norm: 2239.2308477769225, g_norm: 0.29925298681921436, lr:  0.000391, elapsed time:  199753
Step 408000, loss: 0.005261548162834515, acc: 99.82520279288292, p_norm: 2239.311788338394, g_norm: 0.14677719805093642, lr:  0.000391, elapsed time:  199799
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 408000, eval loss: 0.019991277815943252, eval acc: 99.6341323852539
Step 408100, loss: 0.005155849433258482, acc: 99.82995134592056, p_norm: 2239.405328156582, g_norm: 0.1410979208005789, lr:  0.000391, elapsed time:  199853
Step 408200, loss: 0.005675175984724774, acc: 99.81430919468403, p_norm: 2239.50067612329, g_norm: 0.19127608366282042, lr:  0.000391, elapsed time:  199899
Step 408300, loss: 0.005448908793969167, acc: 99.81999193131924, p_norm: 2239.5914774319112, g_norm: 0.2485414231524363, lr:  0.000391, elapsed time:  199946
Step 408400, loss: 0.005800909588442664, acc: 99.81065885722637, p_norm: 2239.673257416349, g_norm: 0.14527901777878782, lr:  0.000391, elapsed time:  199993
Step 408500, loss: 0.00541784415579059, acc: 99.82475960254669, p_norm: 2239.7546217311315, g_norm: 0.1802563537359052, lr:  0.000391, elapsed time:  200039
Step 408600, loss: 0.0053964103389535015, acc: 99.82497814297676, p_norm: 2239.8396675890713, g_norm: 0.16962826482860371, lr:  0.000391, elapsed time:  200085
Step 408700, loss: 0.005410356999309442, acc: 99.82086418569088, p_norm: 2239.931433655087, g_norm: 0.19696657885332422, lr:  0.000391, elapsed time:  200131
Step 408800, loss: 0.005484777650972319, acc: 99.81633976101875, p_norm: 2240.0200262762087, g_norm: 0.18059268540362627, lr:  0.000391, elapsed time:  200178
Step 408900, loss: 0.00558071633401596, acc: 99.82282477617264, p_norm: 2240.1071468944497, g_norm: 0.14136860329925957, lr:  0.000391, elapsed time:  200224
Step 409000, loss: 0.0055190125987064674, acc: 99.81866805255413, p_norm: 2240.19185912569, g_norm: 0.11470395909315209, lr:  0.000391, elapsed time:  200270
Step 409100, loss: 0.0053591457888569494, acc: 99.82501836121082, p_norm: 2240.263343448711, g_norm: 0.3102765682336666, lr:  0.000391, elapsed time:  200317
Step 409200, loss: 0.005848102534691861, acc: 99.80776180326939, p_norm: 2240.3568280766654, g_norm: 0.17849722201146082, lr:  0.000391, elapsed time:  200364
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 409300, loss: 0.0053079392928339075, acc: 99.82669684786359, p_norm: 2240.4296832287196, g_norm: 0.21156442828124164, lr:  0.000391, elapsed time:  200412
Step 409400, loss: 0.005201516772958712, acc: 99.83166813850403, p_norm: 2240.507165860602, g_norm: 0.19817325257060875, lr:  0.000391, elapsed time:  200458
Step 409500, loss: 0.005208603203218445, acc: 99.82272726297379, p_norm: 2240.5896848892626, g_norm: 0.20724581265380046, lr:  0.000391, elapsed time:  200505
Step 409600, loss: 0.005205149221633292, acc: 99.82867680490017, p_norm: 2240.674742345914, g_norm: 0.2562034915282072, lr:  0.000391, elapsed time:  200552
Step 409700, loss: 0.005058586459281287, acc: 99.84045705199242, p_norm: 2240.755285431926, g_norm: 0.20373844775716332, lr:  0.000390, elapsed time:  200599
Step 409800, loss: 0.005572450050749467, acc: 99.81844647228718, p_norm: 2240.8361162912074, g_norm: 0.23159090895831647, lr:  0.000390, elapsed time:  200646
Step 409900, loss: 0.0050744123969798235, acc: 99.83153550326824, p_norm: 2240.9202799197055, g_norm: 0.20971414663858276, lr:  0.000390, elapsed time:  200692
Step 410000, loss: 0.0058826681956361425, acc: 99.80866414308548, p_norm: 2241.008638359711, g_norm: 0.19220034899722285, lr:  0.000390, elapsed time:  200738
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 410000, eval loss: 0.019696240590728845, eval acc: 99.62347412109375
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C C ( C ) O c 1 c c ( O c 2 c c c ( S ( C ) ( = O ) = O ) c c 2 ) c c ( - c 2 c c c ( C 3 = N C C ( C O ) O 3 ) [nH] 2 ) c 1 _EOS
Predicted text: C O C C ( C ) O c 1 c c ( O c 2 c c c ( S ( C ) ( = O ) = O ) c c 2 ) c c ( - c 2 c c c ( C 3 = N C C ( C O ) O 3 ) [nH] 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C ( = O ) c 1 c c 2 c n c ( N c 3 c c c ( N 4 C C N ( C 5 C C C C 5 ) C C 4 ) c n 3 ) n c 2 n 1 C 1 C C C C 1 _EOS
Predicted text: C N ( C ) C ( = O ) c 1 c c 2 c n c ( N c 3 c c c ( N 4 C C N ( C 5 C C C C 5 ) C C 4 ) c n 3 ) n c 2 n 1 C 1 C C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C C 1 C O C ( N ) = N 1 ) O c 1 c c c ( Cl ) c c 1 _EOS
Predicted text: C C ( C C 1 C O C ( N ) = N 1 ) O c 1 c c c ( Cl ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C O c 1 c c c c 2 c c c ( C C ( C C ( N C ( = O ) O C ( C ) ( C ) C ) C 3 C O 3 ) C ( C ) C ) c c 1 2 _EOS
Predicted text: C O C C O c 1 c c c c 2 c c c ( C C ( C C ( N C ( = O ) O C ( C ) ( C ) C ) C 3 C O 3 ) C ( C ) C ) c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( S ( = O ) ( = O ) O C C ( N C ( = O ) O C ( C ) ( C ) C ) C ( C ) C ) c c 1 _EOS
Predicted text: C c 1 c c c ( S ( = O ) ( = O ) O C C ( N C ( = O ) O C ( C ) ( C ) C ) C ( C ) C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 410000, eval acc (token): 0.9410409774362236, eval acc (sequence): 0.8938350680544436
Saving at step 410000
Step 410100, loss: 0.005599050103592162, acc: 99.82094345986843, p_norm: 2241.1005274146146, g_norm: 0.15283026866963903, lr:  0.000390, elapsed time:  200841
Step 410200, loss: 0.0052829680414652105, acc: 99.82524918019772, p_norm: 2241.184058539895, g_norm: 0.23630743469327678, lr:  0.000390, elapsed time:  200887
Step 410300, loss: 0.005421658573495734, acc: 99.82709078490734, p_norm: 2241.2729238835013, g_norm: 0.17144503897384117, lr:  0.000390, elapsed time:  200933
Step 410400, loss: 0.005931406056561173, acc: 99.80851085484028, p_norm: 2241.3604961387464, g_norm: 0.186709409563487, lr:  0.000390, elapsed time:  200980
Step 410500, loss: 0.005536964829489079, acc: 99.8208028525114, p_norm: 2241.4402493720113, g_norm: 0.15318978766728789, lr:  0.000390, elapsed time:  201026
Step 410600, loss: 0.005622268859324322, acc: 99.81612607836723, p_norm: 2241.516385229003, g_norm: 0.17574156096821766, lr:  0.000390, elapsed time:  201072
Step 410700, loss: 0.005811345189031271, acc: 99.80725711584091, p_norm: 2241.6094959340226, g_norm: 0.1816110755697519, lr:  0.000390, elapsed time:  201118
Step 410800, loss: 0.005370013058909535, acc: 99.81885446608067, p_norm: 2241.6880691389847, g_norm: 0.16028321072775004, lr:  0.000390, elapsed time:  201165
Step 410900, loss: 0.005534349454283074, acc: 99.81767490506172, p_norm: 2241.7689198476055, g_norm: 0.22133733237299633, lr:  0.000390, elapsed time:  201211
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 411000, loss: 0.005344834930348532, acc: 99.82327407702027, p_norm: 2241.8704868778086, g_norm: 0.17502093127971177, lr:  0.000390, elapsed time:  201259
Step 411100, loss: 0.004695445377169562, acc: 99.84769789874554, p_norm: 2241.936327431262, g_norm: 0.12645790494252654, lr:  0.000390, elapsed time:  201307
Step 411200, loss: 0.005116183384157012, acc: 99.83087438344955, p_norm: 2242.0165528202238, g_norm: 0.1991110443481473, lr:  0.000390, elapsed time:  201353
Step 411300, loss: 0.005045443500748661, acc: 99.83425752818584, p_norm: 2242.101754261698, g_norm: 0.14353609345963125, lr:  0.000390, elapsed time:  201399
Step 411400, loss: 0.005412117888090507, acc: 99.82575958967209, p_norm: 2242.1781804465813, g_norm: 0.19266211741367684, lr:  0.000390, elapsed time:  201445
Step 411500, loss: 0.005722416981961942, acc: 99.81300114095211, p_norm: 2242.2601201693633, g_norm: 0.1292603981063557, lr:  0.000390, elapsed time:  201491
Step 411600, loss: 0.005240015204626616, acc: 99.82895143330097, p_norm: 2242.336934902689, g_norm: 0.15036436024547456, lr:  0.000390, elapsed time:  201538
Step 411700, loss: 0.004977050526363201, acc: 99.83374309539795, p_norm: 2242.4194581567695, g_norm: 0.17941215505780805, lr:  0.000390, elapsed time:  201585
Step 411800, loss: 0.005485108927750844, acc: 99.82105281949043, p_norm: 2242.5140717853437, g_norm: 0.2144224633891097, lr:  0.000389, elapsed time:  201631
Step 411900, loss: 0.005705919082820401, acc: 99.81834153831005, p_norm: 2242.600885251816, g_norm: 0.19915539410553357, lr:  0.000389, elapsed time:  201678
Step 412000, loss: 0.00543590117887561, acc: 99.82258677482605, p_norm: 2242.680414729802, g_norm: 0.1648766631747532, lr:  0.000389, elapsed time:  201724
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 412000, eval loss: 0.022493646498624002, eval acc: 99.60199737548828
Step 412100, loss: 0.005739510634903126, acc: 99.80722025036812, p_norm: 2242.76873184278, g_norm: 0.1096634894091822, lr:  0.000389, elapsed time:  201777
Step 412200, loss: 0.005453309696385986, acc: 99.82596345245838, p_norm: 2242.8594809441033, g_norm: 0.1706272627362353, lr:  0.000389, elapsed time:  201823
Step 412300, loss: 0.005646199102434366, acc: 99.81504486501217, p_norm: 2242.9501947358067, g_norm: 0.1675076500605822, lr:  0.000389, elapsed time:  201869
Step 412400, loss: 0.005459966549915407, acc: 99.81950172781944, p_norm: 2243.0264927900666, g_norm: 0.18146113944849562, lr:  0.000389, elapsed time:  201916
Step 412500, loss: 0.005134544124512103, acc: 99.83303345739841, p_norm: 2243.109517388632, g_norm: 0.14696338324046135, lr:  0.000389, elapsed time:  201963
Step 412600, loss: 0.005714109681612171, acc: 99.81550578773022, p_norm: 2243.190085994013, g_norm: 0.24666804902607847, lr:  0.000389, elapsed time:  202009
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 412700, loss: 0.005475926793083791, acc: 99.81834021077228, p_norm: 2243.276088527411, g_norm: 0.14824222298704498, lr:  0.000389, elapsed time:  202057
Step 412800, loss: 0.004981505278337863, acc: 99.83942814171314, p_norm: 2243.3497531047906, g_norm: 0.1181881204176578, lr:  0.000389, elapsed time:  202103
Step 412900, loss: 0.004938334992784803, acc: 99.84031923115253, p_norm: 2243.4284504880543, g_norm: 0.07358294511450666, lr:  0.000389, elapsed time:  202150
Step 413000, loss: 0.0049917266103511795, acc: 99.83505648374557, p_norm: 2243.5156164038067, g_norm: 0.16214953015379832, lr:  0.000389, elapsed time:  202197
Step 413100, loss: 0.005584080061876193, acc: 99.81997813284397, p_norm: 2243.6064844182874, g_norm: 0.1968501844105772, lr:  0.000389, elapsed time:  202244
Step 413200, loss: 0.005279616368861753, acc: 99.82623371481895, p_norm: 2243.690916679946, g_norm: 0.1488711397763164, lr:  0.000389, elapsed time:  202290
Step 413300, loss: 0.005374606784125717, acc: 99.82330869138241, p_norm: 2243.780499320377, g_norm: 0.24780423198650545, lr:  0.000389, elapsed time:  202336
Step 413400, loss: 0.005268626990327902, acc: 99.8261708021164, p_norm: 2243.8520412992616, g_norm: 0.22990840563370174, lr:  0.000389, elapsed time:  202382
Step 413500, loss: 0.005913995861765216, acc: 99.80038331449032, p_norm: 2243.951761746881, g_norm: 0.20594817290623177, lr:  0.000389, elapsed time:  202428
Step 413600, loss: 0.005752110724938575, acc: 99.81102892756462, p_norm: 2244.03854342091, g_norm: 0.21797938987317456, lr:  0.000389, elapsed time:  202475
Step 413700, loss: 0.005359906134071934, acc: 99.82889577746391, p_norm: 2244.118450304381, g_norm: 0.16734526140793332, lr:  0.000389, elapsed time:  202521
Step 413800, loss: 0.005807894305762602, acc: 99.80993634462357, p_norm: 2244.2087532353244, g_norm: 0.335139786358953, lr:  0.000389, elapsed time:  202567
Step 413900, loss: 0.005611886655105991, acc: 99.82046854496002, p_norm: 2244.2873759918116, g_norm: 0.11459620792447178, lr:  0.000388, elapsed time:  202614
Step 414000, loss: 0.005589620596847453, acc: 99.81603243947029, p_norm: 2244.375897580638, g_norm: 0.14875038776142538, lr:  0.000388, elapsed time:  202660
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 414000, eval loss: 0.022428258411746362, eval acc: 99.61128234863281
Step 414100, loss: 0.005312309031251061, acc: 99.82601775228977, p_norm: 2244.4543476693084, g_norm: 0.19689110825400538, lr:  0.000388, elapsed time:  202713
Step 414200, loss: 0.005671023448508094, acc: 99.8163840174675, p_norm: 2244.544318530487, g_norm: 0.20290147073418868, lr:  0.000388, elapsed time:  202760
Step 414300, loss: 0.005244943665693427, acc: 99.83091101050377, p_norm: 2244.626730054189, g_norm: 0.21084933593614646, lr:  0.000388, elapsed time:  202807
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 414400, loss: 0.005108175793355813, acc: 99.83650976907526, p_norm: 2244.7067479189013, g_norm: 0.17281751555548078, lr:  0.000388, elapsed time:  202855
Step 414500, loss: 0.00518929698465854, acc: 99.83148869872093, p_norm: 2244.7906354281595, g_norm: 0.3118584912222105, lr:  0.000388, elapsed time:  202901
Step 414600, loss: 0.005347998628858477, acc: 99.82516375184059, p_norm: 2244.8640189071702, g_norm: 0.23371897302307004, lr:  0.000388, elapsed time:  202948
Step 414700, loss: 0.0054225585146105, acc: 99.8239698857069, p_norm: 2244.9382657019596, g_norm: 0.1861595037487556, lr:  0.000388, elapsed time:  202994
Step 414800, loss: 0.005596140557968283, acc: 99.82023768126965, p_norm: 2245.027423855061, g_norm: 0.23175460278845958, lr:  0.000388, elapsed time:  203041
Step 414900, loss: 0.005374790026180563, acc: 99.82264207303524, p_norm: 2245.1144306585616, g_norm: 0.17206198593846214, lr:  0.000388, elapsed time:  203088
Step 415000, loss: 0.005557898230490537, acc: 99.8193091750145, p_norm: 2245.1897819353144, g_norm: 0.20739797942837984, lr:  0.000388, elapsed time:  203135
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O C c 1 c n 2 c ( n 1 ) s c 1 c c ( Cl ) c c c 1 2 _EOS
Predicted text: O C c 1 c n 2 c ( n 1 ) s c 1 c c ( Cl ) c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) C ( C C 1 C C O C C 1 ) c 1 c c c ( S ( = O ) ( = O ) C 2 C C 2 ) c ( C 2 C C 2 ) c 1 _EOS
Predicted text: C C O C ( = O ) C ( C C 1 C C O C C 1 ) c 1 c c c ( S ( = O ) ( = O ) C 2 C C 2 ) c ( C 2 C C 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( C ) O C ( = O ) N 1 C C N ( c 2 c c c ( N ) c c 2 ) C C 1 _EOS
Predicted text: C C ( C ) ( C ) O C ( = O ) N 1 C C N ( c 2 c c c ( N ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C = C C C = C C C = C C C C C C ( C ) I _EOS
Predicted text: C C C C C C = C C C = C C C = C C C C C C ( C ) I _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N C ( C c 1 c c ( Cl ) c 2 [nH] n c c 2 c 1 ) C ( = O ) N 1 C C C ( N 2 C C C C C 2 ) C C 1 ) N 1 C C C ( N 2 C c 3 c c c c c 3 N C 2 = O ) C C 1 _EOS
Predicted text: O = C ( N C ( C c 1 c c ( Cl ) c 2 [nH] n c c 2 c 1 ) C ( = O ) N 1 C C C ( N 2 C C C C C 2 ) C C 1 ) N 1 C C C ( N 2 C c 3 c c c c c 3 N C 2 = O ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 415000, eval acc (token): 0.9415505738575246, eval acc (sequence): 0.8936745359524239
Saving at step 415000
Step 415100, loss: 0.005210176552873235, acc: 99.8279926776886, p_norm: 2245.26529023325, g_norm: 0.1705190089166427, lr:  0.000388, elapsed time:  203232
Step 415200, loss: 0.005364103886058728, acc: 99.82736684381962, p_norm: 2245.341908864651, g_norm: 0.18623155655698295, lr:  0.000388, elapsed time:  203278
Step 415300, loss: 0.0054615469393456805, acc: 99.81989739835262, p_norm: 2245.4162792394204, g_norm: 0.4499217262276325, lr:  0.000388, elapsed time:  203325
Step 415400, loss: 0.005574070293896512, acc: 99.81467828154564, p_norm: 2245.5092293621256, g_norm: 0.19299730382266905, lr:  0.000388, elapsed time:  203371
Step 415500, loss: 0.0052763177612359866, acc: 99.83183455467224, p_norm: 2245.5902571534366, g_norm: 0.16335271562843792, lr:  0.000388, elapsed time:  203418
Step 415600, loss: 0.00552082700270148, acc: 99.81956508755684, p_norm: 2245.6772910745053, g_norm: 0.22680563299888373, lr:  0.000388, elapsed time:  203463
Step 415700, loss: 0.005235618249116669, acc: 99.83094514906406, p_norm: 2245.761151318952, g_norm: 0.17321719454803594, lr:  0.000388, elapsed time:  203510
Step 415800, loss: 0.005358080919468194, acc: 99.82336384057999, p_norm: 2245.836603755247, g_norm: 0.413913549685583, lr:  0.000388, elapsed time:  203557
Step 415900, loss: 0.005325263873492077, acc: 99.82930964231491, p_norm: 2245.928708569517, g_norm: 0.2068344265011521, lr:  0.000388, elapsed time:  203603
Step 416000, loss: 0.005403187484871523, acc: 99.82101783156395, p_norm: 2246.0080670005227, g_norm: 0.15428024997746329, lr:  0.000387, elapsed time:  203649
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 416000, eval loss: 0.021398399258105202, eval acc: 99.60646057128906
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 416100, loss: 0.0051668612577667325, acc: 99.82987967673365, p_norm: 2246.085165499892, g_norm: 0.1908992144097084, lr:  0.000387, elapsed time:  203704
Step 416200, loss: 0.004996324821704547, acc: 99.83251595497131, p_norm: 2246.174183941969, g_norm: 0.1602805160655977, lr:  0.000387, elapsed time:  203750
Step 416300, loss: 0.005636006129413999, acc: 99.81848023831844, p_norm: 2246.2570729432414, g_norm: 0.120759107417718, lr:  0.000387, elapsed time:  203796
Step 416400, loss: 0.005346760117431586, acc: 99.82840356230736, p_norm: 2246.3442025308746, g_norm: 0.14713581433079057, lr:  0.000387, elapsed time:  203843
Step 416500, loss: 0.005507046740792703, acc: 99.82175612449646, p_norm: 2246.4350902382976, g_norm: 0.14533181577551543, lr:  0.000387, elapsed time:  203890
Step 416600, loss: 0.00564982145673639, acc: 99.81704445183277, p_norm: 2246.523511064921, g_norm: 0.17150262829294924, lr:  0.000387, elapsed time:  203936
Step 416700, loss: 0.005383409683931859, acc: 99.82169723510742, p_norm: 2246.592394964738, g_norm: 0.16443360881251934, lr:  0.000387, elapsed time:  203982
Step 416800, loss: 0.005396590908676444, acc: 99.82497590780258, p_norm: 2246.683354482052, g_norm: 0.2703821139752096, lr:  0.000387, elapsed time:  204029
Step 416900, loss: 0.005385514241133933, acc: 99.82106497883797, p_norm: 2246.7730355389767, g_norm: 0.1989510562273251, lr:  0.000387, elapsed time:  204075
Step 417000, loss: 0.005154722088286689, acc: 99.8303996026516, p_norm: 2246.8597393085097, g_norm: 0.1692912608527541, lr:  0.000387, elapsed time:  204122
Step 417100, loss: 0.005597053674518975, acc: 99.82089081406593, p_norm: 2246.9449398349157, g_norm: 0.1800688914679215, lr:  0.000387, elapsed time:  204168
Step 417200, loss: 0.005740857738446721, acc: 99.8142608255148, p_norm: 2247.033567234745, g_norm: 0.20457807056405772, lr:  0.000387, elapsed time:  204214
Step 417300, loss: 0.00539670994278822, acc: 99.82453009486198, p_norm: 2247.1152799827014, g_norm: 0.2014819979580484, lr:  0.000387, elapsed time:  204261
Step 417400, loss: 0.005298145973238206, acc: 99.82484570145607, p_norm: 2247.197090023431, g_norm: 0.16810557891831313, lr:  0.000387, elapsed time:  204307
Step 417500, loss: 0.005223263856892118, acc: 99.82418324053288, p_norm: 2247.284062027775, g_norm: 0.14298921344175627, lr:  0.000387, elapsed time:  204354
Step 417600, loss: 0.005853459258032672, acc: 99.80655613541603, p_norm: 2247.3829840089074, g_norm: 0.17969338891537207, lr:  0.000387, elapsed time:  204401
Step 417700, loss: 0.005244218509124039, acc: 99.82847593724728, p_norm: 2247.476357921002, g_norm: 0.28991396299564554, lr:  0.000387, elapsed time:  204447
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 417800, loss: 0.005734414106190166, acc: 99.81237909390559, p_norm: 2247.54511278415, g_norm: 0.1509875075402296, lr:  0.000387, elapsed time:  204494
Step 417900, loss: 0.004694576204465193, acc: 99.84550906717777, p_norm: 2247.6163735064238, g_norm: 0.14354419702724797, lr:  0.000387, elapsed time:  204541
Step 418000, loss: 0.0055424597047112915, acc: 99.8177545517683, p_norm: 2247.696665188954, g_norm: 0.10352349391468364, lr:  0.000387, elapsed time:  204587
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 418000, eval loss: 0.0233591782507574, eval acc: 99.57748413085938
Step 418100, loss: 0.004861386567936279, acc: 99.83892394602299, p_norm: 2247.773604826847, g_norm: 0.24589713654848222, lr:  0.000387, elapsed time:  204641
Step 418200, loss: 0.005611828740920827, acc: 99.81557659804821, p_norm: 2247.8550391400345, g_norm: 0.22926690431151986, lr:  0.000386, elapsed time:  204687
Step 418300, loss: 0.005560275989810179, acc: 99.81756170094013, p_norm: 2247.9557941220596, g_norm: 0.21656894005016317, lr:  0.000386, elapsed time:  204734
Step 418400, loss: 0.005895313772598456, acc: 99.80912967026234, p_norm: 2248.0499990533153, g_norm: 0.19223913733240378, lr:  0.000386, elapsed time:  204780
Step 418500, loss: 0.005446288402799837, acc: 99.82176639139652, p_norm: 2248.13222164561, g_norm: 0.16472050304471192, lr:  0.000386, elapsed time:  204826
Step 418600, loss: 0.005450993036620275, acc: 99.8202056735754, p_norm: 2248.2007808488647, g_norm: 0.25093570960113626, lr:  0.000386, elapsed time:  204873
Step 418700, loss: 0.005285995596009343, acc: 99.8249741345644, p_norm: 2248.276868717892, g_norm: 0.1806413521330564, lr:  0.000386, elapsed time:  204919
Step 418800, loss: 0.005238780823218576, acc: 99.82790179550648, p_norm: 2248.3571610797794, g_norm: 0.1454300782247885, lr:  0.000386, elapsed time:  204966
Step 418900, loss: 0.0053406205796272845, acc: 99.8258643746376, p_norm: 2248.4304087979076, g_norm: 0.15058985984991533, lr:  0.000386, elapsed time:  205012
Step 419000, loss: 0.005491171389717237, acc: 99.82284903526306, p_norm: 2248.5102939597205, g_norm: 0.19568710546964754, lr:  0.000386, elapsed time:  205059
Step 419100, loss: 0.005233646840342772, acc: 99.82845114171505, p_norm: 2248.590973971934, g_norm: 0.2202988411457598, lr:  0.000386, elapsed time:  205105
Step 419200, loss: 0.005084419217491813, acc: 99.83005730807781, p_norm: 2248.6711658369277, g_norm: 0.15215133057295643, lr:  0.000386, elapsed time:  205152
Step 419300, loss: 0.0052394139130137775, acc: 99.8264424353838, p_norm: 2248.7567057538467, g_norm: 0.28527466190935125, lr:  0.000386, elapsed time:  205199
Step 419400, loss: 0.005562618575731903, acc: 99.81863732635975, p_norm: 2248.8423956104816, g_norm: 0.22809871057962974, lr:  0.000386, elapsed time:  205245
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 419500, loss: 0.0057206829249534805, acc: 99.81336694451707, p_norm: 2248.94077711579, g_norm: 0.1609470846492575, lr:  0.000386, elapsed time:  205292
Step 419600, loss: 0.0051809541073362195, acc: 99.8309338837862, p_norm: 2249.019654790685, g_norm: 0.21915806824815987, lr:  0.000386, elapsed time:  205339
Step 419700, loss: 0.0050475713791638555, acc: 99.83561888337135, p_norm: 2249.0920967847787, g_norm: 0.1310090199410276, lr:  0.000386, elapsed time:  205386
Step 419800, loss: 0.005132153069989726, acc: 99.83504030108452, p_norm: 2249.1707745171198, g_norm: 0.13263599865220693, lr:  0.000386, elapsed time:  205433
Step 419900, loss: 0.005505138957942108, acc: 99.81953911483288, p_norm: 2249.2419121128783, g_norm: 0.18571723470218576, lr:  0.000386, elapsed time:  205479
Step 420000, loss: 0.0053103670512246025, acc: 99.8210797905922, p_norm: 2249.3164852996906, g_norm: 0.16159534549162766, lr:  0.000386, elapsed time:  205526
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 420000, eval loss: 0.023546531440806574, eval acc: 99.5870361328125
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C N 1 C C C ( C O C c 2 c c ( - c 3 c c c ( C # N ) c c 3 ) c c ( C ( F ) ( F ) F ) c 2 ) ( c 2 c c n c c 2 ) C C 1 _EOS
Predicted text: C N 1 C C C ( C O C c 2 c c ( - c 3 c c c ( C # N ) c c 3 ) c c ( C ( F ) ( F ) F ) c 2 ) ( c 2 c c n c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C c 1 s c ( N C ( = O ) O C ( C ) ( C ) C ) n c 1 C ( = O ) O C P ( = O ) ( O C C ) O C C _EOS
Predicted text: C = C c 1 s c ( N C ( = O ) O C ( C ) ( C ) C ) n c 1 C ( = O ) O C P ( = O ) ( O C C ) O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( C = O ) c n 1 _EOS
Predicted text: C c 1 c c c ( C = O ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N C ( = O ) c 1 c ( C 2 C C 2 ) n c ( C C ) n 1 C c 1 c c c 2 o c ( - c 3 c c c c c 3 N S ( = O ) ( = O ) C ( F ) ( F ) F ) c c 2 c 1 _EOS
Predicted text: C C N C ( = O ) c 1 c ( C 2 C C 2 ) n c ( C C ) n 1 C c 1 c c c 2 o c ( - c 3 c c c c c 3 N S ( = O ) ( = O ) C ( F ) ( F ) F ) c ( C ) c 2 c 1 _EOS
acc_token: 0.9285714285714286, acc_seq: False

Target text: C C # C C O C ( = O ) N 1 C C C ( N 2 C C C 3 ( C C N ( C ( = O ) N ( C ) C ) c 4 c c c c c 4 3 ) C C 2 ) C C 1 _EOS
Predicted text: C C # C C O C ( = O ) N 1 C C C ( N 2 C C C 3 ( C C N ( C ( = O ) N ( C ) C ) c 4 c c c c c 4 3 ) C C 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 420000, eval acc (token): 0.9421599322901095, eval acc (sequence): 0.89421573736321
Saving at step 420000
Step 420100, loss: 0.005572274425526302, acc: 99.82005472481251, p_norm: 2249.4098450411157, g_norm: 0.2399740202690749, lr:  0.000386, elapsed time:  205630
Step 420200, loss: 0.005365201805279867, acc: 99.82542008161545, p_norm: 2249.4918839948828, g_norm: 0.1423286532035058, lr:  0.000386, elapsed time:  205677
Step 420300, loss: 0.005452518318797957, acc: 99.82145911455154, p_norm: 2249.5742169190007, g_norm: 0.16097804544502614, lr:  0.000386, elapsed time:  205723
Step 420400, loss: 0.005835202459884385, acc: 99.80857288837433, p_norm: 2249.6487974997667, g_norm: 0.16999623657577398, lr:  0.000385, elapsed time:  205769
Step 420500, loss: 0.005363558261442449, acc: 99.82320906221867, p_norm: 2249.737647689781, g_norm: 0.18517529219829235, lr:  0.000385, elapsed time:  205816
Step 420600, loss: 0.005204790890375079, acc: 99.8310073018074, p_norm: 2249.8226261816358, g_norm: 0.1867582488785291, lr:  0.000385, elapsed time:  205862
Step 420700, loss: 0.005050380733773636, acc: 99.8328705728054, p_norm: 2249.8943339354187, g_norm: 0.2082144037473473, lr:  0.000385, elapsed time:  205909
Step 420800, loss: 0.0051712478856416055, acc: 99.82949481904507, p_norm: 2249.986431896407, g_norm: 0.21725066508667998, lr:  0.000385, elapsed time:  205956
Step 420900, loss: 0.005707242305561522, acc: 99.81466688215733, p_norm: 2250.079343816123, g_norm: 0.16542262947383238, lr:  0.000385, elapsed time:  206002
Step 421000, loss: 0.005630573313537752, acc: 99.81636691093445, p_norm: 2250.156529397128, g_norm: 0.24893485948045327, lr:  0.000385, elapsed time:  206048
Step 421100, loss: 0.005295066659473377, acc: 99.82560653984547, p_norm: 2250.2358214203746, g_norm: 0.2490063969658313, lr:  0.000385, elapsed time:  206095
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 421200, loss: 0.005693301754263866, acc: 99.80925441379878, p_norm: 2250.324807780687, g_norm: 0.20708542746167147, lr:  0.000385, elapsed time:  206142
Step 421300, loss: 0.005419593664491913, acc: 99.82506203651428, p_norm: 2250.401113271473, g_norm: 0.17332206980929063, lr:  0.000385, elapsed time:  206188
Step 421400, loss: 0.004811627688868611, acc: 99.84318740665913, p_norm: 2250.479574282676, g_norm: 0.13595690903404148, lr:  0.000385, elapsed time:  206235
Step 421500, loss: 0.005358914451626333, acc: 99.82316206395626, p_norm: 2250.552515533398, g_norm: 0.23629079867399352, lr:  0.000385, elapsed time:  206281
Step 421600, loss: 0.0051226964034958656, acc: 99.83520084619522, p_norm: 2250.6311832205934, g_norm: 0.16781619795226915, lr:  0.000385, elapsed time:  206327
Step 421700, loss: 0.00517821591264692, acc: 99.83140158653259, p_norm: 2250.706611033033, g_norm: 0.15888807629693402, lr:  0.000385, elapsed time:  206374
Step 421800, loss: 0.005554544195765629, acc: 99.82104402780533, p_norm: 2250.7821414028003, g_norm: 0.17282130353556638, lr:  0.000385, elapsed time:  206421
Step 421900, loss: 0.005550629095841942, acc: 99.82229061424732, p_norm: 2250.876422132052, g_norm: 0.23340041493825622, lr:  0.000385, elapsed time:  206467
Step 422000, loss: 0.00530828382465188, acc: 99.82541409134865, p_norm: 2250.961918104985, g_norm: 0.257621734810559, lr:  0.000385, elapsed time:  206514
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 422000, eval loss: 0.024300007329238725, eval acc: 99.5616226196289
Step 422100, loss: 0.005359713226389431, acc: 99.82576887309551, p_norm: 2251.051716789659, g_norm: 0.24344275832185946, lr:  0.000385, elapsed time:  206587
Step 422200, loss: 0.005677768872037632, acc: 99.81470085680485, p_norm: 2251.136829958602, g_norm: 0.17741930655523155, lr:  0.000385, elapsed time:  206641
Step 422300, loss: 0.005044984595115238, acc: 99.83721229434013, p_norm: 2251.2087499770864, g_norm: 0.14945240601531384, lr:  0.000385, elapsed time:  206691
Step 422400, loss: 0.005595212289435949, acc: 99.81588253378868, p_norm: 2251.293960192536, g_norm: 0.23827875617655325, lr:  0.000385, elapsed time:  206739
Step 422500, loss: 0.0051359522851157635, acc: 99.83154527842999, p_norm: 2251.372737257299, g_norm: 0.18025693067396653, lr:  0.000385, elapsed time:  206786
Step 422600, loss: 0.0053687614475256855, acc: 99.82428896427155, p_norm: 2251.4441447091253, g_norm: 0.17121319522724326, lr:  0.000384, elapsed time:  206834
Step 422700, loss: 0.005380745386883063, acc: 99.8238807618618, p_norm: 2251.5353935636494, g_norm: 0.21114699602698986, lr:  0.000384, elapsed time:  206881
Step 422800, loss: 0.005635514473378862, acc: 99.81004662811756, p_norm: 2251.6213275812734, g_norm: 0.11587138101896928, lr:  0.000384, elapsed time:  206928
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 422900, loss: 0.0052121877169658765, acc: 99.8293960717187, p_norm: 2251.6904283966473, g_norm: 0.16435945207876823, lr:  0.000384, elapsed time:  206976
Step 423000, loss: 0.004958625969711647, acc: 99.83546653389931, p_norm: 2251.7693264578597, g_norm: 0.20003660179890032, lr:  0.000384, elapsed time:  207024
Step 423100, loss: 0.005397826981434264, acc: 99.8234948515892, p_norm: 2251.852539367123, g_norm: 0.20605346134750233, lr:  0.000384, elapsed time:  207071
Step 423200, loss: 0.005127167092468881, acc: 99.83046972751617, p_norm: 2251.9391416995577, g_norm: 0.18347021373133104, lr:  0.000384, elapsed time:  207119
Step 423300, loss: 0.00509981243258153, acc: 99.83235716819763, p_norm: 2252.0175991348447, g_norm: 0.20418876610318745, lr:  0.000384, elapsed time:  207166
Step 423400, loss: 0.004981760681548621, acc: 99.83466020226479, p_norm: 2252.0962910324206, g_norm: 0.1815136252899647, lr:  0.000384, elapsed time:  207214
Step 423500, loss: 0.005097219874792245, acc: 99.83473908901215, p_norm: 2252.177660235367, g_norm: 0.16910033799215562, lr:  0.000384, elapsed time:  207261
Step 423600, loss: 0.005236573636648245, acc: 99.83205676078796, p_norm: 2252.2628130045646, g_norm: 0.2475031489805731, lr:  0.000384, elapsed time:  207309
Step 423700, loss: 0.005269288547847282, acc: 99.82626181840897, p_norm: 2252.3484880101482, g_norm: 0.1072947689722412, lr:  0.000384, elapsed time:  207357
Step 423800, loss: 0.004949552353457421, acc: 99.84142334759235, p_norm: 2252.4265766581357, g_norm: 0.1418894338211384, lr:  0.000384, elapsed time:  207405
Step 423900, loss: 0.005771766067637145, acc: 99.81382793188095, p_norm: 2252.5097928136506, g_norm: 0.1415317839394427, lr:  0.000384, elapsed time:  207452
Step 424000, loss: 0.0050164531716791316, acc: 99.83366012573242, p_norm: 2252.592542538483, g_norm: 0.2059899564903119, lr:  0.000384, elapsed time:  207500
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 424000, eval loss: 0.020226566156411538, eval acc: 99.62960815429688
Step 424100, loss: 0.005596662443686, acc: 99.8172906190157, p_norm: 2252.6753638045534, g_norm: 0.25342974550568936, lr:  0.000384, elapsed time:  207554
Step 424200, loss: 0.005324412572599612, acc: 99.82223528623581, p_norm: 2252.758784245689, g_norm: 0.20398658352852178, lr:  0.000384, elapsed time:  207602
Step 424300, loss: 0.005227941288244438, acc: 99.83510525524616, p_norm: 2252.837012976865, g_norm: 0.21686052519788965, lr:  0.000384, elapsed time:  207650
Step 424400, loss: 0.005995074488255341, acc: 99.80409176647663, p_norm: 2252.924402338953, g_norm: 0.14506204024706953, lr:  0.000384, elapsed time:  207697
Step 424500, loss: 0.005734118206564744, acc: 99.81316182017326, p_norm: 2253.0125491270255, g_norm: 0.17277941679647138, lr:  0.000384, elapsed time:  207747
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 424600, loss: 0.005411802818350645, acc: 99.82159493574456, p_norm: 2253.095841044179, g_norm: 0.20163112221952176, lr:  0.000384, elapsed time:  207795
Step 424700, loss: 0.00512291378640839, acc: 99.83510538935661, p_norm: 2253.1807242427394, g_norm: 0.16415884091362304, lr:  0.000384, elapsed time:  207842
Step 424800, loss: 0.005199276676692079, acc: 99.82844033837318, p_norm: 2253.259535025397, g_norm: 0.16572525201125335, lr:  0.000383, elapsed time:  207890
Step 424900, loss: 0.005209896433407266, acc: 99.82636837661266, p_norm: 2253.341909448633, g_norm: 0.16127504405631146, lr:  0.000383, elapsed time:  207938
Step 425000, loss: 0.0049351738447603564, acc: 99.8362268358469, p_norm: 2253.429338858007, g_norm: 0.18757630365119374, lr:  0.000383, elapsed time:  207985
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C C c 1 c ( O ) c c 2 o c 3 c c ( Cl ) c ( C N ( C ) C ) n 3 c ( = O ) c 2 c 1 O _EOS
Predicted text: C C C c 1 c ( O ) c c 2 o c 3 c c ( Cl ) c ( C = O ) n 3 c ( = O ) c 2 c 1 O _EOS _PAD _PAD _PAD
acc_token: 0.5476190476190477, acc_seq: False

Target text: C C 1 C ( N ( C ) C ( = O ) C ( F ) ( F ) F ) C N 1 c 1 c ( F ) c c 2 c ( = O ) c ( C ( = O ) O ) c n ( C 3 C C 3 ) c 2 c 1 F _EOS
Predicted text: C C 1 C ( N ( C ) C ( = O ) C ( F ) ( F ) F ) C N 1 c 1 c ( F ) c c 2 c ( = O ) c ( C ( = O ) O ) c n ( C 3 C C 3 ) c 2 c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C C C c 1 c n ( C ( c 2 c c c c c 2 ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c n 1 _EOS
Predicted text: O = C C C c 1 c n ( C ( c 2 c c c c c 2 ) ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N c 1 c c c ( C N 2 C C N ( C ( = O ) O C ( C ) ( C ) C ) C ( C ) C 2 ) n c 1 _EOS
Predicted text: C N c 1 c c c ( C N ( C ) c 2 c c c ( C ( O C ) O C ) n c 2 ) n c 1 _EOS _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.2682926829268293, acc_seq: False

Target text: C C c 1 c c c c ( C ) c 1 C N c 1 c c ( C ( = O ) N 2 C C O C C 2 ) c n 2 c ( C ) c ( C ) n c 1 2 _EOS
Predicted text: C C c 1 c c c c ( C ) c 1 C N c 1 c c ( C ( = O ) N 2 C C O C C 2 ) c n 2 c ( C ) c ( C ) n c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 425000, eval acc (token): 0.9473301006112508, eval acc (sequence): 0.9005563282336578
Saving at step 425000
Step 425100, loss: 0.005390952672605635, acc: 99.82106614112854, p_norm: 2253.50225547407, g_norm: 0.17805108766838765, lr:  0.000383, elapsed time:  208084
Step 425200, loss: 0.005070221329915512, acc: 99.83430689573288, p_norm: 2253.591490714494, g_norm: 0.07975303077787918, lr:  0.000383, elapsed time:  208130
Step 425300, loss: 0.00532014939804867, acc: 99.82384134829044, p_norm: 2253.673498522677, g_norm: 0.17475531394544772, lr:  0.000383, elapsed time:  208177
Step 425400, loss: 0.005145809209407162, acc: 99.83347551524639, p_norm: 2253.752174317175, g_norm: 0.1759657593757974, lr:  0.000383, elapsed time:  208224
Step 425500, loss: 0.005424903532293683, acc: 99.81961280107498, p_norm: 2253.83468557, g_norm: 0.20930692383140484, lr:  0.000383, elapsed time:  208270
Step 425600, loss: 0.005090684181268444, acc: 99.83188544213772, p_norm: 2253.9162383706857, g_norm: 0.1582368090068903, lr:  0.000383, elapsed time:  208316
Step 425700, loss: 0.005371535763683824, acc: 99.82286098599434, p_norm: 2253.9952517475817, g_norm: 0.13290913491299108, lr:  0.000383, elapsed time:  208362
Step 425800, loss: 0.005403579924013684, acc: 99.82775947451591, p_norm: 2254.0738279480397, g_norm: 0.15495151060939052, lr:  0.000383, elapsed time:  208409
Step 425900, loss: 0.0050865244211036045, acc: 99.8328904658556, p_norm: 2254.149480350909, g_norm: 0.13762609162633335, lr:  0.000383, elapsed time:  208455
Step 426000, loss: 0.005687160535817384, acc: 99.81221742928028, p_norm: 2254.2267617283865, g_norm: 0.10470610298319194, lr:  0.000383, elapsed time:  208501
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 426000, eval loss: 0.019549819148678586, eval acc: 99.66387176513672
Step 426100, loss: 0.004991769875296086, acc: 99.8355810791254, p_norm: 2254.3010874985334, g_norm: 0.22581070019249816, lr:  0.000383, elapsed time:  208555
Step 426200, loss: 0.005038809585989838, acc: 99.83352071046829, p_norm: 2254.3756890072036, g_norm: 0.1681172119107691, lr:  0.000383, elapsed time:  208602
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 426300, loss: 0.005251382134254038, acc: 99.82268601211149, p_norm: 2254.4640131289343, g_norm: 0.36350056049990853, lr:  0.000383, elapsed time:  208649
Step 426400, loss: 0.004923727918235272, acc: 99.83693517744541, p_norm: 2254.538549750965, g_norm: 0.17723338651963086, lr:  0.000383, elapsed time:  208696
Step 426500, loss: 0.005107348879191704, acc: 99.83285424113274, p_norm: 2254.623320396833, g_norm: 0.19743352726112598, lr:  0.000383, elapsed time:  208742
Step 426600, loss: 0.0052666912039649105, acc: 99.82308015227318, p_norm: 2254.7205842296607, g_norm: 0.48625922351862927, lr:  0.000383, elapsed time:  208790
Step 426700, loss: 0.005287753336751848, acc: 99.83061940968037, p_norm: 2254.8019889706375, g_norm: 0.25301524586976615, lr:  0.000383, elapsed time:  208836
Step 426800, loss: 0.005367372549808351, acc: 99.82516342401505, p_norm: 2254.8904787323722, g_norm: 0.26429197017952766, lr:  0.000383, elapsed time:  208883
Step 426900, loss: 0.004917703917235485, acc: 99.8378928154707, p_norm: 2254.973289925758, g_norm: 0.18391651587914326, lr:  0.000383, elapsed time:  208930
Step 427000, loss: 0.005265475473288461, acc: 99.8249332010746, p_norm: 2255.0423580273996, g_norm: 0.18401109717343064, lr:  0.000382, elapsed time:  208976
Step 427100, loss: 0.005482017735885165, acc: 99.81487339735031, p_norm: 2255.120287279916, g_norm: 0.1141155219709628, lr:  0.000382, elapsed time:  209022
Step 427200, loss: 0.0052250777482049674, acc: 99.82448656857014, p_norm: 2255.2072472775953, g_norm: 0.17651055466915597, lr:  0.000382, elapsed time:  209069
Step 427300, loss: 0.005299645346158286, acc: 99.82195049524307, p_norm: 2255.292842448977, g_norm: 0.1708192969581404, lr:  0.000382, elapsed time:  209116
Step 427400, loss: 0.005312220205451012, acc: 99.82598750293255, p_norm: 2255.3655898951747, g_norm: 0.17437677186884282, lr:  0.000382, elapsed time:  209163
Step 427500, loss: 0.005229504485128018, acc: 99.83170203864574, p_norm: 2255.457665258279, g_norm: 0.20684482728753956, lr:  0.000382, elapsed time:  209209
Step 427600, loss: 0.0053482054961114045, acc: 99.82348822057247, p_norm: 2255.5227165543542, g_norm: 0.1554486246842197, lr:  0.000382, elapsed time:  209255
Step 427700, loss: 0.00574753173343197, acc: 99.81412479281425, p_norm: 2255.605226958935, g_norm: 0.16401282841503856, lr:  0.000382, elapsed time:  209301
Step 427800, loss: 0.005451457950421172, acc: 99.82190139591694, p_norm: 2255.688456658167, g_norm: 0.21403038229598065, lr:  0.000382, elapsed time:  209348
Step 427900, loss: 0.005177193199656358, acc: 99.82785439491272, p_norm: 2255.775672725907, g_norm: 0.1562220135082433, lr:  0.000382, elapsed time:  209394
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 428000, loss: 0.005348483462232532, acc: 99.82376747924104, p_norm: 2255.863830972815, g_norm: 0.2638474473205774, lr:  0.000382, elapsed time:  209442
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 428000, eval loss: 0.02193568677641451, eval acc: 99.5915756225586
Step 428100, loss: 0.0053562111753444695, acc: 99.82854475080967, p_norm: 2255.9416479387264, g_norm: 0.1320802835619394, lr:  0.000382, elapsed time:  209495
Step 428200, loss: 0.005412532272102908, acc: 99.8166956603527, p_norm: 2256.0275420419434, g_norm: 0.1017354829216854, lr:  0.000382, elapsed time:  209542
Step 428300, loss: 0.005300444491147118, acc: 99.82652100920677, p_norm: 2256.1088133101434, g_norm: 0.27245658802256906, lr:  0.000382, elapsed time:  209588
Step 428400, loss: 0.005002598976443551, acc: 99.83734041452408, p_norm: 2256.179491432021, g_norm: 0.19226160608965895, lr:  0.000382, elapsed time:  209635
Step 428500, loss: 0.005390665152153815, acc: 99.8236953318119, p_norm: 2256.267328914393, g_norm: 0.17213896897595773, lr:  0.000382, elapsed time:  209681
Step 428600, loss: 0.005166341900285261, acc: 99.83076320588589, p_norm: 2256.3351096710653, g_norm: 0.1414053295953066, lr:  0.000382, elapsed time:  209727
Step 428700, loss: 0.0050460605162766115, acc: 99.83090390264988, p_norm: 2256.4117536481012, g_norm: 0.19231863971728977, lr:  0.000382, elapsed time:  209774
Step 428800, loss: 0.005391164075381312, acc: 99.82446153461933, p_norm: 2256.499090612507, g_norm: 0.2114441145721608, lr:  0.000382, elapsed time:  209823
Step 428900, loss: 0.005236002133387956, acc: 99.82960723340511, p_norm: 2256.5908258115164, g_norm: 0.2917662109346264, lr:  0.000382, elapsed time:  209872
Step 429000, loss: 0.005235280685355974, acc: 99.8280995041132, p_norm: 2256.6701555000072, g_norm: 0.35229658790179724, lr:  0.000382, elapsed time:  209919
Step 429100, loss: 0.005377694741300729, acc: 99.82367207109928, p_norm: 2256.7402830268397, g_norm: 0.1274666907461438, lr:  0.000382, elapsed time:  209967
Step 429200, loss: 0.005092345784000827, acc: 99.83467617630959, p_norm: 2256.8036285979706, g_norm: 0.11504869400558841, lr:  0.000381, elapsed time:  210014
Step 429300, loss: 0.004968809864349169, acc: 99.83595694601536, p_norm: 2256.877542591153, g_norm: 0.12516714916173324, lr:  0.000381, elapsed time:  210062
Step 429400, loss: 0.005188208000181476, acc: 99.83449193835258, p_norm: 2256.9586893648057, g_norm: 0.15239463473268733, lr:  0.000381, elapsed time:  210110
Step 429500, loss: 0.005488010439876234, acc: 99.81986755132675, p_norm: 2257.040282548125, g_norm: 0.18527355509195995, lr:  0.000381, elapsed time:  210157
Step 429600, loss: 0.005578734248279034, acc: 99.81510396301746, p_norm: 2257.126907415947, g_norm: 0.2319518787398884, lr:  0.000381, elapsed time:  210204
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 429700, loss: 0.005151992521760391, acc: 99.83041827654957, p_norm: 2257.2043354318466, g_norm: 0.1823668321530129, lr:  0.000381, elapsed time:  210253
Step 429800, loss: 0.005074226886281394, acc: 99.83674222230911, p_norm: 2257.2773542627115, g_norm: 0.21001834743862147, lr:  0.000381, elapsed time:  210300
Step 429900, loss: 0.005093798805546612, acc: 99.83330312371254, p_norm: 2257.359674938017, g_norm: 0.11887587168450413, lr:  0.000381, elapsed time:  210347
Step 430000, loss: 0.005366573198998594, acc: 99.82174010574818, p_norm: 2257.441121493354, g_norm: 0.15648607760476282, lr:  0.000381, elapsed time:  210395
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 430000, eval loss: 0.01892870064044588, eval acc: 99.67018127441406
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( = O ) N C c 1 c c c ( C N ( C ( = O ) O C ( C ) ( C ) C ) C 2 C C C c 3 c c c n c 3 2 ) c ( C O ) c 1 _EOS
Predicted text: C C ( = O ) N C c 1 c c c ( C N ( C ( = O ) O C ( C ) ( C ) C ) C 2 C C C c 3 c c c n c 3 2 ) c ( C O ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) N C C C C C ( C C 1 ( C ( = O ) N C 2 C C C ( C ( = O ) O ) C C 2 ) C C C C 1 ) C ( = O ) O _EOS
Predicted text: C C ( = O ) N C C C C C ( C C 1 ( C ( = O ) N C 2 C C C ( C ( = O ) O ) C C 2 ) C C C C 1 ) C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C O C ( C ( F ) ( F ) F ) ( C ( F ) ( F ) F ) C ( F ) ( F ) C ( F ) ( F ) C ( F ) ( F ) F _EOS
Predicted text: C C C O C ( C ( F ) ( F ) F ) ( C ( F ) ( F ) F ) C ( F ) ( F ) C ( F ) ( F ) C ( F ) ( F ) F _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C C C O c 1 c n c ( - c 2 c c c 3 c ( O C C 4 O C 4 C C C ) c ( F ) c ( F ) c c 3 c 2 F ) n c 1 _EOS
Predicted text: C C C C C C O c 1 c n c ( - c 2 c c c 3 c ( O C C 4 O C 4 C C C ) c ( F ) c ( F ) c c 3 c 2 F ) n c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C = C C O C c 1 c c c ( C ( = O ) c 2 c c c c c 2 ) c c 1 _EOS
Predicted text: O = C ( c 1 c c c c c 1 ) c 1 c c c ( C O C c 2 c c c ( C ( = O ) c 3 c c c c c 3 ) c c 2 ) c c 1 _EOS
acc_token: 0.3, acc_seq: False

Evaluation (without teacher) at step 430000, eval acc (token): 0.9418078990647842, eval acc (sequence): 0.8938169517008081
Saving at step 430000
Step 430100, loss: 0.005514729617780176, acc: 99.81955668330193, p_norm: 2257.5301259728635, g_norm: 0.17019955664069011, lr:  0.000381, elapsed time:  210502
Step 430200, loss: 0.005277742234984544, acc: 99.82788556814194, p_norm: 2257.628706418347, g_norm: 0.19278815467952845, lr:  0.000381, elapsed time:  210549
Step 430300, loss: 0.005416172543973517, acc: 99.82296684384346, p_norm: 2257.71306280407, g_norm: 0.16612887072403212, lr:  0.000381, elapsed time:  210597
Step 430400, loss: 0.005021753994974461, acc: 99.83937914669514, p_norm: 2257.788699578543, g_norm: 0.16315618267465284, lr:  0.000381, elapsed time:  210645
Step 430500, loss: 0.0053045534371995015, acc: 99.82714509963989, p_norm: 2257.8706249540674, g_norm: 0.15290756661850502, lr:  0.000381, elapsed time:  210693
Step 430600, loss: 0.005115623656097341, acc: 99.8328169286251, p_norm: 2257.947037703636, g_norm: 0.16955096855913426, lr:  0.000381, elapsed time:  210740
Step 430700, loss: 0.005007014110988166, acc: 99.83579578995705, p_norm: 2258.01419875249, g_norm: 0.210202613880968, lr:  0.000381, elapsed time:  210788
Step 430800, loss: 0.005579840169166346, acc: 99.8129912763834, p_norm: 2258.098791004126, g_norm: 0.1952488157756819, lr:  0.000381, elapsed time:  210835
Step 430900, loss: 0.005110733581768727, acc: 99.83358669281006, p_norm: 2258.177257821768, g_norm: 0.12866230681528884, lr:  0.000381, elapsed time:  210882
Step 431000, loss: 0.005181689225037189, acc: 99.82898247241974, p_norm: 2258.2606793464884, g_norm: 0.18383818078973313, lr:  0.000381, elapsed time:  210930
Step 431100, loss: 0.005415228345846117, acc: 99.82543382048607, p_norm: 2258.3576803898613, g_norm: 0.21132519364441538, lr:  0.000381, elapsed time:  210978
Step 431200, loss: 0.0052514573259577445, acc: 99.82811810076237, p_norm: 2258.42865890794, g_norm: 0.1619657476852878, lr:  0.000381, elapsed time:  211025
Step 431300, loss: 0.00534897156565421, acc: 99.83073079586029, p_norm: 2258.5202190058358, g_norm: 0.19376263102711144, lr:  0.000381, elapsed time:  211072
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 431400, loss: 0.005563908461355313, acc: 99.8190878342754, p_norm: 2258.6061322414503, g_norm: 0.3754479656686629, lr:  0.000381, elapsed time:  211121
Step 431500, loss: 0.005252792124429107, acc: 99.82597921788692, p_norm: 2258.689601644589, g_norm: 0.1363008668114459, lr:  0.000380, elapsed time:  211168
Step 431600, loss: 0.005127230040880022, acc: 99.82991436123848, p_norm: 2258.7586129981914, g_norm: 0.15014183848655646, lr:  0.000380, elapsed time:  211215
Step 431700, loss: 0.004983814159877511, acc: 99.83744752407074, p_norm: 2258.8237205764444, g_norm: 0.23347589622349843, lr:  0.000380, elapsed time:  211263
Step 431800, loss: 0.0052347805593308296, acc: 99.82933062314987, p_norm: 2258.9046672304544, g_norm: 0.2384727222740318, lr:  0.000380, elapsed time:  211310
Step 431900, loss: 0.005045879545650678, acc: 99.83780333399773, p_norm: 2258.9853935520173, g_norm: 0.14089748211541483, lr:  0.000380, elapsed time:  211358
Step 432000, loss: 0.0050847309779283026, acc: 99.83307166397572, p_norm: 2259.065832563065, g_norm: 0.13590256042053445, lr:  0.000380, elapsed time:  211405
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 432000, eval loss: 0.023191109196486648, eval acc: 99.5892333984375
Step 432100, loss: 0.005334285282760903, acc: 99.82821790874004, p_norm: 2259.1556078799144, g_norm: 0.1410545881184546, lr:  0.000380, elapsed time:  211460
Step 432200, loss: 0.005205023007665659, acc: 99.82518464326859, p_norm: 2259.2335829664466, g_norm: 0.14485702039524617, lr:  0.000380, elapsed time:  211507
Step 432300, loss: 0.005247327663701071, acc: 99.82519505918026, p_norm: 2259.3101074613496, g_norm: 0.23726796348784665, lr:  0.000380, elapsed time:  211555
Step 432400, loss: 0.005015636282960259, acc: 99.83353501558304, p_norm: 2259.391302076656, g_norm: 0.14594216065768797, lr:  0.000380, elapsed time:  211603
Step 432500, loss: 0.005286464057710418, acc: 99.82648093998432, p_norm: 2259.466413699759, g_norm: 0.19147377562396664, lr:  0.000380, elapsed time:  211649
Step 432600, loss: 0.005104206946089107, acc: 99.83496063947678, p_norm: 2259.5467041434395, g_norm: 0.17389660503922144, lr:  0.000380, elapsed time:  211698
Step 432700, loss: 0.005337371796003936, acc: 99.823068857193, p_norm: 2259.6202357403904, g_norm: 0.17841439147399268, lr:  0.000380, elapsed time:  211745
Step 432800, loss: 0.005074289129238423, acc: 99.83458709716797, p_norm: 2259.6965031428917, g_norm: 0.1049133443171559, lr:  0.000380, elapsed time:  211793
Step 432900, loss: 0.005786198476480422, acc: 99.80865068733692, p_norm: 2259.7814793297393, g_norm: 0.14711559839047433, lr:  0.000380, elapsed time:  211840
Step 433000, loss: 0.00546674155945766, acc: 99.81747476756573, p_norm: 2259.8647364328494, g_norm: 0.17028596409190533, lr:  0.000380, elapsed time:  211888
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 433100, loss: 0.005029595555102928, acc: 99.83651241652723, p_norm: 2259.954309359077, g_norm: 0.3938328209720594, lr:  0.000380, elapsed time:  211936
Step 433200, loss: 0.00480627917968377, acc: 99.84119771420956, p_norm: 2260.0337929830507, g_norm: 0.12073963968118878, lr:  0.000380, elapsed time:  211984
Step 433300, loss: 0.0049591501430950305, acc: 99.83565835654736, p_norm: 2260.101326691288, g_norm: 0.12456685380155136, lr:  0.000380, elapsed time:  212031
Step 433400, loss: 0.005048745737742593, acc: 99.83156678080559, p_norm: 2260.1753209107715, g_norm: 0.10555362696918676, lr:  0.000380, elapsed time:  212078
Step 433500, loss: 0.00505905135350531, acc: 99.83763590455055, p_norm: 2260.257219722061, g_norm: 0.24502327916608074, lr:  0.000380, elapsed time:  212126
Step 433600, loss: 0.005442219017722892, acc: 99.82465440034866, p_norm: 2260.3344491070225, g_norm: 0.162442176723311, lr:  0.000380, elapsed time:  212174
Step 433700, loss: 0.004949184269703437, acc: 99.834387794137, p_norm: 2260.416709372678, g_norm: 0.15306862312916172, lr:  0.000380, elapsed time:  212221
Step 433800, loss: 0.005128611869940869, acc: 99.8313710540533, p_norm: 2260.501796830629, g_norm: 0.21840157050874542, lr:  0.000379, elapsed time:  212269
Step 433900, loss: 0.0054943258887578846, acc: 99.81929717957973, p_norm: 2260.5956297817384, g_norm: 0.1948268171060261, lr:  0.000379, elapsed time:  212316
Step 434000, loss: 0.004992800885092947, acc: 99.83701126277447, p_norm: 2260.671253327192, g_norm: 0.14646103263295834, lr:  0.000379, elapsed time:  212364
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 434000, eval loss: 0.023753507561632428, eval acc: 99.58473205566406
Step 434100, loss: 0.0046650793310118385, acc: 99.84444977343082, p_norm: 2260.7545377007973, g_norm: 0.22670443824510703, lr:  0.000379, elapsed time:  212419
Step 434200, loss: 0.005435294743656414, acc: 99.81815749406815, p_norm: 2260.8366936651487, g_norm: 0.18247789649644486, lr:  0.000379, elapsed time:  212467
Step 434300, loss: 0.005312199162299294, acc: 99.82569968700409, p_norm: 2260.920581555681, g_norm: 0.17803592825230163, lr:  0.000379, elapsed time:  212514
Step 434400, loss: 0.00549928680409721, acc: 99.81953400373459, p_norm: 2261.0086271549817, g_norm: 0.1233991188767312, lr:  0.000379, elapsed time:  212562
Step 434500, loss: 0.004972912545185864, acc: 99.83835437893867, p_norm: 2261.0770036182203, g_norm: 0.1553230171912124, lr:  0.000379, elapsed time:  212610
Step 434600, loss: 0.005205493765092797, acc: 99.8358727991581, p_norm: 2261.1517075198826, g_norm: 0.13077164084190968, lr:  0.000379, elapsed time:  212657
Step 434700, loss: 0.005403944842369128, acc: 99.8217358738184, p_norm: 2261.242191264067, g_norm: 0.17391451937446417, lr:  0.000379, elapsed time:  212705
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 434800, loss: 0.004787100112848263, acc: 99.84184468058736, p_norm: 2261.3183957506617, g_norm: 0.11013772150605823, lr:  0.000379, elapsed time:  212753
Step 434900, loss: 0.00500028404706427, acc: 99.83602634072304, p_norm: 2261.390265282579, g_norm: 0.22236517373173081, lr:  0.000379, elapsed time:  212801
Step 435000, loss: 0.004756053436822185, acc: 99.84871590137482, p_norm: 2261.4605918853304, g_norm: 0.22771535470776036, lr:  0.000379, elapsed time:  212849
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C C C C ( = O ) O ) N 1 C C N ( c 2 c c c 3 c c c c c 3 n 2 ) C C 1 _EOS
Predicted text: C C ( C C C C ( = O ) O ) N 1 C C N ( c 2 c c c 3 c c c c c 3 n 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = S ( = O ) ( N c 1 n c ( - c 2 c c c c c 2 Cl ) c s 1 ) c 1 c c c ( Cl ) c ( Cl ) c 1 Cl _EOS
Predicted text: O = S ( = O ) ( N c 1 n c ( - c 2 c c c c c 2 Cl ) c s 1 ) c 1 c c c ( Cl ) c ( Cl ) c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C C ( C # N ) c 1 n n ( C c 2 c c c ( F ) c ( Cl ) c 2 ) c ( = O ) c 2 c ( O C ) c 3 n ( c 1 2 ) C C N ( C ) C 3 = O _EOS
Predicted text: C O C ( = O ) C C ( C # N ) c 1 n n ( C c 2 c c c ( F ) c ( Cl ) c 2 ) c ( = O ) c 2 c ( O C ) c 3 n ( c 1 2 ) C C N ( C ) C 3 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C S ( = O ) ( = O ) N c 1 c c ( C ( O ) C N C 2 C C N ( c 3 c c c ( C C 4 S C ( = O ) N ( C C ( = O ) O ) C 4 = O ) c c 3 ) C C 2 ) c c c 1 O _EOS
Predicted text: C S ( = O ) ( = O ) N c 1 c c ( C ( O ) C N C 2 C C N ( c 3 c c c ( C C 4 S C ( = O ) N ( C C ( = O ) O ) C 4 = O ) c c 3 ) C C 2 ) c c c 1 O _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C C ( C ) N ( C ( = O ) N ( C C Cl ) N = O ) C 1 O C ( C O ) C ( O ) C ( O ) C 1 O _EOS
Predicted text: C O C C ( C ) N ( C ( = O ) N ( C C Cl ) N = O ) C 1 O C ( C O ) C ( O ) C ( O ) C 1 O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 435000, eval acc (token): 0.9435552806318569, eval acc (sequence): 0.8937623584396908
Saving at step 435000
Step 435100, loss: 0.005226292974630269, acc: 99.8256122469902, p_norm: 2261.5481389073047, g_norm: 0.11584333577177897, lr:  0.000379, elapsed time:  212938
Step 435200, loss: 0.005143921242670331, acc: 99.83469192683697, p_norm: 2261.630257642447, g_norm: 0.3392839775816969, lr:  0.000379, elapsed time:  212977
Step 435300, loss: 0.005594017436978902, acc: 99.81606175005436, p_norm: 2261.709444889005, g_norm: 0.11807061029353554, lr:  0.000379, elapsed time:  213016
Step 435400, loss: 0.005353011325460102, acc: 99.8212111145258, p_norm: 2261.800435745749, g_norm: 0.18542519637241106, lr:  0.000379, elapsed time:  213056
Step 435500, loss: 0.005223072745602622, acc: 99.8283860385418, p_norm: 2261.8854369405935, g_norm: 0.12979601002308744, lr:  0.000379, elapsed time:  213095
Step 435600, loss: 0.005361985227218611, acc: 99.82185190916061, p_norm: 2261.9564886374756, g_norm: 0.2444887206713115, lr:  0.000379, elapsed time:  213134
Step 435700, loss: 0.005100826842317474, acc: 99.8329883813858, p_norm: 2262.0305333254973, g_norm: 0.1411642128169951, lr:  0.000379, elapsed time:  213174
Step 435800, loss: 0.005017244164664589, acc: 99.83768951892853, p_norm: 2262.1123117870197, g_norm: 0.18169702747036134, lr:  0.000379, elapsed time:  213214
Step 435900, loss: 0.005535190816108298, acc: 99.82011806964874, p_norm: 2262.1881161654383, g_norm: 0.23013714987847736, lr:  0.000379, elapsed time:  213253
Step 436000, loss: 0.0055432745919688385, acc: 99.82122130692005, p_norm: 2262.2662646793633, g_norm: 0.18427923939811555, lr:  0.000379, elapsed time:  213292
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Evaluation (with teacher) at step 436000, eval loss: 0.021255486644222405, eval acc: 99.63196563720703
Step 436100, loss: 0.00520689300579761, acc: 99.83033484220505, p_norm: 2262.3518220523965, g_norm: 0.13631790060408974, lr:  0.000378, elapsed time:  213337
Step 436200, loss: 0.005246802468027454, acc: 99.82558979094028, p_norm: 2262.4195095182126, g_norm: 0.16931647096603158, lr:  0.000378, elapsed time:  213377
Step 436300, loss: 0.004944055882060638, acc: 99.83731861412525, p_norm: 2262.5028241105674, g_norm: 0.21337005206784407, lr:  0.000378, elapsed time:  213417
Step 436400, loss: 0.005082914884642378, acc: 99.83414362370968, p_norm: 2262.580493434049, g_norm: 0.24344678178227552, lr:  0.000378, elapsed time:  213456
Calling G2SDataset.batch()
Done, time:  0.61 s, total batches: 6822
Step 436500, loss: 0.005379478117328951, acc: 99.8231827769031, p_norm: 2262.661944508479, g_norm: 0.1710626292281533, lr:  0.000378, elapsed time:  213497
Step 436600, loss: 0.005009210190078193, acc: 99.83699569106102, p_norm: 2262.741738783629, g_norm: 0.2167650628895452, lr:  0.000378, elapsed time:  213536
Step 436700, loss: 0.005261797710245446, acc: 99.82917514443398, p_norm: 2262.8140584364032, g_norm: 0.12498459972669712, lr:  0.000378, elapsed time:  213576
Step 436800, loss: 0.0050878275425748146, acc: 99.8333221822977, p_norm: 2262.892760633577, g_norm: 0.19341956627908183, lr:  0.000378, elapsed time:  213615
Step 436900, loss: 0.004926782682414341, acc: 99.83386990427971, p_norm: 2262.976841763448, g_norm: 0.1741627335024883, lr:  0.000378, elapsed time:  213655
Step 437000, loss: 0.0050689945067188096, acc: 99.83159765601158, p_norm: 2263.057943097053, g_norm: 0.23255605193373616, lr:  0.000378, elapsed time:  213694
Step 437100, loss: 0.005140334524476202, acc: 99.83319371938705, p_norm: 2263.1331739743896, g_norm: 0.16821155552168998, lr:  0.000378, elapsed time:  213733
Step 437200, loss: 0.004875077226179201, acc: 99.8385810405016, p_norm: 2263.206313704264, g_norm: 0.20505101828548103, lr:  0.000378, elapsed time:  213772
Step 437300, loss: 0.00519497879685332, acc: 99.82978744804859, p_norm: 2263.289053857768, g_norm: 0.19188417936120625, lr:  0.000378, elapsed time:  213811
Step 437400, loss: 0.005291614495790782, acc: 99.82354548573494, p_norm: 2263.3663810878743, g_norm: 0.37676823521465425, lr:  0.000378, elapsed time:  213850
Step 437500, loss: 0.005290079045394123, acc: 99.82696714997292, p_norm: 2263.449257704477, g_norm: 0.1443092984261261, lr:  0.000378, elapsed time:  213889
Step 437600, loss: 0.005194237515306668, acc: 99.82721200585365, p_norm: 2263.528431307682, g_norm: 0.29806405727877916, lr:  0.000378, elapsed time:  213929
Step 437700, loss: 0.005193507151780068, acc: 99.82905800640583, p_norm: 2263.6034643412263, g_norm: 0.1488818891647219, lr:  0.000378, elapsed time:  213968
Step 437800, loss: 0.00507500535962663, acc: 99.83213801681995, p_norm: 2263.687051607, g_norm: 0.1567692880033266, lr:  0.000378, elapsed time:  214007
Step 437900, loss: 0.005140467631690626, acc: 99.83308106660843, p_norm: 2263.76713162777, g_norm: 0.2603753183062599, lr:  0.000378, elapsed time:  214047
Step 438000, loss: 0.005329044958498344, acc: 99.82534517347813, p_norm: 2263.8561647397814, g_norm: 0.19644740402067645, lr:  0.000378, elapsed time:  214086
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 526
Evaluation (with teacher) at step 438000, eval loss: 0.022827117661763627, eval acc: 99.61099243164062
Step 438100, loss: 0.005119545247925999, acc: 99.83062022924423, p_norm: 2263.9348234622757, g_norm: 0.204850230100718, lr:  0.000378, elapsed time:  214130
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6822
Step 438200, loss: 0.005186659365799597, acc: 99.835565745534, p_norm: 2264.0041596643964, g_norm: 0.17597344221874112, lr:  0.000378, elapsed time:  214170
Step 438300, loss: 0.004800903803197798, acc: 99.84016358852386, p_norm: 2264.08526807259, g_norm: 0.12657611334983518, lr:  0.000378, elapsed time:  214210
Step 438400, loss: 0.00483941099754702, acc: 99.83959050476551, p_norm: 2264.149279464209, g_norm: 0.18828811197797696, lr:  0.000377, elapsed time:  214249
Step 438500, loss: 0.005010069563149954, acc: 99.836609095335, p_norm: 2264.220228662029, g_norm: 0.18324247165830818, lr:  0.000377, elapsed time:  214289
Step 438600, loss: 0.004959843679025653, acc: 99.83570615947247, p_norm: 2264.296082827237, g_norm: 0.14552830759926516, lr:  0.000377, elapsed time:  214328
Step 438700, loss: 0.0051590347412548, acc: 99.82923546433449, p_norm: 2264.3879943619, g_norm: 0.19505319450096198, lr:  0.000377, elapsed time:  214367
Step 438800, loss: 0.005083889974703198, acc: 99.83364394307137, p_norm: 2264.4567551573573, g_norm: 0.3969377742248299, lr:  0.000377, elapsed time:  214406
Step 438900, loss: 0.0049232620712700735, acc: 99.83778363466263, p_norm: 2264.5465250546895, g_norm: 0.13287711982216482, lr:  0.000377, elapsed time:  214446
Step 439000, loss: 0.005069363081429401, acc: 99.83572448790073, p_norm: 2264.627872950787, g_norm: 0.3933358176814173, lr:  0.000377, elapsed time:  214485
Step 439100, loss: 0.005363322967778004, acc: 99.81765100359917, p_norm: 2264.7077255602253, g_norm: 0.16754575075026562, lr:  0.000377, elapsed time:  214524
Step 439200, loss: 0.00540340021191696, acc: 99.82038415968418, p_norm: 2264.7876408690086, g_norm: 0.18928044237923777, lr:  0.000377, elapsed time:  214564
Step 439300, loss: 0.005190025176834752, acc: 99.8326990455389, p_norm: 2264.8607959969236, g_norm: 0.17889982333466434, lr:  0.000377, elapsed time:  214604
Step 439400, loss: 0.005043021289934586, acc: 99.83230774104595, p_norm: 2264.933673244106, g_norm: 0.13946683950003777, lr:  0.000377, elapsed time:  214644
Step 439500, loss: 0.005194694154595254, acc: 99.83207964897156, p_norm: 2265.011900756564, g_norm: 0.20668257343077887, lr:  0.000377, elapsed time:  214683
Step 439600, loss: 0.005420135922900044, acc: 99.81724260747433, p_norm: 2265.1024301110456, g_norm: 0.25036975155556795, lr:  0.000377, elapsed time:  214722
Step 439700, loss: 0.005031634682823096, acc: 99.8319780677557, p_norm: 2265.190639010936, g_norm: 0.15885816959267623, lr:  0.000377, elapsed time:  214761
Step 439800, loss: 0.005070981515145832, acc: 99.82852277159691, p_norm: 2265.271905569429, g_norm: 0.20730171960465663, lr:  0.000377, elapsed time:  214801
Calling G2SDataset.batch()
Done, time:  0.62 s, total batches: 6823
Step 439900, loss: 0.0056441543951386034, acc: 99.81447129107234, p_norm: 2265.3472497618495, g_norm: 0.13909251088943686, lr:  0.000377, elapsed time:  214841
Step 440000, loss: 0.00505611017189949, acc: 99.83300113677979, p_norm: 2265.4285283565087, g_norm: 0.19603249919720458, lr:  0.000377, elapsed time:  214880
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Evaluation (with teacher) at step 440000, eval loss: 0.02356545392588486, eval acc: 99.59368896484375
Calling G2SDataset.batch()
Done, time:  0.04 s, total batches: 527
Target text: C n 1 c ( C ( F ) ( F ) F ) c n c ( - c 2 c c 3 c ( c c 2 F ) O C C ( = O ) N 3 ) c 1 = O _EOS
Predicted text: C n 1 c ( C ( F ) ( F ) F ) c n c ( - c 2 c c 3 c ( c c 2 F ) O C C ( = O ) N 3 ) c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C # N ) c c c 2 n c ( N ) n c ( N ) c 1 2 _EOS
Predicted text: C c 1 c ( C # N ) c c c 2 n c ( N ) n c ( N ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( C ) n c ( N 2 C C ( C ) C C ( C ) C 2 ) n 1 _EOS
Predicted text: C c 1 c c ( C ) n c ( N 2 C C ( C ) O C ( C ) C 2 ) n 1 _EOS
acc_token: 0.9655172413793104, acc_seq: False

Target text: C c 1 c c ( N 2 C C ( C N C ( = O ) c 3 c c c ( Cl ) s 3 ) O C 2 = O ) c c c 1 N 1 C C C N ( C C O ) C 1 = O _EOS
Predicted text: C c 1 c c ( N 2 C C ( C N C ( = O ) c 3 c c c ( Cl ) s 3 ) O C 2 = O ) c c c 1 N 1 C C C N ( C C O ) C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( C ( = O ) N C 2 C C 2 ) c c c 1 N c 1 n c c 2 c ( n 1 ) N ( C 1 C C C ( F ) ( F ) C 1 ) C C 1 ( C C 1 ) C ( = O ) N 2 C _EOS
Predicted text: C O c 1 c c ( C ( = O ) N C 2 C C 2 ) c c c 1 N c 1 n c c 2 c ( n 1 ) N ( C 1 C C C ( F ) ( F ) C 1 ) C C 1 ( C C 1 ) C ( = O ) N 2 C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 440000, eval acc (token): 0.9433874432056174, eval acc (sequence): 0.8988063424193836
Saving at step 440000
Step 440100, loss: 0.00488837345738375, acc: 99.83837702870369, p_norm: 2265.4978491305956, g_norm: 0.21758622952368512, lr:  0.000377, elapsed time:  214980
Step 440200, loss: 0.004913715545990271, acc: 99.83763839304447, p_norm: 2265.5726712084615, g_norm: 0.2418842604576925, lr:  0.000377, elapsed time:  215028
Step 440300, loss: 0.005116785205404995, acc: 99.83876356482506, p_norm: 2265.6559268583283, g_norm: 0.17572612269897217, lr:  0.000377, elapsed time:  215076
Step 440400, loss: 0.004969628598701092, acc: 99.83570690453053, p_norm: 2265.7349843689058, g_norm: 0.17030244141207693, lr:  0.000377, elapsed time:  215124
Step 440500, loss: 0.004724917950024974, acc: 99.84803070127964, p_norm: 2265.810409987961, g_norm: 0.2836151207534375, lr:  0.000377, elapsed time:  215171
Step 440600, loss: 0.005164385166908687, acc: 99.8340317606926, p_norm: 2265.886921301683, g_norm: 0.17385801228423262, lr:  0.000377, elapsed time:  215218
Step 440700, loss: 0.005399806689154047, acc: 99.82403810322285, p_norm: 2265.9652972416907, g_norm: 0.28601328507832047, lr:  0.000376, elapsed time:  215265
Step 440800, loss: 0.0054175492505783044, acc: 99.82620958983898, p_norm: 2266.0551852322537, g_norm: 0.19475026035336834, lr:  0.000376, elapsed time:  215312
Step 440900, loss: 0.005394032474032429, acc: 99.82453191280365, p_norm: 2266.143627694294, g_norm: 0.26783868191137294, lr:  0.000376, elapsed time:  215360
Step 441000, loss: 0.005104101111936643, acc: 99.83685825765133, p_norm: 2266.2287985484422, g_norm: 0.1459984958640999, lr:  0.000376, elapsed time:  215408
Step 441100, loss: 0.005215999831925729, acc: 99.83568543195724, p_norm: 2266.3030264725617, g_norm: 0.22893041955011315, lr:  0.000376, elapsed time:  215455
Step 441200, loss: 0.005264906999900632, acc: 99.82776576280594, p_norm: 2266.3839496817486, g_norm: 0.18534515585447903, lr:  0.000376, elapsed time:  215503
Step 441300, loss: 0.0050760567938232274, acc: 99.82880641520023, p_norm: 2266.4578021469433, g_norm: 0.224000606723006, lr:  0.000376, elapsed time:  215550
Step 441400, loss: 0.004998764455808669, acc: 99.8333193808794, p_norm: 2266.5347628913482, g_norm: 0.13169266175736116, lr:  0.000376, elapsed time:  215598
Step 441500, loss: 0.005374276489146723, acc: 99.82198812067509, p_norm: 2266.6200038376, g_norm: 0.15757694019428836, lr:  0.000376, elapsed time:  215645
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 441600, loss: 0.005033123543042112, acc: 99.83296290816503, p_norm: 2266.697073332423, g_norm: 0.224813397490942, lr:  0.000376, elapsed time:  215694
Step 441700, loss: 0.00512550605184515, acc: 99.83326733112335, p_norm: 2266.7781289651825, g_norm: 0.21862708250433033, lr:  0.000376, elapsed time:  215741
Step 441800, loss: 0.005079031758550627, acc: 99.82920990884304, p_norm: 2266.851677300812, g_norm: 0.16428013052970628, lr:  0.000376, elapsed time:  215789
Step 441900, loss: 0.005369679867035302, acc: 99.82559058070183, p_norm: 2266.9298391453344, g_norm: 0.24459042699923986, lr:  0.000376, elapsed time:  215836
Step 442000, loss: 0.004965059399310121, acc: 99.83552710711956, p_norm: 2267.0050114846927, g_norm: 0.1749050990582236, lr:  0.000376, elapsed time:  215883
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 442000, eval loss: 0.024259898772215818, eval acc: 99.58375549316406
Step 442100, loss: 0.005040776485648166, acc: 99.83698439598083, p_norm: 2267.076567343224, g_norm: 0.16453570665776157, lr:  0.000376, elapsed time:  215938
Step 442200, loss: 0.0050399300993535685, acc: 99.82925926148891, p_norm: 2267.154208349031, g_norm: 0.1417182492370457, lr:  0.000376, elapsed time:  215986
Step 442300, loss: 0.005069531309036392, acc: 99.83291009068489, p_norm: 2267.2331570674237, g_norm: 0.1838402661179045, lr:  0.000376, elapsed time:  216033
Step 442400, loss: 0.005163652975488731, acc: 99.82932478189468, p_norm: 2267.3259092834787, g_norm: 0.10735955170751475, lr:  0.000376, elapsed time:  216080
Step 442500, loss: 0.005156301260813052, acc: 99.83148327469826, p_norm: 2267.4038235807643, g_norm: 0.14566321946326305, lr:  0.000376, elapsed time:  216128
Step 442600, loss: 0.0051143673528713405, acc: 99.83176827430725, p_norm: 2267.4852420150883, g_norm: 0.14019414759810025, lr:  0.000376, elapsed time:  216176
Step 442700, loss: 0.005087876159468579, acc: 99.83606831729412, p_norm: 2267.565679620459, g_norm: 0.24180433302283807, lr:  0.000376, elapsed time:  216223
Step 442800, loss: 0.005209637410348478, acc: 99.8301160633564, p_norm: 2267.6471721440425, g_norm: 0.33884992601460295, lr:  0.000376, elapsed time:  216271
Step 442900, loss: 0.005018289722233931, acc: 99.83298550546169, p_norm: 2267.7143535134264, g_norm: 0.11526199233193529, lr:  0.000376, elapsed time:  216319
Step 443000, loss: 0.005251445508952202, acc: 99.82776509225368, p_norm: 2267.7935415830148, g_norm: 0.22368984141150705, lr:  0.000376, elapsed time:  216366
Step 443100, loss: 0.0053917192174913, acc: 99.82297423481941, p_norm: 2267.87374437799, g_norm: 0.11728183396712819, lr:  0.000375, elapsed time:  216414
Step 443200, loss: 0.005145242503929239, acc: 99.83284226059914, p_norm: 2267.9598439547417, g_norm: 0.1254512508485156, lr:  0.000375, elapsed time:  216461
Step 443300, loss: 0.005117766399694119, acc: 99.8364177197218, p_norm: 2268.029003917696, g_norm: 0.17058479398465629, lr:  0.000375, elapsed time:  216509
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 443400, loss: 0.005029737919554356, acc: 99.83553461933846, p_norm: 2268.1029221058147, g_norm: 0.14466121433065288, lr:  0.000375, elapsed time:  216558
Step 443500, loss: 0.004829486336516311, acc: 99.84159089624882, p_norm: 2268.1702961360497, g_norm: 0.13263070986005338, lr:  0.000375, elapsed time:  216606
Step 443600, loss: 0.005143307020198336, acc: 99.83130952715874, p_norm: 2268.2504304424797, g_norm: 0.1902706975757137, lr:  0.000375, elapsed time:  216653
Step 443700, loss: 0.0052728386423586925, acc: 99.82222793996334, p_norm: 2268.3397796657237, g_norm: 0.2031316913216418, lr:  0.000375, elapsed time:  216701
Step 443800, loss: 0.00505559039398122, acc: 99.83625791966915, p_norm: 2268.4195682186746, g_norm: 0.12835922517157194, lr:  0.000375, elapsed time:  216748
Step 443900, loss: 0.005177707724160427, acc: 99.83053258061409, p_norm: 2268.4921386100136, g_norm: 0.1357949634817018, lr:  0.000375, elapsed time:  216795
Step 444000, loss: 0.004849740724148432, acc: 99.83963684737682, p_norm: 2268.5758957043577, g_norm: 0.20618504348447933, lr:  0.000375, elapsed time:  216843
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 444000, eval loss: 0.021671698553029722, eval acc: 99.6259994506836
Step 444100, loss: 0.005278925097691171, acc: 99.82438710331917, p_norm: 2268.646063552152, g_norm: 0.204457012588693, lr:  0.000375, elapsed time:  216897
Step 444200, loss: 0.00531179471095129, acc: 99.82170428335667, p_norm: 2268.718905781131, g_norm: 0.16433436083188668, lr:  0.000375, elapsed time:  216945
Step 444300, loss: 0.004953634735975356, acc: 99.84012676775455, p_norm: 2268.798317989108, g_norm: 0.12309843253089009, lr:  0.000375, elapsed time:  216992
Step 444400, loss: 0.005314275634054866, acc: 99.82063779234886, p_norm: 2268.8807387647976, g_norm: 0.147663340902133, lr:  0.000375, elapsed time:  217040
Step 444500, loss: 0.004778242831341686, acc: 99.83701848983765, p_norm: 2268.9531555502695, g_norm: 0.20933882500621476, lr:  0.000375, elapsed time:  217087
Step 444600, loss: 0.005264558629951352, acc: 99.82465216517448, p_norm: 2269.036390639227, g_norm: 0.16686393356175183, lr:  0.000375, elapsed time:  217135
Step 444700, loss: 0.005191715385326461, acc: 99.83261114358902, p_norm: 2269.1214303907955, g_norm: 0.11358924210269125, lr:  0.000375, elapsed time:  217182
Step 444800, loss: 0.005140511475256062, acc: 99.83478009700775, p_norm: 2269.1923394348373, g_norm: 0.17579009261875847, lr:  0.000375, elapsed time:  217230
Step 444900, loss: 0.005355985632022566, acc: 99.8252422362566, p_norm: 2269.2842074510986, g_norm: 0.24442591922749698, lr:  0.000375, elapsed time:  217277
Step 445000, loss: 0.005159585492347105, acc: 99.83005025982857, p_norm: 2269.353693581968, g_norm: 0.16706382430733474, lr:  0.000375, elapsed time:  217324
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C 1 C C ( n 2 c c ( C = C Br ) c ( = O ) [nH] c 2 = O ) O C 1 C O S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 _EOS
Predicted text: C O C 1 C C ( n 2 c c ( C = C Br ) c ( = O ) [nH] c 2 = O ) O C 1 C O S ( = O ) ( = O ) c 1 c c c ( C ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( C C C C ( C C ( = O ) O ) C ( = O ) N C ( C ( = O ) N C ( C ) c 2 c c c c c 2 ) C ( C ) ( C ) C ) c c c 1 O c 1 c c c c c 1 _EOS
Predicted text: C c 1 c c ( C C C C ( C C ( = O ) O ) C ( = O ) N C ( C ( = O ) N C ( C ) c 2 c c c c c 2 ) C ( C ) ( C ) C ) c c c 1 O c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c 2 c ( s 1 ) C N ( C ) C C C 2 O c 1 c c c c ( Br ) c 1 Cl _EOS
Predicted text: C c 1 c c 2 c ( s 1 ) C N ( C ) C C C 2 O c 1 c c c c ( Br ) c 1 Cl _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( O ) C ( N c 1 c c c ( C # N ) c ( Cl ) c 1 Cl ) C ( = O ) N N C ( = O ) c 1 c c c c c 1 _EOS
Predicted text: C C ( O ) C ( N c 1 c c c ( C # N ) c ( Cl ) c 1 Cl ) C ( = O ) N N C ( = O ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C O S ( = O ) ( = O ) O _EOS
Predicted text: O = S ( = O ) ( [O-] ) C C C C O _EOS
acc_token: 0.1875, acc_seq: False

Evaluation (without teacher) at step 445000, eval acc (token): 0.9395531734348382, eval acc (sequence): 0.8907139372255651
Saving at step 445000
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 445100, loss: 0.004850598107869831, acc: 99.83842189039164, p_norm: 2269.4317745875974, g_norm: 0.12596380284153638, lr:  0.000375, elapsed time:  217423
Step 445200, loss: 0.004605976424659275, acc: 99.85034848749638, p_norm: 2269.501718957328, g_norm: 0.17653790225067634, lr:  0.000375, elapsed time:  217471
Step 445300, loss: 0.0053587165010503665, acc: 99.82517051696777, p_norm: 2269.57484309085, g_norm: 0.18180186612169397, lr:  0.000375, elapsed time:  217518
Step 445400, loss: 0.00468636743067691, acc: 99.84397426247597, p_norm: 2269.6532116258168, g_norm: 0.15198264659143892, lr:  0.000374, elapsed time:  217566
Step 445500, loss: 0.004900453495872625, acc: 99.84337057173252, p_norm: 2269.736713830133, g_norm: 0.17744075707298793, lr:  0.000374, elapsed time:  217613
Step 445600, loss: 0.005121470927933842, acc: 99.83349421620369, p_norm: 2269.8182556591883, g_norm: 0.1626517739790188, lr:  0.000374, elapsed time:  217661
Step 445700, loss: 0.004941958633908144, acc: 99.83802084624767, p_norm: 2269.886696788122, g_norm: 0.17386162006504277, lr:  0.000374, elapsed time:  217709
Step 445800, loss: 0.004916080102293563, acc: 99.8385224044323, p_norm: 2269.9594133294813, g_norm: 0.1568902548422336, lr:  0.000374, elapsed time:  217757
Step 445900, loss: 0.0051013154897100324, acc: 99.82900765538216, p_norm: 2270.0408929622054, g_norm: 0.28050530545004937, lr:  0.000374, elapsed time:  217804
Step 446000, loss: 0.005380549428768973, acc: 99.82532539963722, p_norm: 2270.1139248430613, g_norm: 0.13047438607380415, lr:  0.000374, elapsed time:  217851
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 446000, eval loss: 0.024236791125949834, eval acc: 99.56600189208984
Step 446100, loss: 0.005592952213210083, acc: 99.81739342212677, p_norm: 2270.191401248902, g_norm: 0.1718692999376188, lr:  0.000374, elapsed time:  217905
Step 446200, loss: 0.004835215743119079, acc: 99.84095232188702, p_norm: 2270.262032827723, g_norm: 0.21232085486045, lr:  0.000374, elapsed time:  217952
Step 446300, loss: 0.005401594848426612, acc: 99.82491517066956, p_norm: 2270.3481178036836, g_norm: 0.2009306520249914, lr:  0.000374, elapsed time:  218000
Step 446400, loss: 0.005073513388629181, acc: 99.8322105705738, p_norm: 2270.4288303195613, g_norm: 0.2876410815699731, lr:  0.000374, elapsed time:  218047
Step 446500, loss: 0.005265758607692988, acc: 99.82292076945305, p_norm: 2270.5096885576427, g_norm: 0.2826116982207802, lr:  0.000374, elapsed time:  218095
Step 446600, loss: 0.0053187396390239885, acc: 99.8290238827467, p_norm: 2270.587451960634, g_norm: 0.2160576876553777, lr:  0.000374, elapsed time:  218142
Step 446700, loss: 0.004910341648337635, acc: 99.83746345341206, p_norm: 2270.6636171903197, g_norm: 0.2592142545786088, lr:  0.000374, elapsed time:  218190
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 446800, loss: 0.004878800457279041, acc: 99.84064054844102, p_norm: 2270.7435795088404, g_norm: 0.20074354961514448, lr:  0.000374, elapsed time:  218239
Step 446900, loss: 0.004976865126755001, acc: 99.83863388001919, p_norm: 2270.822366364935, g_norm: 0.23519830407048858, lr:  0.000374, elapsed time:  218286
Step 447000, loss: 0.005055524161498397, acc: 99.834587007761, p_norm: 2270.9075359990675, g_norm: 0.19025780698953926, lr:  0.000374, elapsed time:  218334
Step 447100, loss: 0.0050156603226650985, acc: 99.8399017304182, p_norm: 2270.976380508705, g_norm: 0.14552473431282628, lr:  0.000374, elapsed time:  218382
Step 447200, loss: 0.005170138014691474, acc: 99.82877746224403, p_norm: 2271.053806047564, g_norm: 0.1804403248989619, lr:  0.000374, elapsed time:  218429
Step 447300, loss: 0.004970633658240331, acc: 99.8373711258173, p_norm: 2271.130408808271, g_norm: 0.23905563306915842, lr:  0.000374, elapsed time:  218477
Step 447400, loss: 0.005123989274006817, acc: 99.8315005749464, p_norm: 2271.214154982477, g_norm: 0.22944248402508366, lr:  0.000374, elapsed time:  218524
Step 447500, loss: 0.005077430769924831, acc: 99.83271366357803, p_norm: 2271.279252195338, g_norm: 0.23300936206958567, lr:  0.000374, elapsed time:  218571
Step 447600, loss: 0.004831248562486508, acc: 99.84008394181728, p_norm: 2271.35220536098, g_norm: 0.21505497445842783, lr:  0.000374, elapsed time:  218619
Step 447700, loss: 0.005382486355365472, acc: 99.82076373696327, p_norm: 2271.439599791722, g_norm: 0.13492985582736425, lr:  0.000374, elapsed time:  218667
Step 447800, loss: 0.005192775486339087, acc: 99.8234324157238, p_norm: 2271.5202668299917, g_norm: 0.25057882168896406, lr:  0.000373, elapsed time:  218713
Step 447900, loss: 0.005105605328344609, acc: 99.82865978777409, p_norm: 2271.59390022418, g_norm: 0.14335698261012075, lr:  0.000373, elapsed time:  218762
Step 448000, loss: 0.004948693515534615, acc: 99.8328316360712, p_norm: 2271.679545899305, g_norm: 0.09994894839829824, lr:  0.000373, elapsed time:  218809
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 448000, eval loss: 0.02477553194380562, eval acc: 99.59078979492188
Step 448100, loss: 0.005495023959147147, acc: 99.81292919814587, p_norm: 2271.7623297811883, g_norm: 0.19375106224196093, lr:  0.000373, elapsed time:  218864
Step 448200, loss: 0.0050598925155372855, acc: 99.83488212525845, p_norm: 2271.8442172805558, g_norm: 0.16262198353847737, lr:  0.000373, elapsed time:  218912
Step 448300, loss: 0.005431837091864508, acc: 99.82041049003601, p_norm: 2271.925295802387, g_norm: 0.1400043499459859, lr:  0.000373, elapsed time:  218959
Step 448400, loss: 0.0051333610087021956, acc: 99.83353932201862, p_norm: 2271.994928259285, g_norm: 0.22364544763432956, lr:  0.000373, elapsed time:  219006
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 448500, loss: 0.00478976021489505, acc: 99.84473328732379, p_norm: 2272.067630404066, g_norm: 0.15139103050686725, lr:  0.000373, elapsed time:  219054
Step 448600, loss: 0.00482732338680762, acc: 99.8399359434843, p_norm: 2272.133355457423, g_norm: 0.15642523345389828, lr:  0.000373, elapsed time:  219101
Step 448700, loss: 0.004673710680326622, acc: 99.84225526452065, p_norm: 2272.200056988897, g_norm: 0.2626490610703189, lr:  0.000373, elapsed time:  219150
Step 448800, loss: 0.004979529078404994, acc: 99.83867302536964, p_norm: 2272.282686645037, g_norm: 0.24670210719317362, lr:  0.000373, elapsed time:  219198
Step 448900, loss: 0.005080078773498826, acc: 99.83192487061024, p_norm: 2272.360086260861, g_norm: 0.15291682331831566, lr:  0.000373, elapsed time:  219245
Step 449000, loss: 0.0048695770474205344, acc: 99.8412212729454, p_norm: 2272.430601949715, g_norm: 0.18016296962884795, lr:  0.000373, elapsed time:  219293
Step 449100, loss: 0.004965669680841529, acc: 99.83695487678051, p_norm: 2272.508043914828, g_norm: 0.14002441097317145, lr:  0.000373, elapsed time:  219340
Step 449200, loss: 0.0050823816023967084, acc: 99.82928685843945, p_norm: 2272.582296267798, g_norm: 0.16506868430322288, lr:  0.000373, elapsed time:  219388
Step 449300, loss: 0.005238613547198838, acc: 99.82910542190075, p_norm: 2272.6588148456117, g_norm: 0.3903093534134426, lr:  0.000373, elapsed time:  219435
Step 449400, loss: 0.005490236346004167, acc: 99.81678661704063, p_norm: 2272.7435554690746, g_norm: 0.11851831666272078, lr:  0.000373, elapsed time:  219482
Step 449500, loss: 0.004895653607873101, acc: 99.84112213551998, p_norm: 2272.824409090062, g_norm: 0.22986376599425468, lr:  0.000373, elapsed time:  219530
Step 449600, loss: 0.005034423656297804, acc: 99.83373552560806, p_norm: 2272.905076291367, g_norm: 0.1511347188308842, lr:  0.000373, elapsed time:  219578
Step 449700, loss: 0.0052285920460417405, acc: 99.82571393251419, p_norm: 2272.9831459645084, g_norm: 0.1884290996749305, lr:  0.000373, elapsed time:  219625
Step 449800, loss: 0.005152655716838126, acc: 99.82711333036423, p_norm: 2273.055601836612, g_norm: 0.2321205048335527, lr:  0.000373, elapsed time:  219672
Step 449900, loss: 0.004894094829796814, acc: 99.8424855619669, p_norm: 2273.1277499077687, g_norm: 0.2138208396701875, lr:  0.000373, elapsed time:  219720
Step 450000, loss: 0.005018558042793302, acc: 99.83026392757893, p_norm: 2273.208176087492, g_norm: 0.11792724989806688, lr:  0.000373, elapsed time:  219767
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 450000, eval loss: 0.02025584802267987, eval acc: 99.6615982055664
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) ( C ) c 1 c s c ( - c 2 c c 3 c c ( C S c 4 c c c c c 4 C O ) c c c 3 o 2 ) n 1 _EOS
Predicted text: C C ( C ) ( C ) c 1 c s c ( - c 2 c c 3 c c ( C S c 4 c c c c c 4 C O ) c c c 3 o 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C O ) s c 2 c ( = O ) c ( C ( = O ) N C c 3 c c c ( Cl ) c c 3 ) c n ( C ) c 1 2 _EOS
Predicted text: C c 1 c ( C O ) s c 2 c ( = O ) c ( C ( = O ) N C c 3 c c c ( Cl ) c c 3 ) c n ( C ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) c 1 c ( - c 2 c c c c c 2 ) c 2 c c ( Br ) c c c 2 c ( = O ) n 1 C c 1 c c c ( C ( = O ) N 2 C C C ( C ( = O ) O ) C C 2 ) c c 1 _EOS
Predicted text: C O C ( = O ) c 1 c ( - c 2 c c c c c 2 ) c 2 c c ( Br ) c c c 2 c ( = O ) n 1 C c 1 c c c ( C ( = O ) N 2 C C C ( C ( = O ) O ) C C 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C # N ) c ( - c 2 n c ( - c 3 c c c c n 3 ) n o 2 ) c 1 _EOS
Predicted text: C O c 1 c c c ( C # N ) c ( - c 2 n c ( - c 3 c c c c n 3 ) n o 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( O C C O c 2 c c c ( C c 3 c c ( C 4 O C ( C O ) C ( O ) C ( O ) C 4 O ) c c c 3 Cl ) c c 2 ) C C 1 _EOS
Predicted text: C C 1 ( O C C O c 2 c c c ( C c 3 c c ( C 4 O C ( C O ) C ( O ) C ( O ) C 4 O ) c c c 3 Cl ) c c 2 ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 450000, eval acc (token): 0.9478649817043857, eval acc (sequence): 0.9030292479108635
Saving at step 450000
Step 450100, loss: 0.005368537957610897, acc: 99.82014687359333, p_norm: 2273.2949523109646, g_norm: 0.10800295592814177, lr:  0.000373, elapsed time:  219873
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 450200, loss: 0.004894894116524252, acc: 99.83993111854763, p_norm: 2273.368969189009, g_norm: 0.09336553850622942, lr:  0.000372, elapsed time:  219921
Step 450300, loss: 0.0045227767663527626, acc: 99.8522724956274, p_norm: 2273.432067736204, g_norm: 0.15360564121331918, lr:  0.000372, elapsed time:  219969
Step 450400, loss: 0.00506998858337738, acc: 99.82758566737175, p_norm: 2273.511453139984, g_norm: 0.17113505817201694, lr:  0.000372, elapsed time:  220016
Step 450500, loss: 0.005187096413519612, acc: 99.82839640974998, p_norm: 2273.598765286533, g_norm: 0.1896792649238171, lr:  0.000372, elapsed time:  220064
Step 450600, loss: 0.0052324702892428835, acc: 99.82644566893578, p_norm: 2273.679774232684, g_norm: 0.15329627635293133, lr:  0.000372, elapsed time:  220111
Step 450700, loss: 0.004892143599381598, acc: 99.84069918096066, p_norm: 2273.749053700971, g_norm: 0.10886547769745814, lr:  0.000372, elapsed time:  220159
Step 450800, loss: 0.005006167197120703, acc: 99.83329644799232, p_norm: 2273.814335919803, g_norm: 0.1915882530632344, lr:  0.000372, elapsed time:  220206
Step 450900, loss: 0.004938507669530736, acc: 99.83877861499786, p_norm: 2273.8884260366717, g_norm: 0.2348931992917755, lr:  0.000372, elapsed time:  220253
Step 451000, loss: 0.004922318350445494, acc: 99.8326336145401, p_norm: 2273.960169848733, g_norm: 0.21399570981766905, lr:  0.000372, elapsed time:  220301
Step 451100, loss: 0.0052124952027224935, acc: 99.82977768778801, p_norm: 2274.045044068306, g_norm: 0.26169649905755715, lr:  0.000372, elapsed time:  220348
Step 451200, loss: 0.00533277236455433, acc: 99.82544888556004, p_norm: 2274.127607356839, g_norm: 0.18072364106190328, lr:  0.000372, elapsed time:  220396
Step 451300, loss: 0.005205070042093212, acc: 99.82748794555664, p_norm: 2274.211830027312, g_norm: 0.2992323800273326, lr:  0.000372, elapsed time:  220444
Step 451400, loss: 0.005336230034936306, acc: 99.82477180659771, p_norm: 2274.296760229878, g_norm: 0.17008809000684103, lr:  0.000372, elapsed time:  220495
Step 451500, loss: 0.005403313827332568, acc: 99.82379205524921, p_norm: 2274.3735151473807, g_norm: 0.21343505092470905, lr:  0.000372, elapsed time:  220548
Step 451600, loss: 0.004722912315482972, acc: 99.84426054358482, p_norm: 2274.446632418385, g_norm: 0.1203343368847084, lr:  0.000372, elapsed time:  220596
Step 451700, loss: 0.005306997349880476, acc: 99.82643802464008, p_norm: 2274.5219257470394, g_norm: 0.17258078438776522, lr:  0.000372, elapsed time:  220644
Step 451800, loss: 0.005407567183169704, acc: 99.82616916298866, p_norm: 2274.603243254425, g_norm: 0.17784359009750694, lr:  0.000372, elapsed time:  220691
Calling G2SDataset.batch()
Done, time:  0.66 s, total batches: 6823
Step 451900, loss: 0.004747464705403458, acc: 99.8464230577744, p_norm: 2274.6766587187485, g_norm: 0.15212862955248235, lr:  0.000372, elapsed time:  220740
Step 452000, loss: 0.0045592258932629194, acc: 99.8516017794609, p_norm: 2274.738265727396, g_norm: 0.22506230337599764, lr:  0.000372, elapsed time:  220788
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 452000, eval loss: 0.022904206683816715, eval acc: 99.61244201660156
Step 452100, loss: 0.0048698712605937545, acc: 99.8392396569252, p_norm: 2274.8039923449824, g_norm: 0.24373402213535583, lr:  0.000372, elapsed time:  220842
Step 452200, loss: 0.004824098550197959, acc: 99.83610148727894, p_norm: 2274.88352138553, g_norm: 0.1778366031560265, lr:  0.000372, elapsed time:  220890
Step 452300, loss: 0.005147925594865228, acc: 99.8322130292654, p_norm: 2274.963284022624, g_norm: 0.3026602535446579, lr:  0.000372, elapsed time:  220937
Step 452400, loss: 0.00495349911392168, acc: 99.8373576104641, p_norm: 2275.041911264237, g_norm: 0.2150343843098687, lr:  0.000372, elapsed time:  220985
Step 452500, loss: 0.0047720109660122035, acc: 99.8426354676485, p_norm: 2275.1220337149075, g_norm: 0.28763169375418146, lr:  0.000372, elapsed time:  221032
Step 452600, loss: 0.005014905636508047, acc: 99.83532504737377, p_norm: 2275.1918412990954, g_norm: 0.18811425044825011, lr:  0.000371, elapsed time:  221080
Step 452700, loss: 0.00495461801534475, acc: 99.83472815155983, p_norm: 2275.266920977467, g_norm: 0.22592039933132696, lr:  0.000371, elapsed time:  221127
Step 452800, loss: 0.005324970251185732, acc: 99.82437200844288, p_norm: 2275.353698467791, g_norm: 0.12405945829625076, lr:  0.000371, elapsed time:  221174
Step 452900, loss: 0.005195032416064577, acc: 99.83183786273003, p_norm: 2275.4278984212997, g_norm: 0.20658755865232833, lr:  0.000371, elapsed time:  221222
Step 453000, loss: 0.005149537551069443, acc: 99.8342023640871, p_norm: 2275.499823516727, g_norm: 0.3138881572439798, lr:  0.000371, elapsed time:  221270
Step 453100, loss: 0.0052607101811918255, acc: 99.82371605932713, p_norm: 2275.5820750299404, g_norm: 0.20761491785945912, lr:  0.000371, elapsed time:  221318
Step 453200, loss: 0.0053271734340432884, acc: 99.82137368619442, p_norm: 2275.6586306725194, g_norm: 0.1897084004801255, lr:  0.000371, elapsed time:  221365
Step 453300, loss: 0.005223704628197084, acc: 99.8304398804903, p_norm: 2275.7245336967817, g_norm: 0.227210729316045, lr:  0.000371, elapsed time:  221412
Step 453400, loss: 0.0052283438365611805, acc: 99.82833793759346, p_norm: 2275.8000285702824, g_norm: 0.18604082180159498, lr:  0.000371, elapsed time:  221460
Step 453500, loss: 0.005097352190132369, acc: 99.83163905143738, p_norm: 2275.8752215356903, g_norm: 0.1479043313079174, lr:  0.000371, elapsed time:  221508
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 453600, loss: 0.004772130436268023, acc: 99.8432028382351, p_norm: 2275.944425524475, g_norm: 0.1826713888101954, lr:  0.000371, elapsed time:  221556
Step 453700, loss: 0.005420187930158135, acc: 99.81896452605724, p_norm: 2276.0275235144527, g_norm: 0.20753877395610032, lr:  0.000371, elapsed time:  221603
Step 453800, loss: 0.004795602976028022, acc: 99.84316824376583, p_norm: 2276.107396537588, g_norm: 0.11949958494348319, lr:  0.000371, elapsed time:  221651
Step 453900, loss: 0.0045587711649250195, acc: 99.85297040641308, p_norm: 2276.1772074593096, g_norm: 0.16738864618302962, lr:  0.000371, elapsed time:  221699
Step 454000, loss: 0.004974592238495461, acc: 99.8375966399908, p_norm: 2276.2437841812366, g_norm: 0.11954661252332872, lr:  0.000371, elapsed time:  221746
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 454000, eval loss: 0.024326942766733736, eval acc: 99.59233856201172
Step 454100, loss: 0.0051612941702819624, acc: 99.83097338676453, p_norm: 2276.3281586306407, g_norm: 0.13461772737947975, lr:  0.000371, elapsed time:  221801
Step 454200, loss: 0.0048630871778323126, acc: 99.84202465415001, p_norm: 2276.409199803131, g_norm: 0.19559916660286059, lr:  0.000371, elapsed time:  221848
Step 454300, loss: 0.004732018128020172, acc: 99.84586018323898, p_norm: 2276.4729040593083, g_norm: 0.31245863860664064, lr:  0.000371, elapsed time:  221897
Step 454400, loss: 0.005108817891727995, acc: 99.8325568139553, p_norm: 2276.5499818040926, g_norm: 0.14098055133422535, lr:  0.000371, elapsed time:  221944
Step 454500, loss: 0.005236363978310692, acc: 99.8333320170641, p_norm: 2276.639794690648, g_norm: 0.22334844928732345, lr:  0.000371, elapsed time:  221991
Step 454600, loss: 0.00493876828768407, acc: 99.8409631550312, p_norm: 2276.7098918528304, g_norm: 0.32558922668771056, lr:  0.000371, elapsed time:  222038
Step 454700, loss: 0.005330221526919559, acc: 99.82352465391159, p_norm: 2276.7886002687683, g_norm: 0.13299247749584023, lr:  0.000371, elapsed time:  222086
Step 454800, loss: 0.005109086490710979, acc: 99.8341501802206, p_norm: 2276.8729918570148, g_norm: 0.207447554186995, lr:  0.000371, elapsed time:  222134
Step 454900, loss: 0.0052473634053694694, acc: 99.82959035038948, p_norm: 2276.9502514640553, g_norm: 0.17694092236633993, lr:  0.000371, elapsed time:  222181
Step 455000, loss: 0.00498277347700423, acc: 99.8356317281723, p_norm: 2277.0273846817245, g_norm: 0.1309296355710595, lr:  0.000371, elapsed time:  222229
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C [N+] ( C ) ( C C C C N C ( = O ) C c 1 c c c ( O C c 2 c c c c c 2 ) c c 1 ) C C N C ( = O ) c 1 n c ( Cl ) c ( N ) n c 1 N _EOS
Predicted text: C [N+] ( C ) ( C C C C N C ( = O ) C c 1 c c c ( O C c 2 c c c c c 2 ) c c 1 ) C C N C ( = O ) c 1 n c ( Cl ) c ( N ) n c 1 N _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C N ( C C ( O ) C ( C c 1 c c c c c 1 ) N C ( = O ) O C 1 C O C 2 O C C C 1 2 ) S ( = O ) ( = O ) c 1 c c c ( F ) c ( C # N ) c 1 _EOS
Predicted text: C C ( C ) C N ( C C ( O ) C ( C c 1 c c c c c 1 ) N C ( = O ) O C 1 C O C 2 O C C C 1 2 ) S ( = O ) ( = O ) c 1 c c c ( F ) c ( C # N ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c ( O c 2 n s n c ( Cl ) c 2 = O ) c n 1 _EOS
Predicted text: C c 1 c c c ( O c 2 n s n c ( Cl ) c 2 = O ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c ( F ) c ( C O c 2 n s c ( N C ( = O ) N C C C 3 C C C N 3 C ) c 2 C ( N ) = O ) c ( F ) c 1 F _EOS
Predicted text: C c 1 c c ( F ) c ( C O c 2 n s c ( N C ( = O ) N C C C 3 C C C N 3 C ) c 2 C ( N ) = O ) c ( F ) c 1 F _EOS
acc_token: 1.0, acc_seq: True

Target text: C O C ( = O ) C ( C ) ( C ) O c 1 c c c ( Cl ) c 2 [nH] c ( = O ) c ( C c 3 c c c ( Cl ) c c 3 ) c ( C ) c 1 2 _EOS
Predicted text: C O C ( = O ) C ( C ) ( C ) O c 1 c c c ( Cl ) c 2 [nH] c ( = O ) c ( C c 3 c c c ( Cl ) c c 3 ) c ( C ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 455000, eval acc (token): 0.9480684178547277, eval acc (sequence): 0.9026449071468767
Saving at step 455000
Step 455100, loss: 0.005163448285543382, acc: 99.82850557565689, p_norm: 2277.105910145605, g_norm: 0.13366997542393017, lr:  0.000370, elapsed time:  222329
Step 455200, loss: 0.004826502004043505, acc: 99.83977562189102, p_norm: 2277.1827768916983, g_norm: 0.23064042335796828, lr:  0.000370, elapsed time:  222377
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 455300, loss: 0.004662971937381625, acc: 99.8441379165175, p_norm: 2277.2617985328293, g_norm: 0.17785310384506872, lr:  0.000370, elapsed time:  222425
Step 455400, loss: 0.004804042793753069, acc: 99.84173494577408, p_norm: 2277.3469413192565, g_norm: 0.08414841192477789, lr:  0.000370, elapsed time:  222472
Step 455500, loss: 0.0048829344564563825, acc: 99.83790804445744, p_norm: 2277.4287122638625, g_norm: 0.1622190546091363, lr:  0.000370, elapsed time:  222520
Step 455600, loss: 0.004939669034911276, acc: 99.83616051077843, p_norm: 2277.4986340240816, g_norm: 0.18212253268158338, lr:  0.000370, elapsed time:  222567
Step 455700, loss: 0.004840611586610066, acc: 99.84195151925087, p_norm: 2277.5758675638413, g_norm: 0.2650350430372406, lr:  0.000370, elapsed time:  222615
Step 455800, loss: 0.00505609300767901, acc: 99.83433973789215, p_norm: 2277.650478753116, g_norm: 0.21552222094316015, lr:  0.000370, elapsed time:  222662
Step 455900, loss: 0.005222131013465514, acc: 99.82517458498478, p_norm: 2277.7319645256503, g_norm: 0.2195502500499217, lr:  0.000370, elapsed time:  222710
Step 456000, loss: 0.004774693702402146, acc: 99.84326405823231, p_norm: 2277.806141158724, g_norm: 0.10910116551798696, lr:  0.000370, elapsed time:  222757
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 456000, eval loss: 0.024094549433352767, eval acc: 99.57865905761719
Step 456100, loss: 0.005185799343362305, acc: 99.83052644133568, p_norm: 2277.889074329366, g_norm: 0.2749489324061371, lr:  0.000370, elapsed time:  222811
Step 456200, loss: 0.005161058590574612, acc: 99.83010822534561, p_norm: 2277.95986689675, g_norm: 0.09695614432140383, lr:  0.000370, elapsed time:  222859
Step 456300, loss: 0.005022050337688597, acc: 99.83700002729893, p_norm: 2278.040170809788, g_norm: 0.10583052732160653, lr:  0.000370, elapsed time:  222907
Step 456400, loss: 0.005167759095420479, acc: 99.83263663947582, p_norm: 2278.1248467052105, g_norm: 0.15994445127029958, lr:  0.000370, elapsed time:  222954
Step 456500, loss: 0.005188231880028979, acc: 99.83143538236618, p_norm: 2278.1990760486337, g_norm: 0.20031952797624913, lr:  0.000370, elapsed time:  223001
Step 456600, loss: 0.005063111091476458, acc: 99.83133447170258, p_norm: 2278.281419793914, g_norm: 0.13575579552193337, lr:  0.000370, elapsed time:  223048
Step 456700, loss: 0.004883930359173973, acc: 99.8421947658062, p_norm: 2278.36163651296, g_norm: 0.199615350519595, lr:  0.000370, elapsed time:  223096
Step 456800, loss: 0.004945025163260652, acc: 99.83166471123695, p_norm: 2278.434740287929, g_norm: 0.15211506168531708, lr:  0.000370, elapsed time:  223144
Step 456900, loss: 0.005185154268874612, acc: 99.83129607141018, p_norm: 2278.5216389783086, g_norm: 0.1574289117686613, lr:  0.000370, elapsed time:  223192
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 457000, loss: 0.005074014105856201, acc: 99.83385637143705, p_norm: 2278.599721385417, g_norm: 0.11764180785789162, lr:  0.000370, elapsed time:  223241
Step 457100, loss: 0.005044635693161581, acc: 99.83532457053661, p_norm: 2278.6736477562345, g_norm: 0.18547494522725586, lr:  0.000370, elapsed time:  223288
Step 457200, loss: 0.005078671454557479, acc: 99.83495460450649, p_norm: 2278.747342711973, g_norm: 0.23328056257781155, lr:  0.000370, elapsed time:  223335
Step 457300, loss: 0.005204109959586276, acc: 99.82661162316799, p_norm: 2278.822674813556, g_norm: 0.16778016807164398, lr:  0.000370, elapsed time:  223383
Step 457400, loss: 0.004823249423798188, acc: 99.84104354679585, p_norm: 2278.889915372325, g_norm: 0.2631767777828057, lr:  0.000370, elapsed time:  223430
Step 457500, loss: 0.005054651136965731, acc: 99.83742968738079, p_norm: 2278.959928440914, g_norm: 0.14603268735894123, lr:  0.000370, elapsed time:  223478
Step 457600, loss: 0.005124562147257166, acc: 99.83111754059792, p_norm: 2279.041864411195, g_norm: 0.2627713726986887, lr:  0.000369, elapsed time:  223525
Step 457700, loss: 0.004903073329714971, acc: 99.83938837051392, p_norm: 2279.1148611375665, g_norm: 0.2399180557562057, lr:  0.000369, elapsed time:  223573
Step 457800, loss: 0.005241038988215223, acc: 99.82690148055553, p_norm: 2279.195047798424, g_norm: 0.1855230292126189, lr:  0.000369, elapsed time:  223620
Step 457900, loss: 0.004896819991377015, acc: 99.83968350291252, p_norm: 2279.265801910158, g_norm: 0.26358115048786795, lr:  0.000369, elapsed time:  223668
Step 458000, loss: 0.00527720134595711, acc: 99.82582961022854, p_norm: 2279.345790250943, g_norm: 0.416433793461812, lr:  0.000369, elapsed time:  223716
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 458000, eval loss: 0.023284655361593427, eval acc: 99.59843444824219
Step 458100, loss: 0.0047995930602496625, acc: 99.84100405871868, p_norm: 2279.408205516565, g_norm: 0.10292483814819019, lr:  0.000369, elapsed time:  223771
Step 458200, loss: 0.004974494146981669, acc: 99.8342524021864, p_norm: 2279.491981113084, g_norm: 0.28957155083061686, lr:  0.000369, elapsed time:  223818
Step 458300, loss: 0.004913972459880824, acc: 99.83641840517521, p_norm: 2279.578963866331, g_norm: 0.19951745242495525, lr:  0.000369, elapsed time:  223866
Step 458400, loss: 0.004947305491559746, acc: 99.83675639331341, p_norm: 2279.6479861785137, g_norm: 0.15188602548039581, lr:  0.000369, elapsed time:  223914
Step 458500, loss: 0.0051982826453786405, acc: 99.83020628988743, p_norm: 2279.728191218101, g_norm: 0.12117007282211113, lr:  0.000369, elapsed time:  223962
Step 458600, loss: 0.00527812977310532, acc: 99.83151996135712, p_norm: 2279.8077085381447, g_norm: 0.1837256057563413, lr:  0.000369, elapsed time:  224009
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 458700, loss: 0.004762377154858669, acc: 99.84471774219874, p_norm: 2279.878423895373, g_norm: 0.24230068847051253, lr:  0.000369, elapsed time:  224058
Step 458800, loss: 0.004685328849373036, acc: 99.846021682024, p_norm: 2279.952278900292, g_norm: 0.13167368890525652, lr:  0.000369, elapsed time:  224105
Step 458900, loss: 0.004812218118296414, acc: 99.84166057407856, p_norm: 2280.0251793721736, g_norm: 0.1501864867500222, lr:  0.000369, elapsed time:  224153
Step 459000, loss: 0.0051077764749607015, acc: 99.83976018428802, p_norm: 2280.104211607185, g_norm: 0.21126053437923215, lr:  0.000369, elapsed time:  224201
Step 459100, loss: 0.004829734661689145, acc: 99.84462362527847, p_norm: 2280.1815344115284, g_norm: 0.06572669404673502, lr:  0.000369, elapsed time:  224249
Step 459200, loss: 0.005033058419758163, acc: 99.83136069774628, p_norm: 2280.251832395462, g_norm: 0.22649933244556025, lr:  0.000369, elapsed time:  224297
Step 459300, loss: 0.004805274893792557, acc: 99.83970250189304, p_norm: 2280.318221645423, g_norm: 0.16809137229884255, lr:  0.000369, elapsed time:  224345
Step 459400, loss: 0.0050647852178371975, acc: 99.83493511378765, p_norm: 2280.399381130346, g_norm: 0.17086061838410313, lr:  0.000369, elapsed time:  224392
Step 459500, loss: 0.004977295340040655, acc: 99.8424416333437, p_norm: 2280.4825011156063, g_norm: 0.10039945399099753, lr:  0.000369, elapsed time:  224439
Step 459600, loss: 0.0050300828853687566, acc: 99.83620342612267, p_norm: 2280.5522322872107, g_norm: 0.19705307453025245, lr:  0.000369, elapsed time:  224487
Step 459700, loss: 0.005127274091782965, acc: 99.83343675732613, p_norm: 2280.624385869931, g_norm: 0.1953489482176942, lr:  0.000369, elapsed time:  224534
Step 459800, loss: 0.005092267837453619, acc: 99.8337959498167, p_norm: 2280.6966151529377, g_norm: 0.23488890946793836, lr:  0.000369, elapsed time:  224581
Step 459900, loss: 0.0049919004404728184, acc: 99.83157077431679, p_norm: 2280.7691260675188, g_norm: 0.14070456569318418, lr:  0.000369, elapsed time:  224629
Step 460000, loss: 0.005172609254254894, acc: 99.8307244181633, p_norm: 2280.8445998386487, g_norm: 0.14715207623521936, lr:  0.000368, elapsed time:  224677
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 460000, eval loss: 0.022160433447497782, eval acc: 99.59733581542969
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: O = C ( O ) C = C c 1 c c c ( C ( = C 2 C C S C C 2 ) c 2 c c c ( O ) c c 2 ) c c 1 _EOS
Predicted text: O = C ( O ) C = C c 1 c c c ( C ( = C 2 C C S C C 2 ) c 2 c c c ( O ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: Br c 1 c c c c ( - c 2 c c c c c 2 ) n 1 _EOS
Predicted text: Br c 1 c c c c ( - c 2 c c c c c 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C N ( C C ( O ) ( C N c 1 c c c c 2 c 1 c n n 2 - c 1 c c c ( F ) c c 1 ) C ( F ) ( F ) F ) C ( = O ) c 1 c c c c c 1 C _EOS
Predicted text: C C N ( C C ( O ) ( C N c 1 c c c c 2 c 1 c n n 2 - c 1 c c c ( F ) c c 1 ) C ( F ) ( F ) F ) C ( = O ) c 1 c c c c c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C ( C O c 2 c c c c c 2 ) N c 2 c c c ( C ( = O ) N ( C ) C C C ( = O ) O ) c c 2 ) o c 2 c c c c c 1 2 _EOS
Predicted text: C c 1 c ( C ( C O c 2 c c c c c 2 ) N c 2 c c c ( C ( = O ) N ( C ) C C C ( = O ) O ) c c 2 ) o c 2 c c c c c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C O C ( = O ) c 1 n c ( N 2 C C C ( N ) C ( O C ) C 2 ) o c 1 C ( C ) C _EOS
Predicted text: C C C C O C ( = O ) c 1 n c ( N 2 C C C ( N ) C ( O C ) C 2 ) o c 1 C ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 460000, eval acc (token): 0.9442551298497115, eval acc (sequence): 0.8969167904903418
Saving at step 460000
Step 460100, loss: 0.005278166961747956, acc: 99.82372361421585, p_norm: 2280.9212428474793, g_norm: 0.14983987795001072, lr:  0.000368, elapsed time:  224784
Step 460200, loss: 0.004873447561958528, acc: 99.83674491941929, p_norm: 2280.9986691675967, g_norm: 0.1662988510471949, lr:  0.000368, elapsed time:  224831
Step 460300, loss: 0.005286360951004099, acc: 99.82442581653595, p_norm: 2281.0790627683905, g_norm: 0.19745037288716044, lr:  0.000368, elapsed time:  224878
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 460400, loss: 0.005194474909462113, acc: 99.83195300719038, p_norm: 2281.15110562092, g_norm: 0.13321939970895347, lr:  0.000368, elapsed time:  224927
Step 460500, loss: 0.004703789250270347, acc: 99.84330573678017, p_norm: 2281.2172016150507, g_norm: 0.19831625958672808, lr:  0.000368, elapsed time:  224974
Step 460600, loss: 0.005051375486850702, acc: 99.83444832265377, p_norm: 2281.293667501379, g_norm: 0.18903396423274837, lr:  0.000368, elapsed time:  225022
Step 460700, loss: 0.004749663647767193, acc: 99.840550288558, p_norm: 2281.3627189087074, g_norm: 0.18242054057134843, lr:  0.000368, elapsed time:  225070
Step 460800, loss: 0.004929857755014382, acc: 99.83918517827988, p_norm: 2281.4385174745667, g_norm: 0.24466245571233533, lr:  0.000368, elapsed time:  225117
Step 460900, loss: 0.0048291157005041895, acc: 99.84029322862625, p_norm: 2281.510663087597, g_norm: 0.23574147019522754, lr:  0.000368, elapsed time:  225164
Step 461000, loss: 0.004854416120997485, acc: 99.84045349061489, p_norm: 2281.5749254545044, g_norm: 0.2094639218884637, lr:  0.000368, elapsed time:  225211
Step 461100, loss: 0.005083580390627276, acc: 99.83212660253048, p_norm: 2281.6475316628084, g_norm: 0.18339212029423882, lr:  0.000368, elapsed time:  225259
Step 461200, loss: 0.005137220711831105, acc: 99.83229747414589, p_norm: 2281.7315761662153, g_norm: 0.1315112982844502, lr:  0.000368, elapsed time:  225307
Step 461300, loss: 0.004995601645946408, acc: 99.8366624712944, p_norm: 2281.8046506332303, g_norm: 0.14834365496145033, lr:  0.000368, elapsed time:  225354
Step 461400, loss: 0.004930900387325892, acc: 99.84180207550526, p_norm: 2281.882978132936, g_norm: 0.23360581075308, lr:  0.000368, elapsed time:  225402
Step 461500, loss: 0.004994816628714034, acc: 99.83781573176384, p_norm: 2281.9682033745744, g_norm: 0.15110743273952085, lr:  0.000368, elapsed time:  225449
Step 461600, loss: 0.004966459698262042, acc: 99.84086140990257, p_norm: 2282.0387383439815, g_norm: 0.10676286492262385, lr:  0.000368, elapsed time:  225497
Step 461700, loss: 0.0049033752277500755, acc: 99.84124009311199, p_norm: 2282.1196315434186, g_norm: 0.11800169343104291, lr:  0.000368, elapsed time:  225545
Step 461800, loss: 0.0050181523296669184, acc: 99.83582092821598, p_norm: 2282.2044047082586, g_norm: 0.1727582752866803, lr:  0.000368, elapsed time:  225592
Step 461900, loss: 0.0050262217778026756, acc: 99.8328203856945, p_norm: 2282.2766555685416, g_norm: 0.12276671422857684, lr:  0.000368, elapsed time:  225640
Step 462000, loss: 0.005073132001216436, acc: 99.83920572698116, p_norm: 2282.3546253083214, g_norm: 0.23451630050008956, lr:  0.000368, elapsed time:  225688
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 462000, eval loss: 0.023772270834742804, eval acc: 99.58610534667969
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6822
Step 462100, loss: 0.005044653991478274, acc: 99.83558811561642, p_norm: 2282.4339067259803, g_norm: 0.20381454241179872, lr:  0.000368, elapsed time:  225743
Step 462200, loss: 0.0044113728782895125, acc: 99.85802403092384, p_norm: 2282.4952521200034, g_norm: 0.21340757832498974, lr:  0.000368, elapsed time:  225790
Step 462300, loss: 0.004808869668877378, acc: 99.84100864827633, p_norm: 2282.558380867645, g_norm: 0.2619801731729624, lr:  0.000368, elapsed time:  225838
Step 462400, loss: 0.004823221807346272, acc: 99.84107510745525, p_norm: 2282.62735964544, g_norm: 0.14048279066377833, lr:  0.000368, elapsed time:  225885
Step 462500, loss: 0.005048473755061877, acc: 99.83539533615112, p_norm: 2282.7114864886994, g_norm: 0.16874645711751435, lr:  0.000367, elapsed time:  225933
Step 462600, loss: 0.004883549934320399, acc: 99.84117102622986, p_norm: 2282.791586270808, g_norm: 0.20896723535523232, lr:  0.000367, elapsed time:  225980
Step 462700, loss: 0.004954594319490298, acc: 99.83460912108421, p_norm: 2282.862991025545, g_norm: 0.19813941131923718, lr:  0.000367, elapsed time:  226028
Step 462800, loss: 0.0051897934193220864, acc: 99.82692374289036, p_norm: 2282.9407286529854, g_norm: 0.20235531089423103, lr:  0.000367, elapsed time:  226076
Step 462900, loss: 0.004955617605573935, acc: 99.83933985233307, p_norm: 2283.010871745164, g_norm: 0.12082668709643994, lr:  0.000367, elapsed time:  226124
Step 463000, loss: 0.0053461115579375475, acc: 99.82317760586739, p_norm: 2283.0815134315653, g_norm: 0.17478291252150752, lr:  0.000367, elapsed time:  226171
Step 463100, loss: 0.005012178652623334, acc: 99.83461299538612, p_norm: 2283.156780557534, g_norm: 0.2106663094740303, lr:  0.000367, elapsed time:  226219
Step 463200, loss: 0.0049595873214275344, acc: 99.83392709493637, p_norm: 2283.238890974522, g_norm: 0.22305184336649642, lr:  0.000367, elapsed time:  226267
Step 463300, loss: 0.004983665227782695, acc: 99.84117725491524, p_norm: 2283.31301368024, g_norm: 0.2932426935933681, lr:  0.000367, elapsed time:  226315
Step 463400, loss: 0.00493477303652071, acc: 99.83762435615063, p_norm: 2283.3918152651568, g_norm: 0.13439180778542928, lr:  0.000367, elapsed time:  226362
Step 463500, loss: 0.00514558423188646, acc: 99.83412925899029, p_norm: 2283.4620088670627, g_norm: 0.1713870792991992, lr:  0.000367, elapsed time:  226410
Step 463600, loss: 0.005408413886748349, acc: 99.8231421560049, p_norm: 2283.54761389864, g_norm: 0.25698891661578366, lr:  0.000367, elapsed time:  226457
Step 463700, loss: 0.0052014919911925975, acc: 99.83100302517414, p_norm: 2283.61606976535, g_norm: 0.23197693123455154, lr:  0.000367, elapsed time:  226504
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 463800, loss: 0.004866314527680063, acc: 99.8435527086258, p_norm: 2283.6797586657763, g_norm: 0.14110392289467377, lr:  0.000367, elapsed time:  226553
Step 463900, loss: 0.004901641370170182, acc: 99.83912731707096, p_norm: 2283.754644134373, g_norm: 0.10755032983713932, lr:  0.000367, elapsed time:  226600
Step 464000, loss: 0.004991080676372803, acc: 99.83529631793499, p_norm: 2283.8340885412194, g_norm: 0.1152922950215743, lr:  0.000367, elapsed time:  226648
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 464000, eval loss: 0.021512647298269495, eval acc: 99.61860656738281
Step 464100, loss: 0.00440429173550001, acc: 99.85443222522736, p_norm: 2283.9051404966317, g_norm: 0.19116269428923566, lr:  0.000367, elapsed time:  226702
Step 464200, loss: 0.004445767385805084, acc: 99.85503540933132, p_norm: 2283.970375291575, g_norm: 0.2102759533858611, lr:  0.000367, elapsed time:  226750
Step 464300, loss: 0.004919225944172467, acc: 99.84009198844433, p_norm: 2284.040204303071, g_norm: 0.13469259611862083, lr:  0.000367, elapsed time:  226798
Step 464400, loss: 0.005067256644424561, acc: 99.8307517170906, p_norm: 2284.1111090828044, g_norm: 0.17130693154717708, lr:  0.000367, elapsed time:  226846
Step 464500, loss: 0.005128520365824443, acc: 99.83645933866501, p_norm: 2284.179074061897, g_norm: 0.13237480915922395, lr:  0.000367, elapsed time:  226893
Step 464600, loss: 0.004957197159778843, acc: 99.83825346827507, p_norm: 2284.2525643778076, g_norm: 0.11483281338936546, lr:  0.000367, elapsed time:  226941
Step 464700, loss: 0.0051241125997421475, acc: 99.83018413186073, p_norm: 2284.3326907092332, g_norm: 0.10876121042536172, lr:  0.000367, elapsed time:  226988
Step 464800, loss: 0.004986763683791651, acc: 99.83714582026005, p_norm: 2284.4140626605954, g_norm: 0.22816818075136877, lr:  0.000367, elapsed time:  227035
Step 464900, loss: 0.005057705717799763, acc: 99.82929350435734, p_norm: 2284.4962816277775, g_norm: 0.23564362217462945, lr:  0.000367, elapsed time:  227083
Step 465000, loss: 0.004558411399716533, acc: 99.85089367628098, p_norm: 2284.5659788021726, g_norm: 0.17984915168383947, lr:  0.000367, elapsed time:  227130
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C n 1 c ( = O ) n ( C C O C c 2 c c c ( Cl ) c c 2 ) c ( = O ) c 2 c 1 n c n 2 C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
Predicted text: C n 1 c ( = O ) n ( C C O C c 2 c c c ( Cl ) c c 2 ) c ( = O ) c 2 c 1 n c n 2 C ( c 1 c c c c c 1 ) ( c 1 c c c c c 1 ) c 1 c c c c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O C c 1 n c 2 c ( N C c 3 c ( C ) c c c c 3 C ) c c c n 2 c 1 C _EOS
Predicted text: C C ( = O ) O C c 1 n c 2 c ( N C c 3 c ( C ) c c c c 3 C ) c c c n 2 c 1 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C S c 1 c c c ( C ( = N O ) C ( F ) ( F ) F ) c c 1 _EOS
Predicted text: C S c 1 c c c ( C ( = N O ) C ( F ) ( F ) F ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c c c c 1 S ( = O ) ( = O ) N c 1 c c ( - c 2 c c n ( S ( = O ) ( = O ) N ( C ) C ) n 2 ) s c 1 C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C c 1 c c c c c 1 S ( = O ) ( = O ) N c 1 c c ( - c 2 c c n ( S ( = O ) ( = O ) N ( C ) C ) n 2 ) s c 1 C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Target text: O C 1 C C N ( c 2 c c c ( C ( F ) ( F ) F ) c c 2 F ) C 1 _EOS
Predicted text: O C 1 C C N ( c 2 c c c ( C ( F ) ( F ) F ) c c 2 F ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 465000, eval acc (token): 0.9434760399863633, eval acc (sequence): 0.895149191531922
Saving at step 465000
Step 465100, loss: 0.004707409031607312, acc: 99.84221602976322, p_norm: 2284.6452151338285, g_norm: 0.24474313998929062, lr:  0.000366, elapsed time:  227229
Step 465200, loss: 0.004856934446797823, acc: 99.836111292243, p_norm: 2284.71653104005, g_norm: 0.27339216097503105, lr:  0.000366, elapsed time:  227280
Step 465300, loss: 0.005136819253966678, acc: 99.82817530632019, p_norm: 2284.7950017983085, g_norm: 0.22694227956425322, lr:  0.000366, elapsed time:  227327
Step 465400, loss: 0.004918476056113832, acc: 99.84032712876797, p_norm: 2284.870435252525, g_norm: 0.13672310582130437, lr:  0.000366, elapsed time:  227375
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 465500, loss: 0.0049755211402185825, acc: 99.83677880343964, p_norm: 2284.9454649784398, g_norm: 0.13210091012086742, lr:  0.000366, elapsed time:  227423
Step 465600, loss: 0.004726385693702468, acc: 99.84297446906567, p_norm: 2285.0085911499023, g_norm: 0.1848217275470858, lr:  0.000366, elapsed time:  227471
Step 465700, loss: 0.0048828165837039705, acc: 99.8370233476162, p_norm: 2285.0913493375533, g_norm: 0.17438491326530242, lr:  0.000366, elapsed time:  227519
Step 465800, loss: 0.0045182863115223884, acc: 99.85290694236755, p_norm: 2285.1592409596146, g_norm: 0.23082109824852856, lr:  0.000366, elapsed time:  227567
Step 465900, loss: 0.004633307549470373, acc: 99.84370112419128, p_norm: 2285.2386210690593, g_norm: 0.1749805211308451, lr:  0.000366, elapsed time:  227614
Step 466000, loss: 0.005273309844155847, acc: 99.82763896882534, p_norm: 2285.318730108243, g_norm: 0.1533698256105578, lr:  0.000366, elapsed time:  227662
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 466000, eval loss: 0.02440925024861827, eval acc: 99.5972900390625
Step 466100, loss: 0.004903069793922441, acc: 99.83678060770035, p_norm: 2285.390913011001, g_norm: 0.13061156834654616, lr:  0.000366, elapsed time:  227716
Step 466200, loss: 0.004924486892105051, acc: 99.83843572437763, p_norm: 2285.4710857444197, g_norm: 0.22656192594184066, lr:  0.000366, elapsed time:  227763
Step 466300, loss: 0.004947563863352116, acc: 99.83261668682098, p_norm: 2285.5578364527128, g_norm: 0.18457913479719357, lr:  0.000366, elapsed time:  227811
Step 466400, loss: 0.004993610548685865, acc: 99.83706314861774, p_norm: 2285.6281095958484, g_norm: 0.16289890595653492, lr:  0.000366, elapsed time:  227858
Step 466500, loss: 0.004687127391880494, acc: 99.84386716783047, p_norm: 2285.702945300571, g_norm: 0.16502693729860993, lr:  0.000366, elapsed time:  227906
Step 466600, loss: 0.005061254051199739, acc: 99.83845727145672, p_norm: 2285.781529505094, g_norm: 0.17145787700422777, lr:  0.000366, elapsed time:  227953
Step 466700, loss: 0.004622877501951735, acc: 99.84797194600105, p_norm: 2285.865269761924, g_norm: 0.20994416115267076, lr:  0.000366, elapsed time:  228001
Step 466800, loss: 0.005303731077419798, acc: 99.82452927529812, p_norm: 2285.9435508581087, g_norm: 0.2873935637579007, lr:  0.000366, elapsed time:  228049
Step 466900, loss: 0.005144835835708363, acc: 99.82826139032841, p_norm: 2286.0153469679585, g_norm: 0.18634156190786758, lr:  0.000366, elapsed time:  228096
Step 467000, loss: 0.004933333767585282, acc: 99.83581010997295, p_norm: 2286.0856615378884, g_norm: 0.17989176255369146, lr:  0.000366, elapsed time:  228143
Step 467100, loss: 0.004746632897094969, acc: 99.84704354405403, p_norm: 2286.157207601562, g_norm: 0.19846785800371292, lr:  0.000366, elapsed time:  228191
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 467200, loss: 0.004989677155440934, acc: 99.83546559331435, p_norm: 2286.2356478668344, g_norm: 0.16803938243056962, lr:  0.000366, elapsed time:  228240
Step 467300, loss: 0.0047858636358250805, acc: 99.84251390397549, p_norm: 2286.307262895542, g_norm: 0.10678798924039384, lr:  0.000366, elapsed time:  228287
Step 467400, loss: 0.004559542412332576, acc: 99.85111328959465, p_norm: 2286.379923620314, g_norm: 0.12898497064406103, lr:  0.000366, elapsed time:  228335
Step 467500, loss: 0.00511006467887455, acc: 99.83262838423252, p_norm: 2286.446157941448, g_norm: 0.17126476663559234, lr:  0.000366, elapsed time:  228383
Step 467600, loss: 0.004648416591508066, acc: 99.84878908097744, p_norm: 2286.5127844934254, g_norm: 0.1645208269171042, lr:  0.000365, elapsed time:  228430
Step 467700, loss: 0.004821056832529393, acc: 99.84638372063637, p_norm: 2286.6007997191464, g_norm: 0.15656612648033913, lr:  0.000365, elapsed time:  228478
Step 467800, loss: 0.004999713648994657, acc: 99.83271799981594, p_norm: 2286.675347608774, g_norm: 0.14085209403557125, lr:  0.000365, elapsed time:  228525
Step 467900, loss: 0.004827596219338375, acc: 99.84324799478054, p_norm: 2286.7548251777075, g_norm: 0.15869994206708046, lr:  0.000365, elapsed time:  228573
Step 468000, loss: 0.005219031901192466, acc: 99.82502873241901, p_norm: 2286.830842031744, g_norm: 0.18023589101678072, lr:  0.000365, elapsed time:  228621
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 468000, eval loss: 0.019393387954748962, eval acc: 99.6593246459961
Step 468100, loss: 0.005289568180887727, acc: 99.82513397932053, p_norm: 2286.912346035999, g_norm: 0.2151077775059759, lr:  0.000365, elapsed time:  228675
Step 468200, loss: 0.005021244602215802, acc: 99.83324800431728, p_norm: 2286.985258377002, g_norm: 0.26332864322671035, lr:  0.000365, elapsed time:  228722
Step 468300, loss: 0.004988301498915462, acc: 99.83698943257332, p_norm: 2287.0695328699367, g_norm: 0.2675739011621921, lr:  0.000365, elapsed time:  228770
Step 468400, loss: 0.005095849242879921, acc: 99.83265213668346, p_norm: 2287.1482604192747, g_norm: 0.14954060279745768, lr:  0.000365, elapsed time:  228817
Step 468500, loss: 0.004738771933489261, acc: 99.83983664214611, p_norm: 2287.2241750351004, g_norm: 0.18970191592889846, lr:  0.000365, elapsed time:  228865
Step 468600, loss: 0.004679768050118582, acc: 99.84521608054638, p_norm: 2287.2929727757996, g_norm: 0.16176981279352032, lr:  0.000365, elapsed time:  228913
Step 468700, loss: 0.004532382302832047, acc: 99.84933675825596, p_norm: 2287.3564040863857, g_norm: 0.19769534680435238, lr:  0.000365, elapsed time:  228961
Step 468800, loss: 0.005181294007163615, acc: 99.82751712203026, p_norm: 2287.439590444443, g_norm: 0.12592406645530338, lr:  0.000365, elapsed time:  229008
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 468900, loss: 0.004740761698463017, acc: 99.8421034801095, p_norm: 2287.5124335002647, g_norm: 0.15140038007152495, lr:  0.000365, elapsed time:  229057
Step 469000, loss: 0.004437980665907162, acc: 99.85121530294418, p_norm: 2287.580686088018, g_norm: 0.1152832122985973, lr:  0.000365, elapsed time:  229105
Step 469100, loss: 0.0048181657288705534, acc: 99.84167823195457, p_norm: 2287.6518258808014, g_norm: 0.22203805500778384, lr:  0.000365, elapsed time:  229153
Step 469200, loss: 0.004662069973201142, acc: 99.84326732158661, p_norm: 2287.7246087651256, g_norm: 0.1690825972132804, lr:  0.000365, elapsed time:  229201
Step 469300, loss: 0.0049923455088878655, acc: 99.83671471476555, p_norm: 2287.7951536645696, g_norm: 0.24116215572423816, lr:  0.000365, elapsed time:  229248
Step 469400, loss: 0.004940561299554247, acc: 99.83911493420601, p_norm: 2287.8671756002022, g_norm: 0.12374380274062421, lr:  0.000365, elapsed time:  229296
Step 469500, loss: 0.004568505212373566, acc: 99.84975409507751, p_norm: 2287.947055749473, g_norm: 0.18329249796970487, lr:  0.000365, elapsed time:  229343
Step 469600, loss: 0.005160206835989811, acc: 99.82900388538837, p_norm: 2288.0324037718137, g_norm: 0.15016758142845646, lr:  0.000365, elapsed time:  229390
Step 469700, loss: 0.004679290342405693, acc: 99.84657160937786, p_norm: 2288.1035233793427, g_norm: 0.1352950238853815, lr:  0.000365, elapsed time:  229438
Step 469800, loss: 0.004994796085725284, acc: 99.83649969100952, p_norm: 2288.1678651388506, g_norm: 0.1455903292175432, lr:  0.000365, elapsed time:  229486
Step 469900, loss: 0.004986244316896773, acc: 99.83664499223232, p_norm: 2288.247195462966, g_norm: 0.16079762060294053, lr:  0.000365, elapsed time:  229534
Step 470000, loss: 0.005105473577423254, acc: 99.82929702103138, p_norm: 2288.319080862373, g_norm: 0.48174755342141234, lr:  0.000365, elapsed time:  229581
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 470000, eval loss: 0.021610158352197296, eval acc: 99.63768005371094
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C ( C ) c 1 c c ( O ) c c 2 c 1 C ( = O ) N S 2 ( = O ) = O _EOS
Predicted text: C C ( C ) c 1 c c ( O ) c c 2 c 1 C ( = O ) N S 2 ( = O ) = O _EOS
acc_token: 1.0, acc_seq: True

Target text: Cl c 1 c c 2 c ( N C c 3 c c c c c 3 ) n c ( - c 3 c c c c n 3 ) n c 2 s 1 _EOS
Predicted text: Cl c 1 c c 2 c ( N C c 3 c c c c c 3 ) n c ( - c 3 c c c c n 3 ) n c 2 s 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( O C C ( = O ) O ) c ( C ) c c 1 S C C c 1 c n ( C c 2 c c c ( C ( F ) ( F ) F ) c c 2 ) c 2 c c c c c 1 2 _EOS
Predicted text: C O C ( = O ) C O c 1 c c ( O C ) c ( S C C c 2 c n ( C c 3 c c c ( C ( F ) ( F ) F ) c c 3 ) c 3 c c c c c 2 3 ) c c 1 C _EOS
acc_token: 0.16393442622950818, acc_seq: False

Target text: C C O C ( = O ) C 1 = C ( O [SiH] ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c 2 c c c c ( C ( C ) ( C ) C ) c 2 C C 1 _EOS
Predicted text: C C O C ( = O ) C 1 = C ( O [SiH] ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c 2 c c c c ( C ( C ) ( C ) C ) c 2 C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( C ) C C n 1 c n c ( - c 2 c ( Cl ) c s c 2 N C ( = O ) C n 2 c ( = O ) c c c 3 c c ( C ( F ) ( F ) F ) c c c 3 2 ) n 1 _EOS
Predicted text: C N ( C ) C C n 1 c n c ( - c 2 c ( Cl ) c s c 2 N C ( = O ) C n 2 c ( = O ) c c c 3 c c ( C ( F ) ( F ) F ) c c c 3 2 ) n 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 470000, eval acc (token): 0.9457361838375576, eval acc (sequence): 0.8967344845272697
Saving at step 470000
Step 470100, loss: 0.004728210128296269, acc: 99.84435790777206, p_norm: 2288.396594893273, g_norm: 0.20292297655250457, lr:  0.000365, elapsed time:  229687
Step 470200, loss: 0.004873976841445256, acc: 99.84208156168461, p_norm: 2288.4610498721213, g_norm: 0.2675495671541912, lr:  0.000364, elapsed time:  229735
Step 470300, loss: 0.005292100548767848, acc: 99.82466726005077, p_norm: 2288.5456436230356, g_norm: 0.1305574280262568, lr:  0.000364, elapsed time:  229782
Step 470400, loss: 0.005242020800533282, acc: 99.82856978476048, p_norm: 2288.6258836129264, g_norm: 0.1605176940479396, lr:  0.000364, elapsed time:  229829
Step 470500, loss: 0.005070757771263743, acc: 99.83071587979794, p_norm: 2288.6997711814893, g_norm: 0.15513821411487708, lr:  0.000364, elapsed time:  229876
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 470600, loss: 0.004633229921170234, acc: 99.84974220727868, p_norm: 2288.769821656087, g_norm: 0.14000482608514148, lr:  0.000364, elapsed time:  229926
Step 470700, loss: 0.004752805230546073, acc: 99.838738322258, p_norm: 2288.8329791511287, g_norm: 0.31303981767830014, lr:  0.000364, elapsed time:  229973
Step 470800, loss: 0.004826989469688669, acc: 99.84177845716476, p_norm: 2288.9061801881753, g_norm: 0.22413522831361438, lr:  0.000364, elapsed time:  230020
Step 470900, loss: 0.004722696077353703, acc: 99.84323278069496, p_norm: 2288.979610512073, g_norm: 0.18205516026265345, lr:  0.000364, elapsed time:  230068
Step 471000, loss: 0.0045959966134478236, acc: 99.84906513988972, p_norm: 2289.0444735907918, g_norm: 0.13503031179179983, lr:  0.000364, elapsed time:  230116
Step 471100, loss: 0.004925350334224277, acc: 99.83559536933899, p_norm: 2289.1156880402136, g_norm: 0.15327025570384437, lr:  0.000364, elapsed time:  230163
Step 471200, loss: 0.005166388276797988, acc: 99.82808578014374, p_norm: 2289.1897426918745, g_norm: 0.23283221212154248, lr:  0.000364, elapsed time:  230211
Step 471300, loss: 0.004755995603929364, acc: 99.84045846760273, p_norm: 2289.2626586190427, g_norm: 0.1836909870754536, lr:  0.000364, elapsed time:  230259
Step 471400, loss: 0.005017656112936492, acc: 99.83850403130054, p_norm: 2289.330064674351, g_norm: 0.11982505729061267, lr:  0.000364, elapsed time:  230306
Step 471500, loss: 0.0046814154849244005, acc: 99.84209087491035, p_norm: 2289.402819024528, g_norm: 0.17028300598674811, lr:  0.000364, elapsed time:  230353
Step 471600, loss: 0.0052135620724675395, acc: 99.83272433280945, p_norm: 2289.482059539728, g_norm: 0.17382287305681918, lr:  0.000364, elapsed time:  230400
Step 471700, loss: 0.0050301135177960535, acc: 99.83270674943924, p_norm: 2289.557524891075, g_norm: 0.13103006446436824, lr:  0.000364, elapsed time:  230448
Step 471800, loss: 0.004970789021267592, acc: 99.83402633666992, p_norm: 2289.6353943685785, g_norm: 0.22671551565768644, lr:  0.000364, elapsed time:  230496
Step 471900, loss: 0.004846773497920367, acc: 99.84180428087711, p_norm: 2289.7171061413483, g_norm: 0.15439938062060599, lr:  0.000364, elapsed time:  230544
Step 472000, loss: 0.0051723758357002225, acc: 99.83144047856331, p_norm: 2289.7863826208145, g_norm: 0.24232531379691338, lr:  0.000364, elapsed time:  230591
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 472000, eval loss: 0.02106249103802838, eval acc: 99.63640594482422
Step 472100, loss: 0.004868308101158618, acc: 99.8374587893486, p_norm: 2289.8494782240095, g_norm: 0.21181695902877393, lr:  0.000364, elapsed time:  230646
Step 472200, loss: 0.004908129490686406, acc: 99.84018552303314, p_norm: 2289.922941108365, g_norm: 0.12160971710103724, lr:  0.000364, elapsed time:  230694
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6823
Step 472300, loss: 0.004772217777946492, acc: 99.83881509333627, p_norm: 2289.993060875491, g_norm: 0.16231946340681, lr:  0.000364, elapsed time:  230743
Step 472400, loss: 0.004968070499830901, acc: 99.83876685798168, p_norm: 2290.067902739608, g_norm: 0.17662608933468488, lr:  0.000364, elapsed time:  230791
Step 472500, loss: 0.004813480757316029, acc: 99.8412673175335, p_norm: 2290.1434594309735, g_norm: 0.11569802898621784, lr:  0.000364, elapsed time:  230838
Step 472600, loss: 0.004602978964085196, acc: 99.84655976295471, p_norm: 2290.203418275755, g_norm: 0.12249046140364886, lr:  0.000364, elapsed time:  230886
Step 472700, loss: 0.004810691265893183, acc: 99.83925971388817, p_norm: 2290.267808402991, g_norm: 0.1768907088162685, lr:  0.000364, elapsed time:  230933
Step 472800, loss: 0.005141236686113188, acc: 99.83007900416851, p_norm: 2290.3529048509563, g_norm: 0.1994170915940373, lr:  0.000363, elapsed time:  230981
Step 472900, loss: 0.005016919317704378, acc: 99.83651469647884, p_norm: 2290.4390003715794, g_norm: 0.26037739737943183, lr:  0.000363, elapsed time:  231028
Step 473000, loss: 0.00538554882776225, acc: 99.81789337098598, p_norm: 2290.5147688147304, g_norm: 0.13793119696024952, lr:  0.000363, elapsed time:  231075
Step 473100, loss: 0.004589549994370827, acc: 99.85186751186848, p_norm: 2290.5862360403285, g_norm: 0.13660813627270268, lr:  0.000363, elapsed time:  231123
Step 473200, loss: 0.0048316488627915535, acc: 99.84179064631462, p_norm: 2290.657472197379, g_norm: 0.1658978506564485, lr:  0.000363, elapsed time:  231170
Step 473300, loss: 0.004882935901896417, acc: 99.83847223222256, p_norm: 2290.727980383362, g_norm: 0.1508805454258412, lr:  0.000363, elapsed time:  231218
Step 473400, loss: 0.00461732188352471, acc: 99.84504418075085, p_norm: 2290.803455854327, g_norm: 0.22090917267438703, lr:  0.000363, elapsed time:  231266
Step 473500, loss: 0.004812706009770409, acc: 99.84437976777554, p_norm: 2290.8734904023327, g_norm: 0.1540233818973321, lr:  0.000363, elapsed time:  231314
Step 473600, loss: 0.004869835552049153, acc: 99.84164863824844, p_norm: 2290.949444577418, g_norm: 0.20777948361575282, lr:  0.000363, elapsed time:  231362
Step 473700, loss: 0.004668867491018318, acc: 99.8509112149477, p_norm: 2291.0289940184584, g_norm: 0.1191484649447237, lr:  0.000363, elapsed time:  231409
Step 473800, loss: 0.005084021698994547, acc: 99.83660745620728, p_norm: 2291.102810379222, g_norm: 0.20311932084074452, lr:  0.000363, elapsed time:  231457
Step 473900, loss: 0.004952735955976095, acc: 99.83748643100262, p_norm: 2291.17686748964, g_norm: 0.22452692179682243, lr:  0.000363, elapsed time:  231505
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 474000, loss: 0.005126828798807498, acc: 99.82987714760357, p_norm: 2291.2500661062163, g_norm: 0.13205162427010908, lr:  0.000363, elapsed time:  231554
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 474000, eval loss: 0.023565499453616204, eval acc: 99.59661102294922
Step 474100, loss: 0.004818996126796264, acc: 99.84020593762398, p_norm: 2291.3204029827466, g_norm: 0.17369511348974592, lr:  0.000363, elapsed time:  231608
Step 474200, loss: 0.0051131138647815535, acc: 99.83303442597389, p_norm: 2291.396643366641, g_norm: 0.16089361571905994, lr:  0.000363, elapsed time:  231656
Step 474300, loss: 0.004764533058446432, acc: 99.84212738275528, p_norm: 2291.4635753876746, g_norm: 0.17302099802742013, lr:  0.000363, elapsed time:  231703
Step 474400, loss: 0.004589529779113945, acc: 99.84686622023582, p_norm: 2291.5239224206603, g_norm: 0.22402691527420834, lr:  0.000363, elapsed time:  231751
Step 474500, loss: 0.004677463813441136, acc: 99.84498751163483, p_norm: 2291.5927685666743, g_norm: 0.2658793562130872, lr:  0.000363, elapsed time:  231798
Step 474600, loss: 0.004657254607582218, acc: 99.84882965683937, p_norm: 2291.6741666056846, g_norm: 0.2274530434856442, lr:  0.000363, elapsed time:  231846
Step 474700, loss: 0.004862262854308028, acc: 99.83623161911964, p_norm: 2291.7460304888004, g_norm: 0.11881351363352785, lr:  0.000363, elapsed time:  231894
Step 474800, loss: 0.004885992289009664, acc: 99.83836476504803, p_norm: 2291.8146325937096, g_norm: 0.11255243423482637, lr:  0.000363, elapsed time:  231942
Step 474900, loss: 0.004965872045800097, acc: 99.83269652724266, p_norm: 2291.8963755409927, g_norm: 0.23804825781129796, lr:  0.000363, elapsed time:  231989
Step 475000, loss: 0.00504742578479636, acc: 99.8339347243309, p_norm: 2291.970813883529, g_norm: 0.18957486368324508, lr:  0.000363, elapsed time:  232037
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C 1 C C C ( N ( C ( = O ) C 2 C C C ( C ) C C 2 ) c 2 c c ( C 3 C C C ( C ) ( C ) C C 3 ) s c 2 C ( = O ) O ) C C 1 _EOS
Predicted text: C O C 1 C C C ( N ( C ( = O ) C 2 C C C ( C ) C C 2 ) c 2 c c ( C 3 C C C ( C ) ( C ) C C 3 ) s c 2 C ( = O ) O ) C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C n 1 n c ( C ( F ) ( F ) F ) c c 1 O c 1 c c ( O C ( F ) F ) c n n 1 _EOS
Predicted text: C C O c 1 c n n c ( O c 2 c n n c ( O c 3 c c ( C ( F ) ( F ) F ) n n 3 C ) c 2 ) c 1 _EOS
acc_token: 0.2777777777777778, acc_seq: False

Target text: N # C C C ( = O ) N C c 1 c c c c ( C ( F ) ( F ) F ) c 1 _EOS
Predicted text: N # C C C ( = O ) N C c 1 c c c c ( C ( F ) ( F ) F ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N C C 1 ( c 2 c c c ( O C C C N 3 C C O C C 3 ) c c 2 ) C C O C C 1 _EOS
Predicted text: C N C C 1 ( c 2 c c c ( O C C C N 3 C C O C C 3 ) c c 2 ) C C O C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( O ) c 1 c c n ( - c 2 c ( Cl ) c c c c 2 Cl ) c 1 _EOS
Predicted text: O = C ( O ) c 1 c c n ( - c 2 c ( Cl ) c c c c 2 Cl ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 475000, eval acc (token): 0.9436096003421965, eval acc (sequence): 0.8985811875985287
Saving at step 475000
Step 475100, loss: 0.0049437397859855995, acc: 99.83515590429306, p_norm: 2292.0437612596497, g_norm: 0.1724932571389815, lr:  0.000363, elapsed time:  232150
Step 475200, loss: 0.00508118724446831, acc: 99.83061940968037, p_norm: 2292.1169540657474, g_norm: 0.12556714363014299, lr:  0.000363, elapsed time:  232198
Step 475300, loss: 0.004672135643254478, acc: 99.84910972416401, p_norm: 2292.187082475207, g_norm: 0.2033449674795708, lr:  0.000363, elapsed time:  232247
Step 475400, loss: 0.005002300808555447, acc: 99.83290886878967, p_norm: 2292.2531901098155, g_norm: 0.17115475307071512, lr:  0.000362, elapsed time:  232295
Step 475500, loss: 0.00491570378160759, acc: 99.83863581717014, p_norm: 2292.3299212398633, g_norm: 0.180017086137074, lr:  0.000362, elapsed time:  232344
Step 475600, loss: 0.004844529972633609, acc: 99.84260278940201, p_norm: 2292.4028758247214, g_norm: 0.1848874254700668, lr:  0.000362, elapsed time:  232391
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 475700, loss: 0.004860526406800616, acc: 99.84075271757898, p_norm: 2292.4872899751826, g_norm: 0.29391536191237233, lr:  0.000362, elapsed time:  232440
Step 475800, loss: 0.004719320257581785, acc: 99.84518367052078, p_norm: 2292.5609147527307, g_norm: 0.1947479634396741, lr:  0.000362, elapsed time:  232488
Step 475900, loss: 0.004732891690782708, acc: 99.84225903451443, p_norm: 2292.6402622208825, g_norm: 0.28116826191579547, lr:  0.000362, elapsed time:  232537
Step 476000, loss: 0.004812169405413442, acc: 99.83902157843113, p_norm: 2292.711201506102, g_norm: 0.1463548606422551, lr:  0.000362, elapsed time:  232585
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 476000, eval loss: 0.02374720101128332, eval acc: 99.60057067871094
Step 476100, loss: 0.004718420268363843, acc: 99.8477714061737, p_norm: 2292.788467540682, g_norm: 0.19565639437727542, lr:  0.000362, elapsed time:  232641
Step 476200, loss: 0.004448331437633897, acc: 99.85466608405113, p_norm: 2292.8610637264696, g_norm: 0.12952819771715396, lr:  0.000362, elapsed time:  232691
Step 476300, loss: 0.004735816182110284, acc: 99.84718683362007, p_norm: 2292.9353442123997, g_norm: 0.20502344536158346, lr:  0.000362, elapsed time:  232739
Step 476400, loss: 0.005020181162981316, acc: 99.8371613919735, p_norm: 2293.005197174227, g_norm: 0.1033343763307712, lr:  0.000362, elapsed time:  232786
Step 476500, loss: 0.005092303244086906, acc: 99.82939790189266, p_norm: 2293.086590298225, g_norm: 0.21539850579007813, lr:  0.000362, elapsed time:  232833
Step 476600, loss: 0.005053644493559659, acc: 99.83261013031006, p_norm: 2293.1584915154917, g_norm: 0.19151961549071816, lr:  0.000362, elapsed time:  232880
Step 476700, loss: 0.004718938379492102, acc: 99.84157012403011, p_norm: 2293.236011437486, g_norm: 0.15410817494660112, lr:  0.000362, elapsed time:  232927
Step 476800, loss: 0.005050560074882924, acc: 99.83493772149086, p_norm: 2293.3149398858236, g_norm: 0.16182480539176874, lr:  0.000362, elapsed time:  232975
Step 476900, loss: 0.004723385470815629, acc: 99.84608800709248, p_norm: 2293.389306266047, g_norm: 0.1807640348205036, lr:  0.000362, elapsed time:  233022
Step 477000, loss: 0.004669820827189142, acc: 99.84953340888023, p_norm: 2293.4591452898653, g_norm: 0.1988194409552193, lr:  0.000362, elapsed time:  233071
Step 477100, loss: 0.004954452005031271, acc: 99.83923932909966, p_norm: 2293.5361079579557, g_norm: 0.15371019836800098, lr:  0.000362, elapsed time:  233119
Step 477200, loss: 0.004728022962772229, acc: 99.84577421844006, p_norm: 2293.602910096275, g_norm: 0.26484987861654785, lr:  0.000362, elapsed time:  233167
Step 477300, loss: 0.004740745553199303, acc: 99.84317857027054, p_norm: 2293.6741457240046, g_norm: 0.23415548852065907, lr:  0.000362, elapsed time:  233216
Step 477400, loss: 0.005268211223187791, acc: 99.82756441831589, p_norm: 2293.753459095082, g_norm: 0.16523424341998086, lr:  0.000362, elapsed time:  233264
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 477500, loss: 0.004342698063211934, acc: 99.85806650618466, p_norm: 2293.8120765653384, g_norm: 0.11870541241995887, lr:  0.000362, elapsed time:  233313
Step 477600, loss: 0.004736275167288113, acc: 99.84422199428082, p_norm: 2293.8830945301106, g_norm: 0.16967719687613064, lr:  0.000362, elapsed time:  233361
Step 477700, loss: 0.004881159347496578, acc: 99.83607068657875, p_norm: 2293.9591479170776, g_norm: 0.17344924719759827, lr:  0.000362, elapsed time:  233409
Step 477800, loss: 0.004828661278288564, acc: 99.84150670468807, p_norm: 2294.0346971422045, g_norm: 0.2114563664428928, lr:  0.000362, elapsed time:  233458
Step 477900, loss: 0.004917023532225357, acc: 99.83829879760742, p_norm: 2294.118295002831, g_norm: 0.16753454545137983, lr:  0.000362, elapsed time:  233506
Step 478000, loss: 0.004962166131390404, acc: 99.83078208565712, p_norm: 2294.194569039297, g_norm: 0.20065496679817935, lr:  0.000361, elapsed time:  233554
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 478000, eval loss: 0.023445395940798325, eval acc: 99.59522247314453
Step 478100, loss: 0.004900700864236569, acc: 99.83848194777966, p_norm: 2294.2630360243293, g_norm: 0.17966963249338058, lr:  0.000361, elapsed time:  233610
Step 478200, loss: 0.004499056048352941, acc: 99.85109607875347, p_norm: 2294.3285327326007, g_norm: 0.23139450389388835, lr:  0.000361, elapsed time:  233658
Step 478300, loss: 0.004742541078935574, acc: 99.84159196913242, p_norm: 2294.3982835683873, g_norm: 0.19933016600038214, lr:  0.000361, elapsed time:  233706
Step 478400, loss: 0.005033461810235167, acc: 99.8344691991806, p_norm: 2294.483343646161, g_norm: 0.17475183313153936, lr:  0.000361, elapsed time:  233754
Step 478500, loss: 0.004560748194253392, acc: 99.84684228897095, p_norm: 2294.5448805271576, g_norm: 0.19316709539989146, lr:  0.000361, elapsed time:  233802
Step 478600, loss: 0.004914159186273537, acc: 99.83607085049152, p_norm: 2294.6188795828784, g_norm: 0.2229758809140477, lr:  0.000361, elapsed time:  233851
Step 478700, loss: 0.005043801952888316, acc: 99.83411855995655, p_norm: 2294.7016072919996, g_norm: 0.15919890846112386, lr:  0.000361, elapsed time:  233899
Step 478800, loss: 0.005070966132616377, acc: 99.83485160768032, p_norm: 2294.776611078665, g_norm: 0.24047687043592048, lr:  0.000361, elapsed time:  233948
Step 478900, loss: 0.005103910377865759, acc: 99.82303029298782, p_norm: 2294.8620765306055, g_norm: 0.1823519000256859, lr:  0.000361, elapsed time:  233996
Step 479000, loss: 0.0049579868560249455, acc: 99.83305382728577, p_norm: 2294.9438734146743, g_norm: 0.10138948286002375, lr:  0.000361, elapsed time:  234043
Step 479100, loss: 0.004651011292153271, acc: 99.85066330432892, p_norm: 2295.0212044252885, g_norm: 0.16896878062475015, lr:  0.000361, elapsed time:  234092
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 479200, loss: 0.004857916514214847, acc: 99.83926924010414, p_norm: 2295.09592366096, g_norm: 0.1865296993601859, lr:  0.000361, elapsed time:  234141
Step 479300, loss: 0.004829818128073384, acc: 99.84043772518635, p_norm: 2295.172151884754, g_norm: 0.14482084857262092, lr:  0.000361, elapsed time:  234189
Step 479400, loss: 0.004489753712032325, acc: 99.85342609882355, p_norm: 2295.2396497966797, g_norm: 0.36218017250896495, lr:  0.000361, elapsed time:  234237
Step 479500, loss: 0.0047942663349658686, acc: 99.84524582326412, p_norm: 2295.3079023021437, g_norm: 0.15418552840292052, lr:  0.000361, elapsed time:  234286
Step 479600, loss: 0.00459397440682551, acc: 99.84712044894695, p_norm: 2295.3769867657898, g_norm: 0.2932364544746378, lr:  0.000361, elapsed time:  234334
Step 479700, loss: 0.0049985875369657155, acc: 99.8347550779581, p_norm: 2295.4553075328045, g_norm: 0.19821439536857535, lr:  0.000361, elapsed time:  234382
Step 479800, loss: 0.004736532893152798, acc: 99.84324696660042, p_norm: 2295.5235653472287, g_norm: 0.17960335922067153, lr:  0.000361, elapsed time:  234430
Step 479900, loss: 0.005003931762676075, acc: 99.8405629992485, p_norm: 2295.598812878879, g_norm: 0.23680288804918684, lr:  0.000361, elapsed time:  234478
Step 480000, loss: 0.004602288321232209, acc: 99.8435846567154, p_norm: 2295.6727352044745, g_norm: 0.18778126059900677, lr:  0.000361, elapsed time:  234528
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 480000, eval loss: 0.023690398652574912, eval acc: 99.59191131591797
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C N ( C ) C ( = O ) c 1 c c ( C ( = O ) O ) n ( C C ( = O ) c 2 c c c ( Cl ) c c 2 ) c 1 _EOS
Predicted text: C N ( C ) C ( = O ) c 1 c c ( C ( = O ) O ) n ( C C ( = O ) c 2 c c c ( Cl ) c c 2 ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) = C c 1 c n c ( N ) c n 1 _EOS
Predicted text: C C ( C ) = C c 1 c n c ( N ) c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C c 1 c c c c c 1 N c 1 n c c c n 1 _EOS
Predicted text: O = C c 1 c c c c c 1 N c 1 n c c c n 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c c 2 c c ( - c 3 n n ( C ( C ) C ) c c 3 - c 3 c c n c ( N C C ( C ) O ) n 3 ) c n c 2 [nH] 1 _EOS
Predicted text: C c 1 c c 2 c c ( - c 3 n n ( C ( C ) C ) c c 3 - c 3 c c n c ( N C C ( C ) O ) n 3 ) c n c 2 [nH] 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( c 1 n c 2 c c c c ( C ( F ) ( F ) F ) c 2 n c 1 - c 1 c c c c c 1 Cl ) N 1 C ( = O ) c 2 c c c c c 2 C 1 = O _EOS
Predicted text: C C ( c 1 n c 2 c c c c ( C ( F ) ( F ) F ) c 2 n c 1 - c 1 c c c c c 1 Cl ) N 1 C ( = O ) c 2 c c c c c 2 C 1 = O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 480000, eval acc (token): 0.9455551698617345, eval acc (sequence): 0.8972868217054264
Saving at step 480000
Step 480100, loss: 0.004728656991419484, acc: 99.84344144165516, p_norm: 2295.7377275181707, g_norm: 0.32428401424855824, lr:  0.000361, elapsed time:  234643
Step 480200, loss: 0.004787358587163908, acc: 99.84437391161919, p_norm: 2295.8081424107095, g_norm: 0.23126458356624416, lr:  0.000361, elapsed time:  234691
Step 480300, loss: 0.0050387992502874115, acc: 99.83468605577946, p_norm: 2295.8832193376406, g_norm: 0.2215426623329403, lr:  0.000361, elapsed time:  234739
Step 480400, loss: 0.004771695527288102, acc: 99.84287631511688, p_norm: 2295.9425556551278, g_norm: 0.2288767161050586, lr:  0.000361, elapsed time:  234787
Step 480500, loss: 0.004758061362208537, acc: 99.84622141718864, p_norm: 2296.0144153950455, g_norm: 0.2035149850095002, lr:  0.000361, elapsed time:  234835
Step 480600, loss: 0.0048584032472899705, acc: 99.83796267211437, p_norm: 2296.0909025110923, g_norm: 0.1574667900850001, lr:  0.000361, elapsed time:  234883
Step 480700, loss: 0.004715572867053197, acc: 99.84231723845005, p_norm: 2296.157721853647, g_norm: 0.2540683363826058, lr:  0.000360, elapsed time:  234931
Step 480800, loss: 0.004863213916455607, acc: 99.84348037838936, p_norm: 2296.2312940152965, g_norm: 0.13277207487541412, lr:  0.000360, elapsed time:  234979
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 480900, loss: 0.004776019873075096, acc: 99.84589100477115, p_norm: 2296.2973305303594, g_norm: 0.14297370637849596, lr:  0.000360, elapsed time:  235028
Step 481000, loss: 0.004441555439907461, acc: 99.85684062540531, p_norm: 2296.366469157222, g_norm: 0.19574412171671937, lr:  0.000360, elapsed time:  235077
Step 481100, loss: 0.004945330040209228, acc: 99.83662830293179, p_norm: 2296.434727726832, g_norm: 0.1389899936288478, lr:  0.000360, elapsed time:  235124
Step 481200, loss: 0.004481344909518157, acc: 99.85181291401386, p_norm: 2296.5065416450966, g_norm: 0.1658845730050685, lr:  0.000360, elapsed time:  235173
Step 481300, loss: 0.004728727811871067, acc: 99.84505020081997, p_norm: 2296.5733535269055, g_norm: 0.12074385494889683, lr:  0.000360, elapsed time:  235221
Step 481400, loss: 0.004694350906283944, acc: 99.84919323027134, p_norm: 2296.6434313393574, g_norm: 0.14232399540898086, lr:  0.000360, elapsed time:  235269
Step 481500, loss: 0.004720166577226337, acc: 99.83979487419128, p_norm: 2296.7244233710344, g_norm: 0.16592345439365389, lr:  0.000360, elapsed time:  235318
Step 481600, loss: 0.004754398872673846, acc: 99.84377521276474, p_norm: 2296.7922216905763, g_norm: 0.21898520210978284, lr:  0.000360, elapsed time:  235366
Step 481700, loss: 0.005084306775902405, acc: 99.83004893362522, p_norm: 2296.8712460190245, g_norm: 0.20355154381203064, lr:  0.000360, elapsed time:  235414
Step 481800, loss: 0.004952324652422248, acc: 99.83715337514877, p_norm: 2296.953707544537, g_norm: 0.16352615444594001, lr:  0.000360, elapsed time:  235461
Step 481900, loss: 0.005153215620803167, acc: 99.82763619720936, p_norm: 2297.0297797130956, g_norm: 0.23491005608729104, lr:  0.000360, elapsed time:  235509
Step 482000, loss: 0.004447067761802827, acc: 99.85574823617935, p_norm: 2297.096262221459, g_norm: 0.13521410772910494, lr:  0.000360, elapsed time:  235557
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 482000, eval loss: 0.025071774715252095, eval acc: 99.57581329345703
Step 482100, loss: 0.004905685794337842, acc: 99.83919216692448, p_norm: 2297.1607785043598, g_norm: 0.19725298090764481, lr:  0.000360, elapsed time:  235612
Step 482200, loss: 0.004806320942152525, acc: 99.84226159751415, p_norm: 2297.2387683273882, g_norm: 0.12163078852955342, lr:  0.000360, elapsed time:  235660
Step 482300, loss: 0.005173968027650062, acc: 99.83200119435787, p_norm: 2297.3182760671107, g_norm: 0.22221535477450285, lr:  0.000360, elapsed time:  235708
Step 482400, loss: 0.005193398305364099, acc: 99.83353090286255, p_norm: 2297.3874922637046, g_norm: 0.2733886990412432, lr:  0.000360, elapsed time:  235755
Step 482500, loss: 0.004787785206508488, acc: 99.8403651714325, p_norm: 2297.463301211769, g_norm: 0.23589464726960727, lr:  0.000360, elapsed time:  235803
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 482600, loss: 0.004728514797444172, acc: 99.84468267514156, p_norm: 2297.5294445757086, g_norm: 0.21709424619099063, lr:  0.000360, elapsed time:  235853
Step 482700, loss: 0.0047927919648509485, acc: 99.84303523600101, p_norm: 2297.603166429146, g_norm: 0.20765381321709672, lr:  0.000360, elapsed time:  235902
Step 482800, loss: 0.004700345609944634, acc: 99.84044136106968, p_norm: 2297.669184631868, g_norm: 0.1649008764694861, lr:  0.000360, elapsed time:  235950
Step 482900, loss: 0.004620730346832715, acc: 99.84639991819859, p_norm: 2297.7306231144585, g_norm: 0.18493952557769094, lr:  0.000360, elapsed time:  235997
Step 483000, loss: 0.00489848843623804, acc: 99.84105440974236, p_norm: 2297.802412927249, g_norm: 0.2330963591084743, lr:  0.000360, elapsed time:  236044
Step 483100, loss: 0.0049026055689955685, acc: 99.84085637331009, p_norm: 2297.882919402113, g_norm: 0.15863627983132456, lr:  0.000360, elapsed time:  236092
Step 483200, loss: 0.004514567143260138, acc: 99.84988182783127, p_norm: 2297.9560431327777, g_norm: 0.14303946867599315, lr:  0.000360, elapsed time:  236140
Step 483300, loss: 0.00490153546636975, acc: 99.84286300837994, p_norm: 2298.0286347640367, g_norm: 0.12988531814509383, lr:  0.000360, elapsed time:  236188
Step 483400, loss: 0.004982664452118115, acc: 99.83527982234955, p_norm: 2298.1097000288078, g_norm: 0.20640449137318448, lr:  0.000359, elapsed time:  236236
Step 483500, loss: 0.005113164380854868, acc: 99.83232653141022, p_norm: 2298.186512725248, g_norm: 0.14792056346456744, lr:  0.000359, elapsed time:  236289
Step 483600, loss: 0.004845971074560112, acc: 99.83731599152088, p_norm: 2298.2566831905665, g_norm: 0.16125512875722522, lr:  0.000359, elapsed time:  236341
Step 483700, loss: 0.00490000538406548, acc: 99.84094095230103, p_norm: 2298.32535333604, g_norm: 0.21932960937819326, lr:  0.000359, elapsed time:  236389
Step 483800, loss: 0.004976359115726154, acc: 99.83431468904018, p_norm: 2298.402171317206, g_norm: 0.15493001741249332, lr:  0.000359, elapsed time:  236437
Step 483900, loss: 0.0050199185357450915, acc: 99.83010704815388, p_norm: 2298.476690130259, g_norm: 0.13262729702516562, lr:  0.000359, elapsed time:  236485
Step 484000, loss: 0.004838844757200604, acc: 99.84448237717152, p_norm: 2298.5462899263052, g_norm: 0.17609214015104546, lr:  0.000359, elapsed time:  236533
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 484000, eval loss: 0.023258964221458883, eval acc: 99.59783172607422
Step 484100, loss: 0.004721659920860475, acc: 99.84428986907005, p_norm: 2298.616721443674, g_norm: 0.2643250735171608, lr:  0.000359, elapsed time:  236588
Step 484200, loss: 0.004812306003204867, acc: 99.84088070690632, p_norm: 2298.6870909636327, g_norm: 0.13452314018474323, lr:  0.000359, elapsed time:  236637
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 484300, loss: 0.004840834751464328, acc: 99.84007396414026, p_norm: 2298.7571415112516, g_norm: 0.17863170754646487, lr:  0.000359, elapsed time:  236686
Step 484400, loss: 0.004712879203561897, acc: 99.84947094321251, p_norm: 2298.827480062268, g_norm: 0.17382309084552977, lr:  0.000359, elapsed time:  236734
Step 484500, loss: 0.004633702086712219, acc: 99.84410358965397, p_norm: 2298.89803101949, g_norm: 0.14115313237655702, lr:  0.000359, elapsed time:  236782
Step 484600, loss: 0.004948792236118607, acc: 99.84031890332699, p_norm: 2298.9668018700827, g_norm: 0.20964015820298756, lr:  0.000359, elapsed time:  236830
Step 484700, loss: 0.004713278219323911, acc: 99.84189359843731, p_norm: 2299.03652124984, g_norm: 0.19992222391988604, lr:  0.000359, elapsed time:  236878
Step 484800, loss: 0.00499729838136318, acc: 99.83683410286903, p_norm: 2299.1118429666985, g_norm: 0.19265877219345018, lr:  0.000359, elapsed time:  236927
Step 484900, loss: 0.0047319293589680456, acc: 99.84522515535355, p_norm: 2299.1843252900203, g_norm: 0.23044921927725243, lr:  0.000359, elapsed time:  236976
Step 485000, loss: 0.004760793568721056, acc: 99.84706228971481, p_norm: 2299.252439832208, g_norm: 0.13490195757564796, lr:  0.000359, elapsed time:  237024
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: C C ( C ) C C ( O C ( = O ) N C c 1 c c c c c 1 ) C ( = O ) N C 1 ( C # N ) C C N ( C c 2 c c c c c 2 ) C 1 _EOS
Predicted text: C C ( C ) C C ( O C ( = O ) N C c 1 c c c c c 1 ) C ( = O ) N C 1 ( C # N ) C C N ( C c 2 c c c c c 2 ) C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) O C C ( = O ) N ( C C ( = O ) O ) C 1 c 2 c c c c c 2 C C 1 N C ( = O ) c 1 c c 2 s c ( Cl ) c ( Cl ) c 2 [nH] 1 _EOS
Predicted text: C C ( = O ) O C C ( = O ) N ( C C ( = O ) O ) C 1 c 2 c c c c c 2 C C 1 N C ( = O ) c 1 c c 2 s c ( Cl ) c ( Cl ) c 2 [nH] 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c ( - n 2 c n c 3 c c ( - c 4 c c c ( Cl ) c c 4 ) s c 3 c 2 = O ) c c c 1 O C C ( = O ) N 1 C C C C C 1 _EOS
Predicted text: C O c 1 c c ( - n 2 c n c 3 c c ( - c 4 c c c ( Cl ) c c 4 ) s c 3 c 2 = O ) c c c 1 O C C ( = O ) N 1 C C C C C 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O C ( = O ) c 1 c c c 2 c ( c 1 ) N ( C C ( = O ) O ) C ( = O ) C ( C C C c 1 c c c ( O C ) c c 1 ) S 2 _EOS
Predicted text: C C O C ( = O ) c 1 c c c 2 c ( c 1 ) N ( C C ( = O ) O ) C ( = O ) C ( C C C c 1 c c c ( O C ) c c 1 ) S 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C 1 ( C ) S C 2 C ( N C ( = O ) C N C ( = O ) N C ( = N ) C c 3 c c c ( Cl ) c c 3 ) C ( = O ) N 2 C 1 c 1 n n n [nH] 1 _EOS
Predicted text: C C 1 ( C ) S C 2 C ( N C ( = O ) C N C ( = O ) N C ( = N ) C c 3 c c c ( Cl ) c c 3 ) C ( = O ) N 2 C 1 c 1 n n n [nH] 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 485000, eval acc (token): 0.9443611421230733, eval acc (sequence): 0.8981013760668873
Saving at step 485000
Step 485100, loss: 0.004955259077139545, acc: 99.84314399957657, p_norm: 2299.3293160824433, g_norm: 0.2220676257900288, lr:  0.000359, elapsed time:  237127
Step 485200, loss: 0.004941888052653667, acc: 99.83635579049587, p_norm: 2299.399327505555, g_norm: 0.25889631914484984, lr:  0.000359, elapsed time:  237174
Step 485300, loss: 0.004313360099067722, acc: 99.85593159496784, p_norm: 2299.4694922411572, g_norm: 0.3482461556639877, lr:  0.000359, elapsed time:  237221
Step 485400, loss: 0.004586550239318967, acc: 99.85035610198975, p_norm: 2299.537304254551, g_norm: 0.17015593423752276, lr:  0.000359, elapsed time:  237268
Step 485500, loss: 0.0048816650330081755, acc: 99.84043787419796, p_norm: 2299.604238948143, g_norm: 0.5069087094582749, lr:  0.000359, elapsed time:  237314
Step 485600, loss: 0.004745139248739178, acc: 99.84692914783955, p_norm: 2299.6727235253375, g_norm: 0.1159039607956378, lr:  0.000359, elapsed time:  237360
Step 485700, loss: 0.005001185315238672, acc: 99.83693538606167, p_norm: 2299.7532285928382, g_norm: 0.15928280448151758, lr:  0.000359, elapsed time:  237407
Step 485800, loss: 0.004760782955827381, acc: 99.84384551644325, p_norm: 2299.8274785176864, g_norm: 0.1711961806995319, lr:  0.000359, elapsed time:  237453
Step 485900, loss: 0.005119003855097617, acc: 99.82769684493542, p_norm: 2299.901139508087, g_norm: 0.23849130031584606, lr:  0.000359, elapsed time:  237499
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 486000, loss: 0.004361179985565153, acc: 99.85680796076583, p_norm: 2299.964046878604, g_norm: 0.15117587456855888, lr:  0.000359, elapsed time:  237547
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 486000, eval loss: 0.022653549094595767, eval acc: 99.60812377929688
Step 486100, loss: 0.004656151687049715, acc: 99.84743727743626, p_norm: 2300.031836167695, g_norm: 0.14496046750715014, lr:  0.000358, elapsed time:  237600
Step 486200, loss: 0.004762429522625098, acc: 99.84430854022503, p_norm: 2300.102910774773, g_norm: 0.20369916996427906, lr:  0.000358, elapsed time:  237646
Step 486300, loss: 0.004532203446008225, acc: 99.84813812375069, p_norm: 2300.169230892718, g_norm: 0.13915317407663527, lr:  0.000358, elapsed time:  237693
Step 486400, loss: 0.004599451736885385, acc: 99.84734931588173, p_norm: 2300.240417390254, g_norm: 0.3374266675591731, lr:  0.000358, elapsed time:  237739
Step 486500, loss: 0.004825323637234646, acc: 99.83748792111874, p_norm: 2300.315351483712, g_norm: 0.2648471812315867, lr:  0.000358, elapsed time:  237785
Step 486600, loss: 0.004738111959723028, acc: 99.84593831002712, p_norm: 2300.387630080689, g_norm: 0.18480066778107748, lr:  0.000358, elapsed time:  237831
Step 486700, loss: 0.0044884858722844005, acc: 99.85153180360794, p_norm: 2300.4601724624285, g_norm: 0.09418789816003159, lr:  0.000358, elapsed time:  237878
Step 486800, loss: 0.004769299705685626, acc: 99.84442093968391, p_norm: 2300.532666386123, g_norm: 0.17383501481451186, lr:  0.000358, elapsed time:  237924
Step 486900, loss: 0.005090605412497098, acc: 99.82764253020287, p_norm: 2300.609396185599, g_norm: 0.18868302974360435, lr:  0.000358, elapsed time:  237970
Step 487000, loss: 0.005080830689855702, acc: 99.82775065302849, p_norm: 2300.695323897744, g_norm: 0.22743520204877254, lr:  0.000358, elapsed time:  238016
Step 487100, loss: 0.004971969028124476, acc: 99.83648456633091, p_norm: 2300.7650576824444, g_norm: 0.20116538094138028, lr:  0.000358, elapsed time:  238062
Step 487200, loss: 0.00500618823763034, acc: 99.83847533166409, p_norm: 2300.8273990074345, g_norm: 0.12136591872363431, lr:  0.000358, elapsed time:  238109
Step 487300, loss: 0.0051065945605296295, acc: 99.83397698402405, p_norm: 2300.9099110495044, g_norm: 0.20214715148516715, lr:  0.000358, elapsed time:  238155
Step 487400, loss: 0.004743745185373882, acc: 99.845026537776, p_norm: 2300.977789864491, g_norm: 0.22837179007970587, lr:  0.000358, elapsed time:  238202
Step 487500, loss: 0.0048951762450087696, acc: 99.84138908982277, p_norm: 2301.052565323227, g_norm: 0.2348284697554333, lr:  0.000358, elapsed time:  238249
Step 487600, loss: 0.004680060021346435, acc: 99.84642368555069, p_norm: 2301.123266984006, g_norm: 0.21140550719412637, lr:  0.000358, elapsed time:  238295
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 487700, loss: 0.004918594477158305, acc: 99.83653201358786, p_norm: 2301.1979454129096, g_norm: 0.15121905099397298, lr:  0.000358, elapsed time:  238342
Step 487800, loss: 0.004662019597972176, acc: 99.8429496884346, p_norm: 2301.26080078428, g_norm: 0.18667005671256354, lr:  0.000358, elapsed time:  238389
Step 487900, loss: 0.004374664996121282, acc: 99.85398606956005, p_norm: 2301.322524920692, g_norm: 0.15437577638341007, lr:  0.000358, elapsed time:  238439
Step 488000, loss: 0.004334121068486638, acc: 99.85834807157516, p_norm: 2301.3935731274655, g_norm: 0.20397207648162785, lr:  0.000358, elapsed time:  238488
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Evaluation (with teacher) at step 488000, eval loss: 0.020995515000486187, eval acc: 99.65231323242188
Step 488100, loss: 0.0048914950733160364, acc: 99.83824230730534, p_norm: 2301.479109988425, g_norm: 0.3799293554686955, lr:  0.000358, elapsed time:  238542
Step 488200, loss: 0.004832018475740369, acc: 99.8413107842207, p_norm: 2301.554852991067, g_norm: 0.192682138041219, lr:  0.000358, elapsed time:  238590
Step 488300, loss: 0.004998190477172102, acc: 99.83806106448174, p_norm: 2301.6268251658944, g_norm: 0.16751331511147147, lr:  0.000358, elapsed time:  238637
Step 488400, loss: 0.0047185205517143915, acc: 99.84744642674923, p_norm: 2301.704588144672, g_norm: 0.14949403017622578, lr:  0.000358, elapsed time:  238685
Step 488500, loss: 0.005201468406048662, acc: 99.8277091383934, p_norm: 2301.772223252457, g_norm: 0.19017283854832862, lr:  0.000358, elapsed time:  238732
Step 488600, loss: 0.004578933698012406, acc: 99.84714439511299, p_norm: 2301.834035575605, g_norm: 0.19926509124309588, lr:  0.000358, elapsed time:  238780
Step 488700, loss: 0.004799727468653145, acc: 99.841049015522, p_norm: 2301.9036835493494, g_norm: 0.21990470880481655, lr:  0.000358, elapsed time:  238827
Step 488800, loss: 0.004919630093891101, acc: 99.83796660602093, p_norm: 2301.9716248805757, g_norm: 0.205884100221943, lr:  0.000357, elapsed time:  238874
Step 488900, loss: 0.0048652525611032615, acc: 99.84203884005547, p_norm: 2302.053190394959, g_norm: 0.12691232325110338, lr:  0.000357, elapsed time:  238922
Step 489000, loss: 0.004824382800015883, acc: 99.84139414131641, p_norm: 2302.121093522067, g_norm: 0.2428524134798907, lr:  0.000357, elapsed time:  238971
Step 489100, loss: 0.004698023145710977, acc: 99.84549409151077, p_norm: 2302.1935053502293, g_norm: 0.19219002166957183, lr:  0.000357, elapsed time:  239018
Step 489200, loss: 0.004567661271676115, acc: 99.84473007917404, p_norm: 2302.2676253536097, g_norm: 0.13796726102558152, lr:  0.000357, elapsed time:  239064
Step 489300, loss: 0.004828284354389325, acc: 99.83906549215317, p_norm: 2302.3423149315836, g_norm: 0.13021802498924662, lr:  0.000357, elapsed time:  239110
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 489400, loss: 0.004345437347866431, acc: 99.8565927518541, p_norm: 2302.407268087004, g_norm: 0.2872389316857655, lr:  0.000357, elapsed time:  239158
Step 489500, loss: 0.004618737600601434, acc: 99.84889176487923, p_norm: 2302.4663512314246, g_norm: 0.1529319766763671, lr:  0.000357, elapsed time:  239204
Step 489600, loss: 0.004599412234542796, acc: 99.84373527765274, p_norm: 2302.537821665967, g_norm: 0.1344476944331617, lr:  0.000357, elapsed time:  239250
Step 489700, loss: 0.004228488909238877, acc: 99.86203722655773, p_norm: 2302.60488809458, g_norm: 0.18661776038806754, lr:  0.000357, elapsed time:  239297
Step 489800, loss: 0.004895769151460172, acc: 99.83607284724712, p_norm: 2302.6773977551593, g_norm: 0.20565390636643266, lr:  0.000357, elapsed time:  239343
Step 489900, loss: 0.004604434860170841, acc: 99.84893369674683, p_norm: 2302.7451203012865, g_norm: 0.1314146951501661, lr:  0.000357, elapsed time:  239390
Step 490000, loss: 0.004695822919229613, acc: 99.8429596722126, p_norm: 2302.817602911404, g_norm: 0.20919528176216043, lr:  0.000357, elapsed time:  239437
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 490000, eval loss: 0.019886694912952405, eval acc: 99.64611053466797
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C O C ( = O ) c 1 c c ( Cl ) c ( C ( = O ) O ) c c 1 Br _EOS
Predicted text: C c 1 c c ( Br ) c ( C ( = O ) O ) c c 1 Cl _EOS _PAD _PAD _PAD _PAD _PAD _PAD
acc_token: 0.07142857142857142, acc_seq: False

Target text: C c 1 c c ( C ( = O ) N C 2 C C N ( C ) C C 2 ) c c c 1 N c 1 n c c 2 c ( n 1 ) N ( C 1 C C C C 1 ) C C 1 ( C C 1 ) C ( = O ) N 2 C _EOS
Predicted text: C c 1 c c ( C ( = O ) N C 2 C C N ( C ) C C 2 ) c c c 1 N c 1 n c c 2 c ( n 1 ) N ( C 1 C C C C 1 ) C C 1 ( C C 1 ) C ( = O ) N 2 C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) C C C C ( C ) C 1 C C C 2 ( C # N ) C 3 = C ( C C C 1 2 C ) C 1 ( C ) C C C ( O ) C ( C ) ( C ) C 1 C C 3 _EOS
Predicted text: C C ( C ) C C C C ( C ) C 1 C C C 2 ( C # N ) C 3 = C ( C C C 1 2 C ) C 1 ( C ) C C C ( O ) C ( C ) ( C ) C 1 C C 3 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C O P ( = O ) ( C = C 1 N C C N ( C ) c 2 c c ( - c 3 c c s c 3 ) c c c 2 1 ) O C C _EOS
Predicted text: C C O P ( = O ) ( C = C 1 N C C N ( C ) c 2 c c ( - c 3 c c s c 3 ) c c c 2 1 ) O C C _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( C ) ( O c 1 c c c ( S ( C ) ( = O ) = O ) c n 1 ) C ( = O ) O _EOS
Predicted text: C C ( C ) ( O c 1 c c c ( S ( C ) ( = O ) = O ) c n 1 ) C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 490000, eval acc (token): 0.94070663901692, eval acc (sequence): 0.8919763806877388
Saving at step 490000
Step 490100, loss: 0.0045930778854290115, acc: 99.84491348266602, p_norm: 2302.879691750286, g_norm: 0.26619145770940694, lr:  0.000357, elapsed time:  239552
Step 490200, loss: 0.004955089968061657, acc: 99.8364689052105, p_norm: 2302.9547151646098, g_norm: 0.1610104365921967, lr:  0.000357, elapsed time:  239599
Step 490300, loss: 0.004837697126677085, acc: 99.84104423224926, p_norm: 2303.0294842853345, g_norm: 0.15812391221778824, lr:  0.000357, elapsed time:  239647
Step 490400, loss: 0.004786204482747962, acc: 99.83799989521503, p_norm: 2303.0939708650058, g_norm: 0.20903379811458034, lr:  0.000357, elapsed time:  239694
Step 490500, loss: 0.005013686572601728, acc: 99.8366181999445, p_norm: 2303.164745240612, g_norm: 0.19157530758985436, lr:  0.000357, elapsed time:  239741
Step 490600, loss: 0.004803512493126618, acc: 99.83964912593365, p_norm: 2303.235530282487, g_norm: 0.1544306745137131, lr:  0.000357, elapsed time:  239789
Step 490700, loss: 0.004955707524004538, acc: 99.83975704014301, p_norm: 2303.313578880495, g_norm: 0.14622236907162176, lr:  0.000357, elapsed time:  239837
Step 490800, loss: 0.004842258813332592, acc: 99.84187775850296, p_norm: 2303.386349619374, g_norm: 0.2090311495059039, lr:  0.000357, elapsed time:  239884
Step 490900, loss: 0.004776805376982338, acc: 99.84215712547302, p_norm: 2303.4551164150134, g_norm: 0.18805693427466122, lr:  0.000357, elapsed time:  239932
Step 491000, loss: 0.0047929982925643344, acc: 99.84096340835094, p_norm: 2303.5266721199623, g_norm: 0.30017919818751926, lr:  0.000357, elapsed time:  239979
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 491100, loss: 0.0048183673775485355, acc: 99.84358503268315, p_norm: 2303.5940450253934, g_norm: 0.16060301671550145, lr:  0.000357, elapsed time:  240028
Step 491200, loss: 0.004533413340027437, acc: 99.84492464363575, p_norm: 2303.6613298242182, g_norm: 0.09795850842010397, lr:  0.000357, elapsed time:  240076
Step 491300, loss: 0.004490748309199262, acc: 99.85377226769924, p_norm: 2303.738363980808, g_norm: 0.1286081718411559, lr:  0.000357, elapsed time:  240124
Step 491400, loss: 0.0047717002537638106, acc: 99.84136193990707, p_norm: 2303.8079619632276, g_norm: 0.35539711000197, lr:  0.000357, elapsed time:  240171
Step 491500, loss: 0.0046302658758486355, acc: 99.84545876085758, p_norm: 2303.8788334540204, g_norm: 0.18181133843321026, lr:  0.000356, elapsed time:  240219
Step 491600, loss: 0.004909323245428822, acc: 99.84221279621124, p_norm: 2303.946407898288, g_norm: 0.19033774808616477, lr:  0.000356, elapsed time:  240267
Step 491700, loss: 0.004990227796834006, acc: 99.83170326054096, p_norm: 2304.0195828472533, g_norm: 0.40782047378861364, lr:  0.000356, elapsed time:  240314
Step 491800, loss: 0.004997446720244625, acc: 99.83548879623413, p_norm: 2304.089611172163, g_norm: 0.22898379797158797, lr:  0.000356, elapsed time:  240361
Step 491900, loss: 0.004790599949064927, acc: 99.84242036938667, p_norm: 2304.158395298491, g_norm: 0.1608880269420138, lr:  0.000356, elapsed time:  240408
Step 492000, loss: 0.004346911759485011, acc: 99.85713072121143, p_norm: 2304.2249619981512, g_norm: 0.20586013834330083, lr:  0.000356, elapsed time:  240456
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 492000, eval loss: 0.0211512675751817, eval acc: 99.64095306396484
Step 492100, loss: 0.004882890881208368, acc: 99.8400351703167, p_norm: 2304.302520084582, g_norm: 0.23825768009508788, lr:  0.000356, elapsed time:  240510
Step 492200, loss: 0.004774912813234096, acc: 99.84417919814587, p_norm: 2304.3806640844286, g_norm: 0.30342790063776226, lr:  0.000356, elapsed time:  240558
Step 492300, loss: 0.004705150458130447, acc: 99.84252977371216, p_norm: 2304.4472694040282, g_norm: 0.2373042018904127, lr:  0.000356, elapsed time:  240606
Step 492400, loss: 0.004703012095487793, acc: 99.84553217887878, p_norm: 2304.521518749915, g_norm: 0.22039875082247, lr:  0.000356, elapsed time:  240654
Step 492500, loss: 0.004848121056566015, acc: 99.84349499642849, p_norm: 2304.5975332322646, g_norm: 0.2341061159147143, lr:  0.000356, elapsed time:  240701
Step 492600, loss: 0.004897986101323113, acc: 99.83444373309612, p_norm: 2304.6706044318194, g_norm: 0.20064083916528544, lr:  0.000356, elapsed time:  240749
Step 492700, loss: 0.0048187962588053775, acc: 99.84460277855396, p_norm: 2304.7348543164753, g_norm: 0.17811254150214562, lr:  0.000356, elapsed time:  240796
Calling G2SDataset.batch()
Done, time:  0.65 s, total batches: 6823
Step 492800, loss: 0.004702194645144105, acc: 99.84632061965412, p_norm: 2304.805183311026, g_norm: 0.13462759854384476, lr:  0.000356, elapsed time:  240845
Step 492900, loss: 0.004410289880911478, acc: 99.85507573187351, p_norm: 2304.8821147381386, g_norm: 0.1730000026945244, lr:  0.000356, elapsed time:  240892
Step 493000, loss: 0.005018985391564002, acc: 99.83322916924953, p_norm: 2304.9612849312966, g_norm: 0.1932715920814956, lr:  0.000356, elapsed time:  240940
Step 493100, loss: 0.004748381811950821, acc: 99.84692297875881, p_norm: 2305.031270659845, g_norm: 0.30333762149114624, lr:  0.000356, elapsed time:  240988
Step 493200, loss: 0.00457477426090918, acc: 99.84660723805428, p_norm: 2305.1005243976297, g_norm: 0.12436463656802177, lr:  0.000356, elapsed time:  241036
Step 493300, loss: 0.004849631936558581, acc: 99.84344194829464, p_norm: 2305.1771483753964, g_norm: 0.10909372570901713, lr:  0.000356, elapsed time:  241082
Step 493400, loss: 0.004801902974531913, acc: 99.84006041288376, p_norm: 2305.241456416506, g_norm: 0.20627170895504934, lr:  0.000356, elapsed time:  241128
Step 493500, loss: 0.004734891444968525, acc: 99.84374658763409, p_norm: 2305.3062387516593, g_norm: 0.2331783874944548, lr:  0.000356, elapsed time:  241175
Step 493600, loss: 0.004871295595939955, acc: 99.84023551642895, p_norm: 2305.3782619675835, g_norm: 0.1519734519760736, lr:  0.000356, elapsed time:  241220
Step 493700, loss: 0.004616750050072369, acc: 99.84685653448105, p_norm: 2305.4492526905096, g_norm: 0.17870592139471295, lr:  0.000356, elapsed time:  241267
Step 493800, loss: 0.004845374872606953, acc: 99.83806157112122, p_norm: 2305.514878470633, g_norm: 0.13139309940694913, lr:  0.000356, elapsed time:  241313
Step 493900, loss: 0.004588522893457138, acc: 99.85112807154655, p_norm: 2305.576267275937, g_norm: 0.3372691047702902, lr:  0.000356, elapsed time:  241359
Step 494000, loss: 0.004950817660121629, acc: 99.8337594717741, p_norm: 2305.6568733696304, g_norm: 0.127348043987472, lr:  0.000356, elapsed time:  241406
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 494000, eval loss: 0.024067626545147512, eval acc: 99.58992004394531
Step 494100, loss: 0.0045668059978561356, acc: 99.84768390655518, p_norm: 2305.7223449557223, g_norm: 0.15898095462030543, lr:  0.000356, elapsed time:  241459
Step 494200, loss: 0.0051043027592368164, acc: 99.82754482328892, p_norm: 2305.794675804734, g_norm: 0.12316636519254621, lr:  0.000356, elapsed time:  241505
Step 494300, loss: 0.004650465158624684, acc: 99.84638492763042, p_norm: 2305.867890987925, g_norm: 0.11202767311106297, lr:  0.000355, elapsed time:  241552
Step 494400, loss: 0.004908413516996006, acc: 99.8367659598589, p_norm: 2305.9409522674073, g_norm: 0.21599432531928003, lr:  0.000355, elapsed time:  241598
Calling G2SDataset.batch()
Done, time:  0.63 s, total batches: 6822
Step 494500, loss: 0.004569276312702158, acc: 99.84914763985438, p_norm: 2306.0096967666504, g_norm: 0.1808396772549894, lr:  0.000355, elapsed time:  241646
Step 494600, loss: 0.004409861052372435, acc: 99.8562522828579, p_norm: 2306.075577283423, g_norm: 0.23227835910366387, lr:  0.000355, elapsed time:  241692
Step 494700, loss: 0.004520255681286472, acc: 99.84603191912174, p_norm: 2306.1486836459567, g_norm: 0.14984195421835142, lr:  0.000355, elapsed time:  241739
Step 494800, loss: 0.0046918473818095665, acc: 99.84889666736126, p_norm: 2306.226754129253, g_norm: 0.15912763447721712, lr:  0.000355, elapsed time:  241785
Step 494900, loss: 0.004597928493158179, acc: 99.85265791416168, p_norm: 2306.2929703861632, g_norm: 0.19469739096404604, lr:  0.000355, elapsed time:  241831
Step 495000, loss: 0.004703592655569082, acc: 99.84775744378567, p_norm: 2306.364133576728, g_norm: 0.14605024273223796, lr:  0.000355, elapsed time:  241878
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Target text: N # C c 1 c c c ( N C ( = O ) c 2 c c c ( C = O ) c c 2 ) c c 1 _EOS
Predicted text: N # C c 1 c c c ( N C ( = O ) c 2 c c c ( C = O ) c c 2 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: O = C ( N c 1 n n n [nH] 1 ) c 1 c n c 2 s c 3 c c c ( [N+] ( = O ) [O-] ) c c 3 n 2 c 1 = O _EOS
Predicted text: O = C ( N c 1 n n n [nH] 1 ) c 1 c n c 2 s c 3 c c c ( [N+] ( = O ) [O-] ) c c 3 n 2 c 1 = O _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) [NH+] ( [O-] ) C C 1 C N ( c 2 c c c ( N 3 C C N ( C ( = O ) C O ) C C 3 ) c ( F ) c 2 ) C ( = O ) O 1 _EOS
Predicted text: C C ( = O ) [NH+] ( [O-] ) C C 1 C N ( c 2 c c c ( N 3 C C N ( C ( = O ) C O ) C C 3 ) c ( F ) c 2 ) C ( = O ) O 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C 1 ( C C N C C c 2 c c c c c 2 ) C ( = O ) C C c 2 c c c ( O C ) c c 2 1 . O = C ( O ) C ( = O ) O _EOS
Predicted text: C C C 1 ( C C N C C c 2 c c c c c 2 ) C ( = O ) C C c 2 c c c ( O C ) c c 2 1 . O = C ( O ) C ( = O ) O _EOS
acc_token: 1.0, acc_seq: True

Target text: C c 1 c ( C # C C O C ( = O ) N ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c c c c 1 O C C ( = O ) O C ( C ) ( C ) C _EOS
Predicted text: C c 1 c ( C # C C O C ( = O ) N ( c 2 c c c c c 2 ) c 2 c c c c c 2 ) c c c c 1 O C C ( = O ) O C ( C ) ( C ) C _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 495000, eval acc (token): 0.9450852383176394, eval acc (sequence): 0.8976960110041265
Saving at step 495000
Step 495100, loss: 0.004924524340685821, acc: 99.83979637920856, p_norm: 2306.440550118278, g_norm: 0.2603294581090448, lr:  0.000355, elapsed time:  241973
Step 495200, loss: 0.004540120618466972, acc: 99.84624493122101, p_norm: 2306.5015764410414, g_norm: 0.07932157062883649, lr:  0.000355, elapsed time:  242019
Step 495300, loss: 0.00456974764100778, acc: 99.84660896658897, p_norm: 2306.5717370045436, g_norm: 0.2412319361323072, lr:  0.000355, elapsed time:  242065
Step 495400, loss: 0.0046719997129685, acc: 99.84204146265984, p_norm: 2306.6395235559844, g_norm: 0.20830354966285447, lr:  0.000355, elapsed time:  242112
Step 495500, loss: 0.0047570926799835435, acc: 99.83939623832703, p_norm: 2306.707534952488, g_norm: 0.19462176246650095, lr:  0.000355, elapsed time:  242158
Step 495600, loss: 0.004592846714107281, acc: 99.85174755752087, p_norm: 2306.7817047645676, g_norm: 0.23108863188066883, lr:  0.000355, elapsed time:  242204
Step 495700, loss: 0.004746485764303543, acc: 99.84095659852028, p_norm: 2306.8594931359053, g_norm: 0.1273932504128352, lr:  0.000355, elapsed time:  242251
Step 495800, loss: 0.004457819989029304, acc: 99.8503646850586, p_norm: 2306.929118026592, g_norm: 0.2794944565243101, lr:  0.000355, elapsed time:  242298
Step 495900, loss: 0.004968043300814315, acc: 99.83642639219761, p_norm: 2307.006533138137, g_norm: 0.18625514491010914, lr:  0.000355, elapsed time:  242344
Step 496000, loss: 0.005048963898734655, acc: 99.83555959165096, p_norm: 2307.083314732647, g_norm: 0.12934134898056768, lr:  0.000355, elapsed time:  242390
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 496000, eval loss: 0.02200141158593396, eval acc: 99.6207275390625
Step 496100, loss: 0.004788712403892532, acc: 99.84104707837105, p_norm: 2307.158049115696, g_norm: 0.09522210061745195, lr:  0.000355, elapsed time:  242444
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 496200, loss: 0.004857499277307791, acc: 99.8400727611276, p_norm: 2307.229081971007, g_norm: 0.1540841210237146, lr:  0.000355, elapsed time:  242491
Step 496300, loss: 0.004438932808561731, acc: 99.85280777513981, p_norm: 2307.295485458355, g_norm: 0.1465288779610748, lr:  0.000355, elapsed time:  242537
Step 496400, loss: 0.0045954999698074065, acc: 99.84536781907082, p_norm: 2307.3630663095955, g_norm: 0.18280823762140772, lr:  0.000355, elapsed time:  242584
Step 496500, loss: 0.004653982967629418, acc: 99.84530486166477, p_norm: 2307.444907318507, g_norm: 0.2582258521655338, lr:  0.000355, elapsed time:  242631
Step 496600, loss: 0.00438384796133505, acc: 99.85271488130093, p_norm: 2307.5101970493943, g_norm: 0.13530487604606467, lr:  0.000355, elapsed time:  242677
Step 496700, loss: 0.004494499849379281, acc: 99.85618023574352, p_norm: 2307.5781957914637, g_norm: 0.07319893407648471, lr:  0.000355, elapsed time:  242724
Step 496800, loss: 0.004699835176816123, acc: 99.84643986821175, p_norm: 2307.6480100166136, g_norm: 0.3923980233841801, lr:  0.000355, elapsed time:  242770
Step 496900, loss: 0.004516611348144579, acc: 99.85466021299362, p_norm: 2307.712919434898, g_norm: 0.1622123657795721, lr:  0.000355, elapsed time:  242817
Step 497000, loss: 0.004941960048927285, acc: 99.83698831498623, p_norm: 2307.7897033824192, g_norm: 0.18281506267219483, lr:  0.000355, elapsed time:  242863
Step 497100, loss: 0.004686976288312507, acc: 99.84359881281853, p_norm: 2307.861309576507, g_norm: 0.17755787797423603, lr:  0.000354, elapsed time:  242909
Step 497200, loss: 0.004885395538276498, acc: 99.84010282158852, p_norm: 2307.935460402301, g_norm: 0.16601773788432125, lr:  0.000354, elapsed time:  242956
Step 497300, loss: 0.00479439415165416, acc: 99.84408132731915, p_norm: 2308.0024043016047, g_norm: 0.1513799086458094, lr:  0.000354, elapsed time:  243002
Step 497400, loss: 0.004635152892683436, acc: 99.84774626791477, p_norm: 2308.081664004457, g_norm: 0.09875687263382861, lr:  0.000354, elapsed time:  243050
Step 497500, loss: 0.0045197628689436446, acc: 99.85391618311405, p_norm: 2308.153891776848, g_norm: 0.15774853938110148, lr:  0.000354, elapsed time:  243097
Step 497600, loss: 0.004968288311483775, acc: 99.83495771884918, p_norm: 2308.2294734230254, g_norm: 0.1850747230132507, lr:  0.000354, elapsed time:  243143
Step 497700, loss: 0.004857949321747128, acc: 99.84129546582699, p_norm: 2308.298714328343, g_norm: 0.14385450137313707, lr:  0.000354, elapsed time:  243190
Step 497800, loss: 0.004958876627656536, acc: 99.83311538398266, p_norm: 2308.3733250776936, g_norm: 0.15067354479555087, lr:  0.000354, elapsed time:  243236
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6823
Step 497900, loss: 0.004772744382711635, acc: 99.84011921420026, p_norm: 2308.434767431715, g_norm: 0.1475001272909266, lr:  0.000354, elapsed time:  243283
Step 498000, loss: 0.004511502309462685, acc: 99.85566169023514, p_norm: 2308.4939601761753, g_norm: 0.18313616653826945, lr:  0.000354, elapsed time:  243329
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 498000, eval loss: 0.024621846307754828, eval acc: 99.5743408203125
Step 498100, loss: 0.004726806854432652, acc: 99.84510712325573, p_norm: 2308.549809826308, g_norm: 0.310918400929524, lr:  0.000354, elapsed time:  243382
Step 498200, loss: 0.004476457071009463, acc: 99.84795551002026, p_norm: 2308.6209186293004, g_norm: 0.20453417914483585, lr:  0.000354, elapsed time:  243429
Step 498300, loss: 0.004517626410706726, acc: 99.85031053423882, p_norm: 2308.6880093985133, g_norm: 0.09109332238252099, lr:  0.000354, elapsed time:  243475
Step 498400, loss: 0.004921614023987786, acc: 99.84115391969681, p_norm: 2308.7583780978675, g_norm: 0.2680596799114551, lr:  0.000354, elapsed time:  243521
Step 498500, loss: 0.004715438102753069, acc: 99.84675081074238, p_norm: 2308.8308725932725, g_norm: 0.15236413309374547, lr:  0.000354, elapsed time:  243567
Step 498600, loss: 0.004574076105700442, acc: 99.84940855205059, p_norm: 2308.9087243829526, g_norm: 0.2105199383779306, lr:  0.000354, elapsed time:  243614
Step 498700, loss: 0.004652756488012528, acc: 99.84836626052856, p_norm: 2308.976881786879, g_norm: 0.17307135299859328, lr:  0.000354, elapsed time:  243661
Step 498800, loss: 0.004766750203077663, acc: 99.84469549357891, p_norm: 2309.0409400691287, g_norm: 0.1468643244858791, lr:  0.000354, elapsed time:  243707
Step 498900, loss: 0.004609691344535349, acc: 99.84878005087376, p_norm: 2309.109730907286, g_norm: 0.1742871690703324, lr:  0.000354, elapsed time:  243753
Step 499000, loss: 0.004721135865506767, acc: 99.84128116071224, p_norm: 2309.1839275166394, g_norm: 0.17057456377834038, lr:  0.000354, elapsed time:  243800
Step 499100, loss: 0.004663352018715159, acc: 99.84335678815842, p_norm: 2309.260030902822, g_norm: 0.16199251422935101, lr:  0.000354, elapsed time:  243846
Step 499200, loss: 0.004960425189919988, acc: 99.8356515020132, p_norm: 2309.337947310392, g_norm: 0.13471966598333335, lr:  0.000354, elapsed time:  243892
Step 499300, loss: 0.004946363510043739, acc: 99.83676488697529, p_norm: 2309.4142144650646, g_norm: 0.18224366038967452, lr:  0.000354, elapsed time:  243939
Step 499400, loss: 0.004915646574663697, acc: 99.83332967758179, p_norm: 2309.491542068268, g_norm: 0.3114957099677162, lr:  0.000354, elapsed time:  243985
Step 499500, loss: 0.0047905600410376795, acc: 99.84308956563473, p_norm: 2309.5601291857715, g_norm: 0.17554703303294192, lr:  0.000354, elapsed time:  244031
Calling G2SDataset.batch()
Done, time:  0.64 s, total batches: 6822
Step 499600, loss: 0.004534194659513097, acc: 99.85021367558178, p_norm: 2309.631313498865, g_norm: 0.14116441573459101, lr:  0.000354, elapsed time:  244079
Step 499700, loss: 0.004431871462802519, acc: 99.8584321141243, p_norm: 2309.688584076233, g_norm: 0.13152630948058622, lr:  0.000354, elapsed time:  244126
Step 499800, loss: 0.0047501990275713975, acc: 99.84382978081703, p_norm: 2309.768254942588, g_norm: 0.169861549802991, lr:  0.000354, elapsed time:  244172
Step 499900, loss: 0.004509204707092067, acc: 99.85454504191875, p_norm: 2309.8346347719703, g_norm: 0.16809722761533613, lr:  0.000353, elapsed time:  244218
Step 500000, loss: 0.004853240134675616, acc: 99.83897262811661, p_norm: 2309.9050182468645, g_norm: 0.2031950995640287, lr:  0.000353, elapsed time:  244264
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 526
Evaluation (with teacher) at step 500000, eval loss: 0.020708111001449658, eval acc: 99.65251159667969
Calling G2SDataset.batch()
Done, time:  0.07 s, total batches: 527
Target text: C C O c 1 n c ( N 2 C C N C C 2 ) n c 2 c 1 s c 1 n c ( - c 3 c c c ( O C ) c ( O C ) c 3 ) c c ( C ) c 1 2 _EOS
Predicted text: C C O c 1 n c ( N 2 C C N C C 2 ) n c 2 c 1 s c 1 n c ( - c 3 c c c ( O C ) c ( O C ) c 3 ) c c ( C ) c 1 2 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C ( = O ) C ( C c 1 c c c ( Cl ) c c 1 ) c 1 c c ( Cl ) c c ( Br ) c 1 _EOS
Predicted text: C C ( = O ) C ( C c 1 c c c ( Cl ) c c 1 ) c 1 c c ( Cl ) c c ( Br ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C C C C O C C O c 1 c c c ( - c 2 c c c 3 c ( c 2 ) C = C ( C ( = O ) N c 2 c c c ( C N ( C ) C 4 C C O C C 4 ) c c 2 ) C C C O 3 ) c c 1 _EOS
Predicted text: C C C C O C C O c 1 c c c ( - c 2 c c c 3 c ( c 2 ) C = C ( C ( = O ) N c 2 c c c ( C N ( C ) C 4 C C O C C 4 ) c c 2 ) C C C O 3 ) c c 1 _EOS
acc_token: 1.0, acc_seq: True

Target text: C N ( c 1 c c c ( F ) c c 1 ) C ( C ( = O ) O C 1 C [N+] 2 ( C C ( = O ) c 3 c c c s 3 ) C C C 1 C C 2 ) c 1 c c c c c 1 . [Cl-] _EOS
Predicted text: C N ( c 1 c c c ( F ) c c 1 ) C ( C ( = O ) O C 1 C [N+] 2 ( C C ( = O ) c 3 c c c s 3 ) C C C 1 C C 2 ) c 1 c c c c c 1 . [Cl-] _EOS
acc_token: 1.0, acc_seq: True

Target text: C O c 1 c c c ( C ) [n+] ( [O-] ) c 1 _EOS
Predicted text: C O c 1 c c c ( C ) [n+] ( [O-] ) c 1 _EOS
acc_token: 1.0, acc_seq: True

Evaluation (without teacher) at step 500000, eval acc (token): 0.9429159991883731, eval acc (sequence): 0.8968626036783267
Saving at step 500000
Max steps reached, finish training
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [230], which does not match the required output shape [46, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [325], which does not match the required output shape [65, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [305], which does not match the required output shape [61, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [550], which does not match the required output shape [110, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [345], which does not match the required output shape [69, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [85], which does not match the required output shape [17, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [485], which does not match the required output shape [97, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [265], which does not match the required output shape [53, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [215], which does not match the required output shape [43, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [200], which does not match the required output shape [40, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [445], which does not match the required output shape [89, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [365], which does not match the required output shape [73, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [270], which does not match the required output shape [54, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [95], which does not match the required output shape [19, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [145], which does not match the required output shape [29, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [375], which does not match the required output shape [75, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [280], which does not match the required output shape [56, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [18, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [315], which does not match the required output shape [63, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [510], which does not match the required output shape [102, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [80], which does not match the required output shape [16, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [465], which does not match the required output shape [93, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [425], which does not match the required output shape [85, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [250], which does not match the required output shape [50, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [255], which does not match the required output shape [51, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [240], which does not match the required output shape [48, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [600], which does not match the required output shape [120, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [355], which does not match the required output shape [71, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [405], which does not match the required output shape [81, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [180], which does not match the required output shape [36, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [680], which does not match the required output shape [136, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [175], which does not match the required output shape [35, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [290], which does not match the required output shape [58, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [370], which does not match the required output shape [74, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [295], which does not match the required output shape [59, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [390], which does not match the required output shape [78, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [415], which does not match the required output shape [83, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [335], which does not match the required output shape [67, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [310], which does not match the required output shape [62, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [235], which does not match the required output shape [47, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [275], which does not match the required output shape [55, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [26, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [110], which does not match the required output shape [22, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [4, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [24, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [185], which does not match the required output shape [37, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [125], which does not match the required output shape [25, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [155], which does not match the required output shape [31, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [525], which does not match the required output shape [105, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [5, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [220], which does not match the required output shape [44, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [245], which does not match the required output shape [49, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [165], which does not match the required output shape [33, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [21, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [170], which does not match the required output shape [34, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [20, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [2, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [515], which does not match the required output shape [103, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [115], which does not match the required output shape [23, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [13, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [190], which does not match the required output shape [38, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
/new-stg/home/aaron/miniconda/envs/g2s_gpu/lib/python3.8/site-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [11, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/Resize.cpp:26.)
  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)
